[{"content":"This post will guide you in setting up your very own Hugo site with this theme. It covers the essential parts: installation, basic usage and recommended next steps. After setting up the basics, feel free to also take a look at other posts!\nInstallation This guide is a shorter version of Hugo\u0026rsquo;s quick start (you may even say it\u0026rsquo;s a quicker start). If you face any problems or want more comprehensive content, make sure to check it out!\nRequirements A basic understanding of Hugo (aka. read the docs) Hugo CLI installed git installed Setup Locally Create a new Hugo site hugo new site my-blog Change the working dir to the newly created one cd my-blog Install the theme from by cloning the GIT repository git clone https://github.com/math-queiroz/rusty-typewriter themes/rusty-typewriter Create some pages with the desired content hugo new content content/posts/first-post.md Test your site locally hugo server -D Congrats! You just got your site up and running locally. Now get to configure and customize it! Going Public Since after build you get just plain static site files (HTML, CSS and JS), there are plenty of pipelines to deploy, places to host and ways to publish your site. If you\u0026rsquo;re interested in the most common ones for Hugo, you can find them listed and documented in here.\nBasic Usage Now that you have a site, the standard workflow for managing content is simply given by:\nCreate the content page with hugo new content content/posts/post-name.md Edit the created file with the intended content Update the repository and publish the alterations Also, make sure to give the content management docs a read.\nNext Steps At last, if you need directions as to where to go next:\nTweak the hugo.toml config file based on the boilerplate one; Get ricing styling your themed site from with CSS; Make sure to leave a star at the theme repo and support my work if you enjoy it! ","date":"24 March, 2025","id":0,"permalink":"/posts/getting-started/","summary":"This post will guide you in setting up your very own Hugo site with this theme. It covers the essential parts: installation, basic usage and recommended next steps. After setting up the basics, feel free to also take a look at other posts!","tags":"starter guide","title":"Getting Started"},{"content":"This page outlines the configuration options for the theme. There are plenty of settings for tweaking your site\u0026rsquo;s layout and content presentation. Key features include options for controlling the side pane visibility, adjusting the number of items displayed on each list page, and managing elements such as featured posts, recent posts, taxonomies, and related content.\nGlobal Config The following configuration options can be added to your site\u0026rsquo;s Hugo config file.\n[rusty_typewriter] [params.rtwt] sidePane = true countPageItems = 7 [params.rtwt.home] showBio = true showAuthorImg = true sidePaneTags = true showFeatured = true showRecent = true hideRecentWhenFeatured = true countRecent = 5 [params.rtwt.side.home] sidePaneSticky = false taxonomies = [\u0026#39;tags\u0026#39;] countTaxonomy = 5 [params.rtwt.side.list] sidePaneSticky = false [params.rtwt.side.single] sidePaneSticky = true showDetails = true showTableOfContents = true showAttachments = true showRelated = true countRelated = 5 Page Config Some configurations are defined in the page frontmatter, they\u0026rsquo;re as following.\n+++ [rtwt] sidePane = false sidePaneSticky = false +++ ... ","date":"24 March, 2025","id":1,"permalink":"/posts/configuration/","summary":"This page outlines the configuration options for the theme. There are plenty of settings for tweaking your site\u0026rsquo;s layout and content presentation. Key features include options for controlling the side pane visibility, adjusting the number of items displayed on each list page, and managing elements such as featured posts, recent posts, taxonomies, and related content.","tags":"guide","title":"Configuration"},{"content":"Linux设备树中MCP2518FD的时钟配置：从0.00MHz到40.00MHz [!TIP] 午夜码农的咏叹调 啊，键盘上的勇士，夜深人静战bug， 代码如顽敌，纠缠至天明将近。 眼皮如铅重，咖啡已成空杯， 仅剩三时安眠，闹钟已张开巨口。 然此时灵光乍现，博客须发于世！ 笑看睡眠债堆积，技术火炬永不灭。 程序猿啊，程序猿，人生如代码，debug永无止境！\n问题背景 在使用MCP2518FD CAN控制器时，通过dmesg查看驱动初始化日志，发现了一个值得关注的细节：\n[ 3.207754] mcp251xfd spi0.0 can0: MCP2518FD rev15.15 (-RX_INT -PLL -MAB_NO_WARN +CRC_REG +CRC_RX +CRC_TX +ECC -HD o:0.00MHz c:40.00MHz m:0.60MHz rs:0.60MHz es:0.59MHz rf:0.60MHz ef:0.59MHz) successfully initialized. 注意其中的 o:0.00MHz，这表示驱动检测到的外部晶振（Oscillator）频率为0，而实际硬件使用的是40MHz晶振。这种不匹配可能会导致时钟相关的潜在问题。\n时钟参数解读 日志中的时钟相关参数含义如下：\n参数 全称 含义 o: Oscillator 外部晶振频率，驱动识别到的基准时钟源 c: CAN Clock CAN控制器内核实际运行时钟 m: Max SPI SPI总线最大通信频率 rs: Requested Speed 设备树中请求的SPI速率 es: Effective Speed SPI控制器实际输出的有效速率 当 o:0.00MHz 时，说明驱动没有正确识别外部晶振频率。虽然 c:40.00MHz 显示CAN时钟为40MHz,但这可能是驱动使用的默认值或推测值,而非基于正确的晶振配置计算得出。\n为什么会出现o:0.00MHz? 原始设备树配置中使用了 clock-frequency 属性：\n\u0026amp;spi0 { status = \u0026#34;okay\u0026#34;; // ... 其他配置 ... spican0: spican@0 { compatible = \u0026#34;microchip,mcp2518fd\u0026#34;; reg = \u0026lt;0\u0026gt;; spi-max-frequency = \u0026lt;100000\u0026gt;; interrupts-extended = \u0026lt;\u0026amp;porta 10 IRQ_TYPE_LEVEL_LOW 0\u0026gt;; clock-frequency = \u0026lt;40000000\u0026gt;; }; }; 正确的解决方案 Linux设备树推荐使用 fixed-clock 节点来描述固定频率的时钟源：\n// 在根设备树节点 /{ } 中添加 can_osc: can-osc { compatible = \u0026#34;fixed-clock\u0026#34;; #clock-cells = \u0026lt;0\u0026gt;; clock-frequency = \u0026lt;40000000\u0026gt;; }; \u0026amp;spi0 { status = \u0026#34;okay\u0026#34;; clocks = \u0026lt;\u0026amp;scmi_clk GATE_LSP0_SSI_M_WCLK_EN\u0026gt;, \u0026lt;\u0026amp;scmi_clk GATE_LSP0_SSI_M_PCLK_EN\u0026gt;; clock-names = \u0026#34;wclk\u0026#34;, \u0026#34;pclk\u0026#34;; resets = \u0026lt;\u0026amp;scmi_reset RST_LSP0_SSI_M_WCLK_SW\u0026gt;; reset-names = \u0026#34;spi\u0026#34;; pinctrl-names = \u0026#34;default\u0026#34;; pinctrl-0 = \u0026lt;\u0026amp;spi0_pinctrl\u0026gt;; spican0: spican@0 { compatible = \u0026#34;microchip,mcp2518fd\u0026#34;; reg = \u0026lt;0\u0026gt;; spi-max-frequency = \u0026lt;100000\u0026gt;; interrupts-extended = \u0026lt;\u0026amp;porta 10 IRQ_TYPE_LEVEL_LOW 0\u0026gt;; clocks = \u0026lt;\u0026amp;can_osc\u0026gt;; /* 显式引用时钟节点 */ }; }; 关键改进点 创建独立的时钟节点：can_osc 作为一个标准的 fixed-clock 提供者 显式引用时钟：通过 clocks = \u0026lt;\u0026amp;can_osc\u0026gt; 建立明确的时钟消费关系 符合设备树规范：这种方式更容易被[[时钟框架]]（[[CCF]]）正确处理 修改后的效果 重新编译设备树并启动后，dmesg日志应显示：\n[ 3.207754] mcp251xfd spi0.0 can0: MCP2518FD rev15.15 (... o:40.00MHz c:40.00MHz ...) successfully initialized. 此时 o: 参数正确显示为 40.00MHz，表明驱动已正确识别外部晶振频率。\n为什么这很重要？ 虽然在某些场景下，即使 o:0.00MHz 系统也可能表面上正常工作，但正确配置时钟源具有以下重要意义：\n波特率计算准确性：CAN控制器需要基于准确的晶振频率计算位时间参数（Bit Timing） 时钟同步：确保发送和接收逻辑使用相同的时间基准 硬件功能完整性：某些高级功能（如时间戳）依赖准确的时钟源 诊断信息可靠性：准确的时钟信息有助于排查其他问题 总结 在配置MCP2518FD等需要外部晶振的SPI CAN控制器时，应该：\n✅ 使用 fixed-clock 节点定义时钟源 ✅ 通过 clocks 属性显式引用时钟 ✅ 验证dmesg中 o: 参数显示正确频率 ❌ 避免直接使用 clock-frequency 属性 ❌ 避免注释掉关键配置而不替换 这种规范的配置方式不仅能解决当前问题,还能为后续的功能扩展和问题排查打下良好基础。\n","date":"2 February, 2026","id":2,"permalink":"/posts/linux%E8%AE%BE%E5%A4%87%E6%A0%91%E4%B8%ADmcp2518fd%E7%9A%84%E6%97%B6%E9%92%9F%E9%85%8D%E7%BD%AE%E4%BB%8E0.00mhz%E5%88%B040.00mhz/","summary":"在使用MCP2518FD CAN控制器时，通过dmesg查看驱动初始化日志，发现了一个值得关注的细节：","tags":"Linux DeviceTree CAN MCP2518FD","title":"Linux设备树中MCP2518FD的时钟配置：从0.00MHz到40.00MHz"},{"content":"前言 如果你曾经被下面任意一种现象折磨过，就说明你已经被 CMake 缓存机制“咬”过：\n第三方库的某个开关怎么关都关不掉 CI 里加了 -DENABLE_XXX=OFF，本地却还是 ON cmake-gui 里改了某个选项，下次重新 configure 又变回来了 同一个变量名在不同子模块里定义了不同的默认值，最后到底是哪个生效了？ 这篇文章将一次性把 CMake 缓存的完整模型 讲透，读完后你将彻底掌握所有配置交互的底层规则。\n1. CMake 缓存到底是什么？ CMake 缓存 = 构建目录下的 CMakeCache.txt 文件\n它是一个全局、持久化、有类型、有描述、有优先级的键值数据库。\n所有你见过的配置方式，最终都会收敛到这个文件：\n-D 参数 cmake-gui / ccmake CMakePresets.json set(... CACHE ...) option(...) 2. 缓存变量的 6 种类型（TYPE）及其真实表现 TYPE CMakeCache.txt 显示 是否在 GUI 显示 典型用途 BOOL BOOL 是（复选框） 开关（最常用） STRING STRING 是 版本号、模式枚举 PATH PATH 是（带浏览按钮） 目录路径 FILEPATH FILEPATH 是（带浏览按钮） 文件路径 INTERNAL INTERNAL 隐藏 CMake 内部使用，不希望用户看到 UNINITIALIZED （无 TYPE） 是 没写 TYPE 时的默认（不推荐） 推荐：对外暴露的开关一律用 BOOL，路径用 PATH，永远不要偷懒留空。\n3. 缓存变量优先级铁律（从高到低，背下来就无敌了） 1. 命令行 -D 参数（最高优先级） 2. CMakePresets.json / CMakeUserPresets.json 中的 cacheVariables 3. 当前 CMakeCache.txt 中已存在的条目（上一次配置的结果） 4. 项目代码中显式的 set(... CACHE ...)（父项目优先于子项目） 5. 项目代码中第一次出现的 option(...) 的默认值 6. 普通的 set(...)（不进缓存，最低优先级） 只要记住这 6 条，你就能准确预测任何情况下变量的最终值。\n4. option() 的真实实现（源码级拆解） # CMake 内置的 option() 实际上长这样（简化版） if(NOT DEFINED ENABLE_HEAVY_FEATURE) set(ENABLE_HEAVY_FEATURE ON CACHE BOOL \u0026#34;description\u0026#34; FORCE) endif() 结论：一旦变量已经被定义过（无论来自 -D、CACHE、父项目），option() 的默认值就完全失效。\n这正是我们“接管第三方开关”的底层原理。\n5. FORCE 关键字的恐怖威力 set(MY_VAR OFF CACHE BOOL \u0026#34;\u0026#34; FORCE) # 强制覆盖缓存中已有值 加了 FORCE 后，连命令行 -D 都压不住（除非命令行也加 FORCE）。\n企业项目里只在极少数“必须锁死”的地方才用，例如：\nset(CMAKE_POSITION_INDEPENDENT_CODE ON CACHE BOOL \u0026#34;\u0026#34; FORCE) 6. 企业级防御性写法大全（2025 年标配） # cmake/options-thirdparty.cmake # 所有第三方开关统一在这里接管，子模块的 option() 全部失效 set(ENABLE_HEAVY_FEATURE OFF CACHE BOOL \u0026#34;[3rdParty] Heavy legacy mode (+6 min build)\u0026#34;) set(ENABLE_EXPERIMENTAL_DRIVER ON 开启 CACHE BOOL \u0026#34;[3rdParty] Next-gen driver (unstable)\u0026#34;) set(THIRD_PARTY_ROOT \u0026#34;\u0026#34; CACHE PATH \u0026#34;[3rdParty] Root directory of all external libs\u0026#34;) # 顶级 CMakeLists.txt 最前面 include(cmake/options-thirdparty.cmake) 这样做的好处：\n所有开关集中一处管理 GUI 里自动分组显示 CI 可以用 -D 轻松覆盖 杜绝“有人偷偷打开了我不知道的开关” 7. 实战最常见的 5 种控制方式对比 方式 优先级 是否推荐 适用场景 命令行 -DENABLE_XXX=OFF 1 强烈推荐 CI 多配置构建 父项目 set(... CACHE ...) 4 强烈推荐 统一接管第三方默认行为 CMakePresets.json cacheVariables 2 强烈推荐 团队统一配置、IDE 集成 子模块自己的 option() 5 基本没用 只能在完全独立项目时才有效 普通 set(ENABLE_XXX ON)（无 CACHE） 6 禁用 会被 option() 覆盖，极易出错 8. 让 GUI 更好看的终极技巧 set(MYCOMPANY_ENABLE_DEBUG_LOG OFF CACHE BOOL \u0026#34;[MyCompany] Enable verbose debug logging (very noisy)\u0026#34;) set(MYCOMPANY_THIRD_PARTY_ROOT \u0026#34;\u0026#34; CACHE PATH \u0026#34;[MyCompany] Root directory of all third-party libraries\u0026#34;) 在 cmake-gui/ccmake 中会自动按 [方括号] 分组，体验直接起飞。\n9. 总结：一句话彻底掌握 CMake 缓存 谁最后（优先级最高）往 CMakeCache.txt 里写，谁就赢。\n掌握了这套模型，你就拥有了：\n完美接管任何第三方库的开关 让 CI、开发者、GUI、Presets 行为完全一致 再也不用猜“这个变量到底是哪来的” 去把你们项目里那些“永远关不掉的开关”全部用 set(... CACHE ...) 接管了吧！\n","date":"10 December, 2025","id":3,"permalink":"/posts/cmake-%E7%BC%93%E5%AD%98%E6%9C%BA%E5%88%B6%E5%AE%8C%E5%85%A8%E6%8C%87%E5%8D%97%E4%BB%8E%E5%8E%9F%E7%90%86%E5%88%B0%E4%BC%81%E4%B8%9A%E7%BA%A7%E9%98%B2%E5%BE%A1%E6%80%A7%E5%86%99%E6%B3%95/","summary":"彻底搞懂 CMakeCache.txt、-D 参数、option()、set(... CACHE ...)、FORCE、GUI 显示顺序的底层原理，以及大厂真实落地的防御性写法。","tags":"CMake 构建系统 缓存机制 最佳实践 企业级","title":"CMake 缓存机制完全指南：从原理到企业级防御性写法"},{"content":"起因：一个“永远关不掉”的巨型开关 最近在维护一个嵌入式多平台驱动仓库时，发现第三方提供的一个 SDK 子模块 默认打开了一个超级重的功能（编译时间从 9 分钟直接飙到 15 分钟+，产出体积也多出好几 MB）。\n子模块里的写法非常“复古”：\noption(ENABLE_HEAVY_FEATURE \u0026#34;Enable very heavy legacy feature\u0026#34; ON) if(ENABLE_HEAVY_FEATURE) add_definitions(-DHEAVY_FEATURE) # 全局污染 endif() 而我们主项目 95% 的配置压根不需要这个功能，CI 每次都白白浪费大量时间。\n最 Modern、最推荐的接管方式（2025 年写法） 在顶级项目（或统一放第三方开关的文件）里，在 add_subdirectory 之前写一行：\n# 第三方模块统一控制区 set(ENABLE_HEAVY_FEATURE OFF CACHE BOOL \u0026#34;[VendorSDK] Enable heavy legacy feature (significantly increases build time and binary size)\u0026#34;) 然后正常添加子模块：\nadd_subdirectory(external/vendor-sdk-v2.3.0) 效果立竿见影：\n子模块里 option() 的默认值被彻底忽略 CMake GUI / ccmake / 命令行都能看到我们自己的描述 CI 想临时打开时只需要加 -DENABLE_HEAVY_FEATURE=ON 再也没有全局宏污染 为什么必须用 set(\u0026hellip; CACHE \u0026hellip;)？ 写法 是否推荐 后果 父目录再次 option(ENABLE_HEAVY_FEATURE ...) 不推荐 CMake 直接报错 父目录 set(ENABLE_HEAVY_FEATURE ON)（无 CACHE） 勉强可用 普通变量会被子模块的 option() 重新变成缓存变量，行为混乱 父目录 set(... CACHE BOOL ...) 强烈推荐 完全接管默认值、描述、类型，最清晰 只靠命令行 -D 推荐配合使用 最灵活，适合 CI 多配置构建 我们现在的统一写法（企业级项目标配） # cmake/options-thirdparty.cmake set(ENABLE_HEAVY_FEATURE OFF CACHE BOOL \u0026#34;[Vendor] Heavy legacy mode (+6 min build)\u0026#34;) set(ENABLE_EXPERIMENTAL_MODULE ON CACHE BOOL \u0026#34;[Vendor] Next-gen experimental driver\u0026#34;) set(ENABLE_DEBUG_SYMBOLS OFF CACHE BOOL \u0026#34;[Vendor] Keep private debug symbols\u0026#34; OFF) # 所有 add_subdirectory 之前统一 include 一次 include(cmake/options-thirdparty.cmake) 这样整个团队和所有 CI 看到的都是同一份干净的开关列表，再也不可能出现“我以为关了结果其实没关”的情况。\n小结 接管第三方子模块的 option，只需要记住最核心的一句话：\n在 add_subdirectory 之前，用 set(XXX xxx CACHE BOOL \u0026quot;你的描述\u0026quot;) 强行设定即可。\n","date":"10 December, 2025","id":4,"permalink":"/posts/modern-cmake-%E6%9C%80%E4%BD%B3%E5%AE%9E%E8%B7%B5%E5%A6%82%E4%BD%95%E4%BC%98%E9%9B%85%E5%9C%B0%E6%8E%A5%E7%AE%A1%E7%AC%AC%E4%B8%89%E6%96%B9%E5%AD%90%E6%A8%A1%E5%9D%97%E7%9A%84-option-%E5%BC%80%E5%85%B3/","summary":"真实项目中遇到一个典型场景：第三方 SDK 默认打开了一个非常重的功能开关，导致全量构建时间暴涨 70%。记录一下用最 Modern 的方式彻底接管它的全过程。","tags":"CMake 第三方模块管理 构建优化 CI加速","title":"Modern CMake 最佳实践：如何优雅地接管第三方子模块的 option 开关"},{"content":"Vim 标签页速查 在 Vim 中，标签页（tab）是比缓冲区更高层次的管理方式，适合多文件编辑和复杂工作流。本速查表整理了常见标签页操作，帮助你快速掌握。\n🔹 基本操作 :tabnew → 新建一个空标签页 :tabnew filename → 在新标签页中打开指定文件 :tabclose → 关闭当前标签页 :tabonly → 关闭其他标签页，仅保留当前标签页 🔹 标签页切换 gt → 切换到下一个标签页 gT → 切换到上一个标签页 {n}gt → 切换到第 n 个标签页 :tabn → 切换到下一个标签页 :tabp → 切换到上一个标签页 :tabfirst → 切换到第一个标签页 :tablast → 切换到最后一个标签页 🔹 标签页管理 :tabs → 显示所有标签页及其缓冲区信息 :tabmove N → 将当前标签页移动到第 N 个位置 :tabdo command → 在所有标签页执行指定命令 示例：:tabdo %s/foo/bar/g → 在所有标签页中替换 foo 为 bar 🔹 启动参数 打开多个文件，每个文件一个标签页： vim -p file1 file2 file3 → 使用 -p 参数启动 Vim 时，每个文件会在单独的标签页中打开 🔹 实战案例 快速在标签页间跳转\ngt / gT → 前后切换 {n}gt → 直接跳到第 n 个标签页 批量替换所有标签页内容\n:tabdo %s/old/new/g 关闭所有标签页的缓冲区\n:tabdo bd 🔹 总结 新建/关闭：:tabnew, :tabclose, :tabonly 切换：gt, gT, {n}gt, :tabn, :tabp 管理：:tabs, :tabmove, :tabdo 启动参数：vim -p file1 file2 ... ","date":"21 November, 2025","id":5,"permalink":"/posts/vim-%E6%A0%87%E7%AD%BE%E9%A1%B5%E9%80%9F%E6%9F%A5/","summary":"在 Vim 中，标签页（tab）是比缓冲区更高层次的管理方式，适合多文件编辑和复杂工作流。本速查表整理了常见标签页操作，帮助你快速掌握。","tags":"Vim 速查表 标签页 tab","title":"Vim 标签页速查"},{"content":"Vim 配置与插件速查 Vim 的强大不仅在于命令，还在于其高度可配置性和丰富的插件生态。本速查表整理了常见配置与插件技巧，帮助你快速打造个性化工作环境。\n🔹 基础配置（.vimrc） 显示行号\nset number set relativenumber 语法高亮\nsyntax on 自动缩进\nset autoindent set smartindent 搜索优化\nset hlsearch \u0026#34; 高亮搜索结果 set incsearch \u0026#34; 输入时即时搜索 set ignorecase \u0026#34; 忽略大小写 set smartcase \u0026#34; 有大写时区分大小写 编码设置\nset encoding=utf-8 set fileencodings=utf-8,gbk,latin1 🔹 键位映射 保存快捷键\nnnoremap \u0026lt;C-s\u0026gt; :w\u0026lt;CR\u0026gt; 退出快捷键\nnnoremap \u0026lt;C-q\u0026gt; :q\u0026lt;CR\u0026gt; 快速切换行号模式\nnnoremap \u0026lt;leader\u0026gt;rn :set relativenumber!\u0026lt;CR\u0026gt; 🔹 常用插件管理器 vim-plug\ncall plug#begin(\u0026#39;~/.vim/plugged\u0026#39;) Plug \u0026#39;preservim/nerdtree\u0026#39; Plug \u0026#39;junegunn/fzf\u0026#39; Plug \u0026#39;tpope/vim-commentary\u0026#39; call plug#end() Vundle\nPlugin \u0026#39;preservim/nerdtree\u0026#39; Plugin \u0026#39;junegunn/fzf\u0026#39; Plugin \u0026#39;tpope/vim-commentary\u0026#39; 🔹 常用插件推荐 文件浏览\nNERDTree → 树状文件浏览器 vim-vinegar → 简化 netrw 文件浏览 搜索与跳转\nfzf.vim → 模糊搜索 ctrlp.vim → 文件快速跳转 代码编辑\nvim-commentary → 快速注释 vim-surround → 操作括号/引号 ale → 异步语法检查 自动补全\ncoc.nvim → 强大的补全与 LSP 支持 美化\nvim-airline → 状态栏美化 gruvbox → 经典配色方案 🔹 实战案例 打造一个现代化 Vim 环境 set number relativenumber set hlsearch incsearch ignorecase smartcase syntax on set tabstop=4 shiftwidth=4 expandtab call plug#begin(\u0026#39;~/.vim/plugged\u0026#39;) Plug \u0026#39;preservim/nerdtree\u0026#39; Plug \u0026#39;junegunn/fzf\u0026#39; Plug \u0026#39;tpope/vim-commentary\u0026#39; Plug \u0026#39;neoclide/coc.nvim\u0026#39; Plug \u0026#39;vim-airline/vim-airline\u0026#39; Plug \u0026#39;morhetz/gruvbox\u0026#39; call plug#end() 🔹 总结 基础配置：行号、缩进、搜索、编码 键位映射：自定义快捷键提升效率 插件管理器：vim-plug / Vundle 常用插件：NERDTree、fzf、vim-commentary、coc.nvim、vim-airline 美化与扩展：主题与状态栏 ","date":"21 November, 2025","id":6,"permalink":"/posts/vim-%E9%85%8D%E7%BD%AE%E4%B8%8E%E6%8F%92%E4%BB%B6%E9%80%9F%E6%9F%A5/","summary":"Vim 的强大不仅在于命令，还在于其高度可配置性和丰富的插件生态。本速查表整理了常见配置与插件技巧，帮助你快速打造个性化工作环境。","tags":"Vim 速查表 配置 插件","title":"Vim 配置与插件速查"},{"content":"Vim 搜索与正则速查 🔹 基本搜索 /pattern → 向前搜索 ?pattern → 向后搜索 n → 重复上一次搜索（同方向） N → 重复上一次搜索（反方向） 🔹 单字符搜索 f{char} → 向右查找字符 F{char} → 向左查找字符 t{char} → 向右查找字符前一位 T{char} → 向左查找字符后一位 ; → 重复上一次字符查找 , → 反向重复上一次字符查找 🔹 正则表达式基础 . → 匹配任意单个字符 * → 匹配零个或多个字符 \\+ → 匹配一个或多个字符 \\? → 匹配零个或一个字符 \\{n,m} → 匹配 n 到 m 次 🔹 字符类与边界 [abc] → 匹配 a、b 或 c [^abc] → 匹配除 a、b、c 之外的字符 [0-9] → 匹配数字 \\d → 匹配数字（等价于 [0-9]） ^ → 匹配行首 $ → 匹配行尾 \\\u0026lt; → 匹配单词开头 \\\u0026gt; → 匹配单词结尾 🔹 分组与引用 \\(...\\) → 分组 \\1, \\2 → 引用分组内容 示例： :%s/\\(foo\\)\\(bar\\)/\\2\\1/g → 把 foobar 替换成 barfoo 🔹 大小写控制 \\c → 忽略大小写 \\C → 强制区分大小写 示例： /foo\\c → 搜索 foo，忽略大小写 🔹 搜索高亮与取消 :set hlsearch → 开启搜索高亮 :set nohlsearch → 关闭搜索高亮 :noh → 临时取消高亮 🔹 实战案例 搜索所有 IP 地址\n/\\d\\{1,3}\\.\\d\\{1,3}\\.\\d\\{1,3}\\.\\d\\{1,3} 搜索并替换日期格式\n:%s/\\([0-9]\\{4\\}\\)-\\([0-9]\\{2\\}\\)-\\([0-9]\\{2\\}\\)/\\2\\/\\3\\/\\1/g → 把 YYYY-MM-DD 转换成 MM/DD/YYYY\n搜索空行\n/^$ 🔹 总结 基本搜索：/, ?, n, N 字符搜索：f, F, t, T, ;, , 正则基础：. * \\+ \\? \\{n,m} 字符类与边界：[ ], ^, $, \\\u0026lt;, \\\u0026gt; 分组与引用：\\(...\\), \\1, \\2 大小写控制：\\c, \\C 高亮控制：:set hlsearch, :noh ","date":"21 November, 2025","id":7,"permalink":"/posts/vim-%E6%90%9C%E7%B4%A2%E4%B8%8E%E6%AD%A3%E5%88%99%E9%80%9F%E6%9F%A5/","summary":"搜索所有 IP 地址","tags":"Vim 速查表 搜索 正则","title":"Vim 搜索与正则速查"},{"content":"Vim 寄存器与宏速查 在 Vim 中，寄存器和宏是提升编辑效率的关键工具。寄存器用于存储文本，宏用于自动化重复操作。本速查表整理了常见命令，帮助你快速掌握。\n🔹 寄存器基础 \u0026quot;a → 使用寄存器 a \u0026quot;ayy → 复制当前行到寄存器 a \u0026quot;ap → 粘贴寄存器 a 的内容 \u0026quot;bdw → 删除一个单词并存入寄存器 b 🔹 常用寄存器 \u0026quot;\u0026quot; → 默认寄存器（最近一次操作） \u0026quot;0 → 最近一次复制的内容（不受删除影响） \u0026quot;1-\u0026quot;9 → 最近删除的内容（按顺序保存） \u0026quot;+ → 系统剪贴板（与操作系统交互） \u0026quot;* → 选择缓冲区（通常与鼠标选择相关） \u0026quot;_ → 黑洞寄存器（丢弃内容，不保存） \u0026quot;% → 当前文件名 \u0026quot;# → 备用文件名 🔹 系统剪贴板操作 \u0026quot;+y → 复制到系统剪贴板 \u0026quot;+p → 从系统剪贴板粘贴 \u0026quot;*y → 复制到选择缓冲区 \u0026quot;*p → 从选择缓冲区粘贴 🔹 宏基础 q{register} → 开始录制宏，存入指定寄存器 q → 停止录制 @{register} → 执行宏 @@ → 重复上一次宏 🔹 宏进阶用法 在多行上执行宏：\n:10,20normal @a → 在第 10 到 20 行执行寄存器 a 中的宏\n在可视模式选区执行宏：\n选择文本 输入： :normal @a 🔹 实战案例 批量添加注释 录制宏：在行首插入 //，保存到寄存器 a\n执行宏：在多行上批量添加注释\n批量修改函数名 录制宏：搜索旧函数名并替换为新函数名\n执行宏：在整个文件中批量修改\n格式化日志 录制宏：调整时间戳格式\n执行宏：在所有日志行上应用\n🔹 总结 寄存器：存储文本，支持系统剪贴板与特殊寄存器 宏：录制并执行重复操作，可在多行或选区中应用 黑洞寄存器：丢弃内容避免污染剪贴板 系统剪贴板：通过 \u0026quot;+ 与操作系统交互 ","date":"21 November, 2025","id":8,"permalink":"/posts/vim-%E5%AF%84%E5%AD%98%E5%99%A8%E4%B8%8E%E5%AE%8F%E9%80%9F%E6%9F%A5/","summary":"在 Vim 中，寄存器和宏是提升编辑效率的关键工具。寄存器用于存储文本，宏用于自动化重复操作。本速查表整理了常见命令，帮助你快速掌握。","tags":"Vim 速查表 寄存器 宏","title":"Vim 寄存器与宏速查"},{"content":"Vim 缓冲区与窗口管理速查 🔹 缓冲区（Buffer） 缓冲区是 Vim 打开的文件在内存中的表示。\n:ls → 列出所有缓冲区 :bN → 切换到编号为 N 的缓冲区 :bn → 切换到下一个缓冲区 :bp → 切换到上一个缓冲区 :bd → 删除缓冲区（关闭文件但不退出 Vim） :bdelete N → 删除指定缓冲区 🔹 窗口分割（Split） :split 或 :sp → 水平分割窗口 :vsplit 或 :vsp → 垂直分割窗口 Ctrl-w s → 水平分割当前窗口 Ctrl-w v → 垂直分割当前窗口 窗口切换：\nCtrl-w h → 切换到左边窗口 Ctrl-w l → 切换到右边窗口 Ctrl-w j → 切换到下方窗口 Ctrl-w k → 切换到上方窗口 窗口操作：\nCtrl-w q → 关闭当前窗口 Ctrl-w o → 只保留当前窗口，关闭其他窗口 Ctrl-w = → 调整所有窗口大小相等 Ctrl-w + / Ctrl-w - → 增加/减少当前窗口高度 Ctrl-w \u0026gt; / Ctrl-w \u0026lt; → 增加/减少当前窗口宽度 🔹 标签页（Tab） 标签页是更高层次的窗口管理方式。\n:tabnew → 新建标签页 :tabn → 切换到下一个标签页 :tabp → 切换到上一个标签页 :tabclose → 关闭当前标签页 :tabonly → 只保留当前标签页，关闭其他标签页 :tabmove N → 将当前标签页移动到第 N 个位置 🔹 多文件编辑工作流 打开多个文件： vim file1 file2 file3 在文件之间切换： :next \u0026#34; 下一个文件 :prev \u0026#34; 上一个文件 :first \u0026#34; 第一个文件 :last \u0026#34; 最后一个文件 🔹 总结 缓冲区：:ls, :bN, :bn, :bp, :bd 窗口分割：:split, :vsplit, Ctrl-w 系列命令 标签页：:tabnew, :tabn, :tabp, :tabclose 多文件编辑：:next, :prev, :first, :last ","date":"21 November, 2025","id":9,"permalink":"/posts/vim-%E7%BC%93%E5%86%B2%E5%8C%BA%E4%B8%8E%E7%AA%97%E5%8F%A3%E7%AE%A1%E7%90%86%E9%80%9F%E6%9F%A5/","summary":"缓冲区是 Vim 打开的文件在内存中的表示。","tags":"Vim 速查表 缓冲区 窗口管理","title":"Vim 缓冲区与窗口管理速查"},{"content":"Vim 编辑与操作速查 🔹 删除命令 x → 删除光标所在字符 dw → 删除到下一个单词开头 de → 删除到单词结尾 dd → 删除整行 d$ → 删除到行尾 d0 → 删除到行首 🔹 复制与粘贴 yy → 复制整行 yw → 复制到下一个单词开头 ye → 复制到单词结尾 p → 在光标后粘贴 P → 在光标前粘贴 🔹 修改命令 cw → 修改一个单词 cc → 修改整行 C → 修改到行尾 s → 替换一个字符并进入插入模式 🔹 撤销与重做 u → 撤销上一步操作 Ctrl-r → 重做撤销的操作 🔹 缩进与格式化 \u0026gt;\u0026gt; → 当前行右缩进 \u0026lt;\u0026lt; → 当前行左缩进 = → 自动缩进选区 gg=G → 自动缩进整个文件 🔹 可视模式编辑 v → 字符选择 V → 行选择 Ctrl-v → 块选择 在选区内使用 d, y, p, = 等命令进行操作 🔹 宏与自动化 q{register} → 开始录制宏 q → 停止录制 @{register} → 执行宏 @@ → 重复上一次宏 🔹 其他常用操作 J → 合并当前行与下一行 . → 重复上一次操作 r{char} → 替换光标所在字符为指定字符 ~ → 切换光标所在字符大小写 🔹 总结 删除：d 系列命令 复制与粘贴：y 与 p 修改：c 系列命令 撤销与重做：u 与 Ctrl-r 缩进与格式化：\u0026gt;\u0026gt;, \u0026lt;\u0026lt;, = 可视模式：v, V, Ctrl-v 宏：q, @ 其他：. 重复操作，J 合并行 ","date":"21 November, 2025","id":10,"permalink":"/posts/vim-%E7%BC%96%E8%BE%91%E4%B8%8E%E6%93%8D%E4%BD%9C%E9%80%9F%E6%9F%A5/","summary":"","tags":"Vim 速查表 编辑 操作","title":"Vim 编辑与操作速查"},{"content":"Vim 移动与导航速查 🔹 基础移动 h → 左移一个字符 l → 右移一个字符 0 → 移动到行首 ^ → 移动到行首第一个非空字符 $ → 移动到行尾 🔹 单词移动 w → 移动到下一个单词开头 e → 移动到当前/下一个单词结尾 b → 移动到当前/上一个单词开头 ge → 移动到上一个单词结尾 🔹 段落与句子 { → 移动到上一段开头 } → 移动到下一段开头 ( → 移动到上一句开头 ) → 移动到下一句开头 🔹 屏幕导航 H → 移动到屏幕顶部 M → 移动到屏幕中间 L → 移动到屏幕底部 Ctrl-d → 向下滚动半屏 Ctrl-u → 向上滚动半屏 Ctrl-f → 向下滚动一屏 Ctrl-b → 向上滚动一屏 🔹 搜索与跳转 /pattern → 向前搜索 ?pattern → 向后搜索 n → 重复上一次搜索（同方向） N → 重复上一次搜索（反方向） f{char} → 向右查找字符 F{char} → 向左查找字符 t{char} → 向右查找字符前一位 T{char} → 向左查找字符后一位 ; → 重复上一次字符查找 , → 反向重复上一次字符查找 🔹 括号与匹配 % → 跳转到匹配的括号、花括号或方括号 [( → 跳转到上一段落或代码块 ]) → 跳转到下一段落或代码块 🔹 行号与定位 :{line} → 跳转到指定行号 gg → 跳转到文件开头 G → 跳转到文件末尾 {n}G → 跳转到第 n 行 🔹 标记与书签 m{a-z} → 设置标记 `{a-z}` → 跳转到标记位置（精确到列） 'a → 跳转到标记所在行 → 跳转到上一次编辑位置 '' → 跳转到上一次跳转位置 🔹 搜索历史与跳转栈 Ctrl-o → 返回上一个跳转位置 Ctrl-i → 前进到下一个跳转位置 🔹 总结 基础移动：h l 0 ^ $ 单词移动：w e b ge 段落与句子：{ } ( ) 屏幕导航：H M L Ctrl-d/u/f/b 搜索与跳转：/ ? n N f F t T ; , 括号匹配：% 行号定位：gg G {n}G 标记与书签：m{a-z}, `{a-z}` 跳转栈：Ctrl-o, Ctrl-i ","date":"21 November, 2025","id":11,"permalink":"/posts/vim-%E7%A7%BB%E5%8A%A8%E4%B8%8E%E5%AF%BC%E8%88%AA%E9%80%9F%E6%9F%A5/","summary":"","tags":"Vim 速查表 导航 编辑器","title":"Vim 移动与导航速查"},{"content":":w\nVim 替换命令速查 在 Vim 中，替换命令的基本格式是：\n:[range]s/pattern/replacement/[flags] range：指定替换的行范围 pattern：要查找的模式（可用正则表达式） replacement：替换成的内容 flags：可选参数，例如 g 表示一行内全部替换，c 表示确认，i 表示忽略大小写 🔹 范围控制 当前行替换\n:s/foo/bar/g 指定行号范围\n:10,20s/foo/bar/g 从当前行到文件末尾\n:.,$s/foo/bar/g 全文件替换\n:%s/foo/bar/g 可视模式选区替换\n进入可视模式（v 或 V）选择文本 输入： :s/foo/bar/g 🔹 Flags 参数 g → 一行内全部替换 c → 每次替换确认 i → 忽略大小写 I → 强制区分大小写 示例：\n:%s/foo/bar/gc → 全文件替换，每次确认\n🔹 特殊字符处理 路径替换（避免 / 冲突）\n:%s#/usr/local/bin#/opt/bin#g :%s|C:\\Program Files|D:\\Apps|g 转义特殊字符\n:%s/\\/usr\\/local\\/bin/\\/opt\\/bin/g 替换为包含 \u0026amp; 的内容\n:%s/foo/\\\u0026amp;bar/g → \u0026amp; 在替换中表示“匹配到的内容”，需转义\n替换为包含反斜杠 \\\n:%s/path/\\\\\\\\newpath/g → 实际结果是 \\\\newpath\n🔹 正则替换 匹配数字\n:%s/[0-9]\\+/NUMBER/g 匹配行首/行尾\n:%s/^foo/bar/g \u0026#34; 行首 :%s/foo$/bar/g \u0026#34; 行尾 分组与引用\n:%s/\\(foo\\)\\(bar\\)/\\2\\1/g → 把 foobar 替换成 barfoo\n🔹 替换结果引用 \u0026amp; → 整个匹配内容 \\1, \\2 → 正则分组引用 ~ → 上一次替换的 replacement 示例：\n:%s/foo/\u0026amp;bar/g → 把 foo 替换成 foobar\n🔹 特殊场景 替换空格\n:%s/ /_/g 替换 Tab\n:%s/\\t/ /g 替换换行符（合并行）\n:%s/\\n/ /g 大小写转换\n:%s/foo/\\Ubar/g \u0026#34; 转大写 :%s/foo/\\lbar/g \u0026#34; 转小写 :%s/foo/\\u\u0026amp;/g \u0026#34; 首字母大写 🔹 实战案例 批量修改函数名\n:%s/my_func/new_func/g 替换配置文件路径\n:%s#/etc/nginx/conf.d#/etc/nginx/sites-enabled#g 日志文件中替换时间格式\n:%s/\\([0-9]\\{4\\}\\)-\\([0-9]\\{2\\}\\)-\\([0-9]\\{2\\}\\)/\\2\\/\\3\\/\\1/g → 把 YYYY-MM-DD 转换成 MM/DD/YYYY\n🔹 总结 范围：% 全文件，10,20 指定行，.,$ 当前到末尾 Flags：g 全部，c 确认，i 忽略大小写 特殊字符：用其他分隔符或转义 正则：支持分组、引用、行首行尾匹配 替换结果：\u0026amp; 表示匹配内容，\\1 引用分组 特殊场景：路径、大小写、空格、换行都可处理 ","date":"21 November, 2025","id":12,"permalink":"/posts/vim-%E6%9B%BF%E6%8D%A2%E5%91%BD%E4%BB%A4%E9%80%9F%E6%9F%A5/","summary":":w","tags":"Vim 速查表 命令 编辑器","title":"Vim 替换命令速查"},{"content":"🧩Dracut vs. Initramfs-tools: 一场Linux早期引导的深度变革 在Linux系统的启动链条中，一个看似短暂却至关重要的阶段是initramfs（Initial RAM Filesystem）的加载和执行。它的核心任务是搭建一个临时的根文件系统，加载必要的驱动（如存储、文件系统、加密模块），并最终挂载真实的根文件系统，将控制权交给系统的init进程（如systemd）。长期以来，Debian及其衍生版（如Ubuntu）依赖initramfs-tools来生成这个初始环境，而Red Hat生态则选择了更为现代的dracut。\n如今，随着Debian 13 (\u0026ldquo;Trixie\u0026rdquo;) 和 Ubuntu 24.04 LTS 等主流发行版纷纷转向dracut作为默认选项，这场关于早期引导工具的变革已经从技术讨论走向了广泛实践。本文将深入探讨这两者的技术架构、核心差异，并展望Linux早期引导的未来。\n1. 两大主角：技术架构与哲学 要理解它们的差异，首先必须理解它们各自是什么，以及它们的设计哲学。\ninitramfs-tools：脚本驱动的传统派 initramfs-tools是为Debian设计的initramfs生成框架。它的哲学是简单、透明、基于钩子（Hook-based）。\n用途与哲学: 它的核心思想是通过一系列有序的Shell脚本（hooks）来构建initramfs。开发者或系统管理员可以通过添加自定义脚本来扩展其功能。这种方式对于熟悉Shell编程的用户来说非常直观，一切皆为脚本。\n技术架构:\n核心命令: update-initramfs 是用户与之交互的主要工具。 配置目录: /etc/initramfs-tools/ 存放主要配置文件initramfs.conf和用户自定义模块。 钩子脚本 (Hooks): 位于/usr/share/initramfs-tools/hooks和/etc/initramfs-tools/hooks。这些脚本在生成initramfs时被执行，负责将必要的文件（如二进制程序、库、内核模块）复制到临时的构建目录中。例如，lvm2钩子会确保lvm二进制文件和相关库被包含进去。 引导脚本 (Boot Scripts): 位于/usr/share/initramfs-tools/scripts/，这些脚本被打包到initramfs内部，在系统启动时于早期用户空间（early userspace）中执行，负责设备发现、模块加载和根文件系统挂载。 生成过程: 当update-initramfs运行时，它会创建一个临时目录，依次执行所有钩子脚本来填充这个目录，然后将目录内容打包成一个cpio归档，并用gzip（或其他压缩工具）压缩，最终生成initrd.img文件。 其本质上是一个加法过程：默认包含一个基础集合，然后通过钩子不断向其中添加需要的内容。\ndracut：事件驱动的现代主义者 dracut (Generic RAMDisk Creation Tool) 由Red Hat开发，其设计哲学是模块化、事件驱动、按需生成。\n用途与哲学: dracut旨在创建一个尽可能小的、仅包含当前系统启动所需驱动和工具的initramfs。它避免硬编码的脚本逻辑，转而严重依赖udev在启动时动态发现和处理硬件。它的口号是：“Dracut contains as little as possible and relies on kernel features and udev to do the rest.”\n技术架构:\n核心命令: dracut。 模块化设计: dracut的核心是模块。所有功能都被组织在位于/usr/lib/dracut/modules.d/的模块中。每个模块是一个目录，包含定义好的脚本，如module-setup.sh（在生成时执行，安装文件）、install（安装文件）、check（检查依赖）等。 内省式生成 (Introspection): 这是dracut的王牌特性。在默认的**“Host-Only”模式**下，dracut会扫描当前正在运行的系统，精确地找出启动到根文件系统挂载这一步所必需的内核模块、二进制文件和配置。这使得生成的initramfs极其精简。 事件驱动的运行时: 在启动阶段，dracut内部的init脚本会启动一个轻量级的udev守护进程。当内核探测到硬件（如硬盘）时，udev会生成事件，触发相应的规则和脚本（例如，LVM卷被发现后，触发lvm相关的脚本进行激活），整个过程是动态和并行的。 配置: 配置文件位于/etc/dracut.conf和/etc/dracut.conf.d/下的.conf文件，用户通过简单的配置项（如add_drivers+=\u0026quot;nvme\u0026quot;）来控制生成过程，而不是编写复杂的钩子脚本。 其本质上是一个按需发现的过程：先确定目标（启动当前系统），然后精确地打包达成目标所需的最小工具集。\n2. 多维度深度对比 维度 initramfs-tools dracut 核心差异分析 核心架构 钩子驱动 (Hook-driven) 模块化、事件驱动 (Module-driven) initramfs-tools的逻辑是线性的、脚本化的，易于理解但难以维护复杂场景。dracut的模块化设计使得功能解耦，更易于扩展和维护。 镜像生成逻辑 包容性/通用性 (Inclusive/Generic) 内省式/最小化 (Introspective/Host-Only by default) initramfs-tools默认会包含大量可能用到的驱动，以确保镜像的通用性。dracut的Host-Only模式只包含当前硬件所需的驱动，生成的镜像更小，启动更快。 性能 较慢 显著更快 dracut的生成速度更快，因为它只处理必需的模块。在启动时，基于udev的并行化设备发现也通常比initramfs-tools的串行脚本执行更快。 镜像大小 较大 小得多 (在Host-Only模式下) 一个典型的initramfs-tools镜像可能在50-100MB，而dracut在Host-Only模式下生成的镜像可能只有10-30MB。这对于网络启动、嵌入式系统和快速启动至关重要。 可定制性 高，通过Shell脚本 高，通过Dracut模块 initramfs-tools的定制对于熟悉Shell的人来说非常直接，但缺乏结构。dracut的模块系统提供了更规范、更强大的定制框架，虽然初学曲线稍陡。 易用性与配置 配置项较少，依赖脚本 丰富的配置选项 dracut提供了清晰的配置文件来添加/排除驱动、模块等，通常比直接编写钩子脚本更简单、更不易出错。例如，强制包含某个驱动只需一行配置。 运行时逻辑 串行执行的Shell脚本 基于udev的并行事件处理 这是两者在启动阶段最大的区别。dracut能更好地利用现代多核CPU，并行处理硬件初始化，理论上能缩短启动时间。 生态系统 Debian, Ubuntu (旧版) RHEL, Fedora, Arch Linux, SUSE, Gentoo, 以及现在的Debian/Ubuntu dracut已成为事实上的跨发行版标准，这有利于工具链的统一和社区知识的共享。 3. 未来展望与竞争对手 dracut的胜利并非偶然，它代表了Linux系统设计向更智能、更模块化方向演进的趋势。但技术的发展永无止境，initramfs领域依然有新的挑战和竞争者。\n未来趋势：统一内核镜像 (Unified Kernel Images, UKI) 未来的引导方向是安全性和原子性。UKI 正是这一趋势的产物。UKI将Linux内核、initramfs、内核命令行和UEFI引导存根（stub）打包成一个单一、可执行的PE文件。\n优势:\n安全启动 (Secure Boot): 整个引导包可以被签名和验证，防止恶意篡改。 原子更新: 内核和其初始环境作为一个整体进行更新，减少了因版本不匹配导致启动失败的风险。 简化引导配置: 不再需要复杂的GRUB配置来分别指定linux和initrd行。 dracut对UKI的支持非常出色，可以通过dracut --uefi命令直接生成UKI文件，这使其在未来的安全引导生态中占据了有利位置。\n其他优秀的竞争者 mkinitcpio: Arch Linux使用的initramfs生成工具。它在设计上类似于initramfs-tools，也是基于钩子（hooks）的，但配置和结构更为简洁清晰。它在Arch社区中广受好评，证明了钩子模型在良好设计下依然具有强大的生命力。\nBooster: 一个用Go语言编写的新兴initramfs生成器，其首要目标是极致的启动速度。它通过以下方式实现优化：\n静态链接的Go二进制文件：减少对外部库的依赖。 高度并行化：充分利用多核CPU。 优化的解析器：快速解析lsmod, crypttab, fstab等文件。 集成图像生成和解压：直接输出最终的压缩镜像。 对于追求毫秒级启动优化的场景（如云原生环境、嵌入式设备），Booster是一个值得关注的强大竞争者。\nsystemd-stub: 虽然systemd本身不生成initramfs（它依赖dracut或mkinitcpio），但其提供的systemd-boot引导加载器和systemd-stub是UKI生态的核心组件。systemd正在逐步整合和简化整个引导链，未来initramfs的生成和使用将与systemd更加紧密地集成。\n结论 initramfs-tools作为一款稳定可靠的工具，服务了Debian社区多年。然而，其基于脚本的串行设计在面对日益复杂的硬件环境和对性能、安全性的更高要求时，显得力不从心。\ndracut的崛起是技术演进的必然结果。其模块化、内省式和事件驱动的设计哲学，不仅在生成速度和镜像大小上取得了压倒性优势，更重要的是，它完美契合了现代Linux内核与udev的交互模式，并积极拥抱了统一内核镜像（UKI）等未来引导技术。Debian和Ubuntu等主流发行版转向dracut，是对其技术优越性的最终认可，也预示着一个更快速、更智能、更安全的Linux引导新时代的到来。\n","date":"11 October, 2025","id":13,"permalink":"/posts/--dracut-vs-initramfs-tools-%E4%B8%80%E5%9C%BAlinux%E6%97%A9%E6%9C%9F%E5%BC%95%E5%AF%BC%E7%9A%84%E6%B7%B1%E5%BA%A6%E5%8F%98%E9%9D%A9/","summary":"在Linux系统的启动链条中，一个看似短暂却至关重要的阶段是initramfs（Initial RAM Filesystem）的加载和执行。它的核心任务是搭建一个临时的根文件系统，加载必要的驱动（如存储、文件系统、加密模块），并最终挂载真实的根文件系统，将控制权交给系统的init进程（如systemd）。长期以来，Debian及其衍生版（如Ubuntu）依赖initramfs-tools来生成这个初始环境，而Red Hat生态则选择了更为现代的dracut。","tags":"ubuntu systemd init dracut","title":"🧩  Dracut vs Initramfs-tools 一场Linux早期引导的深度变革"},{"content":"🧩 Linux 内核启动阶段的临时根文件系统技术文档 📘 1. 概述（Overview） 在 Linux 启动的早期阶段，内核尚未挂载实际的根文件系统（例如 eMMC 上的 ext4 或 NFS 根目录）。\n为了让系统具备运行基本命令、加载驱动、挂载真实根文件系统的能力，\n内核引入了一种称为 临时根文件系统 (Early Root Filesystem) 的机制。\n该机制在不同内核时代有两种主要实现：\n阶段 技术名称 实现方式 Linux 2.4 及以前 initrd (initial RAM disk) 将压缩镜像加载为虚拟块设备 /dev/ram0，再挂载 Linux 2.6 及以后 initramfs (initial RAM filesystem) 将 cpio 压缩包直接解包进内存文件系统（ramfs/tmpfs） ⚙️ 2. 启动阶段流程概览 Linux 启动阶段涉及从 bootloader → 内核 → initramfs/initrd → 用户空间 init 的完整链路。\n1. BIOS/UEFI ↓ 2. Bootloader (GRUB/U-Boot) - 加载 vmlinuz (内核映像) - 加载 initramfs/initrd 到内存 ↓ 3. Linux Kernel - 初始化内核子系统 - 创建 rootfs (ramfs/tmpfs) - 解包 initramfs 或挂载 initrd - 执行临时根中的 /init ↓ 4. /init - 探测真实根文件系统（eMMC/NFS/overlay） - 挂载目标根目录 - 调用 `switch_root` 或 `pivot_root` ↓ 5. 启动真正的 /sbin/init 或 systemd 🧩 3. 技术架构与数据流 3.1 逻辑结构图 ┌────────────────────────────┐ │ Bootloader │ │ - 加载 Kernel + Initramfs │ └────────────┬───────────────┘ │ ┌────────────▼───────────────┐ │ Linux Kernel │ │ - 创建 rootfs (ramfs) │ │ - 解包 initramfs.cpio.gz │ │ - 执行 /init │ └────────────┬───────────────┘ │ ┌────────────▼───────────────┐ │ /init 用户态脚本 │ │ - 探测真实根文件系统 │ │ - 挂载 /new_root │ │ - switch_root /new_root │ └────────────┬───────────────┘ │ ┌────────────▼───────────────┐ │ 真正根文件系统 (ext4/NFS) │ │ /sbin/init → systemd/init │ └────────────────────────────┘ 🧱 4. Initramfs 内部结构 Initramfs 是一个 cpio 格式的压缩包，包含早期启动所需的最小文件集：\ninitramfs/ ├── bin/ │ └── busybox ├── dev/ ├── etc/ ├── proc/ ├── sys/ ├── init ← 启动脚本（最关键） └── lib/ 典型创建命令：\nfind . | cpio -H newc -o | gzip \u0026gt; ../initramfs.cpio.gz 加载方式（由 Bootloader 指定）：\nqemu-system-x86_64 -kernel bzImage -initrd initramfs.cpio.gz -append \u0026#34;console=ttyS0\u0026#34; 🧩 5. 内核解包与挂载流程（源码级） 以 Linux 6.x 为例，主流程如下：\n5.1 调用链概览 start_kernel() └── rest_init() └── kernel_init() └── prepare_namespace() ├── create_rootfs() ├── unpack_to_rootfs() ← 解包 initramfs.cpio └── run_init_process(\u0026#34;/init\u0026#34;) 5.2 关键函数说明 函数 文件 功能描述 populate_rootfs() init/initramfs.c 将 cpio 包内容解包到内存文件系统 do_mounts_initrd() init/do_mounts_initrd.c 若为旧版 initrd，挂载 /dev/ram0 run_init_process() init/main.c 尝试执行 /init、/sbin/init 等 switch_root() /usr/sbin/switch_root.c 从 initramfs 切换到真正 rootfs 🧩 6. 关键内核配置项 配置项 作用 典型值 CONFIG_BLK_DEV_INITRD 启用旧版 initrd 支持 y CONFIG_INITRAMFS_SOURCE 指定内嵌 initramfs 源路径 \u0026quot;initramfs_list\u0026quot; CONFIG_RD_GZIP 支持 gzip 压缩 y CONFIG_TMPFS 允许 tmpfs 用作 rootfs y CONFIG_INIT_ENV_ARG_LIMIT 控制 /init 参数限制 默认 32 🧩 7. 内核内嵌 Initramfs 可以直接将 initramfs 打包进内核：\nmake menuconfig → General setup → Initramfs source file(s) 或通过环境变量：\nmake INITRAMFS_SOURCE=../rootfs 生成的内核会在 usr/initramfs_data.c 中嵌入二进制数据：\nconst char __initramfs_start[]; const char __initramfs_end[]; ⚙️ 8. /init 启动脚本职责 /init 是 initramfs 的“入口点”，它在真正的 /sbin/init 启动前执行。\n典型实现（BusyBox 风格）：\n#!/bin/sh echo \u0026#34;[INITRAMFS] Booting early init system...\u0026#34; mount -t proc proc /proc mount -t sysfs sysfs /sys # 检测真实根分区 mount /dev/mmcblk0p2 /new_root # 切换根文件系统 exec switch_root /new_root /sbin/init 🔩 9. 与真实根文件系统的切换机制 9.1 pivot_root（旧方式） 将新根文件系统切换到 /new_root 原根文件系统挂载到 /new_root/initrd 已弃用，需手动卸载旧根 9.2 switch_root（现代方式） 替换根并清空旧文件系统 由 BusyBox 或 util-linux 提供 更简洁、安全 switch_root /new_root /sbin/init 🧩 10. 调试与验证 操作目标 命令或方法 查看内核是否加载 initramfs dmesg 解包 initramfs 文件 gzip -dc initramfs.cpio.gz 在 /init 中打调试日志 echo \u0026quot;step 1...\u0026quot; \u0026gt; /dev/console 查看 rootfs 类型 cat /proc/filesystems 切换失败原因分析 检查 /dev, /proc, /sys 是否挂载 🧩 11. 嵌入式系统应用案例 应用场景 描述 单镜像系统 BusyBox + initramfs 直接作为系统根，无需外部存储 固件升级系统 initramfs 启动后校验、刷写、重启 加密文件系统启动 initramfs 中负责解密根分区后切换根 容灾/救援系统 提供最小恢复环境 (rescue shell) 🧩 12. 实验验证（QEMU Demo） # 构建 busybox make defconfig make install # 构建 initramfs mkdir -p rootfs/{bin,dev,proc,sys} cp -a _install/* rootfs/ echo -e \u0026#39;#!/bin/sh\\nmount -t proc proc /proc\\nmount -t sysfs sysfs /sys\\necho \u0026#34;Hello Initramfs\u0026#34;\\nexec /bin/sh\u0026#39; \u0026gt; rootfs/init chmod +x rootfs/init find . | cpio -H newc -o | gzip \u0026gt; ../initramfs.cpio.gz # 启动 QEMU qemu-system-x86_64 -kernel bzImage -initrd initramfs.cpio.gz -append \u0026#34;console=ttyS0\u0026#34; 输出：\n[INITRAMFS] Booting... Hello Initramfs / # 🧩 13. 内存占用与性能分析 项目 initrd initramfs 解包方式 解压到块设备 直接展开到 tmpfs 内存占用 双倍（块设备+文件系统） 单份（直接文件缓存） 启动速度 较慢 快 30–50% 占用结构 页缓存 + ramdisk VFS 缓存 回收机制 手动卸载 自动回收 tmpfs 空间 🧩 14. 总结 项目 initrd initramfs 文件格式 ext2 镜像 cpio 包 是否需块设备 是 否 文件系统类型 ext2 tmpfs/ramfs 兼容性 老内核 新内核（2.6+） 性能 一般 优秀 推荐使用 ❌ ✅ 🧩 15. 参考资料 Linux Kernel Documentation\n/usr/src/linux/Documentation/filesystems/ramfs-rootfs-initramfs.txt BusyBox 官方文档: https://busybox.net/ 内核源码：init/initramfs.c, init/main.c LWN: \u0026ldquo;Early userspace in Linux 2.6\u0026rdquo; Yocto Project: initramfs integration guide ","date":"11 October, 2025","id":14,"permalink":"/posts/-linux-%E5%86%85%E6%A0%B8%E5%90%AF%E5%8A%A8%E9%98%B6%E6%AE%B5%E7%9A%84%E4%B8%B4%E6%97%B6%E6%A0%B9%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F%E6%8A%80%E6%9C%AF%E6%96%87%E6%A1%A3/","summary":"该机制在不同内核时代有两种主要实现：","tags":"ubuntu systemd init","title":"🧩 Linux 内核启动阶段的临时根文件系统技术文档"},{"content":"Linux 初始化系统技术文档：从 SysVinit 到 systemd 的演进 1. 概述 Linux 初始化系统是操作系统启动过程中第一个用户空间进程（PID 1），负责引导用户空间环境、管理系统服务和进程。本文档详细介绍了 Linux 初始化系统的发展历程、技术特点及各系统的比较。\n2. 初始化系统发展历程 timeline title Linux 初始化系统发展时间线 section 传统时期 1991 : SysVinit 成为主流 : 基于运行级别 : 串行启动机制 section 演进时期 2006 : Ubuntu 开发 Upstart : 事件驱动架构 : 初步并行启动 2007 : Gentoo 推出 OpenRC : 依赖驱动启动 : 兼容传统脚本 section 现代时期 2010 : systemd 诞生 : 全面并行启动 : 统一系统管理 2010s : 专有领域方案 : procd (嵌入式) : runit (轻量级) 3. 主要初始化系统详解 3.1 SysVinit (System V Init) ​​诞生时间​​：1980年代（源自UNIX System V）\n​​核心特性​​：\n基于运行级别（0-6）的系统状态管理 串行启动过程，顺序执行初始化脚本 使用Shell脚本管理服务启动/停止 ​​脚本结构​​：\n/etc/rc.d/ ├── rc0.d/ # 关机运行级别 ├── rc1.d/ # 单用户模式 ├── rc2.d/ # 多用户无网络 ├── rc3.d/ # 多用户控制台 ├── rc4.d/ # 用户自定义 ├── rc5.d/ # 多用户图形界面 ├── rc6.d/ # 重启运行级别 └── init.d/ # 实际脚本目录 ​​主要命令​​：\n# 管理服务 /etc/init.d/service_name start|stop|restart|status # 改变运行级别 init 3 telinit 5 # 关机/重启 shutdown -h now reboot ​​优缺点​​：\n✅ 简单稳定，易于理解和调试 ✅ 脚本透明，可完全自定义 ❌ 启动速度慢（串行执行） ❌ 无法处理动态事件（如热插拔设备） ❌ 依赖关系管理复杂 3.2 Upstart ​​诞生时间​​：2006年（由Ubuntu开发）\n​​核心创新​​：\n事件驱动架构，响应系统事件 并行服务启动，显著提升启动速度 更好的硬件热插拔支持 ​​配置文件示例​​（/etc/init/nginx.conf）：\n# Nginx - 高性能HTTP服务器 description \u0026#34;Nginx HTTP服务器\u0026#34; # 在运行级别2、3、4、5启动，在0、1、6停止 start on runlevel [2345] stop on runlevel [016] # 期望以daemon方式运行 expect fork # 启动服务 exec /usr/sbin/nginx -g \u0026#34;daemon on;\u0026#34; ​​主要命令​​：\n# 管理任务 start nginx stop nginx status nginx # 查看事件 initctl list initctl emit event-name ​​应用情况​​：\n曾用于Ubuntu（9.10-14.10）、RHEL 6等 现已被systemd取代 3.3 OpenRC ​​诞生时间​​：2007年（由Gentoo社区开发）\n​​设计特点​​：\n依赖驱动的初始化系统 兼容传统SysVinit脚本 不依赖特定Linux内核特性 ​​服务文件示例​​（/etc/init.d/sshd）：\n#!/sbin/openrc-run description=\u0026#34;OpenSSH 守护进程\u0026#34; command=\u0026#34;/usr/sbin/sshd\u0026#34; command_args=\u0026#34;-D\u0026#34; pidfile=\u0026#34;/var/run/sshd.pid\u0026#34; depend() { need net use dns before firewall } ​​主要命令​​：\n# 管理服务 rc-service service_name start rc-status rc-update add service_name default ​​应用情况​​：\nGentoo Linux及其衍生版 Alpine Linux（Docker基础镜像常用） 3.4 runit ​​诞生时间​​：2004年\n​​设计哲学​​：\n简单、可靠、最小化设计 核心功能：进程监督（自动重启崩溃服务） 极快的启动速度 ​​目录结构​​：\n/etc/service/ └── nginx/ ├── run # 启动脚本 └── finish # 停止脚本 ​​服务示例​​（/etc/service/nginx/run）：\n#!/bin/sh exec 2\u0026gt;\u0026amp;1 exec /usr/sbin/nginx -g \u0026#34;daemon off;\u0026#34; ​​主要命令​​：\n# 管理服务 sv start nginx sv status nginx sv restart nginx ​​应用情况​​：\nVoid Linux默认初始化系统 轻量级容器环境 需要高可靠性的服务环境 3.5 systemd ​​诞生时间​​：2010年（由Lennart Poettering和Kay Sievers开发）\n​​架构创新​​：\n并行启动服务，基于依赖关系解析 统一的服务管理配置（单元文件） 集成系统管理功能（日志、定时任务、网络等） ​​服务单元示例​​（/etc/systemd/system/nginx.service）：\n[Unit] Description=The NGINX HTTP and reverse proxy server After=network.target network-online.target Wants=network-online.target Documentation=https://nginx.org/en/docs/ [Service] Type=forking PIDFile=/var/run/nginx.pid ExecStartPre=/usr/bin/nginx -t ExecStart=/usr/bin/nginx ExecReload=/bin/kill -s HUP $MAINPID ExecStop=/bin/kill -s QUIT $MAINPID TimeoutStopSec=5 KillMode=mixed [Install] WantedBy=multi-user.target ​​主要命令​​：\n# 管理服务 systemctl start nginx systemctl status nginx systemctl enable nginx # 系统管理 systemctl halt # 关机 systemctl reboot # 重启 systemctl suspend # 挂起 # 日志查看 journalctl -u nginx journalctl -f # 分析启动性能 systemd-analyze blame systemd-analyze critical-chain nginx.service ​​应用情况​​：\n绝大多数主流Linux发行版默认初始化系统 Debian、Ubuntu、RHEL、CentOS、Fedora、Arch Linux等 3.6 专有领域方案 ​​procd​​：\n用于OpenWrt路由器的轻量级初始化系统 专注于嵌入式设备资源限制 核心功能：进程管理和监控 ​​s6​​：\n另一款轻量级进程监督工具集 设计注重简单性和正确性 常用于容器和最小化系统 4. 技术对比分析 4.1 性能对比 特性 SysVinit Upstart OpenRC runit systemd 启动速度 慢 中等 中等 快 很快 资源占用 低 中等 低 很低 中等 并行能力 无 有限 有限 有 全面 4.2 功能特性对比 功能 SysVinit Upstart OpenRC runit systemd 依赖管理 手动 事件基础 依赖基础 简单 自动依赖解析 服务监控 无 有限 有限 有 有 日志集成 无 无 无 无 有(journald) 热插拔支持 有限 有 有限 无 有 容器支持 无 有限 有限 有 有 4.3 兼容性对比 方面 SysVinit Upstart OpenRC runit systemd 传统脚本兼容 完全 部分 完全 需要适配 部分 跨发行版支持 广泛 有限 中等 有限 广泛 配置复杂度 低 中等 中等 低 高 5. 迁移指南 5.1 从SysVinit迁移到systemd ​服务脚本转换​​：\n将/etc/init.d/脚本转换为.service单元文件 使用systemd-analyze检查启动性能 ​​运行级别映射​​：\nSysVinit运行级别 systemd目标 0 poweroff.target 1 rescue.target 2, 3, 4 multi-user.target 5 graphical.target 6 reboot.target ​常用命令对比​​：\nSysVinit命令 systemd命令 service ssh start systemctl start ssh chkconfig ssh on systemctl enable ssh runlevel systemctl get-default 5.2 从systemd迁移到runit ​创建服务目录​​：\nmkdir -p /etc/sv/nginx ​创建run脚本​​：\ncat \u0026gt; /etc/sv/nginx/run \u0026lt;\u0026lt; EOF #!/bin/sh exec /usr/sbin/nginx -g \u0026#34;daemon off;\u0026#34; EOF chmod +x /etc/sv/nginx/run ​创建服务链接​​：\nln -s /etc/sv/nginx /var/service/ 6. 选择建议 6.1 根据使用场景选择 ​​服务器环境​​：\n✅ systemd：功能全面，管理方便，生态丰富 ✅ OpenRC：稳定可靠，资源占用低 ​​桌面环境​​：\n✅ systemd：与现代桌面集成度高 ✅ runit：轻量快速，响应迅速 ​​嵌入式设备​​：\n✅ procd：专为资源受限环境设计 ✅ runit：简单可靠，占用资源极少 ​​容器环境​​：\n✅ runit：轻量级，适合最小化镜像 ✅ s6：专注于进程监督 ​​传统系统维护​​：\n✅ SysVinit：兼容老旧系统 ✅ OpenRC：平衡传统与现代需求 6.2 未来发展考虑 ​​systemd​​继续占据主流地位，功能不断增强 轻量级方案在容器和嵌入式领域保持重要地位 安全性、容器集成和资源控制成为发展重点 7. 总结 Linux初始化系统经历了从简单的串行启动到复杂的并行依赖管理的演进过程。当前systemd已成为主流选择，但轻量级方案如runit、OpenRC在特定场景下仍有其价值。选择初始化系统应考虑具体需求：功能完整性、资源限制、兼容性要求等因素。\n理解各初始化系统的设计哲学和实现特点，有助于在不同场景下做出合适的技术选型，并有效进行系统维护和故障排除。\n","date":"18 September, 2025","id":15,"permalink":"/posts/linux-%E5%88%9D%E5%A7%8B%E5%8C%96%E7%B3%BB%E7%BB%9F%E6%8A%80%E6%9C%AF%E6%96%87%E6%A1%A3%E4%BB%8E-sysvinit-%E5%88%B0-systemd-%E7%9A%84%E6%BC%94%E8%BF%9B/","summary":"Linux 初始化系统是操作系统启动过程中第一个用户空间进程（PID 1），负责引导用户空间环境、管理系统服务和进程。本文档详细介绍了 Linux 初始化系统的发展历程、技术特点及各系统的比较。","tags":"ubuntu systemd SysVinit 初始化系统","title":"📘Linux 初始化系统技术文档：从 SysVinit 到 systemd 的演进"},{"content":"[[systemd]]\nsystemd 单元文件 systemd 的核心设计思想是将系统里的一切资源都抽象成“单元”（Unit）。单元是 systemd 管理的基本对象，涵盖了服务、套接字、设备、挂载点乃至系统状态等。\n单元文件就是用来定义一个单元的纯文本配置文件。它清晰地描述了这个单元的属性、行为以及它与其他单元之间的关系。这些文件采用类似 INI 的语法，易于阅读和编写。\n文件位置与优先级 systemd 会从多个目录中加载单元文件，并遵循一套明确的优先级规则\n系统级（只读包）：/usr/lib/systemd/system/ 系统级（本地管理员覆写）：/etc/systemd/system/ 运行时（临时，重启丢失）：/run/systemd/system/ 优先级：/etc 覆盖 /run 覆盖 /usr/lib。同名时，高优先级目录生效。 推荐使用 systemctl edit \u0026lt;unit\u0026gt; 生成 drop-in 覆盖，避免直接改发行文件。\n/etc/systemd/system/：最高优先级。系统管理员存放自定义或修改后的单元文件的地方。这里的配置会覆盖其他位置的同名文件。 /run/systemd/system/：第二优先级。通常由程序在运行时动态创建单元文件。系统重启后该目录内容会丢失。 /usr/lib/systemd/system/：最低优先级。通常由软件包管理器（如 apt、yum`）安装的默认单元文件存放于此。不建议直接修改这里的文件。 核心原则：当需要修改一个默认单元文件时（例如 sshd.service），推荐使用 systemctl edit --full sshd.service 命令。它会自动将文件从 /usr/lib/systemd/system/ 复制到 /etc/systemd/system/ 并打开编辑器，确保你的修改具有最高优先级且不会在软件包升级时被覆盖。\nsystemd unit 定义行为、依赖与生命周期\n管理的对象：服务、套接字、计时器、挂载点等。\n常见类型：service、socket、target、timer、path、mount、automount、device、slice、scope。\n单元命名与实例化 文件名格式：name.type，例如：nginx.service、sshd.socket。\n模板单元：name@.type，实例化时用 name@instance.type，适合 per-connection 或 per-device。\n你当前使用的是模板服务 dropbear@.service 配合 dropbear.socket 实现每连接派生。\n单元文件结构 一个单元文件通常由几个配置段（Section）组成，每个段由 [方括号] 标识。其中，[Unit] 和 [Install] 是几乎所有单元类型都通用的。\n[Unit]: 通用元信息、依赖、顺序。 [Service]/[Socket]/[Timer]/…：类型专属的配置段。 [Install]: 启用时的附着点（WantedBy/RequiredBy/Also）。 [Unit] 段：通用元数据与依赖关系 此段定义了单元的通用属性，它不关心单元的类型。\nDescription=: 一段描述性文本，用于在 systemctl status 等命令中直观地展示单元的用途。 Documentation=: 提供文档链接，可以是 man 手册页或 URL，如 man:sshd(8) 或 https://example.com/docs。 After=: 定义启动顺序。此单元将在 After 列出的单元启动完成之后再启动。这是最常用的顺序依赖。 Before=: 定义启动顺序。此单元将在 Before 列出的单元启动之前先启动。 Wants=: 定义一种弱依赖关系。此单元启动时，systemd 会尝试启动 Wants 列出的单元。但即使后者启动失败，也不影响此单元的启动。 Requires=: 定义一种强依赖关系。此单元启动时，systemd 必须成功启动 Requires 列出的单元。如果后者启动失败，此单元也将被停用。 Conflicts=: 定义冲突关系。如果此单元启动，Conflicts` 中列出的单元将会被停止。反之亦然。 [Install] 段：启用与开机自启行为 此段定义了当用户使用 systemctl enable/disable 命令时，该单元应如何表现。\nWantedBy=: 最常用的指令。表示此单元是 WantedBy 所指定的 .target 单元的“一部分”。执行 systemctl enable 时，systemd 会在 /etc/systemd/system/ 目录下创建一个指向此单元文件的符号链接，链接位于 multi-user.target.wants/ 这样的目录中。 RequiredBy=: 类似于 WantedBy，但表示一个更强的依赖。如果 RequiredBy 指定的 .target 启动，此单元必须成功启动。 Also=: 指定当此单元被启用/禁用时，Also` 列出的其他单元也应被一同启用/禁用。 主要单元文件类型详解 Service Unit (.service) 这是最核心、最常用的单元类型，用于定义一个系统服务（守护进程）。\n主要用途：启动、停止、重启和管理后台服务进程。\n核心配置段：[Service]\n常用指令：\nType=: 定义服务的启动类型。 simple (默认): ExecStart 后的主进程就是服务进程。 forking: ExecStart 启动的进程会 fork() 一个子进程作为真正的服务进程，父进程会退出。systemd 会等待父进程退出后认为服务启动完成。 oneshot: 类似于 simple，但 systemd 会等待主进程退出后才认为服务启动完成。适用于一次性任务（如内核模块加载、文件系统检查）。 notify: 服务启动后会通过 sd_notify() 函数向 systemd 发送“准备就绪”的信号。 dbus: 服务需要获取一个 D-Bus 名称。 ExecStart=: 指定启动服务时要执行的命令。 ExecStop=: 指定停止服务时要执行的命令（可选）。 ExecReload=: 指定重载服务配置时要执行的命令（可选）。 Restart=: 定义服务在何种情况下应被自动重启。常用值有 no (默认)、on-success、on-failure、on-abnormal、always。 User= / Group=: 指定运行服务的用户和用户组。出于安全考虑，推荐使用非 root 用户。 WorkingDirectory=: 指定进程的工作目录。 Environment= / EnvironmentFile=: 为服务进程设置环境变量或从文件中加载环境变量。 Socket Unit (.socket) 用于定义一个网络套接字（TCP/UDP）或本地 IPC 套接字。它是 systemd 实现按需启动 (Socket Activation) 的关键。\n主要用途：代替服务进程监听端口。当有连接请求时，systemd 会激活并启动相应的 .service 单元来处理该连接。\n核心配置段：[Socket]\n常用指令：\nListenStream=: 监听一个 TCP 套接字。值是端口号。 ListenDatagram=: 监听一个 UDP 套接字。 ListenFIFO=: 监听一个 FIFO (命名管道)。 Accept=: 布尔值。false (默认) 表示 systemd 接受连接后，会启动一个服务实例并将该连接传递给它，然后该服务负责处理后续所有连接。yes 表示 systemd 会为每一个进来的连接都启动一个新的服务实例（如 dropbear@.service 模板）。 Service=: 指定当此套接字有活动时要激活的服务名。如果 socket 文件名是 foo.socket，默认激活的服务就是 foo.service。 Target Unit (.target) 用于对其他单元进行逻辑分组，本身不执行任何操作。它取代了传统 SysVinit 中的“运行级别”（Runlevel）。\n主要用途：定义系统状态的同步点，管理一组相关的单元。\n核心配置段：无专属配置段，主要通过 [Unit] 段的 Wants 和 Requires 来聚合其他单元。\n常用 Targets：\nmulti-user.target: 类似于运行级别 3，用于启动所有网络服务，进入多用户命令行模式。 graphical.target: 类似于运行级别 5，依赖 multi-user.target，并额外启动图形界面服务。 network.target: 表示网络已就绪。 sockets.target: 所有 .socket 单元都应属于此目标。 reboot.target: 用于重启系统。 Timer Unit (.timer) 用于定义定时器，是 cron 的现代化替代品，可以触发任何 .service 单元。\n主要用途：定时或周期性地执行任务。\n核心配置段：[Timer]\n常用指令：\nOnCalendar=: 基于日历的绝对时间。语法灵活，如 daily, weekly, *-*-* 12:00:00 (每天中午12点)。 OnActiveSec=: 相对于 timer 自身被激活的时间。 OnBootSec=: 相对于系统启动完成的时间。 OnUnitActiveSec=: 相对于它所激活的单元最后一次被激活的时间。 Unit=: 指定此定时器要触发的单元名。默认是同名的 .service 文件。 Persistent=: 布尔值。如果设为 true，当系统关机时错过的执行任务，会在下次开机后立即补上。 Path Unit (.path) 用于监控文件或目录的变化，当事件发生时触发另一个单元。\n主要用途：实现基于文件系统事件的按需服务启动。\n核心配置段：[Path]\n常用指令：\nPathExists=: 当指定路径存在时触发。 PathChanged=: 当文件内容发生变化时触发。 PathModified=: 当文件内容或元数据（如权限、时间戳）发生变化时触发。 DirectoryNotEmpty=: 当指定目录从空变为非空时触发。 Unit=: 指定要触发的单元。 Mount Unit (.mount) \u0026amp; Automount Unit (.automount) .mount: 用于以声明式的方式管理文件系统的挂载点，可以替代 /etc/fstab。systemd 会在启动时自动将 /etc/fstab 条目转换为 .mount 单元。\n.automount: 用于实现文件系统的按需挂载。它会监听一个挂载点目录，只有当该目录被访问时，systemd 才会真正执行挂载操作。\nSlice Unit (.slice) 用于对一组单元进行资源限制。它基于 Linux 内核的 cgroups (控制组) 功能，本身不包含进程，而是作为一个资源控制的层级。\n主要用途：对系统、用户或特定服务的 CPU、内存、I/O 等资源进行分组和限制。\n核心配置段：[Slice]，但资源限制通常直接在此段中定义。\n常用指令：CPUWeight=, MemoryMax=, IOWeight= 等。\n默认 Slice：system.slice (系统服务), user.slice (用户会话), machine.slice (虚拟机和容器)。\nScope Unit (.scope) 与 .service 类似，也用于管理一组进程。但 .scope 单元不是通过 systemd 启动进程，而是用于管理由外部进程（如用户登录、容器运行时）创建的进程。\nDevice Unit (.device) 由 systemd-udevd 服务自动创建，用于响应内核的设备热插拔事件。通常用户不需要手动创建。\nSwap Unit (.swap) 用于定义和管理交换空间（swap分区或文件），可替代 /etc/fstab 中的 swap 条目。\nSnapshot Unit (.snapshot) 一种特殊的单元，用于保存 systemd 管理器的当前状态（所有正在运行的单元）。可以用于临时进入一个不同的状态，然后再恢复到快照时的状态。\n依赖与顺序的要点 Requires= 强依赖；失败会导致依赖者失败。 Wants= 软依赖；失败不导致依赖者失败。 Before=/After= 仅控制顺序，不建立依赖。 套接字激活时，socket 与 service 的依赖/顺序由 systemd 根据命名自动处理。\n条件与断言 ConditionPathExists=、ConditionKernelCommandLine= 等，条件不满足时跳过激活且不视为失败。 Assert*= 不满足时视为失败。\n环境变量与配置注入 Environment=\u0026quot;KEY=VAL\u0026quot; EnvironmentFile=/etc/default/foo`（常见 Debian/BusyBox 习惯） 建议把可变参数放 EnvironmentFile，便于 OTA/不同机型差异化。\n进程模型与 Exec Type=simple：ExecStart 进程为主进程 Type=forking：适配传统 daemonize 程序（会 fork） Type=notify：进程通过 sd_notify 报告就绪 ExecStartPre=/ExecStartPost=：前后钩子 TimeoutStartSec=` 避免卡启动 资源限制与安全沙箱 限制 User=、Group=、SupplementaryGroups= LimitNOFILE=、MemoryMax=、TasksMax= CPUQuota=、IOSchedulingClass= 等 沙箱 ProtectSystem=full/strict ProtectHome=true、PrivateTmp=true、PrivateDevices=true NoNewPrivileges=true CapabilityBoundingSet=、AmbientCapabilities= RestrictAddressFamilies=、RestrictSUIDSGID=、LockPersonality=` 对嵌入式建议：尽量开启 NoNewPrivileges、收窄 capability 集、文件系统 Protect、限制文件句柄与内存。\nsystemd 单元文件管理速查表 命令 用途 systemctl status \u0026lt;unit\u0026gt; 查看单元的当前状态、日志摘要等详细信息。 journalctl -fu \u0026lt;unit\u0026gt; 实时跟踪（follow）指定单元的日志输出。 systemctl cat \u0026lt;unit\u0026gt; 查看单元的最终合成配置（包含所有 drop-in 文件）。 systemctl list-dependencies \u0026lt;unit\u0026gt; 查看单元依赖的其他单元。 systemctl list-dependencies --reverse \u0026lt;unit\u0026gt; 查看依赖此单元的其他单元。 systemctl start \u0026lt;unit\u0026gt; 立即启动一个单元。只影响当前会话，不设置开机自启。 systemctl stop \u0026lt;unit\u0026gt; 立即停止一个单元。只影响当前会话，不影响开机自启设置。 systemctl restart \u0026lt;unit\u0026gt; 重启一个单元。 systemctl reload \u0026lt;unit\u0026gt; 重新加载单元的配置（需要单元自身支持）。 systemctl enable \u0026lt;unit\u0026gt; 设置开机自启。只创建符号链接，不会启动当前未运行的单元。 systemctl disable \u0026lt;unit\u0026gt; 取消开机自启。只移除符号链接，不会停止当前正在运行的单元。 systemctl enable dropbear.socket 示例：设置 dropbear 服务为开机 Socket 激活模式。 systemctl start dropbear.socket 示例：立即开始监听 dropbear 的套接字（通常在 enable 后可选执行）。 systemctl edit \u0026lt;unit\u0026gt; 使用 drop-in 文件覆盖部分配置（最佳实践）。 systemctl edit --full \u0026lt;unit\u0026gt; 完整编辑单元文件，覆盖默认配置。 systemctl daemon-reload 当手动修改磁盘上的单元文件后，执行此命令让 systemd 重新加载所有配置。 ","date":"16 September, 2025","id":16,"permalink":"/posts/systemd-%E5%8D%95%E5%85%83%E6%96%87%E4%BB%B6/","summary":"[[systemd]]","tags":"ubuntu systemd","title":"📘systemd 单元文件"},{"content":"📚 GMSL2 芯片 VDD LDO 调节器配置指南 概述 GMSL2芯片通过 REG_ENABLE 和 REG_MNL 两个寄存器位控制VDD LDO调节器，实现核心电路的精准供电管理。\n1. 硬件架构 1.1 LDO基本参数 输出电压：固定 1.0V 输入电压：外部 VDD（1.0V ~ 1.8V） 供电路径： LDO稳压路径：输出稳定1.0V，精度高、纹波小 旁路路径：VDD直通核心，无稳压功能 1.2 控制寄存器 寄存器位 地址 位置 功能 REG_ENABLE CTRL0[2] 0x17 手动控制电路供电使能 REG_MNL CTRL2[4] 0x19 模式选择开关 2. 寄存器详细定义 2.1 CTRL0 寄存器（地址: 0x17） 功能定位：远程唤醒使能、睡眠模式控制、VDD LDO调节器使能、本地唤醒禁用控制\n字段名 位位置 复位值 访问 功能描述 WAKE_EN_D 7 0b0 R/W Link D远程唤醒使能 WAKE_EN_C 6 0b0 R/W Link C远程唤醒使能 WAKE_EN_B 5 0b0 R/W Link B远程唤醒使能 WAKE_EN_A 4 0b1 R/W Link A远程唤醒使能 SLEEP 3 0b0 R/W 睡眠模式激活 REG_ENABLE 2 0x0 R/W VDD LDO调节器使能 DIS_LOCAL_WAKE[1:0] 1:0 0b0 R/W Port 0/1本地唤醒禁用 REG_ENABLE 解码 0b0：VDD LDO调节器禁用（旁路） 0b1：VDD LDO调节器启用（需配合 REG_MNL=1） 2.2 CTRL2 寄存器（地址: 0x19） 功能定位：VDD LDO调节器手动旁路控制\n字段名 位位置 复位值 访问 功能描述 RSVD 7 0x1 R/W 保留位 RSVD 6 0b0 R/W 保留位 RSVD 5 0x0 R/W 保留位 REG_MNL 4 0b0 R/W 手动旁路控制使能 RSVD[1:0] 2:1 0x1 R/W 保留位 RSVD[0] 0 0x0 R/W 保留位 REG_MNL 解码 0b0：自动模式（范围感应），旁路状态关闭 0b1：手动模式，旁路控制启用 3. 工作模式详解 3.1 自动模式（REG_MNL = 0） 芯片内部电压比较器根据VDD电压自动选择供电路径：\ngraph LR A[VDD输入] --\u0026gt; B{电压检测} B --\u0026gt;|VDD ≤ 1.05V| C[旁路模式] B --\u0026gt;|1.05V \u0026lt; VDD \u0026lt; 1.14V| D[盲区/抖动] B --\u0026gt;|VDD ≥ 1.14V| E[LDO稳压模式] 自动切换阈值 VDD ≤ 1.05V：压差不足，强制旁路 1.05V ~ 1.14V：硬件盲区，可能抖动 VDD ≥ 1.14V：压差充足（≥140mV），LDO稳压 [!warning] 临界区风险 在1.05V~1.14V范围内，比较器可能因电压波动导致模式反复切换\n3.2 手动模式（REG_MNL = 1） 软件强制控制LDO状态，绕过自动检测逻辑。\n前置条件 必须先置 REG_ENABLE = 1，否则手动控制电路处于断电状态，REG_MNL 设置无效。\n4. 双寄存器配合逻辑 4.1 硬件本质 寄存器位 硬件角色 功能说明 REG_MNL 模式选择开关 0=自动模式，1=手动模式 REG_ENABLE 供电使能 0=手动电路断电，1=手动电路上电 4.2 四种组合状态 REG_MNL REG_ENABLE 实际工作模式 0 0 自动模式 0 1 自动模式 1 0 自动模式（手动电路未上电） 1 1 手动模式（生效） [!important] 关键结论 只有 REG_ENABLE=1 且 REG_MNL=1 时，手动模式才真正生效\n4.3 硬件工作流程 graph TD A[VDD输入] --\u0026gt; B{REG_MNL?} B --\u0026gt;|0| C[自动模式] C --\u0026gt; D{电压检测} D --\u0026gt;|≥1.14V| E[LDO稳压] D --\u0026gt;|≤1.05V| F[旁路] D --\u0026gt;|盲区| G[可能抖动] B --\u0026gt;|1| H{REG_ENABLE?} H --\u0026gt;|0| C H --\u0026gt;|1| I[手动模式] I --\u0026gt; J[强制LDO稳压] 5. VDD=1.2V 临界问题分析 5.1 为什么1.2V是\u0026quot;坑点\u0026quot;？ 虽然1.2V在标称范围（1.0V~1.8V）内，但存在三重风险：\n极度靠近自动切换阈值\n1.2V距离1.14V仅60mV VDD波动±50mV即可跨越阈值 LDO压差接近极限\n实际压差：1.2V - 1.0V = 200mV 最小压差：140mV 裕量仅60mV 自动模式下的后果\nVDD波动 → 反复跨阈值 → LDO稳压⇄旁路疯狂切换 → 核心供电不稳 5.2 解决方案：强制手动模式 // 正确配置顺序 step1: REG_ENABLE = 1; // 上电手动控制电路 delay_us(1); // 等待稳定（1-2个I2C时钟周期） step2: REG_MNL = 1; // 切换到手动模式，强制LDO稳压 [!danger] 顺序错误的后果 如果先写 REG_MNL=1，再写 REG_ENABLE=1：\n手动控制电路未上电时，REG_MNL指令丢失 芯片继续运行在自动模式，问题依旧 6. 配置时序要求 6.1 标准配置流程 启用手动模式（VDD=1.2V）： ┌─────────────────────────────────────┐ │ 1. 写 REG_ENABLE = 1 │ │ ↓ │ │ 2. 延迟 1-2 个 I2C 时钟周期 │ │ ↓ │ │ 3. 写 REG_MNL = 1 │ │ ↓ │ │ 4. LDO 进入强制稳压状态 │ └─────────────────────────────────────┘ 6.2 时序细节 步骤 时间 说明 写REG_ENABLE t0 启动手动控制电路上电 稳定延迟 t0+几十ns 手动控制模块稳定 写REG_MNL t0+延迟 切换到手动路径 LDO响应 t0+延迟+响应 强制进入稳压状态 7. 工程实践指南 7.1 配置决策树 graph TD A[需要配置LDO] --\u0026gt; B{VDD电压?} B --\u0026gt;|≤1.05V| C[不支持LDO稳压\u0026lt;br/\u0026gt;只能旁路] B --\u0026gt;|1.05V~1.14V| D[临界区\u0026lt;br/\u0026gt;建议手动模式] B --\u0026gt;|1.14V~1.8V| E{稳定性要求?} E --\u0026gt;|高| F[手动模式\u0026lt;br/\u0026gt;强制稳压] E --\u0026gt;|一般| G[自动模式\u0026lt;br/\u0026gt;即可] B --\u0026gt;|1.2V| H[**必须手动模式**\u0026lt;br/\u0026gt;先REG_ENABLE=1\u0026lt;br/\u0026gt;再REG_MNL=1] 7.2 常见错误 错误操作 后果 正确做法 只设 REG_MNL=1 手动电路未上电，仍为自动模式 先设 REG_ENABLE=1 顺序颠倒 REG_MNL指令丢失 严格按序：ENABLE→MNL VDD=1.2V用自动模式 LDO稳压⇄旁路抖动 强制使用手动模式 未加延迟 手动电路未稳定 两次写操作间加延迟 7.3 代码示例 C语言配置（I2C接口） // VDD=1.2V 配置示例 void configure_ldo_for_1v2(void) { uint8_t ctrl0_val, ctrl2_val; // 1. 读取当前CTRL0值 i2c_read(GMSL2_ADDR, 0x17, \u0026amp;ctrl0_val); // 2. 设置REG_ENABLE=1（保持其他位不变） ctrl0_val |= (1 \u0026lt;\u0026lt; 2); i2c_write(GMSL2_ADDR, 0x17, ctrl0_val); // 3. 延迟等待稳定（至少1us） delay_us(2); // 4. 读取当前CTRL2值 i2c_read(GMSL2_ADDR, 0x19, \u0026amp;ctrl2_val); // 5. 设置REG_MNL=1（保持保留位不变） ctrl2_val |= (1 \u0026lt;\u0026lt; 4); i2c_write(GMSL2_ADDR, 0x19, ctrl2_val); // 6. 验证配置 verify_ldo_mode(); } Python配置示例 def configure_ldo_manual_mode(i2c_dev, vdd_voltage): \u0026#34;\u0026#34;\u0026#34; 配置GMSL2 LDO为手动模式 Args: i2c_dev: I2C设备对象 vdd_voltage: VDD电压值（V） \u0026#34;\u0026#34;\u0026#34; CTRL0_ADDR = 0x17 CTRL2_ADDR = 0x19 # 检查是否需要手动模式 if 1.05 \u0026lt;= vdd_voltage \u0026lt;= 1.25: print(f\u0026#34;VDD={vdd_voltage}V 在临界区，使用手动模式\u0026#34;) # Step 1: 设置 REG_ENABLE=1 ctrl0 = i2c_dev.read_byte(CTRL0_ADDR) ctrl0 |= (1 \u0026lt;\u0026lt; 2) i2c_dev.write_byte(CTRL0_ADDR, ctrl0) # Step 2: 延迟 time.sleep(0.000002) # 2us # Step 3: 设置 REG_MNL=1 ctrl2 = i2c_dev.read_byte(CTRL2_ADDR) ctrl2 |= (1 \u0026lt;\u0026lt; 4) i2c_dev.write_byte(CTRL2_ADDR, ctrl2) print(\u0026#34;LDO手动模式配置完成\u0026#34;) else: print(f\u0026#34;VDD={vdd_voltage}V 可使用自动模式\u0026#34;) 8. 调试与验证 8.1 验证清单 REG_ENABLE 已设置为1 已等待足够的稳定时间 REG_MNL 已设置为1 读回寄存器值验证配置 测量核心电路供电电压（应稳定在1.0V） 观察VDD波动时供电是否稳定 8.2 常见问题排查 症状 可能原因 排查方法 核心电压不稳定 仍在自动模式 读取CTRL0[2]和CTRL2[4]确认 配置无效 顺序错误 确认先ENABLE后MNL 间歇性故障 延迟不足 增加延迟时间 LDO无输出 VDD压差不足 检查VDD电压是否≥1.14V 9. 关键要点总结 [!summary] 核心结论 VDD=1.2V 必须用手动模式，且必须先 REG_ENABLE=1，再 REG_MNL=1，强制 LDO 稳压，避开自动模式的临界抖动。\n9.1 记忆要点 REG_MNL：模式选择开关\n0 = 自动模式（硬件决策） 1 = 手动模式（软件决策） REG_ENABLE：手动电路供电开关\n0 = 手动电路断电（REG_MNL无效） 1 = 手动电路上电（REG_MNL生效） 1.2V临界问题\n距离自动切换阈值1.14V仅60mV 压差仅200mV，裕量不足 自动模式下会导致LDO稳压⇄旁路抖动 配置顺序\nREG_ENABLE=1 → 延迟 → REG_MNL=1 顺序错误将导致配置失败\n10. 参考资料 10.1 相关寄存器 [[CTRL0寄存器详解]]（地址0x17） [[CTRL2寄存器详解]]（地址0x19） [[DEV_REG14寄存器]]（地址0xE，Port 2唤醒控制） 10.2 相关主题 [[LDO稳压器原理]] [[I2C寄存器配置]] [[GMSL2电源管理]] [[硬件调试技巧]] 附录：术语表 术语 英文 说明 LDO Low Dropout Regulator 低压差线性稳压器 VDD Voltage Drain Drain 芯片供电电压 旁路模式 Bypass Mode LDO不工作，VDD直通 稳压模式 Regulation Mode LDO主动稳压输出 压差 Dropout Voltage 输入输出电压差 DXA Document Units 文档单位（1440 DXA = 1英寸） RSID Revision Save ID 修订保存标识 附录：寄存器说明 寄存器 CTRL0 (地址: 0x17) 功能定位：远程唤醒使能、睡眠模式控制、VDD LDO调节器使能、本地唤醒禁用控制。\n字段名 位位置 复位值 访问类型 功能描述 解码说明 WAKE_EN_D 7 0b0 R/W 使能连接到Link D的远程芯片唤醒功能 0b0: Link D远程唤醒禁用0b1: Link D远程唤醒启用 WAKE_EN_C 6 0b0 R/W 使能连接到Link C的远程芯片唤醒功能 0b0: Link C远程唤醒禁用0b1: Link C远程唤醒启用 WAKE_EN_B 5 0b0 R/W 使能连接到Link B的远程芯片唤醒功能 0b0: Link B远程唤醒禁用0b1: Link B远程唤醒启用 WAKE_EN_A 4 0b1 R/W 使能连接到Link A的远程芯片唤醒功能 0b0: Link A远程唤醒禁用0b1: Link A远程唤醒启用 SLEEP 3 0b0 R/W 激活睡眠模式 0b0: 睡眠模式禁用0b1: 睡眠模式启用 REG_ENABLE 2 0x0 R/W VDD LDO调节器使能，与CTRL2的REG_MNL配合使用：- 当REG_MNL=1时，此位为1则调节器启用- 当REG_MNL=0时，手动控制不可用，需先设此位为1再写REG_MNL=1 0b0: VDD LDO调节器禁用（旁路）0b1: VDD LDO调节器启用（当REG_MNL=1时） DIS_LOCAL_WAKE[1:0] 1:0 0b0 R/W 禁用Port 0/1的本地唤醒（来自SDA_RX引脚）：- 位[1]控制Port 1- 位[0]控制Port 0Port 2的本地唤醒控制见DEV_REG14 (0xE) 0bX0: Port 0本地唤醒启用0bX1: Port 0本地唤醒禁用0b0X: Port 1本地唤醒启用0b1X: Port 1本地唤醒禁用 寄存器 CTRL2 (地址: 0x19) 功能定位：VDD LDO调节器手动旁路控制，其余为保留位。\n字段名 位位置 复位值 访问类型 功能描述 解码说明 RSVD 7 0x1 R/W 保留位，写操作需写入复位值，读操作返回当前值 - RSVD 6 0b0 R/W 保留位，写操作需写入复位值，读操作返回当前值 - RSVD 5 0x0 R/W 保留位，写操作需写入复位值，读操作返回当前值 - REG_MNL 4 0b0 R/W 使能VDD LDO调节器手动旁路控制，与CTRL0的REG_ENABLE配合使用 0b0: VDD LDO调节器范围感应开启，旁路状态关闭0b1: VDD LDO调节器旁路控制启用，当VDD=1.2V时，先设REG_ENABLE=1再写此位为1以启用调节器 RSVD[1:0] 2:1 0x1 R/W 保留位，写操作需写入复位值，读操作返回当前值 - RSVD[0] 0 0x0 R/W 保留位，写操作需写入复位值，读操作返回当前值 - 关键关联说明 REG_ENABLE (CTRL0[2]) 与 REG_MNL (CTRL2[4]) 的配合逻辑： 当需要手动控制VDD LDO调节器时，需先将 REG_ENABLE 置1，再将 REG_MNL 置1，此时调节器启用。 若 REG_MNL 为0，调节器处于范围感应模式，旁路状态关闭，手动控制不可用。 当VDD电压为1.2V时，必须遵循“先置REG_ENABLE=1，再置REG_MNL=1”的顺序来启用调节器。 标签：#GMSL2 #LDO #寄存器配置 #硬件调试\n","date":"16 September, 2025","id":17,"permalink":"/posts/-gmsl2-%E8%8A%AF%E7%89%87-vdd-ldo-%E8%B0%83%E8%8A%82%E5%99%A8%E9%85%8D%E7%BD%AE%E6%8C%87%E5%8D%97/","summary":"GMSL2芯片通过 REG_ENABLE 和 REG_MNL 两个寄存器位控制VDD LDO调节器，实现核心电路的精准供电管理。","tags":"ADI SERDES GMSL ldo vdd","title":"📚 GMSL2 芯片 VDD LDO 调节器配置指南"},{"content":"LDO（低压差线性稳压器）技术文档 📝 文档说明：本文档详细介绍LDO的工作原理、关键参数及应用要点\n1. LDO概述 1.1 定义 LDO（Low Dropout Regulator） 是一种低压差线性稳压器，属于电源管理芯片的重要组成部分。\n1.2 核心功能 将不稳定、电压偏高的输入电压 $V_{IN}$ 转换为稳定、精准的输出电压 $V_{OUT}$ 为芯片内部核心电路（CPU、SerDes、逻辑单元）提供稳定供电 采用线性稳压方式，通过消耗多余电压实现稳压（区别于开关电源的能量转换） 2. LDO基本结构 2.1 核心组件 LDO由四个核心模块组成：\ngraph LR A[输入VIN] --\u0026gt; B[调整管] B --\u0026gt; C[输出VOUT] C --\u0026gt; D[反馈网络] D --\u0026gt; E[误差放大器] F[参考电压源] --\u0026gt; E E --\u0026gt; B 2.1.1 调整管（Pass Transistor） 类型：功率MOS管或双极型晶体管 位置：串联在输入和输出之间 作用：导通程度决定输出电压 导通充分 → 压降小 导通受限 → 压降大 2.1.2 误差放大器（Error Amplifier） 实时比较反馈电压 $V_{FB}$ 与参考电压 $V_{REF}$ 输出控制信号调节调整管导通状态 2.1.3 参考电压源（Voltage Reference） 提供稳定、精准的基准电压（如0.8V、1.0V） 作为稳压的目标值 2.1.4 反馈网络（Feedback Network） 由电阻分压网络组成 将输出电压按比例缩小后反馈至误差放大器 3. 工作原理：负反馈稳压机制 3.1 闭环控制逻辑 目标设定 → 电压采样 → 误差检测 → 调整修正 → 稳定输出 ↑ ↓ └───────────────── 反馈 ─────────────────────┘ 3.2 详细步骤 目标设定：参考电压源提供基准电压 $V_{REF}$\n电压采样：反馈网络将输出电压分压得到反馈电压 $V_{FB}$\n误差检测：误差放大器比较 $V_{FB}$ 和 $V_{REF}$\n调整修正：\n情况A：$V_{OUT}$ 偏高 $$V_{FB} \u0026gt; V_{REF} \\Rightarrow \\text{误差放大器输出降低} \\Rightarrow \\text{调整管导通减小} \\Rightarrow \\text{压降增大} \\Rightarrow V_{OUT} \\downarrow$$\n情况B：$V_{OUT}$ 偏低 $$V_{FB} \u0026lt; V_{REF} \\Rightarrow \\text{误差放大器输出升高} \\Rightarrow \\text{调整管导通增大} \\Rightarrow \\text{压降减小} \\Rightarrow V_{OUT} \\uparrow$$\n通过持续的负反馈调节，LDO将输出电压稳定在目标值附近。\n4. 关键参数：压差（Dropout Voltage） 4.1 定义 压差 $V_{DO}$ 是指在保证输出电压稳定在额定值的前提下，输入电压与输出电压之间的最小差值。\n$$V_{IN(min)} = V_{OUT} + V_{DO}$$\n4.2 示例计算 例：某LDO额定输出 $V_{OUT} = 1.0V$，压差 $V_{DO} = 140mV$\n最小输入电压： $$V_{IN(min)} = 1.0V + 0.14V = 1.14V$$\n4.3 物理意义 压差本质上是调整管在最大导通状态下的压降：\n当 $V_{IN} = V_{OUT} + V_{DO}$ 时，调整管完全导通，压降达到最小值 当 $V_{IN} \u0026lt; V_{OUT} + V_{DO}$ 时，LDO失去稳压能力，进入dropout状态 输出电压随输入电压下降而下降 4.4 压差裕量设计原则 工作模式 压差值 LDO状态 说明 正常稳压 $V_{IN} - V_{OUT} \\gg V_{DO}$ 正常工作 推荐裕量≥2倍 $V_{DO}$ 临界状态 $V_{IN} - V_{OUT} \\approx V_{DO}$ 不稳定 易受负载波动影响 Dropout $V_{IN} - V_{OUT} \u0026lt; V_{DO}$ 失效 输出跟随输入下降 4.5 压差设计实例 例：某芯片内部LDO需要输出1.0V，压差为140mV\n不推荐：使用1.2V供电，压差仅200mV（1.43倍裕量） 推荐：使用1.4V供电，压差400mV（2.86倍裕量） 5. LDO应用案例分析 5.1 工作模式 场景：某高速SerDes芯片内部LDO，$V_{OUT} = 1.0V$，$V_{DO} = 140mV$\n5.1.1 不同供电电压下的工作状态 外部供电 实际压差 压差裕量 LDO状态 说明 1.2V 200mV 1.43× ⚠️ 临界 接近最小压差，易受干扰 1.15V 150mV 1.07× ⚠️ 危险 几乎达到极限 1.13V 130mV 0.93× ❌ Dropout 无法稳压，切换旁路 1.4V 400mV 2.86× ✅ 正常 足够裕量 5.2 临界工作点分析 当外部供电电压为1.2V时：\n$$\\text{压差} = 1.2V - 1.0V = 200mV = 1.43 \\times V_{DO}$$\n潜在问题：\n负载波动可能导致供电电压瞬间下降 如电压降至1.15V，压差仅为150mV（1.07倍 $V_{DO}$） LDO可能在\u0026quot;正常稳压\u0026quot;和\u0026quot;dropout\u0026quot;模式间反复切换 导致输出电压不稳定，影响系统可靠性 解决方案：\n提高输入电压：使用1.4V以上供电，确保充足压差裕量 强制工作模式：手动控制LDO工作模式，避免自动切换 增加输入滤波：减少供电电压波动 优化负载设计：降低负载电流突变幅度 6. LDO特性分析 6.1 优点 特性 说明 适用场景 纹波小、噪声低 无开关频率，输出干净 模拟电路、高速SerDes 响应快 闭环带宽高 负载快速变化场景 电路简单 无需电感等复杂元件 空间受限应用 成本低 集成度高 消费电子 6.2 缺点 6.2.1 效率问题 转换效率公式：\n$$\\eta = \\frac{V_{OUT}}{V_{IN}} \\times 100%$$\n示例：\n输入1.8V，输出1.0V：$\\eta = 55.6%$ 输入3.3V，输出1.0V：$\\eta = 30.3%$ ⚠️ 注意：压差越大，效率越低，发热越严重\n6.2.2 功耗与散热 调整管功耗：\n$$P_{dissipation} = (V_{IN} - V_{OUT}) \\times I_{OUT}$$\n设计要点：\n大电流应用需考虑散热设计 选择合适封装（如散热增强型封装） 必要时添加散热片 6.2.3 输入电压范围 必须满足：\n$$V_{IN} \u0026gt; V_{OUT} + V_{DO}$$\n否则无法正常稳压。\n7. LDO选型要点 7.1 关键参数清单 参数 考量因素 设计建议 压差 $V_{DO}$ 最小输入电压要求 留2-3倍裕量 输出电流 $I_{OUT}$ 负载需求 留20-30%余量 输出电压精度 稳压精度要求 典型±1%~±3% PSRR 输入纹波抑制 高速电路需\u0026gt;60dB 噪声 输出噪声电压 敏感电路需\u0026lt;50μVrms 静态电流 $I_Q$ 待机功耗 电池供电需\u0026lt;10μA 热阻 $\\theta_{JA}$ 散热能力 根据功耗计算结温 7.2 应用注意事项 输入输出电容配置 输入电容：通常1-10μF，抑制输入噪声 输出电容：根据datasheet要求，影响稳定性和瞬态响应 ESR要求：部分LDO对输出电容ESR有特定要求 负载瞬态响应 负载突变时输出电压会产生下冲/上冲 通过增大输出电容或选择快速响应LDO改善 热设计 结温计算公式：\n$$T_J = T_A + P_{dissipation} \\times \\theta_{JA}$$\n确保 $T_J \u0026lt; T_{J(max)}$（通常125-150°C）\n8. 总结 8.1 LDO核心要点 工作原理：基于负反馈的线性稳压 关键参数：压差决定最小输入电压要求 优势：低噪声、快响应、电路简单 劣势：效率低、发热大、输入范围受限 8.2 设计黄金法则 💡 压差裕量充足 + 合理热设计 + 适当电容配置 = 稳定可靠的LDO应用\n8.3 典型应用场景 graph TD A[LDO应用] --\u0026gt; B[数字电路供电] A --\u0026gt; C[模拟电路供电] A --\u0026gt; D[RF电路供电] A --\u0026gt; E[传感器供电] B --\u0026gt; F[CPU核心电压] C --\u0026gt; G[ADC/DAC参考电压] D --\u0026gt; H[VCO/PLL电源] E --\u0026gt; I[低功耗传感器] 参考资源 📚 LDO数据手册（各厂商） 📐 电源设计工具（TI WEBENCH、ADI Design Tools） 🔧 PCB Layout指南（输入输出电容布局、散热设计）s ","date":"16 September, 2025","id":18,"permalink":"/posts/ldo%E4%BD%8E%E5%8E%8B%E5%B7%AE%E7%BA%BF%E6%80%A7%E7%A8%B3%E5%8E%8B%E5%99%A8%E5%9F%BA%E7%A1%80%E8%AE%B2%E8%A7%A3/","summary":"📝 文档说明：本文档详细介绍LDO的工作原理、关键参数及应用要点","tags":"ldo power","title":"📚LDO（低压差线性稳压器）基础讲解"},{"content":"📘SVN 服务器环境搭建 环境声明 ubuntu 24.04\nlsb_release -a No LSB modules are available. Distributor ID: Ubuntu Description: Ubuntu 24.04.3 LTS Release: 24.04 Codename: noble 安装服务端 subversion sudo apt install subversion svn --version svn, version 1.14.3 (r1914484) compiled Apr 1 2024, 04:55:49 on x86_64-pc-linux-gnu Copyright (C) 2023 The Apache Software Foundation. This software consists of contributions made by many people; see the NOTICE file for more information. Subversion is open source software, see http://subversion.apache.org/ The following repository access (RA) modules are available: * ra_svn : Module for accessing a repository using the svn network protocol. - with Cyrus SASL authentication - handles \u0026#39;svn\u0026#39; scheme * ra_local : Module for accessing a repository on local disk. - handles \u0026#39;file\u0026#39; scheme * ra_serf : Module for accessing a repository via WebDAV protocol using serf. - using serf 1.3.10 (compiled with 1.3.10) - handles \u0026#39;http\u0026#39; scheme - handles \u0026#39;https\u0026#39; scheme The following authentication credential caches are available: * Plaintext cache in /home/luyang/.subversion * Gnome Keyring * GPG-Agent * KWallet (KDE) 创建版本库 mkdir -p /home/luyang/svn cd /home/luyang/svn sudo svnadmin create material sudo chmod 777 material -R ls material/ README.txt conf/ db/ format hooks/ locks/ 修改 SVN 配置 高端配置\nconf/authz\n[aliases] # demo_alias = /C=XX/ST=YY/L=ZZ/O=Demo Corp/OU=Research/CN=John Doe [groups] manager = user1,user2 hardware = user3,user4 software = user5,user6 algo = user2,user7,user5 # [/foo/bar] # userA = rw # \u0026amp;demo_alias = r # * = # [repository:/baz/fuz] # @group_demo = rw # * = r [material:/] @manager = rw @hardware = rw @software = rw @algo = rw * = /conf/passwd\n[users] user1 = pass_user1 user2 = pass_user2 user3 = pass_user3 user4 = pass_user4 user5 = pass_user5 user6 = pass_user6 user7 = pass_user7 重启 svn 服务 sudo svnserve -d -r /home/luyang/workspace/svn/ ps aux | grep svnserve root 128325 0.0 0.0 16580 2476 ? Ss 13:05 0:00 svnserve -d -r material/ luyang 128450 0.0 0.0 4092 1920 pts/4 S+ 13:05 0:00 grep --color=auto svnserve svn 默认端口：3690\nss -tuln | grep 3690 tcp LISTEN 0 128 0.0.0.0:3690 0.0.0.0:* 客户端检出仓库 安装 TortoiseSVN ![[Pasted image 20250910140302.png]] 检出仓库，注意路径： 服务端启动时已经通过 -r /home/luyang/workspace/svn/ 而我们的 material 仓库位于该目录下因此 svn co 路径可以忽略 -r 指定的部分。 ","date":"10 September, 2025","id":19,"permalink":"/posts/svn-%E6%9C%8D%E5%8A%A1%E5%99%A8%E7%8E%AF%E5%A2%83%E6%90%AD%E5%BB%BA/","summary":"ubuntu 24.04","tags":"svn ubuntu","title":"📘SVN 服务器环境搭建"},{"content":"📘使用 nvm 安装最新版本的 nodejs npm 安装最新版本的 nvm 确认 nvm 最新版本 https://github.com/nvm-sh/nvm/releases 2025-09-09 v0.40.3\nsudo pacman -Syu curl curl -o- https://raw.githubusercontent.com/nvm-sh/nvm/v0.40.3/install.sh | bash ➜ workspace curl -o- https://raw.githubusercontent.com/nvm-sh/nvm/v0.40.3/install.sh | bash % Total % Received % Xferd Average Speed Time Time Time Current Dload Upload Total Spent Left Speed 100 16631 100 16631 0 0 66591 0 --:--:-- --:--:-- --:--:-- 66791 =\u0026gt; Downloading nvm from git to \u0026#39;/home/luyang/.nvm\u0026#39; =\u0026gt; Cloning into \u0026#39;/home/luyang/.nvm\u0026#39;... remote: Enumerating objects: 383, done. remote: Counting objects: 100% (383/383), done. remote: Compressing objects: 100% (326/326), done. remote: Total 383 (delta 43), reused 178 (delta 29), pack-reused 0 (from 0) Receiving objects: 100% (383/383), 391.78 KiB | 1.57 MiB/s, done. Resolving deltas: 100% (43/43), done. * (HEAD detached at FETCH_HEAD) master =\u0026gt; Compressing and cleaning up git repository =\u0026gt; Appending nvm source string to /home/luyang/.zshrc =\u0026gt; Appending bash_completion source string to /home/luyang/.zshrc =\u0026gt; Close and reopen your terminal to start using nvm or run the following to use it now: export NVM_DIR=\u0026#34;$HOME/.nvm\u0026#34; [ -s \u0026#34;$NVM_DIR/nvm.sh\u0026#34; ] \u0026amp;\u0026amp; \\. \u0026#34;$NVM_DIR/nvm.sh\u0026#34; # This loads nvm [ -s \u0026#34;$NVM_DIR/bash_completion\u0026#34; ] \u0026amp;\u0026amp; \\. \u0026#34;$NVM_DIR/bash_completion\u0026#34; # This loads nvm bash_completion source ~/.zshrc ➜ workspace source ~/.zshrc ➜ workspace nvm --version 0.40.3 安装最新版本的 Node.js 和 npm 安装最新的稳定版（Stable）\nnvm install stable 或安装最新的LTS版本（长期支持版，推荐生产环境）\nnvm install --lts 安装完成后，设置为默认版本：\n# 将刚安装的版本设为默认（下次打开终端自动生效） nvm use default 验证安装\n检查 Node.js 和 npm 版本：\n➜ workspace nvm ls v22.19.0 -\u0026gt; v24.7.0 default -\u0026gt; v24.7.0 iojs -\u0026gt; N/A (default) unstable -\u0026gt; N/A (default) node -\u0026gt; stable (-\u0026gt; v24.7.0) (default) stable -\u0026gt; 24.7 (-\u0026gt; v24.7.0) (default) nlts/* -\u0026gt; lts/jod (-\u0026gt; v22.19.0) lts/argon -\u0026gt; v4.9.1 (-\u0026gt; N/A) lts/boron -\u0026gt; v6.17.1 (-\u0026gt; N/A) lts/carbon -\u0026gt; v8.17.0 (-\u0026gt; N/A) lts/dubnium -\u0026gt; v10.24.1 (-\u0026gt; N/A) lts/erbium -\u0026gt; v12.22.12 (-\u0026gt; N/A) lts/fermium -\u0026gt; v14.21.3 (-\u0026gt; N/A) lts/gallium -\u0026gt; v16.20.2 (-\u0026gt; N/A) lts/hydrogen -\u0026gt; v18.20.8 (-\u0026gt; N/A) lts/iron -\u0026gt; v20.19.5 (-\u0026gt; N/A) lts/jod -\u0026gt; v22.19.0 ➜ workspace node -v v24.7.0 ➜ workspace npm -v 11.5.1 配置默认版本以及版本切换方法 在 nvm 中，即使同时安装了 stable（最新稳定版）和 --lts（最新长期支持版），也可以通过以下步骤将指定版本设置为默认版本（即新终端打开时自动生效的版本）：\n步骤 1：查看已安装的 Node.js 版本 首先，确认你已安装的所有 Node.js 版本及其标识（版本号或别名）：\nnvm ls 输出示例（不同版本号会随时间变化）：\n-\u0026gt; v22.19.0 v24.7.0 default -\u0026gt; v22.19.0 iojs -\u0026gt; N/A (default) unstable -\u0026gt; N/A (default) node -\u0026gt; stable (-\u0026gt; v24.7.0) (default) stable -\u0026gt; 24.7 (-\u0026gt; v24.7.0) (default) lts/* -\u0026gt; lts/jod (-\u0026gt; v22.19.0) lts/argon -\u0026gt; v4.9.1 (-\u0026gt; N/A) lts/boron -\u0026gt; v6.17.1 (-\u0026gt; N/A) lts/carbon -\u0026gt; v8.17.0 (-\u0026gt; N/A) lts/dubnium -\u0026gt; v10.24.1 (-\u0026gt; N/A) lts/erbium -\u0026gt; v12.22.12 (-\u0026gt; N/A) lts/fermium -\u0026gt; v14.21.3 (-\u0026gt; N/A) lts/gallium -\u0026gt; v16.20.2 (-\u0026gt; N/A) lts/hydrogen -\u0026gt; v18.20.8 (-\u0026gt; N/A) lts/iron -\u0026gt; v20.19.5 (-\u0026gt; N/A) lts/jod -\u0026gt; v22.19.0 从输出中找到你想设置为默认的版本号（如 v24.7.0）。\n步骤 2：设置指定版本为默认 使用 nvm alias default 命令，将目标版本设为默认：\nnvm alias default v24.7.0 步骤 3：验证默认版本是否生效 重新打开一个终端（默认版本仅对新终端生效），或在当前终端手动切换到默认版本：\nnvm use default 检查当前使用的版本：\nnode -v # 输出应为你设置的默认版本号 再次通过 nvm ls 确认 default 已指向目标版本：\nnvm ls 输出中会显示 default -\u0026gt; v目标版本号，表示设置成功。\n","date":"9 September, 2025","id":20,"permalink":"/posts/%E4%BD%BF%E7%94%A8-nvm-%E5%AE%89%E8%A3%85%E6%9C%80%E6%96%B0%E7%89%88%E6%9C%AC%E7%9A%84-nodejs-npm/","summary":"安装最新的稳定版（Stable）","tags":"linux blog Arch node nodejs npm nvm quartz","title":"📘 使用 nvm 安装最新版本的 nodejs npm"},{"content":"📘 Android 14 上搭建 NDK 开发环境需要通过 Android Studio 和 NDK r27+ 进行配置 ## 1. 安装依赖 ```bash sudo apt update sudo apt install openjdk-17-jdk cmake ninja-build unzip git -y JDK 虽然主要用于 Android 构建系统，但有些工具依赖。\n2. 下载并配置 NDK 去 Google NDK 下载页面 下载 NDK r27b (Linux 版本)。\nLinux 64-bit (x86) android-ndk-r27d-linux.zip\nwget https://dl.google.com/android/repository/android-ndk-r27d-linux.zip unzip android-ndk-r27d-linux.zip -d $HOME/ 配置环境变量（写入 ~/.bashrc）：\nexport ANDROID_NDK_HOME=$HOME/android-ndk-r27d export PATH=$PATH:$ANDROID_NDK_HOME/toolchains/llvm/prebuilt/linux-x86_64/bin 应用：\nsource ~/.bashrc 3. 确认交叉编译工具链 NDK r26+ 使用 Clang/LLVM toolchain，支持 Android 14 (API 34)。\n检查工具链：\n$ clang --version Android (6443078, based on r416183b1) clang version 14.0.6 ... 常用交叉编译器前缀（API 34，arm64-v8a 为例）：\naarch64-linux-android34-clang\narmv7a-linux-androideabi34-clang\ni686-linux-android34-clang\nx86_64-linux-android34-clang\n问题 luyang@xretinai:~$ tail ~/.bashrc if [ -f /usr/share/bash-completion/bash_completion ]; then . /usr/share/bash-completion/bash_completion elif [ -f /etc/bash_completion ]; then . /etc/bash_completion fi fi export ANDROID_NDK_HOME=$HOME/android-ndk-r27d export PATH=$PATH:$ANDROID_NDK_HOME/toolchains/llvm/prebuilt/linux-x86_64/bin luyang@xretinai:~$ source ~/.bashrc luyang@xretinai:~$ clang --version Command \u0026#39;clang\u0026#39; not found, but can be installed with: sudo apt install clang 从 NDK r19 开始，Google 移除了 clang 这种“裸命令”，改成了 带三元组的 clang 驱动。\n所以你在 $ANDROID_NDK_HOME/toolchains/llvm/prebuilt/linux-x86_64/bin/ 目录下，能看到的是：\nluyang@xretinai:~$ ls android-ndk-r27d/toolchains/llvm/prebuilt/linux-x86_64/bin/aarch64-linux-android* -lah -rwxr-xr-x 1 luyang luyang 201 Jul 9 03:52 android-ndk-r27d/toolchains/llvm/prebuilt/linux-x86_64/bin/aarch64-linux-android21-clang -rwxr-xr-x 1 luyang luyang 205 Jul 9 03:52 android-ndk-r27d/toolchains/llvm/prebuilt/linux-x86_64/bin/aarch64-linux-android21-clang++ -rwxr-xr-x 1 luyang luyang 201 Jul 9 03:52 android-ndk-r27d/toolchains/llvm/prebuilt/linux-x86_64/bin/aarch64-linux-android22-clang -rwxr-xr-x 1 luyang luyang 205 Jul 9 03:52 android-ndk-r27d/toolchains/llvm/prebuilt/linux-x86_64/bin/aarch64-linux-android22-clang++ ... -rwxr-xr-x 1 luyang luyang 201 Jul 9 03:52 android-ndk-r27d/toolchains/llvm/prebuilt/linux-x86_64/bin/aarch64-linux-android34-clang -rwxr-xr-x 1 luyang luyang 205 Jul 9 03:52 android-ndk-r27d/toolchains/llvm/prebuilt/linux-x86_64/bin/aarch64-linux-android34-clang++ -rwxr-xr-x 1 luyang luyang 201 Jul 9 03:52 android-ndk-r27d/toolchains/llvm/prebuilt/linux-x86_64/bin/aarch64-linux-android35-clang -rwxr-xr-x 1 luyang luyang 205 Jul 9 03:52 android-ndk-r27d/toolchains/llvm/prebuilt/linux-x86_64/bin/aarch64-linux-android35-clang++ 测试：\nluyang@xretinai:~$ aarch64-linux-android35-clang++ --version Android (13691557, +pgo, +bolt, +lto, +mlgo, based on r522817d) clang version 18.0.4 (https://android.googlesource.com/toolchain/llvm-project d8003a456d14a3deb8054cdaa529ffbf02d9b262) Target: aarch64-unknown-linux-android35 Thread model: posix InstalledDir: /home/luyang/android-ndk-r27d/toolchains/llvm/prebuilt/linux-x86_64/bin 4. 创建 CMake 工程 工程目录 ndk-demo/ ├── CMakeLists.txt ├── src/ │ └── main.cpp main.cpp #include \u0026lt;iostream\u0026gt; int main() { std::cout \u0026lt;\u0026lt; \u0026#34;Hello from Android NDK r26 on Ubuntu 24.04!\u0026#34; \u0026lt;\u0026lt; std::endl; return 0; } CMakeLists.txt cmake_minimum_required(VERSION 3.22) project(ndk_demo) set(CMAKE_CXX_STANDARD 17) add_executable(ndk_demo src/main.cpp) 5. 交叉编译配置 NDK 提供 CMake toolchain 文件：\n${ANDROID_NDK_HOME}/build/cmake/android.toolchain.cmake\n构建命令（以 arm64-v8a / API 35 为例）：\nmkdir build \u0026amp;\u0026amp; cd build cmake .. \\ -DCMAKE_TOOLCHAIN_FILE=$ANDROID_NDK_HOME/build/cmake/android.toolchain.cmake \\ -DANDROID_ABI=arm64-v8a \\ -DANDROID_PLATFORM=android-35 \\ -DCMAKE_BUILD_TYPE=Release cmake --build . 生成结果：\nbuild/ └── ndk_demo (Android ARM64 可执行文件) 6. 验证可执行文件 检查目标架构：\nfile build/ndk_demo 输出应类似：\nbuild/ndk_demo: ELF 64-bit LSB pie executable, ARM aarch64, version 1 (SYSV), dynamically linked, interpreter /system/bin/linker64, BuildID[sha1]=c8d078ba8f6c9835abf3463e9032debf03ecc7d5, with debug_info, not stripped 拷贝到设备：\nadb push build/ndk_demo /data/ adb shell \u0026#34;chmod +x /data/ndk_demo \u0026amp;\u0026amp; /data/ndk_demo\u0026#34; 运行输出：\nHello from Android NDK r26 on Ubuntu 24.04! ","date":"8 September, 2025","id":21,"permalink":"/posts/android-14-%E4%B8%8A%E6%90%AD%E5%BB%BA-ndk-%E5%BC%80%E5%8F%91%E7%8E%AF%E5%A2%83%E9%9C%80%E8%A6%81%E9%80%9A%E8%BF%87-android-studio-%E5%92%8C-ndk-r27+-%E8%BF%9B%E8%A1%8C%E9%85%8D%E7%BD%AE/","summary":"JDK 虽然主要用于 Android 构建系统，但有些工具依赖。","tags":"AArch64 ARM android ndk","title":"📘Android 14 上搭建 NDK 开发环境需要通过 Android Studio 和 NDK r27+ 进行配置"},{"content":"📘 bin 文件内容特征与编辑器打开模式行为分析 —— 以 UltraEdit 和二进制数据结构为案例剖析\n一、背景与问题现象 在使用 [[UltraEdit]]、HxD、VSCode 等文本或十六进制编辑器查看 .bin 文件时，经常会遇到以下现象：\n有些 .bin 文件一打开就是 十六进制视图 有些 .bin 文件却被当作 普通文本文件显示，看到一堆“乱码”或 ASCII 字符 这种行为并不是 bug，而是由编辑器的智能判断逻辑所决定的。\n二、bin 文件的本质 ✅ bin 是什么？ .bin 文件本质是“原始二进制数据的连续存储”，不包含结构定义、元数据或格式头。\n特点如下：\n特性 描述 原始性 没有文件头、格式标记、符号等 结构透明性 实际含义需由上下文或程序代码解析（结构体/位图等） 广泛用途 存储固件、配置段、内存转储、Flash 镜像、资源文件等 三、UltraEdit 打开 bin 文件的“模式判断机制” 📌 默认逻辑（推测自长期使用） UltraEdit 在打开 .bin 文件时，会根据文件内容前若干字节来判断：\n是否为“文本”文件（显示为 ASCII） 是否为“二进制”文件（启用十六进制编辑模式） 🚦 判断依据（经验总结）： 条件 UltraEdit 默认行为 文件前几个字节大部分为 ASCII 可打印字符（0x20~0x7E） 默认以 文本模式 打开 包含大量控制字符或不可打印字节（0x00、0xFF、0x80~） 默认以 十六进制模式 打开 📌 举例说明： 文件内容（前几字节） UltraEdit 行为 41 42 43 0A 44 45（ASCII: \u0026ldquo;ABC\\nDE\u0026rdquo;） 文本模式（ASCII 显示） 00 FF 80 1F CD AB（含非打印字节） 十六进制模式 四、演示 Demo（实验证明） 我们设计了一个简洁的 Demo 程序，生成两个 .bin 文件：\n#include \u0026lt;fstream\u0026gt; #include \u0026lt;iostream\u0026gt; #include \u0026lt;cstdint\u0026gt; void writeAsciiLikeFile(const std::string\u0026amp; filename) { std::ofstream ofs(filename, std::ios::binary); for (int i = 0x20; i \u0026lt;= 0x7E; ++i) ofs.put(static_cast\u0026lt;uint8_t\u0026gt;(i)); ofs \u0026lt;\u0026lt; \u0026#34;\\r\\nHelloWorld123\\n\u0026#34;; } void writeBinaryLikeFile(const std::string\u0026amp; filename) { std::ofstream ofs(filename, std::ios::binary); for (int i = 0x00; i \u0026lt;= 0x1F; ++i) ofs.put(static_cast\u0026lt;uint8_t\u0026gt;(i)); for (int i = 0x80; i \u0026lt;= 0xFF; ++i) ofs.put(static_cast\u0026lt;uint8_t\u0026gt;(i)); for (int i = 0; i \u0026lt; 16; ++i) ofs.put(0x00); for (int i = 0; i \u0026lt; 16; ++i) ofs.put(0xFF); } int main() { writeAsciiLikeFile(\u0026#34;ascii_like.bin\u0026#34;); writeBinaryLikeFile(\u0026#34;binary_like.bin\u0026#34;); std::cout \u0026lt;\u0026lt; \u0026#34;两个 bin 文件已生成，请用 UltraEdit 打开验证打开模式差异。\\n\u0026#34;; return 0; } 运行结果文件对比： 文件名 内容特征 UltraEdit 默认模式 ascii_like.bin 包含 0x20~0x7E 的可打印字符为主 文本模式，显示为字符 binary_like.bin 包含 0x00、0xFF、0x80 等非文本字节 十六进制模式 UltraEdit default view of ascii_like.bin\nUltraEdit default view of binary_like.bin\nUltraEdit hex view of ascii_like.bin\nxxd default view\n✅ 小结： 这证实了：UltraEdit 并不是通过扩展名 .bin 决定打开方式，而是通过内容猜测文件类型。\n五、为什么这是一个重要知识点？ 当你调试嵌入式固件、分析存储格式或设计通信协议时：\n你需要明确知道 bin 文件的结构和意义 编辑器可能误导你看到的内容（显示为乱码/文本） 确保编辑器使用正确模式打开，防止误改、误读 六、如何手动控制 UltraEdit 行为 ✅ 切换为十六进制模式： 快捷键：Ctrl + H 菜单：编辑 → 十六进制模式 ✅ 设置固定扩展名默认 Hex 打开： 路径： 设置（Advanced） → 文件处理 → 二进制文件识别\n在里面添加扩展名，例如：\n*.bin; *.dat; *.raw 七、跨平台建议和工具对比 工具 默认打开 bin 行为 是否可强制十六进制 UltraEdit 按内容猜测 ✅（Ctrl+H） HxD 默认十六进制 ✅ xxd 十六进制命令行 ✅ VSCode + Hex 插件 需手动打开 Hex 视图 ✅ Notepad++ 按文本打开 ❌ 不推荐查看 bin 八、开发建议 场景 推荐做法 写入结构体数据到 bin 使用 #pragma pack(1) 避免结构体 padding 避免 UltraEdit 把 bin 当作文本打开 文件中加入明显的非 ASCII 字节（如 0x00, 0xFF） 设计 bin 文件头 可用 magic number（如 0xAA55）标记为 binary 格式 使用十六进制工具调试 结合 xxd、HxD、UltraEdit 十六进制视图 保证数据一致性 读/写时使用同一端序、对齐策略，并明确结构体布局 九、附录：推荐调试命令 xxd ascii_like.bin | head xxd binary_like.bin | head #include \u0026lt;cstddef\u0026gt; std::cout \u0026lt;\u0026lt; offsetof(MyStruct, field); // 查看偏移 十、总结 .bin 文件的显示方式与其内容紧密相关。理解编辑器行为不仅能避免“乱码困惑”，更是确保你正确解析、修改、调试二进制文件的重要前提。\n","date":"13 July, 2025","id":22,"permalink":"/posts/bin-%E6%96%87%E4%BB%B6%E5%86%85%E5%AE%B9%E7%89%B9%E5%BE%81%E4%B8%8E%E7%BC%96%E8%BE%91%E5%99%A8%E6%89%93%E5%BC%80%E6%A8%A1%E5%BC%8F%E8%A1%8C%E4%B8%BA%E5%88%86%E6%9E%90/","summary":"—— 以 UltraEdit 和二进制数据结构为案例剖析","tags":"cpp bin","title":"📘 bin 文件内容特征与编辑器打开模式行为分析"},{"content":"📘GMSL2 I2C别名与PEC校验的冲突：深层技术解析、根本性解决方案与安全考量 摘要 在汽车电子领域，GMSL2（Gigabit Multimedia Serial Link 2）因其高带宽、低延迟的传感器数据传输能力而被广泛应用。其I2C别名功能解决了相同设备（如图像传感器）之间的地址冲突问题，而SMBus/I2C的PEC（Packet Error Checking，数据包错误校验）则增强了通信的可靠性。然而，同时使用这两种功能时，PEC校验会失效，原因在于两者存在固有的不兼容性。本文深入剖析了这一问题，将其归类为“泄露的抽象”，并提供了一个实用的应用层解决方案。\n1. 引言：汽车系统中的通信挑战 随着ADAS（高级驾驶辅助系统）和自动驾驶技术的发展，现代汽车依赖于大量传感器，这些传感器产生海量数据流。GMSL2由Analog Devices开发，凭借其6 Gbps的带宽和15米的传输距离，广泛用于连接传感器和中央处理器。然而，两个挑战随之而来：\nI2C地址冲突：多个相同的传感器（如摄像头）共享相同的I2C地址，导致通信冲突。 数据可靠性：汽车内部的电磁干扰（EMI）可能损坏I2C控制消息，对安全性构成威胁。 GMSL2的I2C别名功能解决了地址冲突问题，而PEC则确保了数据的完整性。然而，同时使用这两种功能会导致PEC校验失败，危及系统稳定性。\n2. GMSL2与I2C别名：工作原理 2.1 GMSL2 SerDes架构 GMSL2采用串行器/解串器（SerDes）架构。传感器端的串行器将数据转换为串行流，处理器端的解串器将其还原。双向控制通道（包括I2C）实现了主机与远程设备之间的透明通信。\n2.2 I2C别名机制 I2C别名通过将唯一别名地址（主机使用）映射到真实地址（远程设备使用）来解决地址冲突。解串器硬件无缝执行这一转换：\n示例：两个真实地址为0x1A的摄像头被分配别名0x70和0x72。主机使用别名通信，解串器将其重映射为0x1A发送给相应设备。 这一抽象简化了系统设计，但与PEC结合使用时会引发问题。\n3. SMBus/I2C PEC：确保可靠性 PEC使用CRC-8校验和（多项式x^8 + x^2 + x^1 + 1）附加到I2C消息中，覆盖整个消息（包括地址字节和数据），确保端到端的数据完整性。如果接收方计算的PEC与发送的PEC不匹配，则通过NACK信号报告错误。\n4. 冲突根源：泄露的抽象 问题的根源在于PEC计算中的地址不匹配：\n主机：使用别名地址（如0x70 → 0xE0含写位）计算PEC。 解串器：将别名转换为真实地址（如0x1A → 0x34）后转发。 远程设备：使用其真实地址（0x34）验证PEC。 由于CRC-8对每个输入字节敏感，不同的地址会导致PEC不一致，校验失败。这是一个“泄露的抽象”——GMSL2的别名功能隐藏了地址转换，但PEC依赖于原始地址，暴露了这一细节。\n5. 根本性解决方案：应用层I2C重构 为解决此问题，需将通信地址（别名）与PEC计算地址（真实）解耦。标准I2C API会自动使用事务地址计算PEC，因此我们使用Linux的I2C_RDWR ioctl绕过这一限制。\n5.1 实施步骤 禁用内核PEC\n阻止自动PEC计算：\nioctl(fd, I2C_PEC, 0); 手动计算PEC\n使用真实地址进行CRC-8计算：\nuint8_t real_addr = 0x1A; uint8_t data[] = {0xAB, 0xCD}; uint8_t pec_input[] = {(real_addr \u0026lt;\u0026lt; 1) | 0, 0xAB, 0xCD}; uint8_t pec = crc8(pec_input, 3); // 自定义CRC-8函数 构建I2C负载\n将计算的PEC附加到数据中：\nuint8_t payload[] = {0xAB, 0xCD, pec}; 使用I2C_RDWR发送\n使用别名地址进行事务：\nstruct i2c_msg msg = { .addr = 0x70, // 别名地址 .flags = 0, .len = sizeof(payload), .buf = payload }; struct i2c_rdwr_ioctl_data data = { \u0026amp;msg, 1 }; ioctl(fd, I2C_RDWR, \u0026amp;data); 5.2 完整示例代码 #include \u0026lt;linux/i2c-dev.h\u0026gt; #include \u0026lt;sys/ioctl.h\u0026gt; #include \u0026lt;fcntl.h\u0026gt; #include \u0026lt;unistd.h\u0026gt; uint8_t crc8(uint8_t *data, size_t len) { uint8_t crc = 0; for (size_t i = 0; i \u0026lt; len; i++) { crc ^= data[i]; for (int j = 0; j \u0026lt; 8; j++) crc = (crc \u0026amp; 0x80) ? (crc \u0026lt;\u0026lt; 1) ^ 0x07 : crc \u0026lt;\u0026lt; 1; } return crc; } int main() { int fd = open(\u0026#34;/dev/i2c-0\u0026#34;, O_RDWR); ioctl(fd, I2C_PEC, 0); uint8_t real_addr = 0x1A, alias_addr = 0x70; uint8_t data[] = {0xAB, 0xCD}; uint8_t pec_input[] = {(real_addr \u0026lt;\u0026lt; 1) | 0, 0xAB, 0xCD}; uint8_t pec = crc8(pec_input, 3); uint8_t payload[] = {0xAB, 0xCD, pec}; struct i2c_msg msg = {alias_addr, 0, sizeof(payload), payload}; struct i2c_rdwr_ioctl_data tx = {\u0026amp;msg, 1}; ioctl(fd, I2C_RDWR, \u0026amp;tx); close(fd); return 0; } 此方法确保远程设备接收到与其真实地址匹配的PEC，校验成功。\n6. 安全考量 在符合ISO 26262的汽车系统中，可靠通信至关重要。此解决方案：\n保持了PEC的错误检测能力。 保留了别名的可扩展性。 无需硬件修改，适用于现有设计。 开发者应验证CRC-8实现并测试边缘情况（如EMI引起的位翻转），以确保功能安全。\n7. 结论 GMSL2 I2C别名与PEC的冲突表明，复杂系统中的抽象可能失效。通过深入了解协议机制并在应用层实施定制解决方案，我们在不牺牲可靠性和可扩展性的前提下解决了这一问题。这一方法强调了深入协议细节以应对集成挑战的重要性。\n","date":"8 July, 2025","id":23,"permalink":"/posts/gmsl2-i2c%E5%88%AB%E5%90%8D%E4%B8%8Epec%E6%A0%A1%E9%AA%8C%E7%9A%84%E5%86%B2%E7%AA%81%E6%B7%B1%E5%B1%82%E6%8A%80%E6%9C%AF%E8%A7%A3%E6%9E%90%E6%A0%B9%E6%9C%AC%E6%80%A7%E8%A7%A3%E5%86%B3%E6%96%B9%E6%A1%88%E4%B8%8E%E5%AE%89%E5%85%A8%E8%80%83%E9%87%8F/","summary":"在汽车电子领域，GMSL2（Gigabit Multimedia Serial Link 2）因其高带宽、低延迟的传感器数据传输能力而被广泛应用。其I2C别名功能解决了相同设备（如图像传感器）之间的地址冲突问题，而SMBus/I2C的PEC（Packet Error Checking，数据包错误校验）则增强了通信的可靠性。然而，同时使用这两种功能时，PEC校验会失效，原因在于两者存在固有的不兼容性。本文深入剖析了这一问题，将其归类为“泄露的抽象”，并提供了一个实用的应用层解决方案。","tags":"GMSL ADI I2C SMBus PEC CRC","title":"📘 GMSL2 I2C别名与PEC校验的冲突：深层技术解析、根本性解决方案与安全考量"},{"content":"📘 深入理解 ZeroMQ 异步连接与 REQ 消息堆积行为 ✨ 文档概览 章节 内容 1. 简介 ZeroMQ connect() 行为误区 2. 异步连接机制 connect() 实现原理与延迟连接 3. REQ socket 特性 REQ 的 FSM 状态机与堆积陷阱 4. 内存增长问题分析 实例重现与底层解释 5. 如何规避问题 参数设置、代码优化方案 6. 替代方案 使用 DEALER 替代 REQ 的可行性 7. 源码分析 ZeroMQ 源码路径与关键组件说明 8. 附录与参考资料 官方文献、工具、命令等 1. 🔰 简介：为什么连接成功了服务端却没起来？ 当你调用如下代码时：\nzmq::socket_t socket(context, zmq::socket_type::req); socket.connect(\u0026#34;tcp://127.0.0.1:5555\u0026#34;); LogInfo(\u0026#34;Socket connected to endpoint\u0026#34;); 你可能会误以为服务端已经在线并成功连接。\n这是一个常见误区。\n✅ 正确理解： connect() 只是将目标 endpoint 添加到内部连接目标列表中，并不会立即发起 TCP 连接或等待对端响应。\n这是 ZeroMQ 异步非阻塞通信模型的特性。\n2. ⚙️ 异步连接机制原理 connect() 实际做了什么？ socket.connect(\u0026#34;tcp://127.0.0.1:5555\u0026#34;); 执行过程：\n向 ZeroMQ socket 注册连接目标（endpoint）； 将连接请求投递给后台 I/O 线程； I/O 线程尝试通过 connect() 建立 TCP 连接； 若连接失败，ZeroMQ 会自动重试（受 reconnect_ivl 控制）； 期间调用者不会被阻塞或抛出异常。 所以： connect() 不代表连接已成功； 即使服务端未启动，日志依然会显示 “连接成功”。 3. 🚨 REQ socket 的状态机陷阱 REQ socket 的行为与其他类型不同：\nFSM（有限状态机）： [ReadyToSend] --send()--\u0026gt; [MustRecv] [MustRecv] --recv()--\u0026gt; [ReadyToSend] 规则： 每次 send() 之后必须调用 recv()，否则：\n再次调用 send() 会悄悄排入队列； 这些消息不会立即报错； 不受 ZMQ_SNDHWM 限制； 消息缓冲区将无限增长 → 内存持续上涨。 4. 💥 内存增长问题复现与分析 示例：只调用 send()，不 recv()： for (int i = 0; i \u0026lt; 1000000; ++i) { socket.send(msg, zmq::send_flags::dontwait); } 结果：\n服务端未启动； 内存使用量不断增加； 不触发 sndhwm，也不会报错； 系统资源最终耗尽。 5. ✅ 正确写法与规避方案 ✅ 修复方案一：严格 send/recv 配对 socket.send(msg, zmq::send_flags::dontwait); zmq::message_t reply; socket.recv(reply, zmq::recv_flags::dontwait); 即使对端未上线，也要调用 recv() 清空状态机。\n✅ 修复方案二：切换为 DEALER socket zmq::socket_t socket(context, zmq::socket_type::dealer); DEALER 没有 FSM 限制； 支持多次 send / recv； 更适合高频、异步、多线程模型； 服务端需改为 ROUTER。 ⚙️ 参数推荐配置 socket.set(zmq::sockopt::linger, 0); // 快速关闭 socket.set(zmq::sockopt::sndhwm, 100); // 控制消息堆积 socket.set(zmq::sockopt::rcvtimeo, 3000); // 防止 recv 阻塞 socket.set(zmq::sockopt::sndtimeo, 1000); // 防止 send 阻塞 socket.set(zmq::sockopt::reconnect_ivl, 100); // 快速重连 socket.set(zmq::sockopt::reconnect_ivl_max, 3000); ✅ 使用监控检测连接状态 socket.monitor(\u0026#34;inproc://monitor\u0026#34;, ZMQ_EVENT_CONNECTED | ZMQ_EVENT_DISCONNECTED); // 用另一个 socket 监听事件流 6. 🔁 DEALER 替代 REQ 的完整对比 特性 REQ DEALER 是否受 FSM 限制 ✅ 是 ❌ 否 是否支持异步 ❌ 阻塞式 ✅ 完全异步 是否可以持续发送 ❌ 必须 recv 之后才能 send ✅ 任意 send / recv 是否适合多线程 ❌ 一般不推荐 ✅ 高度可控 适用服务端类型 REP ROUTER 7. 🔍 源码解析（libzmq） 调用链： zmq::socket_t::connect() ↓ zmq_connect() ↓ socket_base_t::connect() ↓ endpoint_base_t::connect() ↓ tcp_connecter_t::start_connecting() ↓ ::connect() → EINPROGRESS → poll 写事件等待连接完成 buffer 堆积的位置： 在 socket_base_t::send() 中，REQ FSM 状态控制逻辑会判断是否允许发送； 若处于 MustRecv 状态，会将消息缓存入 outpipe 而不是立即发送； ZMQ_SNDHWM 只作用于 outbound pipe，FSM 内部状态机并不受限于它。 8. 📚 附录与参考资料 官方文献： ZeroMQ Guide (zguide) ZeroMQ API Reference ZeroMQ Monitoring Events ZeroMQ GitHub (libzmq) 相关命令： 命令 说明 `netstat -an grep 5555` 查看端口监听 lsof -i:5555 查看哪个进程占用 valgrind --tool=massif 检查内存使用增长 🎯 总结 ZeroMQ 的 connect() 是非阻塞、异步行为； REQ socket 必须 send → recv 配对，否则会无限堆积消息； sndhwm 对 REQ 不起作用，不能限制其消息堆积； 最好使用 DEALER 替代 REQ，以支持灵活通信； 必须监控连接状态，合理设计握手机制，避免因误判“已连接”而堆积消息导致 OOM。 ","date":"8 July, 2025","id":24,"permalink":"/posts/-%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3-zeromq-%E5%BC%82%E6%AD%A5%E8%BF%9E%E6%8E%A5%E4%B8%8E-req-%E6%B6%88%E6%81%AF%E5%A0%86%E7%A7%AF%E8%A1%8C%E4%B8%BA/","summary":"当你调用如下代码时：","tags":"cpp zmq OOM 内存泄漏","title":"📘 深入理解 ZeroMQ 异步连接与 REQ 消息堆积行为"},{"content":"📘AArch64 下 glibc open() 调用到内核系统调用入口的全路径解析 目标 本文档对 AArch64 (即 ARM64) 架构下从 glibc 中的 open() 函数调用至 Linux 内核中 sys_openat() 系统调用入口的全路径进行全面、精精、严密的分析。选用 AArch64 架构是因为其在嵌入式、手机、服务器等领域应用很广，宜于全面理解 Linux syscall 机制。\n一、从 glibc open() 函数调用开始 int fd = open(\u0026#34;/tmp/a.txt\u0026#34;, O_RDONLY); open() 是 POSIX API，glibc 中实际是一层展开：\n#define open(...) SYSCALL_CANCEL(openat, AT_FDCWD, __VA_ARGS__) 即使用 openat() 实现。\n二、glibc syscall 展开层层结构 以 5 个参数为例：\n1. 调用链进程 SYSCALL_CANCEL(openat, AT_FDCWD, file, flags, mode) 展开层层如下：\nSYSCALL_CANCEL(...) → INLINE_SYSCALL_CALL(...) → __INLINE_SYSCALL_DISP(__INLINE_SYSCALL, ...) → __SYSCALL_CONCAT(__INLINE_SYSCALL, N)(...) → __INLINE_SYSCALL5(name, a1, a2, a3, a4, a5) → INLINE_SYSCALL(name, 5, a1, a2, a3, a4, a5) 2. INLINE_SYSCALL 实现 #define INLINE_SYSCALL(name, nr, args...) \\ ({ \\ long int sc_ret = INTERNAL_SYSCALL(name, nr, args); \\ __glibc_unlikely(INTERNAL_SYSCALL_ERROR_P(sc_ret)) \\ ? SYSCALL_ERROR_LABEL(INTERNAL_SYSCALL_ERRNO(sc_ret)) \\ : sc_ret; \\ }) 三、INTERNAL_SYSCALL 到 svc #0 入核 1. 实际定义分部 在 sysdeps/unix/sysv/linux/aarch64/sysdep.h 中：\n#define INTERNAL_SYSCALL(name, nr, args...) \\ INTERNAL_SYSCALL_RAW(__NR_##name, nr, args) 2. INTERNAL_SYSCALL_RAW 核心实现 #define INTERNAL_SYSCALL_RAW(name, nr, args...) \\ ({ long _sys_result; \\ { \\ LOAD_ARGS_##nr (args) \\ register long _x8 asm (\u0026#34;x8\u0026#34;) = (name); \\ asm volatile ( \\ \u0026#34;svc 0 // syscall \u0026#34; #name \\ : \u0026#34;=r\u0026#34; (_x0) \\ : \u0026#34;r\u0026#34;(_x8) ASM_ARGS_##nr \\ : \u0026#34;memory\u0026#34;); \\ _sys_result = _x0; \\ } \\ _sys_result; }) 3. 参数装入 register long _x0 asm(\u0026#34;x0\u0026#34;) = arg1; // fd register long _x1 asm(\u0026#34;x1\u0026#34;) = arg2; // path register long _x2 asm(\u0026#34;x2\u0026#34;) = arg3; // flags register long _x3 asm(\u0026#34;x3\u0026#34;) = arg4; // mode register long _x4 asm(\u0026#34;x4\u0026#34;) = arg5; // reserve register long _x8 asm(\u0026#34;x8\u0026#34;) = __NR_openat; 4. 结果 执行指令：\nsvc #0 四、内核端调用扩展 1. 输入异常向量 entry.S 文件：arch/arm64/kernel/entry.S\nel0_sync: kernel_entry 0 bl el0_sync_handler 2. el0_sync_handler() 文件：arch/arm64/kernel/syscall.c\nvoid el0_sync_handler(struct pt_regs *regs) { ... syscall_handler(regs); } 3. syscall_handler() unsigned long scno = regs-\u0026gt;regs[8]; // x8 是 syscall 号 sys_call_table[scno] → sys_openat(...) 4. sys_openat() 在内核 fs 层：\nSYSCALL_DEFINE4(openat, int dfd, const char __user *filename, int flags, umode_t mode) { return do_sys_openat2(dfd, filename, flags, mode); } 经由 VFS 层扩展到文件系统，最终返回 fd 或错误码\n五、完整调用链流程图 glibc: open(path, flags, mode) → SYSCALL_CANCEL(openat, AT_FDCWD, ...) → __INLINE_SYSCALL5(...) → INLINE_SYSCALL(...) → INTERNAL_SYSCALL(...) → INTERNAL_SYSCALL_RAW(...) → 参数装入到 x0~x5, x8 → svc #0 kernel: svc #0 → entry.S: el0_sync → el0_sync_handler() → syscall_handler() → sys_call_table[__NR_openat] → sys_openat(...) → do_sys_openat2() → VFS → file system 附录: 系统调用 ABI 规则 (AArch64) 参数 存储位 说明 syscall# x8 系统调用编号 arg1 x0 第一个参数 arg2 x1 第二个参数 arg3 x2 第三个参数 arg4 x3 第四个参数 arg5 x4 第五个参数 arg6 x5 第六个参数 return x0 系统调用返回值 结论 glibc 通过多层 macro 抽象，最终进入 INTERNAL_SYSCALL_RAW 模板 参数装入到 x0~x5，系统调用编号装入 x8 svc #0 触发输入异常 内核通过 sys_call_table 分发到 sys_openat() 并最终返回 fd 给用户端 ","date":"8 July, 2025","id":25,"permalink":"/posts/aarch64-%E4%B8%8B-glibc-open-%E8%B0%83%E7%94%A8%E5%88%B0%E5%86%85%E6%A0%B8%E7%B3%BB%E7%BB%9F%E8%B0%83%E7%94%A8%E5%85%A5%E5%8F%A3%E7%9A%84%E5%85%A8%E8%B7%AF%E5%BE%84%E8%A7%A3%E6%9E%90/","summary":"本文档对 AArch64 (即 ARM64) 架构下从 glibc 中的 open() 函数调用至 Linux 内核中 sys_openat() 系统调用入口的全路径进行全面、精精、严密的分析。选用 AArch64 架构是因为其在嵌入式、手机、服务器等领域应用很广，宜于全面理解 Linux syscall 机制。","tags":"glibc AArch64 ARM syscall 系统调用 linux kernel","title":"📘AArch64 下 glibc `open()` 调用到内核系统调用入口的全路径解析"},{"content":"CMake 现代化配置完整指南 目录 项目基础配置 C++ 编译标准设置 编译器选项与警告配置 输出目录结构管理 环境检测与路径配置 第三方依赖管理 目标链接与可见性 安装配置与部署 自定义构建目标 完整示例项目 项目基础配置 最小版本要求与项目声明 cmake_minimum_required(VERSION 3.14) project(VisionDemo VERSION 1.0.0 LANGUAGES CXX) 说明：\ncmake_minimum_required：指定所需的最低CMake版本 project：定义项目名称、版本号和使用的语言 VERSION：设置项目版本，可通过 ${PROJECT_VERSION} 引用 LANGUAGES：明确指定使用的编程语言 C++ 编译标准设置 全局标准设置 # 设置 C++17 标准 set(CMAKE_CXX_STANDARD 17) set(CMAKE_CXX_STANDARD_REQUIRED ON) set(CMAKE_CXX_EXTENSIONS OFF) 各参数含义：\n参数 作用 说明 CMAKE_CXX_STANDARD 指定C++标准版本 告诉编译器使用哪个C++标准（如17、20、23） CMAKE_CXX_STANDARD_REQUIRED 强制要求指定标准 ON：编译器必须支持指定标准，否则报错 CMAKE_CXX_EXTENSIONS 禁用编译器扩展 OFF：使用纯标准C++，提高跨平台兼容性 编译器参数映射：\nGCC/Clang: -std=c++17 MSVC: /std:c++17 针对特定目标的标准设置 set_target_properties(VisionDemo PROPERTIES CXX_STANDARD 17 CXX_STANDARD_REQUIRED ON CXX_EXTENSIONS OFF ) 使用场景：\n项目中不同目标需要不同的C++标准 明确指定某个目标的编译标准 覆盖全局设置 编译器选项与警告配置 全局编译选项 if(CMAKE_CXX_COMPILER_ID MATCHES \u0026#34;GNU|Clang\u0026#34;) add_compile_options(-Wall -Wextra -Wpedantic) endif() 目标特定编译选项（推荐） if(CMAKE_CXX_COMPILER_ID MATCHES \u0026#34;GNU|Clang\u0026#34;) target_compile_options(VisionDemo PRIVATE -Wall -Wextra -Wpedantic -Wno-unused-parameter -Wno-unused-variable ) endif() 编译选项说明：\n选项 作用 -Wall 启用所有常用警告 -Wextra 启用更多额外警告 -Wpedantic 强制标准兼容性检查 -Wno-unused-parameter 关闭未使用参数警告 -Wno-unused-variable 关闭未使用变量警告 多编译器支持 if(CMAKE_CXX_COMPILER_ID MATCHES \u0026#34;GNU|Clang\u0026#34;) target_compile_options(${TARGET_NAME} PRIVATE -Wall -Wextra -Wpedantic -Wno-unused-parameter -Wno-unused-variable ) elseif(CMAKE_CXX_COMPILER_ID STREQUAL \u0026#34;MSVC\u0026#34;) target_compile_options(${TARGET_NAME} PRIVATE /W4 # 高警告级别 /WX # 将警告视为错误 /utf-8 # 使用UTF-8编码 ) endif() 重要提醒： target_compile_options 必须在 add_executable 或 add_library 之后调用，否则会报错：\nCannot specify compile options for target \u0026#34;TargetName\u0026#34; which is not built by this project. 输出目录结构管理 构建阶段输出目录 # 设置构建阶段的输出目录 set(CMAKE_RUNTIME_OUTPUT_DIRECTORY ${CMAKE_BINARY_DIR}/bin) set(CMAKE_LIBRARY_OUTPUT_DIRECTORY ${CMAKE_BINARY_DIR}/lib) set(CMAKE_ARCHIVE_OUTPUT_DIRECTORY ${CMAKE_BINARY_DIR}/lib) 目录类型说明：\n变量 文件类型 示例 CMAKE_RUNTIME_OUTPUT_DIRECTORY 可执行文件 .exe, 无扩展名的二进制文件 CMAKE_LIBRARY_OUTPUT_DIRECTORY 动态链接库 .so, .dylib, .dll CMAKE_ARCHIVE_OUTPUT_DIRECTORY 静态库 .a, .lib 多配置生成器支持 # 为多配置生成器（如 MSVC）指定每个构建类型的输出路径 foreach(OUTPUT_CONFIG IN LISTS CMAKE_CONFIGURATION_TYPES) string(TOUPPER ${OUTPUT_CONFIG} OUTPUT_CONFIG) set(CMAKE_RUNTIME_OUTPUT_DIRECTORY_${OUTPUT_CONFIG} ${CMAKE_RUNTIME_OUTPUT_DIRECTORY}) set(CMAKE_LIBRARY_OUTPUT_DIRECTORY_${OUTPUT_CONFIG} ${CMAKE_LIBRARY_OUTPUT_DIRECTORY}) set(CMAKE_ARCHIVE_OUTPUT_DIRECTORY_${OUTPUT_CONFIG} ${CMAKE_ARCHIVE_OUTPUT_DIRECTORY}) endforeach() 构建结果示例：\nbuild/ ├── bin/ │ └── VisionDemo └── lib/ ├── libVisionDemo.a └── libVisionDemo.so 环境检测与路径配置 Anaconda 环境检测 # 检查是否在 Anaconda 环境中 if(DEFINED ENV{CONDA_PREFIX}) set(CMAKE_PREFIX_PATH $ENV{CONDA_PREFIX}) set(CMAKE_INCLUDE_PATH $ENV{CONDA_PREFIX}/include) set(CMAKE_LIBRARY_PATH $ENV{CONDA_PREFIX}/lib) message(STATUS \u0026#34;Detected Conda environment: $ENV{CONDA_PREFIX}\u0026#34;) endif() 环境变量说明：\nCONDA_PREFIX：当前激活的Conda环境路径 CMAKE_PREFIX_PATH：CMake包查找路径前缀 CMAKE_INCLUDE_PATH：头文件查找路径 CMAKE_LIBRARY_PATH：库文件查找路径 路径优先级管理 # 设置查找路径优先级 list(INSERT CMAKE_PREFIX_PATH 0 ${CMAKE_CURRENT_SOURCE_DIR}/extern) list(INSERT CMAKE_MODULE_PATH 0 ${CMAKE_CURRENT_SOURCE_DIR}/cmake) 第三方依赖管理 使用 FetchContent 自动下载依赖 include(FetchContent) # 下载并构建 fmt 库 FetchContent_Declare( fmt GIT_REPOSITORY https://github.com/fmtlib/fmt.git GIT_TAG 9.1.0 ) FetchContent_MakeAvailable(fmt) # 下载并构建 spdlog 库 FetchContent_Declare( spdlog GIT_REPOSITORY https://github.com/gabime/spdlog.git GIT_TAG v1.11.0 ) FetchContent_MakeAvailable(spdlog) FetchContent 优点：\n📦 无需手动安装第三方库 🔒 可指定版本，避免兼容性问题 🔁 支持缓存和增量更新 🧩 与CMake依赖管理无缝集成 常用第三方库配置 # Google Test FetchContent_Declare( googletest GIT_REPOSITORY https://github.com/google/googletest.git GIT_TAG release-1.12.1 ) FetchContent_MakeAvailable(googletest) # JSON库 FetchContent_Declare( nlohmann_json GIT_REPOSITORY https://github.com/nlohmann/json.git GIT_TAG v3.11.2 ) FetchContent_MakeAvailable(nlohmann_json) # Eigen 数学库 FetchContent_Declare( eigen GIT_REPOSITORY https://gitlab.com/libeigen/eigen.git GIT_TAG 3.4.0 ) FetchContent_MakeAvailable(eigen) find_package 方式 # 查找系统安装的包 find_package(OpenCV REQUIRED) find_package(Boost REQUIRED COMPONENTS system filesystem thread) find_package(PkgConfig REQUIRED) pkg_check_modules(GTK3 REQUIRED gtk+-3.0) 目标链接与可见性 链接可见性修饰符 target_link_libraries(MyTarget PRIVATE privately_used_lib # 仅当前目标使用 PUBLIC publicly_exposed_lib # 当前目标和依赖者都使用 INTERFACE interface_only_lib # 仅依赖者使用 ) 可见性对比：\n修饰符 对当前目标生效 传播到依赖者 使用场景 PRIVATE ✅ ❌ 内部实现依赖 PUBLIC ✅ ✅ 公共API的一部分 INTERFACE ❌ ✅ 头文件库、接口库 实际应用示例 # 创建库 add_library(MyLib src/mylib.cpp) target_link_libraries(MyLib PRIVATE spdlog::spdlog # 内部日志，不对外暴露 PUBLIC fmt::fmt # 公共接口使用fmt格式化 INTERFACE Eigen3::Eigen # 头文件库，仅依赖者需要 ) # 创建应用程序 add_executable(MyApp src/main.cpp) target_link_libraries(MyApp PRIVATE MyLib) # MyApp 可以使用 fmt::fmt 和 Eigen，但不能直接使用 spdlog 接口库创建 # 创建纯头文件库 add_library(MyHeaderLib INTERFACE) target_include_directories(MyHeaderLib INTERFACE $\u0026lt;BUILD_INTERFACE:${CMAKE_CURRENT_SOURCE_DIR}/include\u0026gt; $\u0026lt;INSTALL_INTERFACE:include\u0026gt; ) target_link_libraries(MyHeaderLib INTERFACE fmt::fmt) 安装配置与部署 基础安装配置 include(GNUInstallDirs) # 提供标准安装路径 # 安装可执行文件 install(TARGETS VisionDemo RUNTIME DESTINATION ${CMAKE_INSTALL_BINDIR} ) # 安装库文件 install(TARGETS VisionDemo ARCHIVE DESTINATION ${CMAKE_INSTALL_LIBDIR} LIBRARY DESTINATION ${CMAKE_INSTALL_LIBDIR} RUNTIME DESTINATION ${CMAKE_INSTALL_BINDIR} # Windows DLL ) 完整安装配置 # 安装头文件 install(DIRECTORY include/VisionDemo DESTINATION ${CMAKE_INSTALL_INCLUDEDIR} FILES_MATCHING PATTERN \u0026#34;*.h\u0026#34; PATTERN \u0026#34;*.hpp\u0026#34; ) # 安装配置文件 install(FILES config/VisionDemo.conf DESTINATION ${CMAKE_INSTALL_SYSCONFDIR}/VisionDemo ) # 生成并安装版本文件 include(CMakePackageConfigHelpers) write_basic_package_version_file( \u0026#34;${CMAKE_CURRENT_BINARY_DIR}/VisionDemoConfigVersion.cmake\u0026#34; VERSION ${PROJECT_VERSION} COMPATIBILITY AnyNewerVersion ) install(FILES \u0026#34;${CMAKE_CURRENT_BINARY_DIR}/VisionDemoConfigVersion.cmake\u0026#34; DESTINATION ${CMAKE_INSTALL_LIBDIR}/cmake/VisionDemo ) 安装路径说明 GNUInstallDirs 提供的标准路径：\n变量 默认值 说明 CMAKE_INSTALL_BINDIR bin 可执行文件 CMAKE_INSTALL_LIBDIR lib 库文件 CMAKE_INSTALL_INCLUDEDIR include 头文件 CMAKE_INSTALL_SYSCONFDIR etc 配置文件 CMAKE_INSTALL_DATADIR share 数据文件 使用安装 # 配置并构建 cmake -S . -B build -DCMAKE_BUILD_TYPE=Release cmake --build build # 安装到指定目录 cmake --install build --prefix /opt/VisionDemo # 或使用传统方式 cd build \u0026amp;\u0026amp; make install 自定义构建目标 版本信息目标 add_custom_target(version_info COMMAND ${CMAKE_COMMAND} -E echo \u0026#34;Building ${PROJECT_NAME} version ${PROJECT_VERSION}\u0026#34; COMMAND ${CMAKE_COMMAND} -E echo \u0026#34;C++ compiler: ${CMAKE_CXX_COMPILER_ID} ${CMAKE_CXX_COMPILER_VERSION}\u0026#34; COMMAND ${CMAKE_COMMAND} -E echo \u0026#34;Build type: ${CMAKE_BUILD_TYPE}\u0026#34; COMMAND ${CMAKE_COMMAND} -E echo \u0026#34;Install prefix: ${CMAKE_INSTALL_PREFIX}\u0026#34; VERBATIM ) # 让主目标依赖版本信息 add_dependencies(VisionDemo version_info) 代码格式化目标 find_program(CLANG_FORMAT clang-format) if(CLANG_FORMAT) file(GLOB_RECURSE SOURCE_FILES \u0026#34;${CMAKE_SOURCE_DIR}/src/*.cpp\u0026#34; \u0026#34;${CMAKE_SOURCE_DIR}/src/*.h\u0026#34; \u0026#34;${CMAKE_SOURCE_DIR}/include/*.h\u0026#34; ) add_custom_target(format COMMAND ${CLANG_FORMAT} -i ${SOURCE_FILES} COMMENT \u0026#34;Formatting source code with clang-format\u0026#34; VERBATIM ) endif() 文档生成目标 find_package(Doxygen) if(DOXYGEN_FOUND) set(DOXYGEN_IN ${CMAKE_CURRENT_SOURCE_DIR}/docs/Doxyfile.in) set(DOXYGEN_OUT ${CMAKE_CURRENT_BINARY_DIR}/Doxyfile) configure_file(${DOXYGEN_IN} ${DOXYGEN_OUT} @ONLY) add_custom_target(docs COMMAND ${DOXYGEN_EXECUTABLE} ${DOXYGEN_OUT} WORKING_DIRECTORY ${CMAKE_CURRENT_BINARY_DIR} COMMENT \u0026#34;Generating API documentation with Doxygen\u0026#34; VERBATIM ) endif() 完整示例项目 项目结构 VisionDemo/ ├── CMakeLists.txt ├── cmake/ │ ├── Dependencies.cmake │ └── CompilerOptions.cmake ├── include/ │ └── VisionDemo/ │ ├── VisionDemo.h │ └── Config.h ├── src/ │ ├── main.cpp │ ├── VisionDemo.cpp │ └── Config.cpp ├── tests/ │ └── test_VisionDemo.cpp ├── docs/ │ └── Doxyfile.in └── README.md 主 CMakeLists.txt cmake_minimum_required(VERSION 3.14) project(VisionDemo VERSION 1.2.0 DESCRIPTION \u0026#34;Modern VisionDemo Management System\u0026#34; LANGUAGES CXX ) # --- 编译标准设置 --- set(CMAKE_CXX_STANDARD 17) set(CMAKE_CXX_STANDARD_REQUIRED ON) set(CMAKE_CXX_EXTENSIONS OFF) # --- 输出目录设置 --- set(CMAKE_RUNTIME_OUTPUT_DIRECTORY ${CMAKE_BINARY_DIR}/bin) set(CMAKE_LIBRARY_OUTPUT_DIRECTORY ${CMAKE_BINARY_DIR}/lib) set(CMAKE_ARCHIVE_OUTPUT_DIRECTORY ${CMAKE_BINARY_DIR}/lib) # --- 环境检测 --- if(DEFINED ENV{CONDA_PREFIX}) set(CMAKE_PREFIX_PATH $ENV{CONDA_PREFIX}) message(STATUS \u0026#34;Using Conda environment: $ENV{CONDA_PREFIX}\u0026#34;) endif() # --- 包含子模块 --- list(APPEND CMAKE_MODULE_PATH ${CMAKE_CURRENT_SOURCE_DIR}/cmake) include(Dependencies) include(CompilerOptions) # --- 包含目录 --- include_directories(${PROJECT_SOURCE_DIR}/include) # --- 源文件收集 --- file(GLOB_RECURSE SOURCES src/*.cpp) file(GLOB_RECURSE HEADERS include/*.h) # --- 创建库目标 --- add_library(VisionDemoLib STATIC ${SOURCES} ${HEADERS}) target_include_directories(VisionDemoLib PUBLIC $\u0026lt;BUILD_INTERFACE:${CMAKE_CURRENT_SOURCE_DIR}/include\u0026gt; $\u0026lt;INSTALL_INTERFACE:include\u0026gt; ) # --- 创建可执行目标 --- add_executable(VisionDemo src/main.cpp) target_link_libraries(VisionDemo PRIVATE VisionDemoLib fmt::fmt spdlog::spdlog ) # --- 设置编译选项 --- setup_compiler_options(VisionDemo) setup_compiler_options(VisionDemoLib) # --- 版本信息 --- add_custom_target(version_info COMMAND ${CMAKE_COMMAND} -E echo \u0026#34;Building ${PROJECT_NAME} ${PROJECT_VERSION}\u0026#34; COMMAND ${CMAKE_COMMAND} -E echo \u0026#34;Compiler: ${CMAKE_CXX_COMPILER_ID} ${CMAKE_CXX_COMPILER_VERSION}\u0026#34; COMMAND ${CMAKE_COMMAND} -E echo \u0026#34;Build type: ${CMAKE_BUILD_TYPE}\u0026#34; ) add_dependencies(VisionDemo version_info) # --- 测试 --- option(BUILD_TESTS \u0026#34;Build tests\u0026#34; ON) if(BUILD_TESTS) enable_testing() add_subdirectory(tests) endif() # --- 安装配置 --- include(GNUInstallDirs) install(TARGETS VisionDemo VisionDemoLib RUNTIME DESTINATION ${CMAKE_INSTALL_BINDIR} ARCHIVE DESTINATION ${CMAKE_INSTALL_LIBDIR} LIBRARY DESTINATION ${CMAKE_INSTALL_LIBDIR} ) install(DIRECTORY include/VisionDemo DESTINATION ${CMAKE_INSTALL_INCLUDEDIR} FILES_MATCHING PATTERN \u0026#34;*.h\u0026#34; ) # --- 包配置 --- include(CMakePackageConfigHelpers) write_basic_package_version_file( \u0026#34;${CMAKE_CURRENT_BINARY_DIR}/VisionDemoConfigVersion.cmake\u0026#34; VERSION ${PROJECT_VERSION} COMPATIBILITY SameMajorVersion ) install(FILES \u0026#34;${CMAKE_CURRENT_BINARY_DIR}/VisionDemoConfigVersion.cmake\u0026#34; DESTINATION ${CMAKE_INSTALL_LIBDIR}/cmake/VisionDemo ) cmake/Dependencies.cmake include(FetchContent) # fmt 库 FetchContent_Declare( fmt GIT_REPOSITORY https://github.com/fmtlib/fmt.git GIT_TAG 9.1.0 ) # spdlog 库 FetchContent_Declare( spdlog GIT_REPOSITORY https://github.com/gabime/spdlog.git GIT_TAG v1.11.0 ) # 如果构建测试，添加 Google Test option(BUILD_TESTS \u0026#34;Build tests\u0026#34; ON) if(BUILD_TESTS) FetchContent_Declare( googletest GIT_REPOSITORY https://github.com/google/googletest.git GIT_TAG release-1.12.1 ) set(gtest_force_shared_crt ON CACHE BOOL \u0026#34;\u0026#34; FORCE) endif() # 使所有依赖可用 FetchContent_MakeAvailable(fmt spdlog) if(BUILD_TESTS) FetchContent_MakeAvailable(googletest) endif() cmake/CompilerOptions.cmake function(setup_compiler_options target) if(CMAKE_CXX_COMPILER_ID MATCHES \u0026#34;GNU|Clang\u0026#34;) target_compile_options(${target} PRIVATE -Wall -Wextra -Wpedantic -Wno-unused-parameter -Wno-unused-variable $\u0026lt;$\u0026lt;CONFIG:Debug\u0026gt;:-g3 -O0\u0026gt; $\u0026lt;$\u0026lt;CONFIG:Release\u0026gt;:-O3 -DNDEBUG\u0026gt; ) elseif(CMAKE_CXX_COMPILER_ID STREQUAL \u0026#34;MSVC\u0026#34;) target_compile_options(${target} PRIVATE /W4 /utf-8 $\u0026lt;$\u0026lt;CONFIG:Debug\u0026gt;:/Od /RTC1\u0026gt; $\u0026lt;$\u0026lt;CONFIG:Release\u0026gt;:/O2 /DNDEBUG\u0026gt; ) endif() endfunction() 构建和使用 # 克隆项目 git clone \u0026lt;repository_url\u0026gt; cd VisionDemo # 配置构建 cmake -S . -B build -DCMAKE_BUILD_TYPE=Release # 构建 cmake --build build --parallel # 运行测试 cd build \u0026amp;\u0026amp; ctest --verbose # 安装 cmake --install build --prefix install # 查看版本信息 cd build \u0026amp;\u0026amp; make version_info 最佳实践总结 ✅ 推荐做法 使用现代CMake语法 (3.14+) 明确指定目标属性 而非全局变量 使用 target_* 系列命令 而非废弃的全局命令 合理使用链接可见性 (PRIVATE/PUBLIC/INTERFACE) 组织化管理配置文件 (cmake/目录) 提供完整的安装配置 支持多平台编译器 ❌ 避免的做法 不要使用过时的CMake语法 避免硬编码路径 不要忽略编译器差异 避免在 add_executable 前使用 target_* 命令 不要混用全局和目标特定的设置 🔧 调试技巧 # 打印变量值 message(STATUS \u0026#34;CMAKE_CXX_COMPILER_ID: ${CMAKE_CXX_COMPILER_ID}\u0026#34;) message(STATUS \u0026#34;PROJECT_VERSION: ${PROJECT_VERSION}\u0026#34;) # 打印所有变量 get_cmake_property(_variableNames VARIABLES) foreach(_variableName ${_variableNames}) message(STATUS \u0026#34;${_variableName}=${${_variableName}}\u0026#34;) endforeach() # 详细构建输出 set(CMAKE_VERBOSE_MAKEFILE ON) 这份指南涵盖了现代CMake项目配置的所有重要方面，从基础设置到高级功能，可以作为实际项目开发的参考模板。\n","date":"29 June, 2025","id":26,"permalink":"/posts/cmake-%E7%8E%B0%E4%BB%A3%E5%8C%96%E9%85%8D%E7%BD%AE%E5%AE%8C%E6%95%B4%E6%8C%87%E5%8D%97/","summary":"说明：","tags":"cpp cmake","title":"📌CMake 现代化配置完整指南"},{"content":"📌HP 惠普 NPI4D1722 (HP LaserJet MFP M232dw) 打印机扫面环境配置及扫描方法 进入网页 123HP 输入打印机产品型号：HP LaserJet MFP M232dw Printer, 点击 下一步 安装 HP Smart 以完成设置。点击 安装 HP SMART 跳转到 Microsoft Store 进行安装\n安装完成后自动运行 HP Smart, 根据直到一步一步配置好打印机。如果打印机和电脑在同一个局域网中，自动就能找到该设备 ![[Pasted image 20250724193838.png]]\n连接成功后，程序主界面如下，根据需要点击相应图标来进行相关工作 ![[Pasted image 20250724193940.png]]\n扫描 点击 扫描 图标\n![[Pasted image 20250724195027.png]]\n此时将待扫描的内容放到打印机里，然后点击右下角的 扫描，等待几秒钟扫描完成，显示如下 ![[Pasted image 20250724195247.png]]\n如果想扫描多张内容，点击右上角的 +添加, 循环执行前面的操作。\n点击 保存 ![[Pasted image 20250724200751.png]]\n点击 保存 ![[Pasted image 20250724200830.png]]\n三页扫描内容就会保存在一份 PDF 中。\n","date":"29 June, 2025","id":27,"permalink":"/posts/hp%E6%83%A0%E6%99%AEnpi4d1722_hp_laserjet_mfp_m232dw%E6%89%93%E5%8D%B0%E6%9C%BA%E6%89%AB%E9%9D%A2%E7%8E%AF%E5%A2%83%E9%85%8D%E7%BD%AE%E5%8F%8A%E6%89%AB%E6%8F%8F%E6%96%B9%E6%B3%95/","summary":"点击 扫描 图标","tags":"打印机 扫描 扫描仪","title":"📌HP 惠普 NPI4D1722 (HP LaserJet MFP M232dw) 打印机扫面环境配置及扫描方法"},{"content":"环境声明 $ lsb_release -a No LSB modules are available. Distributor ID: Ubuntu Description: Ubuntu 20.04.6 LTS Release: 20.04 Codename: focal 🎯 YOLO 实时目标检测笔记：Windows 摄像头推流 + WSL YOLO 识别 🧩 场景说明 Windows 端摄像头（如 HP 5MP Camera） 使用 ffmpeg 推流至本地 RTSP 服务器 WSL 中运行 Ultralytics YOLO，读取 RTSP 流进行目标检测 ⚙️ 环境配置（WSL 中） ✅ 安装依赖 pip install -U pip pip install opencv-python pip install torch torchvision torchaudio ✅ 安装 Ultralytics（源码模式） # 克隆仓库 git clone https://github.com/ultralytics/ultralytics # 进入目录 cd ultralytics # 以开发模式安装（editable） # pip install -e . python3 -m pip install -e . ✅ 优势：你可以随时修改 YOLO 源码，调试/开发更灵活。\n✅ 步骤一：安装并运行 RTSP 服务器（mediamtx） 推荐使用轻量开源 RTSP 服务器 mediamtx（原 rtsp-simple-server）\n安装（WSL 中）： wget https://github.com/bluenviron/mediamtx/releases/download/v1.12.3/mediamtx_v1.12.3_linux_amd64.tar.gz tar -xvzf mediamtx_linux_amd64.tar.gz cd mediamtx ./mediamtx ✅ 步骤二：Windows 端摄像头推流（FFmpeg） 推荐推流命令如下：\nffmpeg -f dshow -i video=\u0026#34;HP 5MP Camera\u0026#34; -vf \u0026#34;yadif,format=yuv420p\u0026#34; -vcodec libx264 -preset ultrafast -tune zerolatency -color_primaries bt709 -colorspace bt709 -color_trc bt709 -r 30 -g 30 -threads 2 -pix_fmt yuv420p -f rtsp rtsp://172.20.24.196:8554/live.sdp ✅ 步骤三：WSL 中运行 YOLO 目标检测 yolo detect predict \\ model=yolov8n.pt \\ source=\u0026#34;rtsp://127.0.0.1:8554/live.sdp\u0026#34; \\ show=True \\ device=cpu ✅ 可选：调试 RTSP 流 ffplay rtsp://127.0.0.1:8554/live.sdp 💡 常见问题排查 问题 原因或解决方案 udp:// 无法打开 YOLO 不完全支持，推荐使用 rtsp:// 转发 YOLO 无法连接 RTSP 确保 RTSP 服务在运行，FFmpeg 正常推送 无法显示窗口 确保你用的是支持 GUI 的 WSL（如 WSLg 或 X11 桥接） torch.cuda.is_available(): False 使用 device=cpu ✅ 总结流程图 Windows 摄像头 │ └───▶ FFmpeg（推送） ───▶ RTSP Server（Mediamtx） │ ▼ WSL YOLO（读取 RTSP 流识别） 问题说明 1 ➜ python3 --version Python 3.8.10 ➜ pip --version /usr/bin/pip:6: DeprecationWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html from pkg_resources import load_entry_point pip 20.0.2 from /usr/lib/python3/dist-packages/pip (python 3.8) ➜ git clone https://github.com/ultralytics/ultralytics Cloning into \u0026#39;ultralytics\u0026#39;... remote: Enumerating objects: 61803, done. remote: Counting objects: 100% (201/201), done. remote: Compressing objects: 100% (140/140), done. remote: Total 61803 (delta 139), reused 78 (delta 61), pack-reused 61602 (from 3) Receiving objects: 100% (61803/61803), 33.73 MiB | 11.33 MiB/s, done. Resolving deltas: 100% (45988/45988), done. ➜ cd ultralytics ➜ pip install -e . ERROR: File \u0026#34;setup.py\u0026#34; not found. Directory cannot be installed in editable mode: /home/ultralytics (A \u0026#34;pyproject.toml\u0026#34; file was found, but editable mode currently requires a setup.py based build.) ➜ ls CITATION.cff CONTRIBUTING.md LICENSE README.md README.zh-CN.md docker docs examples mkdocs.yml pyproject.toml tests ultralytics 说明 Ultralytics 现在是基于 pyproject.toml 的现代构建系统，而 pip install -e . 旧的可编辑模式要求有 setup.py，所以直接用会失败。\n解决方案 用新的 PEP 660 可编辑模式 Python 3.8+ + pip 21.3+ 才支持。\npython -m pip install --upgrade pip setuptools wheel python3 -m pip --version pip 25.0.1 from /home/luyang/.local/lib/python3.8/site-packages/pip (python 3.8) cd ultralytics python3 -m pip install -e \u0026#39;.[dev]\u0026#39; 问题说明 2 第一次运行 yolo 时由于权重文件不存在，会先下载权重文件。如果下载过程中 ctrl c 异常结束后，再次运行就会报错。\nyolo detect predict model=yolo11n.pt source=./demo.mp4 Traceback (most recent call last): File \u0026#34;/home/max/.local/bin//yolo\u0026#34;, line 8, in \u0026lt;module\u0026gt; sys.exit(entrypoint()) File \u0026#34;/home/ultralytics/ultralytics/cfg/__init__.py\u0026#34;, line 956, in entrypoint model = YOLO(model, task=task) File \u0026#34;/home/ultralytics/ultralytics/models/yolo/model.py\u0026#34;, line 81, in __init__ super().__init__(model=model, task=task, verbose=verbose) File \u0026#34;/home/ultralytics/ultralytics/engine/model.py\u0026#34;, line 151, in __init__ self._load(model, task=task) File \u0026#34;/home/ultralytics/ultralytics/engine/model.py\u0026#34;, line 295, in _load self.model, self.ckpt = attempt_load_one_weight(weights) File \u0026#34;/home/ultralytics/ultralytics/nn/tasks.py\u0026#34;, line 1549, in attempt_load_one_weight ckpt, weight = torch_safe_load(weight) # load ckpt File \u0026#34;/home/ultralytics/ultralytics/nn/tasks.py\u0026#34;, line 1447, in torch_safe_load ckpt = torch_load(file, map_location=\u0026#34;cpu\u0026#34;) File \u0026#34;/home/ultralytics/ultralytics/utils/patches.py\u0026#34;, line 118, in torch_load return torch.load(*args, **kwargs) File \u0026#34;/home/max/.local/lib/python3.8/site-packages/torch/serialization.py\u0026#34;, line 1072, in load with _open_zipfile_reader(opened_file) as opened_zipfile: File \u0026#34;/home/max/.local/lib/python3.8/site-packages/torch/serialization.py\u0026#34;, line 480, in __init__ super().__init__(torch._C.PyTorchFileReader(name_or_buffer)) RuntimeError: PytorchStreamReader failed reading zip archive: failed finding central directory 说明 关键日志：\nRuntimeError: PytorchStreamReader failed reading zip archive: failed finding central directory 意思是 PyTorch 在加载权重文件时发现文件不是一个有效的 .pt zip 格式，通常有几种原因：\nyolo11n.pt 文件损坏或下载不完整 Ultralytics 会在第一次运行时自动下载权重，如果网络中断或下载被墙，文件可能是空的或部分内容缺失。 路径错误，加载到了一个错误的文件 例如你目录下可能有一个同名空文件。 Python / PyTorch 版本和权重文件格式不兼容（概率小，但存在） 解决方案 手动下载权重再运行 从官方仓库下载：\nwget https://github.com/ultralytics/assets/releases/download/v8.3.0/yolo11n.pt -O yolo11n.pt\n然后：\nyolo detect predict model=yolo11n.pt source=./demo.mp4\n","date":"27 June, 2025","id":28,"permalink":"/posts/-yolo-%E5%AE%9E%E6%97%B6%E7%9B%AE%E6%A0%87%E6%A3%80%E6%B5%8B%E7%AC%94%E8%AE%B0windows-%E6%91%84%E5%83%8F%E5%A4%B4%E6%8E%A8%E6%B5%81-+-wsl-yolo-%E8%AF%86%E5%88%AB/","summary":"✅ 优势：你可以随时修改 YOLO 源码，调试/开发更灵活。","tags":"Python YOLO OpenCV wsl windows","title":"🎯 YOLO 实时目标检测笔记：Windows 摄像头推流 + WSL YOLO 识别"},{"content":" The beauty of open source is that it is technically borderless. \u0026mdash; u/AlterTableUsernames\nVisual Studio 切换语言 在Visual Studio 中切换语言\n打开“工具”菜单:在Visual Studio 中，点击“工具”菜单。 进入“选项”:选择“选项” (Options)。 找到“环境”:在左侧的树形菜单中，找到“环境” (Environment)。 选择“区域设置”:在“环境”下，选择“区域设置” (International Settings)。 选择语言:在右侧的“语言”下拉菜单中，选择你想要的语言(例如中文)。 应用并重启:点击“确定” (OK) 应用更改，然后重启Visual Studio。 如果下拉语言后没有没有想要的语言，需要通过 Visual Studio Installer 安装后再来设置。\nfopen 编译报错 This function or variable may be unsafe 1\u0026gt;xxxxx error C4996: \u0026#39;fopen\u0026#39;: This function or variable may be unsafe. Consider using fopen_s instead. To disable deprecation, use _CRT_SECURE_NO_WARNINGS. See online help for details. 在 Visual Studio 项目设置中，请按照以下步骤操作：\n打开项目属性： 在 Visual Studio 的解决方案资源管理器中，右键单击项目名称。 从上下文菜单中选择“属性”。 导航至预处理器定义： 在项目属性窗口中，展开“配置属性”。 展开“C/C++”。 点击“预处理器”。 添加： 在“预处理器定义”字段中，添加_CRT_SECURE_NO_WARNINGS。 点击“确定”以应用更改。 重新构建项目：这将确保更改生效，并且警告 C4996 被抑制。 调试过程中遇到了严格按照上述配置后，即使 Build -\u0026gt; Clean Solution, Build -\u0026gt; Build Solution 仍然报相同的错误。退出 Visual Studio 后再次打开，重新编译，通过。\n重要提示：\nSDL 检查：如果你使用的是 Visual Studio 2012 或更高版本，还有一个额外的设置，称为“SDL 检查”，位于 C/C++ \u0026gt; 通用。此设置启用了额外的安全代码生成功能，并将安全相关的警告作为错误处理。将“SDL 检查”设置为“否”也可以抑制警告，但通常建议保持启用状态，并尽可能解决底层的安全问题。 替代方法：虽然将_CRT_SECURE_NO_WARNINGS添加到预处理器定义是全局抑制项目中警告的推荐方式，但你也可以： 在代码文件的开头添加#define _CRT_SECURE_NO_WARNINGS，在任何#include指令之前。 使用#pragma warning(disable:4996)来抑制特定代码段的警告。 请记住，抑制警告并不能解决使用潜在不安全函数相关的安全风险。最好使用这些函数的安全版本（如strcpy_s、sprintf_s等），或在代码中实现适当的安全措施。\n","date":"25 June, 2025","id":29,"permalink":"/posts/visual-studio/","summary":"The beauty of open source is that it is technically borderless. \u0026mdash; u/AlterTableUsernames","tags":"visual_studio","title":"🛠️ Visual Studio"},{"content":" The beauty of open source is that it is technically borderless. \u0026mdash; u/AlterTableUsernames\nThreadLocal 全面解析 在多线程并发编程中，保证线程安全是开发者必须面对的核心挑战之一。ThreadLocal 作为 Java 提供的一种独特的线程同步解决方案，它另辟蹊径，通过为每个线程提供变量的独立副本，巧妙地避免了多线程间的数据共享和竞争，从而实现了线程安全。本文将从 ThreadLocal 的基本概念入手，深入剖析其源码实现，探讨其在 C++ 中的对应方案，并结合常见的面试题，为您全方位揭示 ThreadLocal 的奥秘，包括其精妙的弱引用设计以及潜在的内存泄漏风险。\nThreadLocal 简介 ThreadLocal，顾名思义，即“线程局部变量”。它提供了一种创建变量的机制，该变量对于访问它的每个线程都有其自己独立的、初始化的副本。换言之，如果您在主线程中创建了一个 ThreadLocal 变量，那么在其他任何线程中，都无法直接访问主线程中该变量的值，而是会拥有并操作属于自己线程的那个变量的副本。\n这种“空间换时间”的策略，核心思想是隔离而非同步。与使用 synchronized 关键字或 Lock 锁等同步机制来保护共享资源不同，ThreadLocal 直接杜绝了资源共享的可能性，从而在根本上避免了线程间的竞争和同步开销。\n核心应用场景：\n每个线程需要一个独立的实例：例如，SimpleDateFormat 在多线程环境下是非线程安全的。通过 ThreadLocal 为每个线程创建一个 SimpleDateFormat 实例，可以有效避免并发问题。 维护线程上下文信息：在复杂的业务逻辑调用链中，为了避免在每个方法参数中都传递用户信息、事务 ID 等上下文信息，可以使用 ThreadLocal 在线程生命周期内持有这些信息，方便在调用链的任何位置随时获取。 数据库连接管理：在服务层和数据访问层之间，可以通过 ThreadLocal 来管理每个线程的数据库连接，确保同一个线程中的多次数据库操作使用的是同一个连接，从而保证事务的一致性。 源码实现讲解 要真正理解 ThreadLocal 的工作原理，必须深入其源码。ThreadLocal 的核心在于其内部类 ThreadLocalMap。\n核心关系图：\n每个 Thread 对象内部都有一个 threadLocals 成员变量，其类型就是 ThreadLocal.ThreadLocalMap。也就是说，ThreadLocalMap 实际上是 Thread 的一个属性，而不是 ThreadLocal 的。当调用 ThreadLocal 的 set(T value) 或 get() 方法时，ThreadLocal 会首先获取当前线程的 ThreadLocalMap，然后以 ThreadLocal 实例自身作为 key，进行值的存取。\n// Thread.java /* ThreadLocal values pertaining to this thread. This map is maintained * by the ThreadLocal class. */ ThreadLocal.ThreadLocalMap threadLocals = null; ThreadLocal.set(T value) 方法解析：\n获取当前线程对象 Thread t = Thread.currentThread();。 通过 getMap(t) 方法获取当前线程的 ThreadLocalMap 对象 map。 如果 map 存在，则调用 map.set(this, value)，将当前 ThreadLocal 实例作为 key，value 作为值，存入 map 中。 如果 map 不存在，则调用 createMap(t, value) 为当前线程创建一个新的 ThreadLocalMap，并将初始键值对存入。 // ThreadLocal.java public void set(T value) { Thread t = Thread.currentThread(); ThreadLocalMap map = getMap(t); if (map != null) map.set(this, value); else createMap(t, value); } ThreadLocalMap getMap(Thread t) { return t.threadLocals; } void createMap(Thread t, T firstValue) { t.threadLocals = new ThreadLocalMap(this, firstValue); } ThreadLocalMap 的内部结构：\nThreadLocalMap 是一个定制化的哈希表，其内部维护一个 Entry 数组。Entry 是 ThreadLocalMap 的一个静态内部类，它继承了 WeakReference\u0026lt;ThreadLocal\u0026lt;?\u0026gt;\u0026gt;。\n// ThreadLocal.java static class Entry extends WeakReference\u0026lt;ThreadLocal\u0026lt;?\u0026gt;\u0026gt; { /** The value associated with this ThreadLocal. */ Object value; Entry(ThreadLocal\u0026lt;?\u0026gt; k, Object v) { super(k); value = v; } } C++ 如何实现，是否有线程方案 在 C++ 中，同样存在线程局部存储（Thread-Local Storage, TLS）的概念，并且自 C++11 标准起，已经有了内建的支持。\nC++11 thread_local 关键字： C++11 引入了 thread_local 存储说明符。任何用 thread_local 声明的变量，在每个线程中都有其独立的实例。该变量的生命周期与线程的生命周期相同。这是在现代 C++ 中实现线程局部存储的首选和标准方式。\n#include \u0026lt;iostream\u0026gt; #include \u0026lt;thread\u0026gt; thread_local int g_tls_var = 0; void thread_func(int id) { g_tls_var = id; std::cout \u0026lt;\u0026lt; \u0026#34;Thread \u0026#34; \u0026lt;\u0026lt; id \u0026lt;\u0026lt; \u0026#34;: g_tls_var = \u0026#34; \u0026lt;\u0026lt; g_tls_var \u0026lt;\u0026lt; std::endl; } int main() { std::thread t1(thread_func, 1); std::thread t2(thread_func, 2); t1.join(); t2.join(); std::cout \u0026lt;\u0026lt; \u0026#34;Main thread: g_tls_var = \u0026#34; \u0026lt;\u0026lt; g_tls_var \u0026lt;\u0026lt; std::endl; return 0; } Boost 库 boost::thread_specific_ptr： 在 C++11 标准之前，Boost 库提供了 boost::thread_specific_ptr 类模板，它提供了一种可移植的线程局部存储实现。它为每个线程管理一个指向对象的指针。\nPOSIX 线程 (Pthreads)： 在遵循 POSIX 标准的系统（如 Linux、macOS）上，可以使用 pthread_key_create 来创建一个键，然后通过 pthread_setspecific 和 pthread_getspecific 来为每个线程设置和获取与该键关联的数据。\n常见面试题及解答 为什么key要使用 ThreadLocal？ 在 ThreadLocalMap 的设计中，ThreadLocal 实例本身被用作键（key），而不是线程 ID 或者其他标识符。这是因为 ThreadLocalMap 是存储在每个 Thread 对象内部的。一个线程可以关联多个 ThreadLocal 变量。因此，需要一种方式来区分这些不同的线程局部变量。使用 ThreadLocal 实例作为 key，可以精准地定位到当前线程中与该 ThreadLocal 变量对应的那个值。\n可以将其理解为一个两级的映射关系：Thread -\u0026gt; ThreadLocalMap -\u0026gt; (ThreadLocal -\u0026gt; Value)。\n为什么键（Key）必须是弱引用 (Weak Reference)？ 这是 ThreadLocal 设计中最为精妙和常被问及的一点。ThreadLocalMap 中的 Entry 的键（即 ThreadLocal 实例）被设计为弱引用。\n弱引用（Weak Reference） 是一种相对“弱”的引用，它所引用的对象可以在垃圾回收（GC）时被回收，即使该弱引用本身还存在。当垃圾回收器扫描内存时，如果一个对象只被弱引用指向，那么这个对象就会被回收。\n在 ThreadLocal 的场景下，如果 ThreadLocal 实例（通常是某个类的静态字段）在外部不再被强引用（例如，类被卸载），垃圾回收器就会回收这个 ThreadLocal 对象。由于 ThreadLocalMap 中的键是弱引用，这个键（Entry 中的 referent）就会变为 null。\n这样的设计主要是为了防止内存泄漏。如果键是强引用，那么即使外部的 ThreadLocal 实例被置为 null，只要线程还存活，ThreadLocalMap 就会一直持有对 ThreadLocal 实例的强引用，导致 ThreadLocal 实例无法被垃圾回收，进而它所关联的 value 也无法被回收，从而造成内存泄漏。\nThreadLocal 内存泄漏的根本原因 尽管 ThreadLocalMap 的键使用了弱引用来试图避免内存泄漏，但在特定场景下，内存泄漏的风险依然存在。其根本原因在于 ThreadLocalMap 的生命周期与 Thread 的生命周期绑定。\n泄漏场景分析：\n当一个 ThreadLocal 变量不再被使用时，我们通常会将其引用置为 null，以便垃圾回收器能够回收它。由于 ThreadLocalMap 的键是弱引用，ThreadLocal 对象本身确实可以被回收，Entry 中的键会变为 null。\n然而，Entry 中的值（value）是强引用。只要这个 Entry 对象还存在于 ThreadLocalMap 中（即线程还存活），这个强引用链（Thread -\u0026gt; ThreadLocalMap -\u0026gt; Entry -\u0026gt; value）就会一直存在，导致 value 对象无法被回收。\n如果线程是长期存活的，比如在线程池中被复用，那么这些键为 null 的 Entry 就会越来越多，它们所引用的 value 对象也无法被释放，最终可能导致内存溢出（OutOfMemoryError）。\n如何防止内存泄漏？\n虽然 ThreadLocal 在 get(), set(), remove() 等方法中会检查并清理键为 null 的 Entry，但这是一种“被动”的清理方式，并不保证能及时清理。\n因此，最佳实践是在使用完 ThreadLocal 变量后，显式地调用其 remove() 方法，将当前线程的 ThreadLocalMap 中对应的 Entry 彻底移除，从而断开对 value 的强引用，让垃圾回收器能够正常回收。\nThreadLocal\u0026lt;MyObject\u0026gt; myThreadLocal = new ThreadLocal\u0026lt;\u0026gt;(); try { myThreadLocal.set(new MyObject()); // ... use myThreadLocal } finally { myThreadLocal.remove(); // 关键！确保清理 } 总结 ThreadLocal 为多线程编程提供了一种优雅的线程安全解决方案。它通过数据隔离的方式，避免了复杂的同步问题，在特定场景下能显著提升程序性能和代码简洁性。然而，对其工作原理的深入理解至关重要，尤其是其内部的 ThreadLocalMap 结构、弱引用键的设计以及潜在的内存泄漏风险。掌握其源码实现细节，并养成在使用后及时调用 remove() 方法的良好习惯，是安全、高效地使用 ThreadLocal 的关键所在。\n![@startuml \u0026rsquo; Diagram Title title Thread, ThreadLocal, and ThreadLocalMap Relationship\n\u0026rsquo; Skin parameters for a clean look skinparam classAttributeIconSize 0 skinparam linetype ortho\n\u0026rsquo; Class Definitions\nclass Thread {\nthreadLocals: ThreadLocal.ThreadLocalMap } class \u0026ldquo;ThreadLocal\u0026rdquo; as ThreadLocal {\nget(): T set(value: T): void remove(): void } package \u0026ldquo;java.lang\u0026rdquo; { class ThreadLocalMap { - table: Entry[] }\nclass \u0026ldquo;Entry\u0026rdquo; extends \u0026ldquo;WeakReference\u0026rdquo; { + value: Object } }\nclass Data { .. User-specific data .. }\n\u0026rsquo; Relationships and Associations\n\u0026rsquo; A Thread has one ThreadLocalMap Thread \u0026ldquo;1\u0026rdquo; *\u0026ndash; \u0026ldquo;0..1\u0026rdquo; ThreadLocalMap : contains\n\u0026rsquo; ThreadLocalMap contains multiple Entry objects ThreadLocalMap \u0026ldquo;1\u0026rdquo; \u0026ndash; \u0026ldquo;1..\u0026rdquo; Entry : contains an array of\n\u0026rsquo; An Entry\u0026rsquo;s key is a WeakReference to a ThreadLocal instance Entry o\u0026ndash;\u0026gt; \u0026ldquo;1\u0026rdquo; ThreadLocal : key (Weak Reference)\n\u0026rsquo; An Entry\u0026rsquo;s value is a Strong Reference to the actual data object Entry \u0026ndash;\u0026gt; \u0026ldquo;1\u0026rdquo; Data : value (Strong Reference)\n\u0026rsquo; ThreadLocal interacts with the current Thread and its ThreadLocalMap ThreadLocal ..\u0026gt; Thread : uses Thread.currentThread() ThreadLocal ..\u0026gt; ThreadLocalMap : operates on\n\u0026rsquo; Notes and Explanations\nnote right of Entry Key (ThreadLocal) is a Weak Reference. This allows the ThreadLocal object to be garbage collected if it\u0026rsquo;s no longer referenced elsewhere, preventing one type of memory leak. end note\nnote \u0026ldquo;Potential Memory Leak!\\nIf the ThreadLocal instance is garbage collected, the key in the Entry becomes null.\\nHowever, the value (Data) is still strongly referenced by the Entry.\\nIf the thread is long-lived (like in a thread pool) and remove() is not called,\\nthese entries with null keys will accumulate and the value objects will not be freed,\\nleading to a memory leak.\u0026rdquo; as LeakNote\nEntry .. LeakNote @enduml]()\n","date":"24 June, 2025","id":30,"permalink":"/posts/-threadlocal-%E5%85%A8%E9%9D%A2%E8%A7%A3%E6%9E%90/","summary":"The beauty of open source is that it is technically borderless. \u0026mdash; u/AlterTableUsernames","tags":"cpp java thread ThreadLocal","title":"📘ThreadLocal 全面解析"},{"content":"📘 关于 Intel I210 网卡的 Device ID 要确认 Intel I210 网卡的 Device ID（设备ID），最直接、可靠的方式是通过 lspci 命令读取 PCI 设备的配置空间信息（无需拆机或修改代码），以下是具体步骤和验证方法：\n一、核心命令：lspci -nn（直接显示 Device ID） lspci 是 Linux 下查询 PCI 设备的工具，-nn 参数会显示 厂商ID（Vendor ID）和设备ID（Device ID）（格式：VendorID:DeviceID），这是最直接的方式：\n执行命令： # 方法1：查询所有以太网设备的 ID（推荐，避免混淆） lspci -nn | grep -i Ethernet # 方法2：精准查询目标 BDF 地址的设备 ID（你的 I210 网卡 BDF 是 0001:18:00.0） lspci -nn -s 0001:18:00.0 输出解读： 执行后会看到类似如下结果（重点关注 [8086:xxxx] 部分）：\n0001:18:00.0 Ethernet controller [0200]: Intel Corporation I210 Gigabit Network Connection [8086:1533] (rev 03) 8086：Intel 的标准 厂商ID（Vendor ID）（固定值，所有 Intel PCI 设备通用）； 1533：就是你要的 Device ID（I210 网卡的设备ID，对应驱动中的宏定义）。 二、验证：I210 的 Device ID 与驱动宏定义匹配 结合你之前提供的驱动代码中的宏定义，I210 系列的 Device ID 预定义如下（核对是否与你查询到的一致）：\n// 你之前提供的 igb 驱动宏定义 #define E1000_DEV_ID_I210_COPPER\t0x1533 // 铜缆接口（RJ45） #define E1000_DEV_ID_I210_FIBER\t0x1536 // 光纤接口 #define E1000_DEV_ID_I210_SERDES\t0x1537 // SERDES 接口 #define E1000_DEV_ID_I210_SGMII\t0x1538 // SGMII 接口 #define E1000_DEV_ID_I210_COPPER_FLASHLESS\t0x157B // 无闪存铜缆版 #define E1000_DEV_ID_I210_SERDES_FLASHLESS\t0x157C // 无闪存 SERDES 版 你的 I210 是 铜缆接口（RJ45），查询到的 Device ID 应为 0x1533（对应 E1000_DEV_ID_I210_COPPER）； 若查询到的 Device ID 是其他值（如 0x1536），则对应 I210 的其他硬件形态（如光纤版）。 三、备用方法：读取 PCI 配置空间（底层验证） 若 lspci 命令不可用（如嵌入式系统无该工具），可通过 setpci 命令直接读取 PCI 配置空间的 Device ID 寄存器（PCI 配置空间偏移 0x02，2字节长度）：\n执行命令（针对目标 BDF 地址 0001:18:00.0）： # 格式：setpci -s BDF地址 寄存器偏移值.l setpci -s 0001:18:00.0 02.l 输出解读： 命令会返回 4 位十六进制数（如 1533），对应 Device ID（注意：setpci 输出是 小端序，但 Intel 设备的 ID 是小端存储，直接输出即为正确的 Device ID）； 例如输出 1533，即 Device ID 为 0x1533，与 lspci -nn 结果一致。 四、关键核对：确认驱动是否支持该 Device ID 若查询到的 Device ID（如 0x1533）在你提供的 E1000_DEV_ID_XXX 宏定义中存在 → 驱动本身支持该硬件； 若不存在 → 说明当前 igb 驱动版本过旧，需要升级驱动或内核（新增该 Device ID 的支持）。 drivers/net/ethernet/intel/igb/e1000_hw.h\n#define E1000_DEV_ID_82576\t0x10C9 #define E1000_DEV_ID_82576_FIBER\t0x10E6 #define E1000_DEV_ID_82576_SERDES\t0x10E7 #define E1000_DEV_ID_82576_QUAD_COPPER\t0x10E8 #define E1000_DEV_ID_82576_QUAD_COPPER_ET2\t0x1526 #define E1000_DEV_ID_82576_NS\t0x150A #define E1000_DEV_ID_82576_NS_SERDES\t0x1518 #define E1000_DEV_ID_82576_SERDES_QUAD\t0x150D #define E1000_DEV_ID_82575EB_COPPER\t0x10A7 #define E1000_DEV_ID_82575EB_FIBER_SERDES\t0x10A9 #define E1000_DEV_ID_82575GB_QUAD_COPPER\t0x10D6 #define E1000_DEV_ID_82580_COPPER\t0x150E #define E1000_DEV_ID_82580_FIBER\t0x150F #define E1000_DEV_ID_82580_SERDES\t0x1510 #define E1000_DEV_ID_82580_SGMII\t0x1511 #define E1000_DEV_ID_82580_COPPER_DUAL\t0x1516 #define E1000_DEV_ID_82580_QUAD_FIBER\t0x1527 #define E1000_DEV_ID_DH89XXCC_SGMII\t0x0438 #define E1000_DEV_ID_DH89XXCC_SERDES\t0x043A #define E1000_DEV_ID_DH89XXCC_BACKPLANE\t0x043C #define E1000_DEV_ID_DH89XXCC_SFP\t0x0440 #define E1000_DEV_ID_I350_COPPER\t0x1521 #define E1000_DEV_ID_I350_FIBER\t0x1522 #define E1000_DEV_ID_I350_SERDES\t0x1523 #define E1000_DEV_ID_I350_SGMII\t0x1524 #define E1000_DEV_ID_I210_COPPER\t0x1533 #define E1000_DEV_ID_I210_FIBER\t0x1536 #define E1000_DEV_ID_I210_SERDES\t0x1537 #define E1000_DEV_ID_I210_SGMII\t0x1538 #define E1000_DEV_ID_I210_COPPER_FLASHLESS\t0x157B #define E1000_DEV_ID_I210_SERDES_FLASHLESS\t0x157C #define E1000_DEV_ID_I211_COPPER\t0x1539 #define E1000_DEV_ID_I354_BACKPLANE_1GBPS\t0x1F40 #define E1000_DEV_ID_I354_SGMII\t0x1F41 #define E1000_DEV_ID_I354_BACKPLANE_2_5GBPS\t0x1F45 五、关于 I210 Device ID 描述 #define E1000_DEV_ID_I210_COPPER\t0x1533 #define E1000_DEV_ID_I210_FIBER\t0x1536 #define E1000_DEV_ID_I210_SERDES\t0x1537 #define E1000_DEV_ID_I210_SGMII\t0x1538 #define E1000_DEV_ID_I210_COPPER_FLASHLESS\t0x157B #define E1000_DEV_ID_I210_SERDES_FLASHLESS\t0x157C #define E1000_DEV_ID_I211_COPPER\t0x1539 如上这些 E1000_DEV_ID_I210_XXX 宏，本质是 Intel I210 千兆网卡不同硬件变体的唯一标识——核心芯片都是 I210，但物理接口类型、硬件形态、功能特性 存在差异，驱动通过不同 Device ID 匹配对应的硬件参数（如接口初始化逻辑、NVM 读写规则），确保兼容性。\n下面用通俗的语言拆解每个 ID 的核心区别：\nDevice ID 宏 十六进制值 核心区别（硬件形态） 应用场景 关键特性 E1000_DEV_ID_I210_COPPER 0x1533 铜缆版（RJ45接口） 桌面机、服务器、工业板卡（最常见） 1. 用网线（双绞线）传输，支持百兆/千兆自适应；2. 带板载闪存（Flash），存储网卡固件、MAC地址、配置参数；3. 家用/商用场景的主流版本。 E1000_DEV_ID_I210_FIBER 0x1536 光纤版（SFP接口） 机房、长距离传输（如跨楼宇） 1. 插光纤模块（SFP），传输距离可达几十公里（远超铜缆的100米）；2. 抗干扰能力强，适合工业/电信级场景；3. 成本高于铜缆版。 E1000_DEV_ID_I210_SERDES 0x1537 SERDES版（串行/解串器接口） 服务器背板、工业交换机 1. 无外部物理接口，直接对接主板/背板的 SERDES 总线；2. 用于“板内/背板”高速通信，减少外部接口损耗；3. 纯工业级设计，一般不面向普通用户。 E1000_DEV_ID_I210_SGMII 0x1538 SGMII版（串行千兆介质独立接口） 嵌入式板卡、定制化硬件 1. 对接外部 PHY 芯片（物理层芯片），而非直接出网口；2. 灵活性高，可适配不同物理接口（铜缆/光纤）；3. 常见于嵌入式Linux设备（如工控机、路由器）。 E1000_DEV_ID_I210_COPPER_FLASHLESS 0x157B 无闪存铜缆版 低成本定制化场景、白牌硬件 1. 接口和功能和 0x1533 一致（RJ45铜缆）；2. 无板载闪存，网卡固件、MAC地址需从系统内存加载；3. 成本更低，依赖主板/系统提供配置。 E1000_DEV_ID_I210_SERDES_FLASHLESS 0x157C 无闪存SERDES版 工业级无闪存定制场景 1. 接口和功能和 0x1537 一致（SERDES）；2. 无板载闪存，固件/配置从系统加载；3. 极致成本控制的工业场景。 ","date":"24 June, 2025","id":31,"permalink":"/posts/--%E5%85%B3%E4%BA%8E-intel-i210-%E7%BD%91%E5%8D%A1%E7%9A%84-device-id/","summary":"要确认 Intel I210 网卡的 Device ID（设备ID），最直接、可靠的方式是通过 lspci 命令读取 PCI 设备的配置空间信息（无需拆机或修改代码），以下是具体步骤和验证方法：","tags":"linux kernel driver intel ethernet i210 PCIe","title":"📘关于 Intel I210 网卡的 Device ID"},{"content":" The beauty of open source is that it is technically borderless. \u0026mdash; u/AlterTableUsernames\n深入解析 Java 线程本地化：从 ThreadLocal 到 ScopedValue 的演进与选择 摘要 在 Java 服务端开发中，将贯穿单次业务流程的上下文信息（如用户身份、分布式追踪ID）在线程内部进行传递，是一项基础且关键的需求。为应对这一挑战，Java 提供了经典的 ThreadLocal 机制，它通过巧妙地将数据与执行线程绑定，实现了高效的无锁化数据隔离。然而，这一经典方案如同一把双刃剑：其精巧的设计背后，是充满陷阱的无界生命周期、难以追踪的可变性，以及在现代线程池模型下极易触发的内存泄漏风险。\n随着 Project Loom 计划的成熟，Java 并发编程正经历一场深刻的范式革命。虚拟线程（Virtual Threads）的引入，使得 InheritableThreadLocal 的继承成本变得不可接受；而结构化并发（Structured Concurrency）的提出，则呼唤一种更安全、更具确定性的上下文传递机制。在此背景下，ScopedValue 应运而生。它并非 ThreadLocal 的简单改良，而是从设计哲学上对线程本地数据的一次重塑，用“动态作用域”的不可变绑定，取代了“线程寄生”的可变状态。\n本文将对 Java 的线程本地化技术进行一次从经典到现代的完整、深入的探索。我们将首先解构 ThreadLocal 的内部架构，详尽剖析其 Thread-ThreadLocalMap-ThreadLocal 的委托关系模型，并对其“弱引用Key-强引用Value”等关键设计决策背后的深层思辨进行论证。接着，我们将聚焦于 InheritableThreadLocal 在线程池和虚拟线程时代下的困境与宿怨。随后，文章将全面转向 ScopedValue，将其作为面向未来的解决方案，重点阐述其与结构化并发如何天作之合般地解决了数据自动、安全、高效传播的核心难题。最后，本文通过一场涉及正确性、性能与心智模型的全方位对决，为开发者在技术演进的浪潮中做出明智选择提供坚实的理论依据。\n第一章: ThreadLocal - 一个设计精巧而又充满陷阱的经典 ThreadLocal 的核心使命是在多线程环境下，为每个线程提供一个专属的数据存储空间，从而实现线程级别的数据隔离。它让开发者感觉好像在使用一个普通的全局变量，但实际上每个线程操作的都是自己的独立副本。\n1.1 核心架构：委托与寄生的艺术 要理解 ThreadLocal，首先必须破除一个误解：数据并非存储在 ThreadLocal 对象本身。ThreadLocal 实例扮演的是一个“访问工具”或“代理”的角色，真正的存储发生在执行线程 Thread 对象的内部。这种关系可以被理解为一种巧妙的“委托”或“寄生”模型。\n它们之间的关系如下：\nThread 对象: 线程的实体。每个 Thread 实例内部都有一个 ThreadLocal.ThreadLocalMap 类型的成员变量 threadLocals。这个 Map 是惰性创建的，只在线程首次需要存储 ThreadLocal 数据时才被实例化。 ThreadLocalMap: ThreadLocal 的一个内部静态类，是一个为 ThreadLocal 量身定制的、非通用的哈希表。它才是真正存储数据的容器，其所有权完全归属于 Thread 对象。 ThreadLocal 对象: 它在整个体系中是“定位键”和“访问入口”。你的代码通过调用 ThreadLocal 实例的 set() 或 get() 方法来操作数据。 用户数据 (e.g., RequestData): 期望在线程内共享的业务数据，作为“值”被存储。 一次 set 操作的完整轨迹: 当 CONTEXT.set(data) 被调用时：\n获取当前线程: ThreadLocal 内部通过 Thread.currentThread() 获取到当前执行线程的实例。 获取线程的 Map: 它会访问当前线程的 threadLocals 字段。如果该字段为 null，就创建一个新的 ThreadLocalMap 并将其赋值给 threadLocals。 委托存储: ThreadLocal 将自身（this）作为 Key，将 data 作为 Value，调用 ThreadLocalMap 的 set 方法，将这个键值对存入 Map 内部的 Entry 数组中。 这个架构确保了数据与线程的生命周期绑定，实现了彻底的隔离。\ngraph TD subgraph \u0026#34;Application Code (你的代码)\u0026#34; U1[\u0026#34;ThreadLocal\u0026amp;lt;User\u0026amp;gt; USER_CTX\u0026#34;] U2[\u0026#34;ThreadLocal\u0026amp;lt;Tx\u0026amp;gt; TX_CTX\u0026#34;] OP[\u0026#34;调用 USER_CTX.set(user)\u0026#34;] end subgraph \u0026#34;Thread-1 Instance (当前线程)\u0026#34; A[Thread-1 对象] -- \u0026#34;内部持有\u0026#34; --\u0026gt; B(threadLocals: ThreadLocalMap) end subgraph \u0026#34;ThreadLocalMap (属于 Thread-1)\u0026#34; %% 正确的语法：节点定义后直接跟链接符或换行 B -- \u0026#34;内部维护一个\u0026#34; --\u0026gt; C[\u0026#34;Entry[] 数组\u0026#34;] C -- \u0026#34;包含多个条目\u0026#34; --\u0026gt; E1[\u0026#34;Entry 1\u0026#34;] C -- \u0026#34;包含多个条目\u0026#34; --\u0026gt; E2[\u0026#34;Entry 2\u0026#34;] end subgraph \u0026#34;Entry 1 的结构\u0026#34; E1 -- \u0026#34;Key (弱引用)\u0026#34; --\u0026gt; K1[\u0026#34;USER_CTX 实例\u0026#34;] E1 -- \u0026#34;Value (强引用)\u0026#34; --\u0026gt; V1[\u0026#34;user 对象\u0026#34;] end subgraph \u0026#34;Entry 2 的结构\u0026#34; E2 -- \u0026#34;Key (弱引用)\u0026#34; --\u0026gt; K2[\u0026#34;TX_CTX 实例\u0026#34;] E2 -- \u0026#34;Value (强引用)\u0026#34; --\u0026gt; V2[\u0026#34;tx 对象\u0026#34;] end %% 描述动态关系 U1 -- \u0026#34;作为唯一的 Key\u0026#34; --\u0026gt; K1 U2 -- \u0026#34;作为唯一的 Key\u0026#34; --\u0026gt; K2 OP -- \u0026#34;1. 获取当前线程\u0026#34; --\u0026gt; A OP -- \u0026#34;2. 获取/创建 ThreadLocalMap\u0026#34; --\u0026gt; B OP -- \u0026#34;3. 将 Key-Value 存入\u0026#34; --\u0026gt; E1 1.2 设计抉择的深层思辨 ThreadLocalMap 的设计细节充满了权衡与智慧，理解它们是掌握 ThreadLocal 的关键。\n1.2.1 辨身之钥：为何 Key 必须是 ThreadLocal 实例？\n在一个线程中，我们可能需要存储用户、事务、语言等多种上下文。ThreadLocalMap 如何区分它们？答案是独一无二的 Key。\n如果采用String作为 Key，会立即面临三大问题：\n命名冲突: 无法保证不同模块或第三方库不使用相同的字符串，导致数据被意外覆盖。 类型不安全: 值只能是 Object，每次 get() 都需要不安全的强制类型转换。 封装性差: 任何代码都可以猜测字符串 Key，破坏模块间的数据隔离。 而使用 ThreadLocal 对象本身作为 Key 则完美地解决了这些问题：\n绝对唯一: 每个 new ThreadLocal\u0026lt;\u0026gt;() 实例的内存地址都是唯一的，作为 Key 永不冲突。 类型安全: ThreadLocal\u0026lt;T\u0026gt; 泛型确保了 set 和 get 的类型在编译期就得到保证。 访问控制: 必须持有 ThreadLocal 对象的引用（这把“钥匙”），才能访问对应的“保险箱”，提供了天然的封装。 1.2.2 生死之契：为何 Key 是弱引用，Value 是强引用？\n这是 ThreadLocal 中最精妙也最容易引起误解的设计，其目标是在 ThreadLocal 对象本身被废弃后，为其关联的数据创造被回收的“机会”。\nKey 为弱引用 (Weak Reference):\n目的: 防止 ThreadLocal 对象本身的内存泄漏。 场景: 假设一个 ThreadLocal 实例在代码中不再被任何强引用指向。如果 ThreadLocalMap 中的 Key 是强引用，那么只要线程不死，这个 ThreadLocal 对象就永远无法被 GC 回收，其关联的类和类加载器也同样无法卸载。 弱引用的作用: 弱引用不会阻止 GC。当 ThreadLocal 实例在外部没有强引用时，GC 会回收它。回收后，ThreadLocalMap 中对应的 Entry 的 Key 就会变为 null。 Value 为强引用 (Strong Reference):\n目的: 保证用户数据的生命周期由用户控制。 场景: 用户存入的数据理应在用户主动 remove() 或线程结束前一直有效。如果 Value 是弱引用，那么当用户数据在别处没有强引用时，它可能会被 GC 意外回收，导致 get() 时返回 null，这违背了 ThreadLocal 的设计初衷。 这个设计的“漏洞”与开发者的责任: 这个“弱 Key - 强 Value”的设计，恰恰是 ThreadLocal 内存泄漏的根源。当 Key 因弱引用被回收变为 null 后，这个 Entry 就成了 \u0026lt;null, StrongRef\u0026lt;Value\u0026gt;\u0026gt; 的“幽灵条目”。虽然 ThreadLocal 在 get/set 时会尝试清理这些“幽灵”，但这种清理是被动且不确定的。只要线程持续存活且不进行 get/set 操作，这个强引用的 Value 就永远不会被释放。 因此，在使用 ThreadLocal 的地方，必须在 finally 块中通过调用 remove() 方法来主动清理，这是保证系统稳定的铁律。\n1.3 继承的代价：InheritableThreadLocal 与线程池的宿怨 InheritableThreadLocal 允许子线程继承父线程的 ThreadLocal 值，其原理是在创建子线程时，将父线程的 ThreadLocalMap 复制一份给子线程。在与线程池模型结合时，这会产生两个严重问题：\n数据污染: 线程池会复用线程。当任务 A 在线程 T1 中设置了值但未清理，任务 B 复用 T1 时，会“继承”到任务 A 的残留数据，导致严重的数据错乱和安全问题。 性能瓶颈: 复制 Map 的操作是有成本的。在即将到来的虚拟线程时代，创建百万级别的线程是常态，此时为每个线程都进行一次 Map 复制，其性能开销将是灾难性的，完全抵消了虚拟线程的轻量级优势。 第二章: ScopedValue - 面向结构化并发的范式革命 ScopedValue (预览功能) 是 Java 为应对 ThreadLocal 的固有缺陷，并拥抱结构化并发而推出的全新解决方案。它从根本上改变了线程本地数据的编程模型。\n2.1 从“可变状态”到“动态作用域” ScopedValue 的核心哲学是 Immutability + Dynamic Scoping (不可变性 + 动态作用域)。\n它没有 set() 方法，数据一旦在某个作用域内被绑定，就是不可变的。这使得数据流清晰、可预测且线程安全。 它的生命周期与一个清晰的词法作用域绑定，通过 ScopedValue.where(KEY, value).run(...) 或 call(...) 来定义。当代码执行离开这个 run 方法的 lambda 表达式时，绑定自动、确定性地失效。 public static final ScopedValue\u0026lt;String\u0026gt; CONTEXT = ScopedValue.newInstance(); // 定义一个作用域，并在此期间绑定值 ScopedValue.where(CONTEXT, \u0026#34;Hello, Scoped World\u0026#34;).run(() -\u0026gt; { // 在此 lambda 内部，CONTEXT.get() 返回 \u0026#34;Hello, Scoped World\u0026#34; System.out.println(CONTEXT.get()); // 可以嵌套绑定，创建新的、更内层的作用域 ScopedValue.where(CONTEXT, \u0026#34;Inner Value\u0026#34;).run(() -\u0026gt; { System.out.println(CONTEXT.get()); // 输出 \u0026#34;Inner Value\u0026#34; }); // 内部作用域结束后，恢复为外部作用域的值 System.out.println(CONTEXT.get()); // 再次输出 \u0026#34;Hello, Scoped World\u0026#34; }); // 作用域之外，CONTEXT 未绑定，get() 会抛出异常 // System.out.println(CONTEXT.get()); // throws NoSuchElementException 这种设计从根本上消除了内存泄漏的可能，并将资源管理责任从开发者手中交还给了平台。\n2.2 自动传播的魔法：ScopedValue 与 StructuredTaskScope ScopedValue 最强大的能力，体现在与 StructuredTaskScope 的无缝集成上，它完美地解决了并发任务间的数据传递问题。\n其机制可以简化为“捕获与传播”：\n捕获 (Capture): 当 new StructuredTaskScope() 在一个 ScopedValue 的作用域内被实例化时，它会“快照”并捕获当前线程所有已绑定的 ScopedValue。 传播 (Propagate): 当调用 scope.fork() 创建一个子任务（通常是虚拟线程）时，StructuredTaskScope 会确保这个子任务在运行时，能够访问到之前捕获的所有绑定。这并非昂贵的“复制”，而是一种高效的“共享”或“挂载”机制。 代码示例：\npublic static void handleRequest(String userName) throws ExecutionException, InterruptedException { ScopedValue.where(USER_CONTEXT, new User(userName)).run(() -\u0026gt; { // 在此作用域内创建 TaskScope，它将捕获 USER_CONTEXT 的绑定 try (var scope = new StructuredTaskScope.ShutdownOnFailure()) { Future\u0026lt;Order\u0026gt; orderFuture = scope.fork(() -\u0026gt; { // 子任务无需任何额外操作，即可安全地获取上下文 // 这个 get() 调用发生在另一个（可能是虚拟）线程上 User currentUser = USER_CONTEXT.get(); return service.fetchOrderByUser(currentUser); }); Future\u0026lt;Profile\u0026gt; profileFuture = scope.fork(() -\u0026gt; { // 另一个子任务同样能获取到 User currentUser = USER_CONTEXT.get(); return service.fetchProfileByUser(currentUser); }); // 等待所有子任务完成 scope.join().throwIfFailed(); Order order = orderFuture.resultNow(); Profile profile = profileFuture.resultNow(); // ... } }); } 这种模式的优势是压倒性的：\n正确性由结构保证: 不再有 remove() 的遗忘，不再有数据污染。上下文的生命周期与并发任务的生命周期完全同步。 为海量并发而生: 高效的传播机制使得在百万级虚拟线程中传递上下文成为可能，这是 InheritableThreadLocal 无法企及的。 代码清晰可读: 上下文的传递是声明式的，其作用范围一目了然，极大地降低了并发编程的心智负担。 第三章: 综合对决 - 在正确性、性能与心智模型之间权衡 ThreadLocal 与 ScopedValue 的选择，不仅是 API 的选择，更是对两种不同并发世界观的选择。\n对比维度 ThreadLocal (命令式状态管理) ScopedValue (声明式作用域绑定) 深度解读 正确性模型 开发者纪律驱动：依赖开发者在正确的位置手动remove()，极易出错。 平台机制保障：生命周期与词法作用域绑定，自动清理，从设计上免疫泄漏和污染。 ScopedValue 将正确性的责任从开发者转移给了平台，是更健壮的工程实践。 性能模型 继承昂贵：InheritableThreadLocal 依靠复制，在虚拟线程时代是性能杀手。 传播高效：专为虚拟线程优化，通过轻量级共享机制传递，几乎无开销。 ScopedValue 是 Project Loom 能够成功的关键性能基石之一。 心智模型 隐式、分散: 状态何时被改变、何时被清除，在代码中是不可见的，增加了认知负荷。 显式、聚合: where 代码块清晰地界定了上下文的有效范围，代码即文档。 ScopedValue 提供了更易于推理和维护的代码结构，降低了并发编程的复杂度。 世界观 非结构化: 适应于 ExecutorService \u0026ldquo;发射后不管\u0026rdquo; 的模型，父子任务生命周期解耦。 结构化: 与 StructuredTaskScope 完美契合，任务和其上下文的生命周期被统一管理。 ScopedValue 是 Java 迈向更结构化、更安全的并发编程模型的有机组成部分。 第四章: 结论 - 选择你的并发世界观 ThreadLocal 是 Java 并发工具箱中一位功勋卓著但已显疲态的老将。它源于一个平台线程昂贵、并发模型相对简单的时代，其设计要求开发者具备极高的纪律性来驾驭其复杂性。\nScopedValue 则是为即将到来的并发新纪元而生的原生公民。它与虚拟线程、结构化并发共同构成了 Java 现代并发编程的三大支柱。它用声明式的、不可变的、有作用域的绑定，取代了命令式的、可变的、无界的状态管理，为开发者提供了一条通往更安全、更高效、更清晰并发编程的康庄大道。\n最终建议：\n对于所有新开发的、尤其是期望利用虚拟线程和结构化并发优势的应用，ScopedValue 是不二之选。 ThreadLocal 应仅限于维护遗留系统，或在某些与 ScopedValue 模型不兼容的、被充分理解的极端场景下审慎使用。 拥抱 ScopedValue，不仅是学习一个新 API，更是接纳一种更先进的并发编程思想，是与 Java 平台的演进方向保持同步的关键一步。\n","date":"24 June, 2025","id":32,"permalink":"/posts/%E6%B7%B1%E5%85%A5%E8%A7%A3%E6%9E%90-java-%E7%BA%BF%E7%A8%8B%E6%9C%AC%E5%9C%B0%E5%8C%96%E4%BB%8E-threadlocal-%E5%88%B0-scopedvalue-%E7%9A%84%E6%BC%94%E8%BF%9B%E4%B8%8E%E9%80%89%E6%8B%A9/","summary":"The beauty of open source is that it is technically borderless. \u0026mdash; u/AlterTableUsernames","tags":"cpp java thread ThreadLocal ScopedValue 虚拟线程 结构化并发","title":"📘深入解析 Java 线程本地化：从 ThreadLocal 到 ScopedValue 的演进与选择"},{"content":"深入 C++ 的隐秘角落：彻底解析参数依赖查找 (ADL) 在 C++ 的世界里，有些特性如同空气，无处不在，默默地支撑着我们代码的优雅与简洁，但我们却很少去探究其背后的原理。std::cout \u0026lt;\u0026lt; \u0026quot;Hello, World!\u0026quot;; 这行代码对于每个 C++ 开发者来说都再熟悉不过。但是，你是否曾停下来想过，operator\u0026lt;\u0026lt; 函数明明定义在 std 命名空间中，为什么我们在调用它时，并不需要写成 std::operator\u0026lt;\u0026lt;(std::cout, \u0026quot;Hello, World!\u0026quot;); 这种冗长繁琐的形式？\n这个问题的答案，就隐藏在 C++ 语言一个强大而又微妙的机制中——参数依赖查找（Argument-Dependent Lookup），通常被缩写为 ADL。它还有一个广为人知的名字，叫 Koenig 查找（Koenig Lookup），以其发现者 Andrew Koenig 的名字命名。\nADL 是 C++ 名称查找规则的重要组成部分。它极大地提升了泛型编程和操作符重载的可用性，使得代码更符合人类的直觉。然而，它也是一柄双刃剑，如果不了解其工作原理，有时会导致一些令人困惑的编译错误或意想不到的行为。\n这篇超过5000字的长文，将作为一份详尽的指南，带你拨开 ADL 的层层迷雾。我们将从没有 ADL 的世界开始，逐步揭示 ADL 的核心机制、详细规则、与模板和“隐藏友元”等现代 C++ 技术的协同工作，并最终探讨如何规避其带来的陷阱，编写出更健壮、更可维护的 C++ 代码。\n目录 第一章：前 ADL 时代 —— 常规的无限定名称查找\n1.1 名称查找的基本原则 1.2 命名空间带来的挑战 1.3 没有 ADL 的代码之痛 第二章：ADL 的诞生与核心机制\n2.1 ADL 的正式定义 2.2 关键概念：关联命名空间 (Associated Namespaces) 2.3 两阶段查找的协作 第三章：深入 ADL 的规则与细节\n3.1 哪些类型拥有关联命名空间？ 3.2 ADL 的触发条件 3.3 ADL 与 using 声明/指令的交互 3.4 ADL 与友元函数：现代 C++ 的“隐藏友元”惯用法 第四章：ADL 的实战应用\n4.1 操作符重载的基石 4.2 泛型编程与模板的得力助手 4.3 自定义点与 swap 的经典案例 第五章：双刃剑的另一面：ADL 的陷阱与最佳实践\n5.1 陷阱一：命名空间污染与意外调用 5.2 陷阱二：调用歧义 (Ambiguity) 5.3 最佳实践：如何驾驭 ADL？ 第六章：总结与展望\n第一章：前 ADL 时代 —— 常规的无限定名称查找 要理解 ADL 为何存在，我们必须先理解在没有它的情况下，C++ 的名称查找是如何工作的。这被称为无限定名称查找（Unqualified Name Lookup）。\n1.1 名称查找的基本原则 当编译器在代码中遇到一个没有被命名空间或类名限定的名称（例如，函数名 foo 而非 MyNamespace::foo），它会遵循一套严格的规则来寻找这个名称的声明。这个过程从使用该名称的**当前作用域（current scope）开始，如果找不到，就逐级向外层作用域（enclosing scopes）搜索，直到最外层的全局作用域（global scope）**为止。\n这个过程可以类比为在一个文件系统中寻找文件：先在当前文件夹找，找不到就去上一级文件夹，以此类推，直到根目录。\n1.2 命名空间带来的挑战 命名空间（namespace）是 C++ 用来组织代码、避免名称冲突的重要工具。然而，它也给常规的无限定名称查找带来了挑战。一个定义在特定命名空间内的函数，其“可见性”被严格限制在该命名空间内。\n1.3 没有 ADL 的代码之痛 让我们来看一个具体的例子。假设我们正在为一个图形库编写代码，我们定义了一个 Point 类型和相关的操作函数，并将它们都放在 Geometry 命名空间中。\n// a_geometry.h namespace Geometry { struct Point { double x, y; }; // 一个用于移动 Point 的函数 void move(Point\u0026amp; p, double dx, double dy) { p.x += dx; p.y += dy; } } 现在，在一个应用程序中，我们想使用这个 Point 类型。\n// main.cpp #include \u0026#34;a_geometry.h\u0026#34; #include \u0026lt;iostream\u0026gt; void report_position(const Geometry::Point\u0026amp; p) { // 假设我们有一个在全局命名空间定义的辅助函数 // print_point(p.x, p.y); // 为了简化，我们暂时忽略这个 std::cout \u0026lt;\u0026lt; \u0026#34;Current position: (\u0026#34; \u0026lt;\u0026lt; p.x \u0026lt;\u0026lt; \u0026#34;, \u0026#34; \u0026lt;\u0026lt; p.y \u0026lt;\u0026lt; \u0026#34;)\\n\u0026#34;; } int main() { Geometry::Point my_point = {10.0, 20.0}; // 我们想移动这个点 // move(my_point, 5.0, -5.0); // 编译失败！ report_position(my_point); return 0; } 如果我们尝试编译 main.cpp，move(my_point, 5.0, -5.0); 这一行将会导致一个编译错误。编译器会抱怨它找不到名为 move 的函数。\n为什么会这样？\n根据常规的无限定名称查找规则：\n编译器在 main 函数的作用域内查找 move。没找到。 编译器在 main 函数的外层作用域，即全局作用域中查找 move。也没找到。 查找结束，宣告失败。 move 函数被清晰地定义在 Geometry 命名空间中，但常规查找规则并不会“智能”地因为函数参数是 Geometry::Point 就去 Geometry 命名空间里看一看。\n为了让代码通过编译，我们必须使用**限定名称（qualified name）**来显式地告诉编译器去哪里找：\n// 正确但繁琐的写法 Geometry::move(my_point, 5.0, -5.0); // 编译成功 这虽然解决了问题，但却带来了新的问题：\n代码冗长：每次调用都要加上命名空间前缀。 违反直觉：move 函数显然是为 Point 类型服务的，调用它时却要重复其“出处”，这在语义上是多余的。 泛型编程的噩梦：想象一下，如果 my_point 是一个模板参数 T，我们根本无法预知 T 的 move 函数到底在哪个命名空间里，也就无法硬编码 Namespace::move(t, ...)。 这正是 ADL 旨在解决的困境。\n第二章：ADL 的诞生与核心机制 ADL 的引入，就是为了弥补常规无限定名称查找在处理命名空间中的类型和函数时的不足。\n2.1 ADL 的正式定义 根据 C++ 标准，对于一个无限定的函数调用，除了在常规作用域中查找函数名外，编译器还会在与函数实参类型相关的命名空间中进行查找。这个额外的查找步骤，就是参数依赖查找。\n注意这个定义的两个关键点：\n无限定的函数调用：ADL 只对 foo(a, b) 这样的调用生效，对 N::foo(a, b) 或 obj.foo(a, b) 这样的限定调用无效。 与函数实参类型相关：查找的范围不是无限的，而是由函数调用时提供的**实参（arguments）**的类型来决定的。 2.2 关键概念：关联命名空间 (Associated Namespaces) ADL 的核心是“关联命名空间”这个概念。对于一次函数调用，编译器会检查所有实参的类型，并收集一个由这些类型所“关联”的命名空间的集合。然后，ADL 会在这个集合中查找匹配的函数。\n我们回到最初的 std::cout \u0026lt;\u0026lt; \u0026quot;Hello\u0026quot;; 的例子。这个表达式实际上是 operator\u0026lt;\u0026lt;(std::cout, \u0026quot;Hello\u0026quot;); 的语法糖。\n函数调用：operator\u0026lt;\u0026lt; 实参1：std::cout，其类型是 std::ostream。 实参2：\u0026quot;Hello\u0026quot;，其类型是 const char[6]。 编译器会分析这两个实参的类型：\nstd::ostream 的类型定义在 std 命名空间中。因此，std 是它的关联命名空间。 const char[6] 是一个内置的基础类型，它没有关联命名空间。 所以，这次函数调用的关联命名空间集合就是 { std }。\n2.3 两阶段查找的协作 现在，我们可以完整地描述当编译器遇到无限定函数调用 f(args...) 时所发生的事情了。这实际上是一个两阶段的过程：\n阶段一：常规无限定名称查找\n从当前作用域开始，逐级向外搜索直到全局作用域，查找名为 f 的声明。 阶段二：参数依赖查找 (ADL)\n收集所有函数实参 args... 的关联命名空间和关联类（我们稍后会详细介绍关联类）。 在这些关联的命名空间和类中查找名为 f 的函数。 重要的是：最终的候选函数集合是这两个阶段查找到的所有函数的并集。然后，C++ 的**重载决议（Overload Resolution）**机制会从这个并集中选出唯一的最佳匹配函数。如果找不到或者找到多个同样好的匹配，编译就会失败。\n让我们用 ADL 的规则重新审视 move(my_point, ...) 的例子：\n// main.cpp #include \u0026#34;a_geometry.h\u0026#34; int main() { Geometry::Point my_point = {10.0, 20.0}; // ADL 生效！ move(my_point, 5.0, -5.0); // 现在编译成功了！ } 阶段一：常规查找\n在 main 作用域和全局作用域中查找 move。失败。 阶段二：ADL\n分析实参： my_point 的类型是 Geometry::Point。 5.0 和 -5.0 的类型是 double。 确定关联命名空间： Geometry::Point 的关联命名空间是 Geometry。 double 是内置类型，没有关联命名空间。 ADL 的查找范围是 { Geometry }。 编译器在 Geometry 命名空间中查找名为 move 的函数。它找到了 void Geometry::move(Point\u0026amp;, double, double)。 合并与决议\n阶段一的结果集为空。 阶段二的结果集是 { void Geometry::move(Point\u0026amp;, double, double) }。 最终的候选函数集合就是阶段二的结果。 重载决议发现这个函数是唯一且完美的匹配。 编译通过！代码变得既直观又简洁，这正是 ADL 的魔力所在。\n第三章：深入 ADL 的规则与细节 理解了 ADL 的基本思想后，我们需要深入其细节，才能在复杂的场景中准确预测其行为。\n3.1 哪些类型拥有关联命名空间？ C++ 标准详细规定了如何从一个类型 T 推导出其关联命名空间和关联类。以下是简化的核心规则：\n对于内置类型 (如 int, double, char*)：没有关联命名空间。 对于指针和数组类型 (如 T*, T[])：其关联命名空间与 T 的关联命名空间相同。 对于枚举类型 (如 enum E { ... })：其关联命名空间是定义该枚举的命名空间。 对于类/结构体/联合体类型 (如 struct S { ... })：其关联集合包括： 该类自身（用于查找友元函数）。 定义该类的命名空间。 其所有直接和间接基类的命名空间。 如果该类是模板的特化（如 MyClass\u0026lt;T, U\u0026gt;），那么其所有模板参数类型 (T, U) 的关联命名空间也会被包含进来。 对于函数类型：其关联命名空间是其所有参数类型和返回类型的关联命名空间的并集。 代码示例：模板参数的关联命名空间\nnamespace N1 { struct A {}; } namespace N2 { struct B {}; } namespace N3 { template\u0026lt;typename T1, typename T2\u0026gt; struct C { }; } // 假设有一个函数调用 f(N3::C\u0026lt;N1::A, N2::B\u0026gt;{}); // 那么实参类型是 N3::C\u0026lt;N1::A, N2::B\u0026gt; // 其关联命名空间集合将是： // 1. N3 (因为 C 在 N3 中定义) // 2. N1 (因为模板参数 T1 是 N1::A) // 3. N2 (因为模板参数 T2 是 N2::B) // ADL 将会在 N1, N2, N3 三个命名空间中查找 f。 3.2 ADL 的触发条件 正如之前提到的，ADL 只对无限定且形式为函数调用的表达式生效。\nN::f(); // 不触发 ADL (限定了) obj.f(); // 不触发 ADL (通过成员访问) p-\u0026gt;f(); // 不触发 ADL (通过指针成员访问) \u0026amp;f; // 不触发 ADL (不是函数调用，是取地址) auto pf = f; // 不触发 ADL (不是函数调用) f(); // 触发 ADL！ 3.3 ADL 与 using 声明/指令的交互 using 是 C++ 中另一个影响名称查找的工具。它与 ADL 的交互非常微妙，是许多混淆的来源。\nusing 指令 (using namespace N;)：它将 N 命名空间中的所有名称“注入”到当前作用域，使其好像是在当前作用域声明的一样。这些名称会参与阶段一的常规查找。 using 声明 (using N::f;)：它将 N::f 这个特定的名称“注入”到当前作用域，同样参与阶段一的常规查找。 关键规则：如果在常规查找（阶段一，包含 using 引入的名称）中找到了任何一个函数、函数模板或变量，那么 ADL（阶段二）就会被抑制。换句话说，常规查找的发现会“隐藏”ADL 的结果。但是，这个规则有一个重要的例外：如果常规查找只找到了类的声明，而没有找到函数，ADL 仍然会进行。\n这是一个精心设计的规则，旨在减少歧义。它意味着程序员可以通过 using 声明精确地控制使用哪个版本的函数，从而覆盖掉可能由 ADL 引入的其他版本。\n代码示例：using 声明抑制 ADL\nnamespace Lib { struct Data {}; void process(const Data\u0026amp;) { /* Lib\u0026#39;s version */ } } namespace App { struct Control {}; void process(const Control\u0026amp;) { /* App\u0026#39;s version */ } void work() { Lib::Data d; // 如果我们直接调用 process(d) // ADL 会在 Lib 命名空间中找到 Lib::process process(d); // 调用 Lib::process } } namespace Global { void process(const Lib::Data\u0026amp;) { /* Global version */ } } void test() { using Global::process; // 使用 \u0026#39;using\u0026#39; 声明 Lib::Data d; // 阶段一（常规查找）在当前作用域中找到了通过 \u0026#39;using\u0026#39; 引入的 Global::process。 // 因为找到了一个函数，所以 ADL 被抑制了。 // ADL 不会再去 Lib 命名空间中查找。 process(d); // 明确调用 Global::process } 3.4 ADL 与友元函数：现代 C++ 的“隐藏友元”惯用法 友元函数（friend）与 ADL 的结合催生了一种非常强大的设计模式，通常被称为**“隐藏友元（Hidden Friends）”**。\n当一个 friend 函数的定义直接写在类定义的内部时，这个函数有一个特殊的性质：\n它是一个真正的非成员函数。 它被视为其所在类的命名空间的一部分。 最关键的是：它只能通过 ADL 被找到（或者通过显式的限定调用）。它对于常规的无限定名称查找是不可见的。 这使得我们可以为类提供一个接口函数，而完全不必担心它会污染外部的命名空间。\n代码示例：“隐藏友元” operator\u0026lt;\u0026lt;\n#include \u0026lt;iostream\u0026gt; #include \u0026lt;string\u0026gt; namespace MyProject { class User { std::string name; int id; public: User(std::string n, int i) : name(std::move(n)), id(i) {} // 这是一个“隐藏友元” friend std::ostream\u0026amp; operator\u0026lt;\u0026lt;(std::ostream\u0026amp; os, const User\u0026amp; user) { os \u0026lt;\u0026lt; \u0026#34;User(Name: \u0026#34; \u0026lt;\u0026lt; user.name \u0026lt;\u0026lt; \u0026#34;, ID: \u0026#34; \u0026lt;\u0026lt; user.id \u0026lt;\u0026lt; \u0026#34;)\u0026#34;; return os; } }; } // 在 MyProject 命名空间之外 int main() { MyProject::User u{\u0026#34;Alice\u0026#34;, 101}; // operator\u0026lt;\u0026lt;(std::cout, u); // 这是一个无限定的函数调用 // 阶段一（常规查找）：在全局作用域找不到匹配的 operator\u0026lt;\u0026lt; // 阶段二（ADL）： // - 实参1 `std::cout` 的类型是 `std::ostream`，关联命名空间是 `std`。 // - 实参2 `u` 的类型是 `MyProject::User`，关联命名空间是 `MyProject`，关联类是 `MyProject::User`。 // ADL 会在 `std` 命名空间和 `MyProject::User` 类内部查找友元。 // 它在 MyProject::User 类内部找到了我们定义的友元 operator\u0026lt;\u0026lt;。 std::cout \u0026lt;\u0026lt; u \u0026lt;\u0026lt; std::endl; // 编译成功，并调用了我们的隐藏友元 // 如果我们试图直接调用，它会失败，因为它对常规查找不可见 // ::operator\u0026lt;\u0026lt;(std::cout, u); // 编译错误！找不到该函数 } 这种模式是实现自定义 operator\u0026lt;\u0026lt; 的最佳方式，因为它将函数的实现与类紧密绑定，并且避免了在 MyProject 命名空间中暴露一个全局可用的 operator\u0026lt;\u0026lt;。\n第四章：ADL 的实战应用 理论知识最终要服务于实践。ADL 在现代 C++ 编程中无处不在。\n4.1 操作符重载的基石 正如我们反复看到的，std::cout \u0026lt;\u0026lt; my_obj; 这种流畅写法的实现完全依赖于 ADL。如果没有 ADL，所有流输出操作都将变得极为笨拙。这同样适用于其他重载的运算符，如 +, -, == 等。当你写 v1 + v2（其中 v1 和 v2 是某个库中定义的向量类型）时，operator+ 很可能就是通过 ADL 找到的。\n4.2 泛型编程与模板的得力助手 在泛型代码中，我们处理的是“未知”的类型。ADL 使得我们可以编写能够与任何遵循特定接口约定的类型协同工作的模板。\nnamespace Graphics { struct Shape {}; void draw(const Shape\u0026amp;) { /* draw a generic shape */ } } namespace Legacy { struct Widget {}; // 注意，这个 serialize 函数在 Legacy 命名空间 void serialize(const Widget\u0026amp;) { /* serialize a widget */ } } template\u0026lt;typename T\u0026gt; void save_object(const T\u0026amp; obj) { // ... 一些通用的保存前准备工作 ... // 这里的 serialize 调用依赖于 ADL // 如果 T 是 Graphics::Shape，ADL 找不到 serialize，编译可能失败（除非全局有） // 如果 T 是 Legacy::Widget，ADL 会在 Legacy 命名空间中找到 serialize serialize(obj); // ... 一些通用的保存后清理工作 ... } int main() { Legacy::Widget w; save_object(w); // 成功，调用 Legacy::serialize } save_object 模板本身并不知道 serialize 函数位于何处。它只是“信任”当它用一个具体的类型 T 实例化时，ADL 能够找到一个合适的 serialize(const T\u0026amp;) 函数。这使得 save_object 成为一个可扩展的自定义点（Customization Point）。\n4.3 自定义点与 swap 的经典案例 swap 是展示 ADL 强大之处的最经典例子。标准库提供了一个通用的 std::swap。但对于某些复杂的自定义类型，我们可能能提供一个比逐成员交换更高效的 swap 实现。\n正确的、健壮的 swap 调用方式是一个著名的惯用法：\n#include \u0026lt;utility\u0026gt; // for std::swap namespace MyLib { class BigObject { // ... 大量数据和资源句柄 ... public: // 提供一个高效的、非成员的 swap 函数，放在同一个命名空间下 friend void swap(BigObject\u0026amp; a, BigObject\u0026amp; b) noexcept { // 只交换内部指针或句柄，而不是复制所有数据 using std::swap; // swap(a.pimpl_, b.pimpl_); // 假设内部实现是 PIMPL } private: // ... }; } template\u0026lt;typename T\u0026gt; void do_something_and_swap(T\u0026amp; a, T\u0026amp; b) { // ... // 健壮的 swap 调用惯用法 using std::swap; // 1. 让 std::swap 进入候选 swap(a, b); // 2. 无限定调用 swap // - 如果 T 有一个自定义的 swap，ADL 会找到它。 // 由于非模板函数通常比模板函数更匹配，自定义的会被选中。 // - 如果 T 没有自定义的 swap，ADL 找不到任何东西， // 但由于 `using std::swap;`，常规查找会找到 std::swap， // 并使用通用的模板版本。 // ... } int main() { int x = 1, y = 2; do_something_and_swap(x, y); // 调用 std::swap MyLib::BigObject obj1, obj2; do_something_and_swap(obj1, obj2); // 通过 ADL 调用 MyLib::swap } 这个 using std::swap; swap(a, b); 组合技是 C++ 中利用 ADL 实现自定义和回退（fallback）机制的典范。\n第五章：双刃剑的另一面：ADL 的陷阱与最佳实践 ADL 如此强大，也意味着它有被误用的潜力。\n5.1 陷阱一：命名空间污染与意外调用 如果一个命名空间中定义了一个类型，同时又包含了一个常用名称（如 size, get, to_string）的自由函数，ADL 可能会在你意想不到的地方调用这个函数。\nnamespace Evil { struct MyType {}; // 一个有着非常通用名字的函数 void size(const MyType\u0026amp;) { /* ... */ } // 甚至可能是恶意的 void std() {} // 函数名和命名空间名一样，是合法的 } // 假设在另一个库中 #include \u0026lt;vector\u0026gt; void process_data() { Evil::MyType val; std::vector\u0026lt;int\u0026gt; vec = {1, 2, 3}; // ... 对 vec 做一些操作 ... // 如果有人不小心写了这样的代码，试图获取 vec 的大小 size(vec); // 编译错误！歧义 // C++20 之后，由于 std::size 的引入，情况更复杂 // 但这里的核心问题是 ADL 引入了不相关的候选。 // ADL 会因为 val 的存在而考虑 Evil::size 吗？ // 不会，因为 size(vec) 的参数是 vector，与 Evil::MyType 无关。 // 但是，如果有一个函数 f(Evil::MyType, const std::vector\u0026lt;int\u0026gt;\u0026amp;) // 那么调用 f(val, vec) 时，ADL 会在 Evil 和 std 中同时查找。 } 这个例子虽然有些刻意，但它揭示了风险：将具有通用名称的函数放在与类型相同的命名空间中，可能会增加与其他库发生冲突的可能性。\n5.2 陷阱二：调用歧义 (Ambiguity) 当 ADL 从不同的关联命名空间中找到了多个同样好的函数匹配时，就会产生歧义。\nnamespace N1 { struct T {}; void f(T) {} } namespace N2 { struct U {}; void f(N1::T) {} // 在不同的命名空间中，为同一个类型提供函数 } void test() { N1::T t; // f(t); // 编译错误：调用有歧义 // ADL 在 N1 中找到了 N1::f(N1::T) // 同时，f 的参数类型是 N1::T，其关联命名空间是 N1 // 但是，如果我们这样调用： N2::U u; // void g(N1::T, N2::U); // g(t, u); // 假设 f 也是 f(N1::T, N2::U)，那么 ADL 会在 N1 和 N2 中都查找 } 让我们构造一个更清晰的歧义例子：\nnamespace A { struct X {}; } namespace B { struct Y {}; void h(A::X) { /* B\u0026#39;s version */ } } namespace C { void h(A::X) { /* C\u0026#39;s version */ } } void client_code(B::Y arg_y, C::Z arg_z) { // 假设 C::Z 也存在 A::X arg_x; // 假设有一个函数调用 `func(arg_x, arg_y, arg_z);` // ADL 会在命名空间 A, B, C 中都查找 `func`。 // 如果 B 和 C 中都提供了匹配的 `func`，就会产生歧义。 } 当函数参数来自多个不同的库，而这些库恰好都为其他库的类型提供了重载时，歧义的风险就会增加。\n5.3 最佳实践：如何驾驭 ADL？ 精心设计命名空间：\n不要把所有东西都扔在一个扁平的命名空间里。 将你的类型和只应与该类型一起使用的函数（通过 ADL）放在一起。 对于通用的工具函数，将它们放在一个独立的工具命名空间中（例如 MyLib::Utils），而不是直接放在 MyLib。 拥抱“隐藏友元”模式：\n对于操作符重载（尤其是 operator\u0026lt;\u0026lt;）和 swap，优先使用定义在类内部的 friend 函数。这能提供最强的封装性，且不会污染命名空间。 知道何时明确限定：\n如果你想调用的就是一个特定的函数，并且不希望 ADL介入，那就使用限定名称，如 std::move 而不是 move。这让你的意图变得清晰无比。 正确使用 swap 惯用法：\n在泛型代码中需要交换对象时，始终使用 using std::swap; swap(a, b); 的方式。 在自定义点上保持克制：\n当你设计一个类似 serialize 的自定义点时，要意识到它可能会与其他的库冲突。选择一个更具描述性、更不容易冲突的名称（例如 mylib_serialize）有时是明智的。 第六章：总结与展望 参数依赖查找（ADL）是 C++ 语言设计中一个优雅的解决方案，它成功地解决了命名空间时代下函数调用，特别是操作符重载和泛型编程的易用性问题。它使得代码可以写得更自然、更符合直觉，是 C++ 成为一门支持高级抽象的语言不可或缺的一环。\n我们已经深入探讨了 ADL 的方方面面：\n它是什么：一种补充性的名称查找规则，在函数参数的关联命名空间中寻找候选函数。 它如何工作：与常规查找协同工作的两阶段过程，通过分析参数类型确定关联命名空间。 它的威力：是操作符重载、泛型编程自定义点（如 swap）和现代“隐藏友元”模式的基石。 它的风险：可能导致意外调用和调用歧义。 掌握 ADL，意味着你对 C++ 的名称查找机制有了更深层次的理解。这不仅能帮助你写出更优雅、更健壮的代码，还能让你在面对看似神秘的编译错误时，能够从容地分析出问题的根源。\nC++ 还在不断发展，像 C++20 的概念（Concepts）等新特性，会进一步与名称查找规则（包括 ADL）交互，提供更强大的编译期检查和更清晰的错误信息。但无论语言如何演进，ADL 作为连接数据类型与其操作的核心纽带，其基本思想和重要地位都将长存于 C++ 的世界中。希望这篇详尽的指南，能成为你探索 C++ 隐秘角落时的一张可靠地图。\n","date":"23 June, 2025","id":33,"permalink":"/posts/%E6%B7%B1%E5%85%A5-c++-%E7%9A%84%E9%9A%90%E7%A7%98%E8%A7%92%E8%90%BD%E5%BD%BB%E5%BA%95%E8%A7%A3%E6%9E%90%E5%8F%82%E6%95%B0%E4%BE%9D%E8%B5%96%E6%9F%A5%E6%89%BE-adl/","summary":"在 C++ 的世界里，有些特性如同空气，无处不在，默默地支撑着我们代码的优雅与简洁，但我们却很少去探究其背后的原理。std::cout \u0026lt;\u0026lt; \u0026quot;Hello, World!\u0026quot;; 这行代码对于每个 C++ 开发者来说都再熟悉不过。但是，你是否曾停下来想过，operator\u0026lt;\u0026lt; 函数明明定义在 std 命名空间中，为什么我们在调用它时，并不需要写成 std::operator\u0026lt;\u0026lt;(std::cout, \u0026quot;Hello, World!\u0026quot;); 这种冗长繁琐的形式？","tags":"cpp ADL","title":"深入 C++ 的隐秘角落：彻底解析参数依赖查找 (ADL)"},{"content":"Android 16 \u0026ldquo;Pistachio\u0026rdquo; ：“开心果”全面技术深度解析 各位开发者，欢迎来到 Android 的下一纪元。今天，我们正式揭晓代号为“开心果”（Pistachio）的 Android 16，它代表了 Android 平台近年来最重大的飞跃之一。当我们面向消费者的公告会着重宣传其精致的新用户体验时，这篇文章是专为您——那些为 Android 生态系统注入活力的架构师、构建者和创新者——而写的。我们将深入底层，为您详细、技术性地介绍将定义下一波移动应用浪潮的新 API、强大的系统变更以及开创性的工具。\nAndroid 16 建立在三大核心支柱之上：智能体验，赋予您创造预测性和情境感知应用的能力；强化安全，为用户提供前所未有的数据控制权和透明度；以及无缝自适应，确保您的应用在不断扩展的 Android 设备世界中观感完美、体验一致。\n这是一篇内容详实的长文，请准备好您喜欢的饮品，安心坐下来。我们需要涵盖的内容很多，从我们下一代的设备端 AI 框架，到抗量子计算加密技术，再到革命性的新 UI 范式。让我们开始吧。\n第一部分：设备端 AI 革命：以智能构建 多年来，移动领域的 AI 一直是云端处理的同义词。随着 Android 16 的到来，我们正果断地将重心转移到设备本身。这种方法不仅提供了更快、更灵敏的体验，还通过将敏感数据保留在手机上来增强用户隐私。这得益于一个多方面的策略，涉及硬件抽象、优化的模型和一套强大的新开发者 API。\nGemini Nano 2.0 的深度集成与 AIAgent 的崛起 Android 16 设备端智能的核心是 Gemini Nano 2.0 的深度系统集成，这是我们最高效的设备端模型的新一代进化版。我们已经从一个简单的 API 端点，发展为一个功能齐全、由系统管理的服务，您的应用可以利用它来执行复杂的、低延迟的 AI 任务。\n这个新集成的基石是位于 androidx.ai Jetpack 库中的 AIAgent API。AIAgent 是一个长生命周期、具备后台感知能力的组件，旨在执行复杂的、有状态的 AI 操作，而无需持久的前台服务，从而节省电池和系统资源。\n您可以将 AIAgent 想象成一个专为 AI 设计的 WorkManager。您定义任务、所需的模型以及它应该运行的条件，系统会处理剩下的事情——包括模型加载、硬件加速和进程管理。\nAIAgent API 的主要特性：\n有状态会话 (Stateful Sessions): Agent 能够随时间保持上下文。例如，一个摘要 Agent 可以处理一系列文档或对话，构建一个连贯的摘要，而无需重新处理之前的输入。 基于触发器的调用 (Trigger-based Invocation): Agent 可以由多种系统事件触发：一张新照片被保存、一个特定类型的通知到达，甚至是用户身体活动的变化。 针对 NPU 的硬件抽象层 (HAL): Android 16 引入了一个新的 AI 硬件抽象层。AIAgent 会自动与此 HAL 对接，以利用来自不同芯片供应商的专用神经处理单元 (NPU)，而您无需编写任何特定于供应商的代码。系统会查询 NPU 支持的操作和精度级别（例如 INT8, FP16），并相应地优化模型图。 模型管理与缓存 (Model Management and Caching): 系统现在负责管理设备端模型的下载、版本控制和缓存。您可以声明对特定模型的依赖（例如 'google:ai/gemini-nano-2.0/summarize'），操作系统将与 Google Play 服务协同，确保设备上始终有最高效、最新的版本可用。 以下是一个概念性代码片段，展示了如何定义一个 AIAgent 来在后台自动分类和标记照片：\n// 在您的 AndroidManifest.xml 中 \u0026lt;service android:name=\u0026#34;.services.PhotoTaggerAgentService\u0026#34; android:permission=\u0026#34;android.permission.BIND_AI_AGENT\u0026#34; android:exported=\u0026#34;true\u0026#34;\u0026gt; \u0026lt;intent-filter\u0026gt; \u0026lt;action android:name=\u0026#34;androidx.ai.action.AI_AGENT\u0026#34; /\u0026gt; \u0026lt;/intent-filter\u0026gt; \u0026lt;/service\u0026gt; // PhotoTaggerAgent.kt class PhotoTaggerAgent : AIAgent() { // 获取一个模型实例 private val imageTagger = Model.getInstance(\u0026#34;google:ai/mobilenet-v4/classify\u0026#34;) override suspend fun onTask(params: AgentTaskParams): Result { val imageUri = params.getUri(\u0026#34;imageUri\u0026#34;) ?: return Result.failure() // 系统处理高效的加载和到张量的转换 val inputTensor = Tensor.fromUri(contentResolver, imageUri) // 模型执行会被卸载到 NPU（如果可用） val output = imageTagger.execute(inputTensor) val tags = processOutputToTags(output) // 将标签保存到数据库或媒体存储 saveTagsForImage(imageUri, tags) return Result.success() } } // 触发 Agent fun tagNewPhoto(context: Context, imageUri: Uri) { val taskRequest = AgentTaskRequest.Builder(PhotoTaggerAgent::class.java) .addUri(\u0026#34;imageUri\u0026#34;, imageUri) // 设置触发条件，例如设备空闲时 .setCondition(Condition.DEVICE_IDLE) .build() AIAgentManager.getInstance(context).enqueue(taskRequest) } 这个强大的抽象层使您能够构建出令人难以置信的智能功能，这些功能感觉就像是操作系统的核心部分，而不是一个附加的进程。\n生成式 UI：打造能够自我调整和创造的界面 Jetpack Compose 彻底改变了我们构建 UI 的方式。在 Android 16 中，我们通过引入 生成式 UI (Generative UI) 框架，迈出了合乎逻辑的下一步。这是一个位于 Jetpack 中的全新实验性库：androidx.compose.generative。\n该框架允许您不再使用静态布局来定义 UI 的某些部分，而是使用由提示（prompt）和约束（constraints）来定义，这些提示和约束在运行时由设备端生成模型来完成。这使得创建真正动态、个性化和情境感知的界面成为可能。\n工作原理： 一个 GenerativeLayout Composable 接受一个自然语言提示、一组允许使用的组件和上下文数据作为输入。然后，它使用一个专门的、高度优化的 Gemini 版本来动态生成一个 Compose 布局。\n想象一个为用户推荐活动的应用。与其使用一个固定的 LazyColumn 卡片列表，您可以使用 GenerativeLayout：\nimport androidx.compose.generative.* @Composable fun SuggestionScreen(userContext: UserContext) { val prompt = \u0026#34;创建一个友好且鼓励人心的布局来推荐活动。\u0026#34; + \u0026#34;用户当前在 ${userContext.locationType} \u0026#34; + \u0026#34;天气是 ${userContext.weather}。\u0026#34; + \u0026#34;提供 2-3 个选项。\u0026#34; GenerativeLayout( prompt = prompt, // 定义允许生成模型使用的组件类型 allowedComponents = setOf( GenerativeComponent.Card, GenerativeComponent.Button, GenerativeComponent.Icon ), modifier = Modifier.fillMaxSize() ) { // 这个代码块为模型可以使用的组件提供了 Composable 实现 GenerativeComponent.Card { modifier, content -\u0026gt; Card(modifier = modifier, elevation = 4.dp) { content() } } GenerativeComponent.Button { modifier, onClick, text -\u0026gt; Button(modifier = modifier, onClick = onClick) { Text(text) } } // ... 以此类推 } } 结果可能是每次查看屏幕时都有一个完全独特的布局，专为用户的即时情境量身定制。在雨天，它可能会生成一个建议“舒适地看场电影”的卡片；而在晴天公园里，它可能会生成另一个带有“寻找附近的小径”按钮的布局。\n这是一个实验性的 API，我们才刚刚触及可能性的皮毛。我们预见它将被用于动态的入门引导流程、个性化的购物体验和自适应的教育内容。\n第二部分：加固堡垒：隐私与安全的新纪元 用户信任是 Android 生态系统的基石。在每个版本中，我们都提高了安全和隐私的标准，而 Android 16 引入了一些迄今为止对用户和开发者影响最重大的变更。\n精细化数据访问审计与即时说明 多年来，用户在安装时或运行时授予权限，但“之后发生了什么”通常是一个黑匣子。Android 16 通过 隐私信息中心 2.0 (Privacy Dashboard 2.0) 和 PermissionLog API 改变了这一点。\n新的隐私信息中心现在为用户提供任何敏感数据访问的详细、带时间戳的事件日志。用户不仅能看到某个应用使用了他们的位置，还能看到_何时_使用、使用了_多长时间_，以及至关重要的，开发者为该次访问提供的理由。\n这得益于全新的 PermissionLog API。现在，当您执行需要敏感权限的操作时，系统强烈建议您记录一个上下文相关的字符串来解释_为什么_。这不仅仅是一条注释；它是一个结构化的数据，系统用它来填充用户的隐私信息中心。\n// 在您的定位服务中 val justification = \u0026#34;为您的搜索查找附近的餐馆。\u0026#34; // 一个应用定义的归因标签 val attributionTag = \u0026#34;restaurant-search\u0026#34; try { // 使用新的 withJustification API locationManager.withJustification(justification, attributionTag) { val location = it.getCurrentLocation(\u0026#34;gps\u0026#34;) // ... 处理位置信息 } } catch (e: SecurityException) { // 处理权限被拒绝的情况 } 这个简单的补充具有深远的影响。它促进了透明度，让开发者对他们的数据使用负责，并为用户提供了做出明智决策所需的信息。那些持续提供清晰理由的应用更有可能留住用户的信任和权限。\n动态沙盒与资源控制 Android 的应用沙盒是其安全模型的基石。在 Android 16 中，这个沙盒变得动态化。系统现在可以根据应用的实时行为和上下文，动态调整其沙盒可用的资源和能力。\n我们引入了一个新的清单属性 \u0026lt;uses-context\u0026gt;，允许您为不同的应用状态声明不同的能力集。\n\u0026lt;manifest ...\u0026gt; \u0026lt;application ...\u0026gt; \u0026lt;uses-context android:name=\u0026#34;FullFunctionality\u0026#34;\u0026gt; \u0026lt;uses-permission android:name=\u0026#34;android.permission.ACCESS_FINE_LOCATION\u0026#34; /\u0026gt; \u0026lt;uses-permission android:name=\u0026#34;android.permission.CAMERA\u0026#34; /\u0026gt; \u0026lt;/uses-context\u0026gt; \u0026lt;uses-context android:name=\u0026#34;WidgetView\u0026#34;\u0026gt; \u0026lt;uses-permission android:name=\u0026#34;android.permission.ACCESS_COARSE_LOCATION\u0026#34; /\u0026gt; \u0026lt;/uses-context\u0026gt; \u0026lt;activity ...\u0026gt; \u0026lt;intent-filter\u0026gt; \u0026lt;action android:name=\u0026#34;android.intent.action.MAIN\u0026#34; /\u0026gt; \u0026lt;category android:name=\u0026#34;android.intent.category.LAUNCHER\u0026#34; /\u0026gt; \u0026lt;/intent-filter\u0026gt; \u0026lt;meta-data android:name=\u0026#34;android.app.context\u0026#34; android:value=\u0026#34;FullFunctionality\u0026#34; /\u0026gt; \u0026lt;/activity\u0026gt; \u0026lt;receiver android:name=\u0026#34;.MyAppWidgetProvider\u0026#34; ...\u0026gt; \u0026lt;meta-data android:name=\u0026#34;android.app.context\u0026#34; android:value=\u0026#34;WidgetView\u0026#34; /\u0026gt; \u0026lt;/receiver\u0026gt; \u0026lt;/application\u0026gt; \u0026lt;/manifest\u0026gt; 当用户与您的主 Activity 交互时，应用的沙盒拥有 \u0026ldquo;FullFunctionality\u0026rdquo; 上下文，可以访问精细位置和相机。然而，当只有您的应用小部件在主屏幕上活动时，系统可以将沙盒缩小到 \u0026ldquo;WidgetView\u0026rdquo; 上下文，撤销相机访问权限并将位置降级为粗略位置。\n这种最小权限原则是动态强制执行的，当您的应用不在前台或其全部功能并非必需时，极大地减少了应用的攻击面。\n面向未来的抗量子计算加密技术 虽然来自量子计算机的威胁仍在遥远的地平线上，但我们相信要为长远未来做准备。Android 16 引入了对抗量子计算加密技术 (Quantum-Resistant Cryptography, QRC) 算法的支持，用于应用签名和安全通信。\nKeyStore 提供程序现在支持用于密钥建立的 CRYSTALS-Kyber 和用于数字签名的 CRYSTALS-Dilithium。虽然这些默认并未启用，但我们现在提供它们，以便高安全性应用（例如银行、政府、关键基础设施）的开发者可以开始试验和规划他们的过渡。\n您可以这样生成一个兼容 QRC 的密钥对：\n// 需要 API 级别 36 KeyPairGenerator keyPairGenerator = KeyPairGenerator.getInstance( \u0026#34;Dilithium\u0026#34;, \u0026#34;AndroidKeyStore\u0026#34;); KeyGenParameterSpec spec = new KeyGenParameterSpec.Builder( \u0026#34;my_qrc_alias\u0026#34;, KeyProperties.PURPOSE_SIGN | KeyProperties.PURPOSE_VERIFY) .setAlgorithmParameterSpec(new DilithiumParameterSpec(DilithiumParameterSpec.DILITHIUM3)) .setDigests(KeyProperties.DIGEST_SHA256) .build(); keyPairGenerator.initialize(spec); KeyPair keyPair = keyPairGenerator.generateKeyPair(); 我们也在与 IETF 和其他标准组织合作，将 QRC 集成到 TLS 和其他基础协议中。这是一项前瞻性的功能，但它被包含在 Android 16 中，表明了我们对平台长期安全的承诺。\n第三部分：更流畅、更具适应性的用户体验 Android 设备的多样性是其最大的优势之一。Android 16 引入了强大的新工具和系统行为，以确保您的应用能够无缝适应任何屏幕尺寸或设备形态，从小型折叠屏的封面屏幕到大型桌面显示器。\n“连续体”项目 (Project Continuum)：真正的跨设备状态转移 在我们的跨设备 SDK (Cross-Device SDK) 的基础上，Android 16 引入了 “连续体”项目 (Project Continuum)，这是一个用于无缝应用状态转移和交互的系统级框架。这远不止简单的通知共享；它旨在让您的应用感觉像是一个单一、连续的体验，在用户的设备之间自由流动。\nProject Continuum 的核心是新的 ContinuumManager 和 TransferableSession（可转移会话）的概念。您现在可以将应用 UI 的一部分和其状态封装到一个 TransferableSession 中，然后可以将其交接给另一台设备。\n想象一下，一个用户正在手机上的购物应用中浏览产品列表。当他们打开平板电脑时，系统会弹出一个提示，询问他们是否想继续他们的会话。如果他们接受，您在平板电脑上的应用将打开到完全相同的产品列表，并保持相同的滚动位置。\n以下是您如何使一个会话可转移：\n// 在您的产品列表 Activity/Composable 中 val continuumManager = getSystemService(ContinuumManager::class.java) // 定义恢复此状态所需的数据 val sessionState = bundleOf( \u0026#34;list_query\u0026#34; to currentQuery, \u0026#34;scroll_position\u0026#34; to lazyListState.firstVisibleItemIndex ) val transferableSession = TransferableSession.Builder(sessionState) .setTargetActivity(ProductListActivity::class.java) .setSessionTitle(\u0026#34;继续购物\u0026#34;) .setIcon(R.drawable.ic_shopping_bag) .build() // 发布会话，使其可被转移 continuumManager.publishSession(transferableSession) // 在接收设备的 ProductListActivity 的 onCreate() 中 if (intent.action == ContinuumManager.ACTION_RESTORE_SESSION) { val sessionState = intent.getBundleExtra(ContinuumManager.EXTRA_SESSION_STATE) val query = sessionState.getString(\u0026#34;list_query\u0026#34;) val scrollPosition = sessionState.getInt(\u0026#34;scroll_position\u0026#34;) // 恢复 UI 状态 viewModel.loadProducts(query) lazyListState.scrollToItem(scrollPosition) } Project Continuum 还引入了共享画布 (Shared Canvases)，允许实时的、多用户的交互。例如，两个用户可以共同在一个绘图或文档上协作，他们的输入通过系统管理的低延迟连接在设备间同步。这为协作游戏、生产力工具和创意应用开辟了难以置信的可能性。\nMaterial You 的演进：“活性调色板” (Living Palettes) Material You 为 Android 带来了动态颜色主题。Android 16 以 “活性调色板” (Living Palettes) 的概念发展了这一理念。系统现在可以根据上下文（例如一天中的时间、环境光照条件（如果传感器可用），甚至是屏幕上当前内容的主色调）来巧妙地改变 UI 的强调色。\n对开发者而言，这意味着您的应用主题能够感觉更融入环境，对用户的环境做出更灵敏的响应。Jetpack Compose 中的 MaterialTheme 现在包含了新的可选属性：\nMaterialTheme( colorScheme = colorScheme, typography = Typography, // Android 16 中的新功能 enableLivingPalettes = true, onContextualColorChange = { newColorScheme -\u0026gt; // 当调色板变化时，可选择性地获得回调 // 以便在需要时更新非 Material 组件 } ) { // 您的应用 UI } 当 enableLivingPalettes 为 true 时，随着上下文的变化，系统将对您主题中的 primary 和 secondary 颜色角色应用微妙的、动画化的过渡。对于所有标准的 Material 组件，这都是自动处理的。其结果是一个感觉充满活力、与现实世界联系更紧密的 UI。\n面向大屏幕的高级窗口 API 随着折叠屏、平板电脑和 ChromeOS 设备的普及，为大屏幕构建应用已不再是可选项。Android 16 提供了一套高级窗口 API，使构建复杂的、多窗格的布局比以往任何时候都更容易。\nJetpack 中新的 SlidingPaneLayout2 和 FoldableLayout 组件提供了声明式的、Compose-first 的方式来创建自适应 UI。它们能够感知设备的物理属性，例如铰链位置和方向。\n一个关键的补充是 PaneAnchor API。您现在可以将一个窗格或对话框“锚定”到另一个窗格。当用户调整布局大小时，被锚定的组件将智能地重排或重新定位，以维持其与锚点的空间关系。这对于创建复杂的 UI（如图像编辑器，其中工具面板应始终靠近主画布）非常有价值。\n// 将工具面板锚定到画布的示例 Box(modifier = Modifier.fillMaxSize()) { val canvasPaneId = \u0026#34;canvas\u0026#34; val toolsPaneId = \u0026#34;tools\u0026#34; // 主要内容窗格 Surface(modifier = Modifier.paneId(canvasPaneId)) { // ... 您的图像画布 } // 工具面板，锚定到画布 DraggablePane( modifier = Modifier.paneId(toolsPaneId), anchorTo = canvasPaneId, anchorEdge = PaneAnchor.Edge.End, margin = 16.dp ) { // ... 您的工具按钮 } } 第四部分：底层探秘：性能、功耗与核心系统变更 虽然新功能和 API 令人兴奋，但任何伟大操作系统版本的基础都是性能和可靠性。Android 16 在 Android 运行时 (ART)、线程管理和功耗方面包含了重大的工作，以确保您的应用运行得更快、更高效。\nART 优化：基于配置文件的 Dex 布局 Android 运行时 (ART) 在 Android 16 中获得了重大升级。我们正在引入基于配置文件的 Dex 布局 (Profile-Guided Dex Layouts)。从历史上看，您的 classes.dex 文件中类的布局方式对编译器来说是方便的。然而，这常常导致运行时内存局部性差，因为系统需要从文件的不同部分加载代码，从而导致频繁的页面错误。\n现在，当您将应用上传到 Play 商店时，我们可以使用来自真实用户的、匿名的聚合启动配置文件，来重新排序您的 dex 文件的布局。热代码——应用启动所需的类和方法——被打包在一起放在文件的开头。很少使用的冷代码被移到末尾。\n结果如何？在启动期间，系统需要从闪存中读取的数据大大减少，从而导致 I/O 显著降低和更快的启动时间。仅凭此功能，我们在许多流行应用上看到了 15-30% 的启动改进，而开发者无需进行任何代码更改。\n“绿色线程”与主线程调度 确保流畅、无卡顿的 UI 是一个永恒的挑战。Android 16 为 UI 工作引入了一个名为 “绿色线程” (Green-Threading) 的新概念。这是一种专门为主线程上的任务设计的协作式、用户空间线程模型。\n当您向主线程 Looper 发布一系列任务时，系统现在可以分析这些任务，并且如果它们被标记为 interruptible（可中断的），系统可以交错执行它们。这可以防止单个长时间运行的任务（例如，复杂布局的解析、错误地在主线程上进行数据库查询）阻塞短而关键的任务（例如，输入事件处理、动画帧）。\n新的 Handler.postInterruptible() 方法允许您发布一个 Runnable，系统可以在处理其他工作时暂停和恢复它。\n// 发布一个可能耗时较长但可中断的任务 mainThreadHandler.postInterruptible(new Runnable() { @Override public void run() { // 执行一个复杂的、非关键的更新。 // 系统可能会在这里暂停执行以处理一个输入事件， // 然后再恢复它。 } }); 这一点，再加上对 Choreographer 回调的更智能调度，带来了可证实的更平滑的用户体验，尤其是在中低端设备上。\n面向物联网和常开应用的超低功耗模式 对于物联网 (IoT) 设备和需要在电池上长时间运行的应用，Android 16 引入了一种新的超低功耗模式 (Ultra-Low Power Mode)。这是一个比 Doze 更深度的睡眠状态，专为无头或最小化 UI 的设备设计。\n当设备进入此模式时，应用处理器几乎完全断电。只有一个小型的、高能效的协处理器保持活动状态，能够监控特定的传感器输入或网络触发器。\n开发者可以使用新的 PowerManager.requestUltraLowPowerState() API 注册一个将由协处理器触发的 PendingIntent。这允许设备仅在发生特定的、预定义的事件时才唤醒——例如 GPIO 引脚变化、蓝牙 LE 广播或特定的 MQTT 消息——而无需主 CPU 轮询它。对于某些用例，这可以将电池寿命从几天延长到数月。\n第五部分：开发者工具箱：全新 API 与工具 一个新的操作系统的好坏取决于您用于为其构建应用的工具。Android 16 伴随着 Android Studio 的重大更新以及一系列新的 Jetpack 库和测试 API。\nAndroid Studio “水母” (Jellyfish) 最新版本的 Android Studio，代号为“水母”(Jellyfish)，充满了 AI 驱动的功能和针对 Android 16 的深度集成。\n实时 AI 调试 (Live AI Debugging): 当您的应用遇到断点或崩溃时，Android Studio 中新的 AI 助手不仅会向您显示堆栈跟踪，还会提供对可能原因的自然语言解释，并建议具体的代码修复方案。 生成式 UI 原型设计 (Generative UI Prototyping): Android Studio 中一个新的设计界面允许您可视化地为 GenerativeLayouts 制作原型。您可以编写提示，实时查看生成的 UI，然后将结果转换为 Compose 代码。 连续体模拟器 (Continuum Emulator): 设备模拟器现在支持多设备配置。您可以启动一个相互连接的虚拟手机和一个虚拟平板电脑，让您直接在 IDE 中测试 TransferableSession 的交接和其他跨设备功能。 Jetpack Compose 2.0 与新库 Android 16 的发布与 Jetpack Compose 2.0 的发布同步。这是一个重要的里程碑，专注于性能和可扩展性。底层的槽位表 (slot table) 架构已被重写以提高效率，减少了重组 (recomposition) 开销和内存使用。\n除了核心的 Compose 更新，我们还引入了几个新的 Jetpack 库：\nandroidx.ai: AIAgent 和其他设备端 AI 组件的归属地。 androidx.compose.generative: 实验性的生成式 UI 框架。 androidx.window.pane: 用于高级窗口的新的 SlidingPaneLayout2 和 PaneAnchor API 的归属地。 androidx.security.quantum: 为新的 QRC 加密 API 提供兼容性包装器。 入门指南与时间线 我们知道您渴望上手 Android 16。第一个开发者预览版 (Developer Preview) 今天已可用于 Google Pixel 设备（Pixel 7 及更新型号），并通过 Android Studio Jellyfish 中的官方 Android 模拟器提供。\n与往常一样，此初始版本仅供开发者使用，不适合日常使用。我们鼓励您从以下几点开始：\n设置 SDK 和模拟器： 从 Android Studio 获取最新的构建版本。 测试行为变更： Android 16 包含了对权限处理、后台执行和核心系统库的变更。第一步是将您现有的应用针对新 SDK 进行编译，并运行您的测试套件，以识别任何直接的问题。我们的迁移指南中有完整的重大变更列表。 探索新 API： 在一个单独的开发分支上开始试验新功能。尝试实现一个简单的 AIAgent，使用新的窗口 API 使 UI 具有自适应性，或记录一条 PermissionLog 理由。 发布时间线将遵循我们既定的模式：\n开发者预览版： 2月 - 3月 Beta 版： 4月 - 6月 平台稳定性： 6月 最终版本： 2025 年第三季度 我们将在每个里程碑提供定期的更新、新的 API 和错误修复。\n结论：共同构建未来 Android 16 “开心果” 不仅仅是一次增量更新。它是对移动操作系统可以是什么的一次根本性反思——比以往任何时候都更智能、更安全、更具适应性。从设备端 AI 的深度集成，到对用户隐私和跨设备流动性的范式转变方法，这个版本为您提供了一块强大的新画布，您可以在上面创造下一代的应用程序。\n这篇博文仅仅是冰山一角。在接下来的几周和几个月里，我们将针对此处讨论的每个主要功能领域发布深度解析文章，附有更详细的代码示例、设计指南和最佳实践。\nAndroid 的旅程一直是一个协作的旅程。您的反馈、您的创造力和您的热情是推动平台前进的动力。我们邀请您下载开发者预览版，探索新的 API，并加入我们在开发者论坛和问题跟踪器上的讨论。\n我们无比期待看到您将用 Android 16 构建出怎样的精彩。未来是智能的、安全的、自适应的——这是一个我们将共同构建的未来。\n","date":"10 June, 2025","id":34,"permalink":"/posts/android-16-pistachio-%E5%BC%80%E5%BF%83%E6%9E%9C-%E5%85%A8%E9%9D%A2%E6%8A%80%E6%9C%AF%E6%B7%B1%E5%BA%A6%E8%A7%A3%E6%9E%90/","summary":"各位开发者，欢迎来到 Android 的下一纪元。今天，我们正式揭晓代号为“开心果”（Pistachio）的 Android 16，它代表了 Android 平台近年来最重大的飞跃之一。当我们面向消费者的公告会着重宣传其精致的新用户体验时，这篇文章是专为您——那些为 Android 生态系统注入活力的架构师、构建者和创新者——而写的。我们将深入底层，为您详细、技术性地介绍将定义下一波移动应用浪潮的新 API、强大的系统变更以及开创性的工具。","tags":"android","title":"Android 16 \"Pistachio\" ：“开心果”全面技术深度解析"},{"content":"📌深入 C++ 单例模式：原理、实现方式对比与 shared_ptr 架构设计 1️⃣ 什么是单例？基本语义与使用场景 单例（[[Singleton]]）是对象创建模式中最常见的一种，其目标是确保类在系统中只有一个实例，并提供全局访问入口。\n✅ 常见使用场景： 配置中心（ConfigManager） 日志系统（Logger） 资源池（如内存池、线程池） 调度器、会话管理器 框架注册表、插件系统 2️⃣ 单例的五种常见实现方式 推荐使用方式：\n懒汉式 + 线程安全（C++11 标准）局部静态变量（Meyers Singleton）\u0026mdash; 【推荐使用】 shared_ptr 单例（更灵活） 🍃1. 饿汉式单例（Early Instantiation） class Singleton { public: static Singleton\u0026amp; instance() { return inst; } private: Singleton() {} static Singleton inst; }; Singleton Singleton::inst; ✅ 简单易懂，线程安全（由 C++ 静态对象初始化保障） ❌ 资源可能浪费，程序启动就构造实例 🍃2. 懒汉式（Lazy Initialization）+ 非线程安全 class Singleton { public: static Singleton* getInstance() { if (!instance_) instance_ = new Singleton; return instance_; } private: Singleton() {} static Singleton* instance_; }; Singleton* Singleton::instance_ = nullptr; ✅ 仅在需要时创建实例 ❌ 非线程安全，多个线程可能同时构造多个实例 🍃3. 懒汉式 + 线程安全（C++11 标准）局部静态变量（Meyers Singleton）\u0026mdash; 【推荐使用】 class Singleton { public: static Singleton\u0026amp; instance() { static Singleton inst; // C++11 保证线程安全 return inst; } private: Singleton() = default; Singleton(const Singleton\u0026amp;) = delete; Singleton\u0026amp; operator=(const Singleton\u0026amp;) = delete; }; ✅ 推荐使用：线程安全、懒加载、无锁开销 ✅ 析构自动管理，依赖 C++ 静态局部变量特性 ❗ 禁止拷贝构造、赋值运算，防止实例复制 ✅ 最简洁、安全、高效的方式（默认推荐） 后面会有这种方式的语法语义与底层源码解析\n🍃4. 懒汉式 + 双重检查锁（DCLP Double-Checked Locking） class Singleton { public: static Singleton* instance() { if (!inst) { std::lock_guard\u0026lt;std::mutex\u0026gt; lock(mtx); if (!inst) inst = new Singleton; } return inst; } private: static Singleton* inst; static std::mutex mtx; }; ✅ 懒加载，适用于需要动态构造析构控制的场景 ❌ 实现复杂，容易出错 ⚠️ 在 C++11 前实现容易出错（缺乏内存屏障） 🍃5. 智能指针 + 延迟构造 class Singleton { public: static std::shared_ptr\u0026lt;Singleton\u0026gt; instance() { static std::shared_ptr\u0026lt;Singleton\u0026gt; inst(new Singleton); return inst; } }; 支持自定义析构、更适合资源生命周期管理\n🍃6. 模板化 shared_ptr 单例（进阶）\u0026mdash; 现代 C++ 的正确打开方式 template \u0026lt;typename T\u0026gt; class SharedSingleton { public: using Ptr = std::shared_ptr\u0026lt;T\u0026gt;; static void setDeleter(std::function\u0026lt;void(T*)\u0026gt; deleter) { getDeleter() = std::move(deleter); } template\u0026lt;typename... Args\u0026gt; static Ptr instance(Args\u0026amp;\u0026amp;... args) { std::call_once(getOnceFlag(), [\u0026amp;] { instance_() = Ptr(new T(std::forward\u0026lt;Args\u0026gt;(args)...), getDeleter()); }); return instance_(); } static void reset() { std::lock_guard\u0026lt;std::mutex\u0026gt; lock(getMutex()); instance_().reset(); getOnceFlag() = std::once_flag(); } private: static Ptr\u0026amp; instance_() { static Ptr inst; return inst; } static std::once_flag\u0026amp; getOnceFlag() { static std::once_flag flag; return flag; } static std::mutex\u0026amp; getMutex() { static std::mutex mtx; return mtx; } static std::function\u0026lt;void(T*)\u0026gt;\u0026amp; getDeleter() { static std::function\u0026lt;void(T*)\u0026gt; deleter = [](T* p) { delete p; }; return deleter; } }; 3️⃣ 实现方式对比分析 实现方式 构造控制 析构控制 支持传参 线程安全 生命周期可控 工程推荐度 饿汉式 ❌ ❌ ❌ ✅ ❌ 🟡 懒汉式+DCLP ✅ ❌ ❌ ⚠️ ❌ ❌（风险大） Meyers Singleton ✅ ❌ ❌ ✅（C++11） ❌ ✅ shared_ptr静态 ✅ ✅ ❌ ✅ 部分 ✅ shared_ptr模板封装 ✅ ✅ ✅ ✅ ✅ ✅✅✅ 4️⃣ 懒汉式 + 线程安全（C++11 标准）局部静态变量（Meyers Singleton）\u0026mdash; 语法语义与底层源码解析 🍃局部静态变量的线程安全（C++11） static Singleton\u0026amp; getInstance() { static Singleton instance; return instance; } C++11 标准 [stmt.dcl/4]：[[局部静态变量的初始化]]是[[线程安全]]的。\n[[编译器]]在初始化前加锁，保证只有一个线程可以构造它。\n编译器生成等价伪代码（示意）：\nSingleton\u0026amp; getInstance() { static bool initialized = false; static char storage[sizeof(Singleton)]; static std::once_flag flag; std::call_once(flag, [\u0026amp;] { new (\u0026amp;storage) Singleton(); initialized = true; }); return *reinterpret_cast\u0026lt;Singleton*\u0026gt;(\u0026amp;storage); } 🍃析构顺序与静态对象生命周期问题 局部 static 实例会在 main() 退出后被自动[[析构]] 如果你希望手动控制生命周期（如 exit() 后仍然存在），需配合 new 与 atexit 或 shared_ptr 实现。 🍃源码级剖析（glibc + clang libc++） [[glibc]] 层面：pthread_once 实现\n[[glibc]] 中 std::call_once 依赖 pthread_once：\nint pthread_once(pthread_once_t *once_control, void (*init_routine)(void)); pthread_once 使用锁 + 状态标志 + [[memory barrier]] 保证只初始化一次 是 [[C++11]] std::call_once 的基础\n[[libc++]] 实现（\u0026lt;mutex\u0026gt;）\nnamespace std { template\u0026lt;class Callable\u0026gt; void call_once(once_flag\u0026amp; flag, Callable\u0026amp;\u0026amp; f); } 内部采用了双状态原子标记（__called, __complete）\nGCC 实现中使用 __atomic_load_n + __sync_bool_compare_and_swap 保证[[原子性]]\n5️⃣ 底层原理解析：语义 + ABI 行为 + 构造顺序 🧵 std::call_once + std::once_flag static std::once_flag f; std::call_once(f, [] { singleton = new Singleton(); }); 🔥 内存模型分析 局部 static：存储于静态区 shared_ptr：堆区资源，引用计数释放 6️⃣ ResourcePool / ThreadPool 工程实践 auto pool = SharedSingleton\u0026lt;BufferPool\u0026gt;::instance(32, 8*1024); auto buf = pool-\u0026gt;acquire(); auto pool = SharedSingleton\u0026lt;ThreadPool\u0026gt;::instance(8); pool-\u0026gt;enqueue([] { do_work(); }); ✅ 总结与设计哲学 能力点 Meyers Singleton shared_ptr 封装 安全性 ✅ ✅ 灵活性 ❌ ✅✅ 生命周期控制 ❌ ✅✅✅ 测试友好性 ❌ ✅✅ 工程适配度 🟡 ✅✅✅ ","date":"6 June, 2025","id":35,"permalink":"/posts/%E6%B7%B1%E5%85%A5-c++-%E5%8D%95%E4%BE%8B%E6%A8%A1%E5%BC%8F%E5%8E%9F%E7%90%86%E5%AE%9E%E7%8E%B0%E6%96%B9%E5%BC%8F%E5%AF%B9%E6%AF%94%E4%B8%8E-shared_ptr-%E6%9E%B6%E6%9E%84%E8%AE%BE%E8%AE%A1/","summary":"单例（[[Singleton]]）是对象创建模式中最常见的一种，其目标是确保类在系统中只有一个实例，并提供全局访问入口。","tags":"cpp 单例模式 singleton","title":"📌深入 C++ 单例模式：原理、实现方式对比与 shared_ptr 架构设计"},{"content":"📌 C++类成员函数：static 与 const 的声明与定义规则解析 为什么头文件声明要写 static/const，而实现时 static 要省略、const 必须保留？\n🔍 核心规则对比表 关键字 头文件（.h）声明 源文件（.cpp）定义 底层原因 static 必须显式声明：static void func(); 禁止重复：直接写 void Class::func() static 标识函数归属类而非对象；定义时 ClassName:: 已隐含作用域，再写 static 会被解释为文件作用域函数，破坏封装性。 const 必须显式声明：int get() const; 必须保留：int Class::get() const const 是函数签名的一部分，声明与定义必须严格一致，否则编译器视为不同函数，导致链接错误。 ⚙️ 一、static 关键字的声明与定义分离 1. 声明时需 static 在头文件中，static 明确标识该函数是类级别共享的，不依赖对象实例（无 this 指针）：\n// MyClass.h class MyClass { public: static void sharedFunc(); // ✅ 声明为静态 }; 2. 定义时禁止 static 在源文件中，ClassName:: 已指明函数归属类作用域。若添加 static：\n会被编译器解释为文件作用域的静态函数（仅当前 .cpp 可见）； 导致无法通过 MyClass::sharedFunc() 全局访问，破坏封装性。 ✅ 正确写法：\n// MyClass.cpp void MyClass::sharedFunc() { /* 实现 */ } // 无 static ❌ 错误写法：\nstatic void MyClass::sharedFunc() { ... } // ❌ 语义冲突！ 底层原理：static 成员函数无 this 指针，属于类而非对象。定义时通过 ClassName:: 解析作用域，冗余的 static 会覆盖类作用域。\n⚙️ 二、const 关键字的声明与定义一致性 1. 声明时需 const 表明该函数是常量成员函数，承诺不修改对象状态（隐含 const this* 指针），允许 const 对象调用：\nclass MyClass { public: int getValue() const; // ✅ 承诺不修改对象 }; 2. 定义时必须保留 const const 是函数签名的一部分，省略会导致：\n函数签名不匹配（声明为 const，定义非 const）； const 对象无法调用该函数，引发编译错误。 ✅ 正确写法：\nint MyClass::getValue() const { // ✅ 保留 const return value; } ❌ 错误写法：\nint MyClass::getValue() { // ❌ 丢失 const return value; } 底层原理：const 成员函数的本质是修饰隐含的 this 指针（const MyClass* const this），定义时缺失 const 会导致 this 指针类型不匹配。\n⚡ 三、关键设计原则与常见陷阱 1. static 和 const 的互斥性 静态成员函数不能为 const： static 函数无 this 指针，而 const 依赖 const this*，两者语义冲突。\n尝试组合会直接编译失败：\nclass Example { public: static void func() const; // ❌ 编译错误 }; 2. 常见错误示例 // MyClass.h class MyClass { public: static void staticFunc(); // ✅ int getValue() const; // ✅ }; // MyClass.cpp static void MyClass::staticFunc() { ... } // ❌ static 重复 int MyClass::getValue() { ... } // ❌ const 丢失 3. 单一定义规则（ODR） 声明与定义的符号必须完全匹配，否则引发未定义行为。\n✅ 四、最佳实践总结 声明规范： static 成员函数：头文件中显式标记 static。 const 成员函数：头文件中显式标记 const。 定义规范： static 成员函数：省略 static，仅用 ClassName:: 限定作用域。 const 成员函数：保留 const，确保签名一致。 组合使用： 用 static const 定义类级别常量（如 static const int SIZE = 100;），避免跨文件共享可变状态。 💎 结语：理解底层，避免陷阱 static 和 const 在类成员函数中的差异源于 C++ 的作用域解析机制和常量正确性约束：\nstatic 的分离设计（声明写，定义省）确保类作用域与文件作用域不冲突； const 的严格一致性保障对象状态安全。 掌握这些规则，能显著提升代码的健壮性和可维护性。建议在代码审查中重点关注 const 签名一致性，并用 static 优化无状态工具函数！\n扩展思考：C++23 中 constexpr 成员函数的新特性如何与 static/const 协同？欢迎在评论区探讨！\n","date":"4 June, 2025","id":36,"permalink":"/posts/-c++-%E7%B1%BB%E6%88%90%E5%91%98%E5%87%BD%E6%95%B0-static-%E4%B8%8E-const-%E7%9A%84%E5%A3%B0%E6%98%8E%E4%B8%8E%E5%AE%9A%E4%B9%89%E8%A7%84%E5%88%99%E8%A7%A3%E6%9E%90/","summary":"为什么头文件声明要写 static/const，而实现时 static 要省略、const 必须保留？","tags":"cpp","title":"📌 C++类成员函数 static 与 const 的声明与定义规则解析"},{"content":"小对象优化（Small Object Optimization）深度解析：C++容器的性能利器 引言 在现代C++开发中，std::string和std::vector等标准容器的高效性往往被开发者视为理所当然。然而，这些容器在处理小对象时的卓越性能背后，隐藏着一项重要的优化技术——小对象优化（Small Object Optimization, SOO）。对于追求高性能的C++开发者而言，理解SOO的工作原理不仅有助于编写更高效的代码，更能启发我们在设计自定义容器时采用类似的优化策略。\n问题背景：小对象的性能困境 堆分配的性能开销 当我们使用std::string或std::vector存储数据时，这些容器通常需要动态分配内存来存储实际数据。对于大型对象，堆分配的开销相对于数据处理成本而言是可以接受的。但是，当我们频繁处理小对象时，情况就截然不同了：\n分配器开销：每次调用new/delete或malloc/free都涉及复杂的内存管理算法，包括寻找合适大小的内存块、维护空闲列表等 内存碎片：大量小内存块的分配和释放会导致堆内存碎片化，降低内存利用率 缓存局部性差：堆上分配的小对象在内存中分布散乱，访问时缓存命中率低 传统解决方案的局限 栈上分配虽然速度极快，但受限于生命周期管理，无法满足容器需要动态调整大小的需求。而纯粹的堆分配虽然灵活，但在处理短字符串、小容量向量等高频场景时，性能开销变得不可忽视。\n核心问题：如何为需要动态内存管理的容器优化小对象的存储性能？\nSOO核心原理：智能的空间换时间策略 基本思想 小对象优化的核心策略是在容器对象内部预留一个固定大小的内部缓冲区（Internal Buffer）。这个缓冲区作为\u0026quot;快速通道\u0026quot;，专门用于存储小对象的数据。\n大小判定逻辑 SOO的工作机制可以用简单的条件判断来描述：\nif (required_size \u0026lt;= internal_buffer_size) { // 使用内部缓冲区，无需堆分配 store_in_internal_buffer(data); } else { // 退回到传统的堆内存分配 allocate_on_heap(data); } Zero-Overhead抽象 SOO的精妙之处在于对使用者完全透明。无论底层使用的是内部缓冲区还是堆内存，容器提供的接口行为完全一致，这体现了C++中\u0026quot;Zero-Overhead\u0026quot;抽象的设计理念。\n实现剖析：以std::string为例 典型数据结构设计 一个支持SOO的std::string内部结构可能如下所示：\nclass optimized_string { private: static constexpr size_t INTERNAL_BUFFER_SIZE = 15; union { // 大对象模式：指向堆内存 struct { char* ptr; size_t size; size_t capacity; } heap_data; // 小对象模式：直接存储在对象内部 struct { char buffer[INTERNAL_BUFFER_SIZE + 1]; // +1 for null terminator unsigned char remaining_size; // 用于标识当前模式和剩余空间 } stack_data; }; public: bool is_using_soo() const { // 通过特定位或值判断当前使用的存储模式 return stack_data.remaining_size \u0026lt;= INTERNAL_BUFFER_SIZE; } const char* data() const { return is_using_soo() ? stack_data.buffer : heap_data.ptr; } size_t size() const { return is_using_soo() ? (INTERNAL_BUFFER_SIZE - stack_data.remaining_size) : heap_data.size; } }; 状态区分机制 区分当前使用内部缓冲区还是堆内存是SOO实现的关键技术点。常见策略包括：\n利用容量字段的特殊值：当capacity为某个特殊值时表示使用内部缓冲区 专用标志位：使用remaining_size字段既存储剩余空间信息，又作为状态标识 指针值判断：通过检查指针是否指向内部缓冲区来判断状态 源码实现原理深度剖析 完整的SOO实现框架 为了深入理解SOO的工作机制，我们来看一个更完整的实现框架：\nclass soo_string { private: static constexpr size_t SSO_BUFFER_SIZE = 15; static constexpr size_t SSO_MASK = 0x80; // 最高位作为标志位 union data_union { // 长字符串模式 struct long_string { char* ptr; size_t size; size_t capacity; } long_data; // 短字符串模式 struct short_string { char buffer[SSO_BUFFER_SIZE]; unsigned char info; // 存储长度和标志位 } short_data; } data_; // 核心状态判断函数 bool is_short() const noexcept { return (data_.short_data.info \u0026amp; SSO_MASK) == 0; } size_t short_size() const noexcept { return SSO_BUFFER_SIZE - (data_.short_data.info \u0026amp; ~SSO_MASK); } void set_short_size(size_t size) noexcept { data_.short_data.info = static_cast\u0026lt;unsigned char\u0026gt;(SSO_BUFFER_SIZE - size); } void set_long_data(char* ptr, size_t size, size_t cap) noexcept { data_.long_data.ptr = ptr; data_.long_data.size = size; data_.long_data.capacity = cap | SSO_MASK; // 设置标志位 } public: // 默认构造函数 soo_string() noexcept { data_.short_data.buffer[0] = \u0026#39;\\0\u0026#39;; set_short_size(0); } // 从C字符串构造 soo_string(const char* str) { size_t len = strlen(str); if (len \u0026lt;= SSO_BUFFER_SIZE) { // 使用短字符串优化 memcpy(data_.short_data.buffer, str, len); data_.short_data.buffer[len] = \u0026#39;\\0\u0026#39;; set_short_size(len); } else { // 分配堆内存 char* new_ptr = new char[len + 1]; memcpy(new_ptr, str, len + 1); set_long_data(new_ptr, len, len); } } // 拷贝构造函数 soo_string(const soo_string\u0026amp; other) { if (other.is_short()) { // 复制短字符串 data_.short_data = other.data_.short_data; } else { // 复制长字符串 size_t len = other.data_.long_data.size; char* new_ptr = new char[len + 1]; memcpy(new_ptr, other.data_.long_data.ptr, len + 1); set_long_data(new_ptr, len, len); } } // 移动构造函数 soo_string(soo_string\u0026amp;\u0026amp; other) noexcept { if (other.is_short()) { // 短字符串需要复制数据 data_.short_data = other.data_.short_data; } else { // 长字符串可以直接移动指针 data_.long_data = other.data_.long_data; other.data_.short_data.buffer[0] = \u0026#39;\\0\u0026#39;; other.set_short_size(0); } } // 析构函数 ~soo_string() { if (!is_short()) { delete[] data_.long_data.ptr; } } // 访问器函数 const char* c_str() const noexcept { return is_short() ? data_.short_data.buffer : data_.long_data.ptr; } size_t size() const noexcept { return is_short() ? short_size() : data_.long_data.size; } size_t capacity() const noexcept { return is_short() ? SSO_BUFFER_SIZE : (data_.long_data.capacity \u0026amp; ~SSO_MASK); } }; 关键实现细节解析 1. 标志位巧妙设计 // 利用capacity字段的最高位作为标志 // 长字符串: capacity |= SSO_MASK (最高位为1) // 短字符串: info字段最高位为0 static constexpr size_t SSO_MASK = 0x80; 2. 内存布局优化 短字符串模式下，info字段既存储长度信息又作为状态标识：\ninfo = SSO_BUFFER_SIZE - actual_length 最高位始终为0，表示短字符串模式 3. 分支预测优化 // 编译器优化：短字符串是常见情况 if (is_short()) [[likely]] { // 短字符串处理逻辑 } else { // 长字符串处理逻辑 } 不同场景下的调用流程分析 场景1：短字符串构造流程 soo_string str(\u0026#34;Hello\u0026#34;); // 5个字符，小于SSO_BUFFER_SIZE(15) 调用流程：\n// 1. 计算字符串长度 size_t len = strlen(\u0026#34;Hello\u0026#34;); // len = 5 // 2. 长度判断 if (len \u0026lt;= SSO_BUFFER_SIZE) { // 5 \u0026lt;= 15, 条件成立 // 3. 直接复制到内部缓冲区 memcpy(data_.short_data.buffer, \u0026#34;Hello\u0026#34;, 5); data_.short_data.buffer[5] = \u0026#39;\\0\u0026#39;; // 4. 设置长度信息 set_short_size(5); // info = 15 - 5 = 10 // 5. 无堆分配，构造完成 } 性能特征：\n时间복杂度：O(1) 内存分配：0次堆分配 缓存友好：数据存储在对象内部 场景2：长字符串构造流程 soo_string str(\u0026#34;This is a very long string that exceeds the buffer size\u0026#34;); 调用流程：\n// 1. 计算字符串长度 size_t len = strlen(input); // len = 58 \u0026gt; 15 // 2. 长度判断 if (len \u0026lt;= SSO_BUFFER_SIZE) { // 58 \u0026lt;= 15, 条件不成立 // 跳过此分支 } else { // 3. 分配堆内存 char* new_ptr = new char[len + 1]; // 分配59字节 // 4. 复制数据到堆 memcpy(new_ptr, input, len + 1); // 5. 设置长字符串数据 set_long_data(new_ptr, len, len); // data_.long_data.ptr = new_ptr // data_.long_data.size = 58 // data_.long_data.capacity = 58 | SSO_MASK // 设置标志位 } 性能特征：\n时间复杂度：O(n) + 堆分配开销 内存分配：1次堆分配 额外开销：分配器调用、内存管理开销 场景3：短字符串复制流程 soo_string str1(\u0026#34;Hello\u0026#34;); soo_string str2 = str1; // 拷贝构造 调用流程：\n// 1. 检查源字符串类型 if (other.is_short()) { // 短字符串 // 2. 直接复制union数据 data_.short_data = other.data_.short_data; // 包括buffer和info字段的完整复制 // 3. 无需额外分配，复制完成 } 性能特征：\n时间复杂度：O(1) 内存分配：0次 操作：简单的内存复制 场景4：长字符串移动流程 soo_string str1(\u0026#34;Very long string...\u0026#34;); soo_string str2 = std::move(str1); // 移动构造 调用流程：\n// 1. 检查源字符串类型 if (other.is_short()) { // 短字符串无法真正\u0026#34;移动\u0026#34;，需要复制 data_.short_data = other.data_.short_data; } else { // 2. 长字符串：转移所有权 data_.long_data = other.data_.long_data; // 3. 重置源对象为空短字符串 other.data_.short_data.buffer[0] = \u0026#39;\\0\u0026#39;; other.set_short_size(0); // 4. 指针转移完成，无需复制数据 } 性能特征：\n长字符串：O(1)，仅指针转移 短字符串：O(1)，但需要数据复制 场景5：动态增长流程 soo_string str(\u0026#34;Hello\u0026#34;); str += \u0026#34; World! This makes it longer than 15 characters\u0026#34;; 调用流程：\n// 1. 计算新长度 size_t current_len = str.size(); // 5 size_t append_len = strlen(\u0026#34; World! ...\u0026#34;); // 48 size_t new_len = current_len + append_len; // 53 // 2. 检查是否需要转换为长字符串 if (str.is_short() \u0026amp;\u0026amp; new_len \u0026gt; SSO_BUFFER_SIZE) { // 3. 分配新的堆内存 char* new_ptr = new char[new_len + 1]; // 4. 复制原有数据 memcpy(new_ptr, str.data_.short_data.buffer, current_len); // 5. 追加新数据 memcpy(new_ptr + current_len, append_data, append_len); new_ptr[new_len] = \u0026#39;\\0\u0026#39;; // 6. 转换为长字符串模式 str.set_long_data(new_ptr, new_len, new_len); } 性能特征：\n涉及模式转换：一次性的转换开销 后续操作：按长字符串模式处理 内存重分配：不可避免，但仅在转换时发生一次 性能对比总结 操作场景 短字符串(SOO) 长字符串 性能差异 构造 O(1), 0次分配 O(n), 1次分配 10-100倍 拷贝 O(1), 0次分配 O(n), 1次分配 5-50倍 移动 O(1), 需复制 O(1), 仅指针 短字符串略慢 访问 O(1), 高缓存命中 O(1), 可能缓存miss 1.5-3倍 析构 O(1), 无操作 O(1), 1次释放 5-20倍 性能优势分析 量化的性能提升 SOO带来的性能优势在小对象频繁操作场景下尤为显著：\n// 性能对比示例（概念性） void performance_comparison() { // 场景1：SOO优化的短字符串操作 std::string short_str = \u0026#34;Hello\u0026#34;; // 直接存储在内部缓冲区 // 时间复杂度：O(1)，无堆分配开销 // 场景2：超出SOO阈值的长字符串 std::string long_str = \u0026#34;This is a very long string that exceeds buffer\u0026#34;; // 时间复杂度：O(1) + 堆分配开销 // 在循环中创建大量短字符串时，SOO可带来数倍性能提升 for (int i = 0; i \u0026lt; 1000000; ++i) { std::string temp = \u0026#34;short\u0026#34;; // SOO优化：栈速度 // vs 非优化版本需要1000000次堆分配/释放 } } 具体优势 减少分配次数：对于长度不超过阈值的字符串，完全避免堆分配器调用 改善内存局部性：数据存储在容器对象内部，与其他成员变量在同一缓存行中 降低内存碎片：减少堆上小内存块的数量，改善整体内存布局 提升并发性能：减少对全局堆分配器的竞争 关键考量与局限 空间开销权衡 SOO的主要代价是增加了每个容器对象的尺寸。即使存储大对象时使用堆分配，内部缓冲区的空间仍然被占用：\nsizeof(std::string) // 通常为24-32字节，包含内部缓冲区 vs sizeof(char*) + sizeof(size_t) * 2 // 仅指针+大小信息约为24字节 这种空间开销在以下场景中需要特别考虑：\n存储大量空字符串或小字符串的容器（如std::vector\u0026lt;std::string\u0026gt;） 内存受限的嵌入式环境 对象大小敏感的数据结构设计 缓冲区大小的选择艺术 内部缓冲区大小的选择需要在空间开销和优化效果之间找到平衡：\nlibstdc++：通常为15字节（用于std::string） libc++：可能选择22字节或其他值 MSVC：根据目标架构可能有不同选择 选择过小会降低优化覆盖率，选择过大会增加不必要的空间开销。\n移动语义的复杂性 SOO对移动操作带来了额外考虑：\n// 移动SOO对象时的考虑 optimized_string str1 = \u0026#34;short\u0026#34;; // 使用内部缓冲区 optimized_string str2 = std::move(str1); // 需要复制内部缓冲区数据 // vs 移动大对象时只需交换指针 optimized_string long_str1 = \u0026#34;very long string...\u0026#34;; optimized_string long_str2 = std::move(long_str1); // 仅指针交换 实用价值与应用启发 现实应用场景 SOO在以下高频场景中发挥重要作用：\n日志系统：大量短日志消息的处理 配置管理：键值对中的短字符串键名 临时字符串拼接：函数内部的临时字符串操作 小容量向量：初始化时只包含少量元素的std::vector 设计启发 SOO的设计思想可以启发我们在设计自定义容器或封装类时考虑类似优化：\n识别小对象场景：分析你的应用中哪些数据结构经常存储小对象 权衡空间时间：根据具体使用模式决定是否值得引入内部缓冲区 保持接口一致性：确保优化对使用者透明 基准测试验证：通过实际测量验证优化效果 总结 小对象优化代表了C++标准库在性能优化方面的精妙设计。通过在容器内部预留固定大小的缓冲区，SOO成功地为小对象提供了接近栈分配的性能，同时保持了动态内存管理的灵活性。\n虽然SOO会增加对象的空间开销，但在处理大量小对象的场景中，其带来的性能提升往往远超过空间成本。理解SOO不仅有助于我们更好地使用标准容器，更重要的是，它展示了如何通过巧妙的设计在高级抽象和底层性能之间找到完美平衡。\n在设计高性能C++应用时，SOO提醒我们：最优的解决方案往往不是单一的技术，而是针对不同规模问题采用不同策略的智能组合。\n","date":"4 June, 2025","id":37,"permalink":"/posts/%E5%B0%8F%E5%AF%B9%E8%B1%A1%E4%BC%98%E5%8C%96small-object-optimization%E6%B7%B1%E5%BA%A6%E8%A7%A3%E6%9E%90c++%E5%AE%B9%E5%99%A8%E7%9A%84%E6%80%A7%E8%83%BD%E5%88%A9%E5%99%A8/","summary":"在现代C++开发中，std::string和std::vector等标准容器的高效性往往被开发者视为理所当然。然而，这些容器在处理小对象时的卓越性能背后，隐藏着一项重要的优化技术——小对象优化（Small Object Optimization, SOO）。对于追求高性能的C++开发者而言，理解SOO的工作原理不仅有助于编写更高效的代码，更能启发我们在设计自定义容器时采用类似的优化策略。","tags":"cpp SOO","title":"📌小对象优化（Small Object Optimization）深度解析：C++容器的性能利器"},{"content":"[[c++]] [[delete]] [[构造函数]] [[析构函数]]\n深入分析：= delete 与私有化构造和析构函数的本质区别 ​直接结论​：\n绝对不能将构造函数和析构函数写为 = delete 这会直接破坏单例模式的核心功能。以下是详细技术分析：\n一、语法层面的根本差异 方案 可访问性 编译器行为 对单例模式的影响 ​私有构造函数​ 仅类内部可访问 允许类内部代码构造对象 实现单例的核心手段 Singleton() = delete 函数被彻底删除 任何构造尝试直接报错 完全无法创建对象 方案 可访问性 编译器行为 对单例模式的影响 ​私有析构函数​ 仅类内部可访问 允许类内部析构对象 防止外部delete操作 ~Singleton() = delete 函数被彻底删除 对象销毁时直接报错 对象无法被正确释放 二、关键错误场景演示 class Singleton { public: static Singleton\u0026amp; getInstance() { static Singleton instance; // 这里会编译失败！ return instance; } Singleton() = delete; // 构造函数被删除 ~Singleton() = delete; // 析构函数被删除 }; 编译器报错信息 error: use of deleted function \u0026#39;Singleton::Singleton()\u0026#39; static Singleton instance; ^ note: declared here Singleton() = delete; ^~~~~~~~~~~ error: use of deleted function \u0026#39;Singleton::~Singleton()\u0026#39; static Singleton instance; ^ note: declared here ~Singleton() = delete; ^ 三、技术原理深度解析 构造函数删除的致命问题 ​静态局部变量初始化​ static Singleton instance本质需要调用构造函数，但构造函数已被删除 → 编译失败 ​单例模式基础破坏​ 删除构造函数意味着该类无法被实例化，完全失去单例存在的意义 析构函数删除的连锁反应 ​静态变量销毁问题​ 程序退出时，静态变量instance需要调用析构函数 → 因析构函数被删除导致链接错误 ​内存泄漏伪装者​ 即使通过特殊手段构造对象，也无法正常释放资源 → 违反RAII原则 四、正确方案对比验证 正确实现（私有构造/析构） class Singleton { public: static Singleton\u0026amp; getInstance() { static Singleton instance; // 正确：调用私有构造函数 return instance; } // 禁用拷贝操作 Singleton(const Singleton\u0026amp;) = delete; Singleton\u0026amp; operator=(const Singleton\u0026amp;) = delete; private: Singleton() = default; // 正确：私有默认构造 ~Singleton() = default; // 正确：私有析构 }; 关键优势 ​构造可控性​ 通过私有构造函数限制对象创建途径，确保唯一实例 ​析构安全性​ 私有析构函数阻止外部delete操作，依赖系统自动释放 ​资源管理合规​ 静态局部变量在程序结束时自动调用析构函数，符合RAII规范 五、特殊场景扩展讨论 Q：如果确实需要完全禁止某个类的实例化？ class UtilityClass { // 工具类，仅包含静态方法 public: UtilityClass() = delete; ~UtilityClass() = delete; static void helper1(); static int helper2(); }; ​适用场景​：\n纯静态工具类（无需实例） 仅作为模板元编程工具 ​与单例模式的核心区别​：\n单例需要唯一实例 工具类完全不需要实例 六、总结表格：设计决策指南 需求场景 构造函数方案 析构函数方案 典型应用 单例模式 私有默认构造 私有析构 系统全局管理器 不可实例化的工具类 = delete = delete 数学计算工具集 抽象接口基类 protected默认构造 public virtual析构 多态基类 仅堆分配对象 私有构造+静态工厂方法 public非虚析构 对象池管理 ​最终结论​：在单例模式中必须使用私有构造函数/析构函数，而非= delete。= delete语法应仅用于完全禁止类实例化的场景（如纯静态工具类）。\n","date":"4 June, 2025","id":38,"permalink":"/posts/%E6%B7%B1%E5%85%A5%E5%88%86%E6%9E%90-delete-%E4%B8%8E%E7%A7%81%E6%9C%89%E5%8C%96%E6%9E%84%E9%80%A0%E5%92%8C%E6%9E%90%E6%9E%84%E5%87%BD%E6%95%B0%E7%9A%84%E6%9C%AC%E8%B4%A8%E5%8C%BA%E5%88%AB/","summary":"[[c++]] [[delete]] [[构造函数]] [[析构函数]]","tags":"cpp","title":"📌深入分析 =delete 与私有化构造和析构函数的本质区别"},{"content":"深入理解 C++ 中的 std ref 和 cref 的引用封装机制 在现代 C++ 编程中，按值传参是常态，但有时候我们确实需要传引用。尤其是在使用 std::bind、std::thread、标准算法等场景下，如果不加注意，原本希望传引用的变量却被复制，导致逻辑失效甚至程序崩溃。\n本文将带你深入理解 std::ref 和 std::cref 的设计原理、使用场景以及易踩的坑。\n为什么需要引用封装器 先来看一个例子：\nvoid increment(int\u0026amp; x) { x++; } int main() { int a = 5; std::thread t(increment, a); // ❌ 编译失败 t.join(); } 你可能以为把 a 传进去就是引用了，但事实并非如此。std::thread 默认按值复制参数。它尝试将 a 拷贝一份传递给 increment，而 increment 期望的是 int\u0026amp;，于是编译器报错。\n这个时候，std::ref(a) 就派上了用场：\nstd::thread t(increment, std::ref(a)); // ✅ 传引用成功 std ref 和 cref 是什么 std::ref(obj)：返回一个 可修改引用 的包装器。\nstd::cref(obj)：返回一个 const 引用 的包装器。\n这两个函数本质上返回的是一个 std::reference_wrapper\u0026lt;T\u0026gt; 类型，它可以模拟“按引用传参”的行为，但仍然以“按值”方式传递给调用者。\n典型使用场景 1. std::thread void print(int\u0026amp; x) { std::cout \u0026lt;\u0026lt; x \u0026lt;\u0026lt; std::endl; } int main() { int a = 42; std::thread t(print, std::ref(a)); // ✅ 按引用传入 t.join(); } 如果不使用 std::ref，代码会因为引用绑定失败而无法通过编译。\n2. std::bind #include \u0026lt;functional\u0026gt; void set_to_100(int\u0026amp; x) { x = 100; } int main() { int a = 0; auto f = std::bind(set_to_100, std::ref(a)); f(); // ✅ 成功修改 a } 若不使用 std::ref，a 会被拷贝，set_to_100 内部修改的是拷贝，而不是原变量。\n3. 标准算法 #include \u0026lt;algorithm\u0026gt; #include \u0026lt;iostream\u0026gt; #include \u0026lt;vector\u0026gt; #include \u0026lt;functional\u0026gt; void print(int x) { std::cout \u0026lt;\u0026lt; x \u0026lt;\u0026lt; \u0026#34; \u0026#34;; } int main() { std::vector\u0026lt;int\u0026gt; data{1, 2, 3}; std::for_each(data.begin(), data.end(), std::ref(print)); // ✅ 引用函数 } cref 的使用场景 当你希望以只读引用方式传参时，使用 std::cref：\nvoid show(const int\u0026amp; x) { std::cout \u0026lt;\u0026lt; x \u0026lt;\u0026lt; std::endl; } int main() { int val = 10; auto f = std::bind(show, std::cref(val)); f(); // 输出 10 } 实现原理简析 标准库中的 reference_wrapper 本质上就是用一个指针模拟引用：\ntemplate\u0026lt;typename T\u0026gt; class reference_wrapper { public: explicit reference_wrapper(T\u0026amp; ref) noexcept : ptr(std::addressof(ref)) {} T\u0026amp; get() const noexcept { return *ptr; } operator T\u0026amp;() const noexcept { return *ptr; } private: T* ptr; }; 这也意味着：\nreference_wrapper 不会延长原对象的生命周期\nref 和 cref 都只能绑定左值\n使用注意事项 1. 不可绑定右值 std::ref(42); // ❌ 错误：不能对临时对象创建可修改引用 std::cref(42); // ✅ 正确：const 引用可以绑定右值 2. 生命周期问题 不要对临时变量使用 std::ref：\nauto f = std::bind(print, std::ref(temp())); // ❌ 悬垂引用 应用总结 场景 默认传值？ 是否推荐使用 ref/cref std::thread ✅ ✅ std::bind ✅ ✅ std::function ✅（捕获拷贝） ✅ for_each / 算法 ✅ ✅ Lambda 捕获 可选（值/引用） ❌ 推荐 [\u0026amp;] 捕获 结语 std::ref 和 std::cref 是现代 C++ 中非常实用的小工具，它们让你能够安全、显式地在值语义上下文中传递引用，避免拷贝、保持语义清晰。\n在多线程、函数绑定、算法调用等场景下，它们能够显著提高代码的正确性与表达力。\n下次遇到按值调用的问题，不妨试着想一想：这里是不是该用 std::ref 或 std::cref？\n📚 推荐阅读：\ncppreference：std::ref 《Effective Modern C++》第 22 条：避免意外按值传参 ","date":"4 June, 2025","id":39,"permalink":"/posts/%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3-c++-%E4%B8%AD%E7%9A%84-std-ref-%E5%92%8C-cref-%E7%9A%84%E5%BC%95%E7%94%A8%E5%B0%81%E8%A3%85%E6%9C%BA%E5%88%B6/","summary":"先来看一个例子：","tags":"cpp","title":"📌深入理解 C++ 中的 std ref 和 cref 的引用封装机制"},{"content":"C++非侵入性编程范式 文档编号: Cpp-Tech-NIP-20250624-Final\n1. 摘要 本文档为C++开发者提供了一份关于非侵入性 (Non-Intrusive) 编程范式的全面、深入的技术指南。文档从核心定义出发，系统性地阐述了非侵入性设计的理念、基石与关键技术。内容涵盖泛型编程、非成员函数的策略性使用、操作符重载的外部实现机制（包括参数依赖查找ADL与函数重载），以及类型萃取和智能指针等高级应用。本文旨在通过丰富的代码示例和详尽的原理剖析，帮助开发者掌握并应用非侵入性原则，以构建松耦合、高复用性且易于维护的现代C++软件系统。\n2. 何为非侵入性编程？ 在C++中，非侵入性 (Non-Intrusive) 是一种核心设计哲学，其基本原则是：在为现有类型（如类、结构体）增加新功能，或使其与某个框架、库协作时，无需修改该类型自身的源代码。\n与之相对的是“侵入性 (Intrusive)”设计，它要求被操作的类型必须做出“内在”的改变，例如继承自特定的基类、包含特定的成员变量或实现特定的成员函数。\n核心思想对比:\n非侵入性 (Non-Intrusive): 功能是“外加”于类型之上的。如同为一部标准手机配上一个多功能手机壳，手机本身无需任何改造。 侵入性 (Intrusive): 功能是“内建”在类型之中的。如同手机在设计制造时就内置了防水和无线充电功能。 现代C++推崇非侵入性设计，因为它极大地增强了代码的灵活性与可复用性，允许开发者将无法修改的第三方类型、标准库类型或遗留代码无缝集成到新系统中。\n3. 基石：泛型编程与模板 C++模板是非侵入性设计的基石。通过模板，我们可以编写出独立于任何具体类型的算法和数据结构。这些代码仅对类型提出一组“概念”上的要求（例如，可被复制、可被比较），而非结构上的强制要求。\nstd::sort 算法便是非侵入性的典范。它可以对任何满足其要求的迭代器范围进行排序，而元素类型本身完全无需知晓排序算法的存在。\n示例：为一个无法修改的 Product 类提供排序能力\n// third_party_library.h - 源码无法修改 #pragma once #include \u0026lt;string\u0026gt; class Product { public: Product(std::string id, double price) : id_(std::move(id)), price_(price) {} const std::string\u0026amp; getId() const { return id_; } double getPrice() const { return price_; } // 提供一个稳定的公共接口 private: std::string id_; double price_; }; 我们无法修改 Product 类，但我们可以在外部为其添加比较功能。\n// comparison.h - 功能扩展模块 #include \u0026#34;third_party_library.h\u0026#34; // 为 Product 提供比较操作，这是一个非侵入性的外部函数 bool operator\u0026lt;(const Product\u0026amp; lhs, const Product\u0026amp; rhs) { return lhs.getPrice() \u0026lt; rhs.getPrice(); } // main.cpp #include \u0026lt;iostream\u0026gt; #include \u0026lt;vector\u0026gt; #include \u0026lt;algorithm\u0026gt; // for std::sort #include \u0026#34;comparison.h\u0026#34; int main() { std::vector\u0026lt;Product\u0026gt; products; products.emplace_back(\u0026#34;P102\u0026#34;, 99.99); products.emplace_back(\u0026#34;P055\u0026#34;, 19.95); // 调用 std::sort。Product 类完全不知道排序的存在。 std::sort(products.begin(), products.end()); // ... 输出排序结果 ... } 4. 核心机制：外部操作符重载详解 上述示例引出了一个关键问题：定义在类外部的 operator\u0026lt; 是如何被 std::sort 找到并正确调用的？这背后涉及C++的两个核心机制。\n4.1 参数依赖查找 (Argument-Dependent Lookup, ADL) ADL（又称Koenig查找）是让外部函数无缝工作的“魔法”。当编译器在常规作用域查找一个函数名失败时，它会额外执行一步：检查函数调用的实参类型，并到这些类型所属的命名空间中去查找匹配的函数。\n在 std::sort 内部，当执行类似 product1 \u0026lt; product2 的比较时：\n编译器首先在 std 命名空间和当前作用域查找 operator\u0026lt;，通常找不到。 ADL启动：编译器检测到参数类型是 Product。 编译器到 Product 类所在的命名空间（本例中是全局命名空间）进行查找。 查找成功：它找到了我们定义的非成员函数 bool operator\u0026lt;(const Product\u0026amp;, const Product\u0026amp;)，并用它来完成比较。 4.2 函数重载：为多个不同类提供相同功能 进一步地，如果我们有多个不同的类都需要比较，非侵入性设计依然优雅适用。这得益于函数重载 (Function Overloading)。\nC++允许存在多个同名函数，只要它们的参数列表（参数数量或类型）不同即可。一个函数的完整身份由其函数签名（函数名 + 参数列表）唯一确定。\n示例：同时为 Product 和 Employee 提供排序\n// common_types.h (扩展) #pragma once #include \u0026lt;string\u0026gt; #include \u0026lt;iostream\u0026gt; // --- 类定义 --- class Product { /* ... */ }; class Employee { public: Employee(std::string name, int salary) : name_(name), salary_(salary) {} int getSalary() const { return salary_; } private: std::string name_; int salary_; }; // --- 全局命名空间中的函数重载 --- // 重载版本1: 专用于 Product // 签名: operator\u0026lt;(const Product\u0026amp;, const Product\u0026amp;) bool operator\u0026lt;(const Product\u0026amp; lhs, const Product\u0026amp; rhs) { std::cout \u0026lt;\u0026lt; \u0026#34;[DEBUG: 调用 Product 的 operator\u0026lt;]\\n\u0026#34;; return lhs.getPrice() \u0026lt; rhs.getPrice(); } // 重载版本2: 专用于 Employee // 签名: operator\u0026lt;(const Employee\u0026amp;, const Employee\u0026amp;) bool operator\u0026lt;(const Employee\u0026amp; lhs, const Employee\u0026amp; rhs) { std::cout \u0026lt;\u0026lt; \u0026#34;[DEBUG: 调用 Employee 的 operator\u0026lt;]\\n\u0026#34;; return lhs.getSalary() \u0026lt; rhs.getSalary(); } 当 std::sort 分别作用于 std::vector\u0026lt;Product\u0026gt; 和 std::vector\u0026lt;Employee\u0026gt; 时，编译器会根据当前正在比较的元素类型，通过重载解析精确地选择正确的 operator\u0026lt; 版本。这两个函数是完全独立的，互不干扰，展现了C++的类型安全与灵活性。\n5. 其他关键非侵入性技术 5.1 非成员函数与接口原则 “接口应由类的外部、使用类的代码来表达。” 这一思想鼓励我们优先使用非成员非友元函数来扩展类的功能，而非无限制地向类中添加成员函数。这保持了类定义的简洁和稳定。\n示例：非侵入式序列化\n// json_serializer.h #include \u0026#34;common_types.h\u0026#34; #include \u0026lt;string\u0026gt; // 为 Product 类赋予序列化为 JSON 的能力，而无需修改它 std::string toJSON(const Product\u0026amp; p) { return \u0026#34;{ \\\u0026#34;id\\\u0026#34;: \\\u0026#34;\u0026#34; + p.getId() + \u0026#34;\\\u0026#34;, \\\u0026#34;price\\\u0026#34;: \u0026#34; + std::to_string(p.getPrice()) + \u0026#34; }\u0026#34;; } 5.2 类型萃取 (Type Traits) \u0026lt;type_traits\u0026gt; 头文件提供了一套模板元编程工具，允许在编译期查询和操作类型的属性，而无需侵入类型本身。这对于编写高度泛化的、能适应不同类型特征的代码至关重要。\n示例：一个只对算术类型有效的泛型add函数\n#include \u0026lt;type_traits\u0026gt; template\u0026lt;typename T\u0026gt; T add(T a, T b) { // 编译期检查：如果T不是算术类型(整数或浮点数)，编译将失败 static_assert(std::is_arithmetic_v\u0026lt;T\u0026gt;, \u0026#34;add function only accepts arithmetic types.\u0026#34;); return a + b; } add 函数没有要求 T 继承自 Numeric 之类的基类，而是通过类型萃取 std::is_arithmetic_v 非侵入性地约束了适用范围。\n5.3 非侵入式智能指针：std::shared_ptr 标准库的智能指针 std::shared_ptr 和 std::unique_ptr 都是非侵入性的。它们将所有权管理的元数据（如引用计数）存储在外部的一个独立分配的“控制块”中，而不是被管理的对象内部。\n这使得 std::shared_ptr 可以管理任何类型的对象，包括内置类型、无法修改的第三方类，甚至是前向声明的类型，而对象自身无需为此做出任何设计上的妥协。\n6. 优势与权衡 6.1 核心优势 松耦合 (Loose Coupling): 组件之间依赖性最小化。算法不依赖于具体类型，类型也不依赖于作用于其上的算法。 高可复用性 (High Reusability): 通用组件（如 std::sort, std::shared_ptr）可以应用于无限多种类的类型。 易于维护与扩展 (Easier Maintenance \u0026amp; Extension): 为类增加新功能只需添加外部函数或模板特化，无需修改和重新测试稳定的核心类。 关注点分离 (Separation of Concerns): 类的核心职责（业务逻辑）与横切关注点（如排序、序列化、生命周期管理）清晰分离。 6.2 潜在权衡 性能考量: 在对性能要求极致的场景下，非侵入性可能带来微小开销。 内存: std::shared_ptr 的外部控制块带来一次额外内存分配。侵入式指针将引用计数放在对象内部，内存布局更紧凑。 运行时: 非侵入式容器 std::list 在添加元素时需要为节点和数据分配内存。侵入式容器（如boost::intrusive::list）直接利用对象内的指针，没有额外分配开销。 接口发现性: 功能通过非成员函数提供，可能不如直接在IDE中敲出 object. 查看成员函数列表那么直观。这要求更好的文档和代码组织（如清晰的命名空间）。 7. 结论 非侵入性是现代C++软件设计的基石。它通过模板、函数重载、ADL、类型萃取等强大的语言特性，共同构筑了一个支持松耦合、高复用性和强适应性的编程模型。C++标准库本身就是非侵入性设计的最佳实践范本。\n对于C++开发者而言，深入理解并积极践行非侵入性设计，是编写出健壮、灵活且易于长期演进的高质量代码的关键。在架构设计中，应默认采用非侵入性方法，仅在有明确且强烈的性能或底层约束时，才审慎地考虑侵入式方案。\n","date":"4 June, 2025","id":40,"permalink":"/posts/-c++%E9%9D%9E%E4%BE%B5%E5%85%A5%E6%80%A7%E7%BC%96%E7%A8%8B%E8%8C%83%E5%BC%8F/","summary":"文档编号: Cpp-Tech-NIP-20250624-Final","tags":"cpp 编程范式 非侵入","title":"📘 C++非侵入性编程范式"},{"content":"📘 PingPong Buffer 设计文档 一、设计目标 PingPongBuffer（双缓冲区）旨在解决生产者与消费者异步处理数据时的数据一致性与性能问题。适用于实时数据传输、中断采集、多线程通信等场景，具备如下核心目标：\n保证读写互不干扰 支持高吞吐、低延迟 能够应对速率不匹配 可维护、可调试、可扩展 二、核心设计理念 2.1 双缓冲结构 使用两个固定大小的缓冲区 buffer[0] 和 buffer[1]，通过索引或标志位控制读写指向不同缓冲区。\nBuffer Index 用途 write_idx 当前写入缓冲区索引 read_idx 当前读取缓冲区索引 通过原子操作（或锁）切换这两个缓冲区，实现无锁或低锁竞争的数据交替使用。\n2.2 原子切换机制 采用 std::atomic\u0026lt;int\u0026gt; 索引变量配合 memory_order_release/acquire 保证跨线程或中断的数据可见性与一致性。\nwrite_idx.store(new_index, std::memory_order_release); read_idx.store(old_write_index, std::memory_order_acquire); 2.3 数据完整性控制 使用 BeginWrite/EndWrite 和 BeginRead/EndRead 保障帧级数据完整性 使用 frame_valid 标志位标识 buffer 是否写满可读 支持 frame_id、时间戳等附加信息追踪数据来源及一致性 三、异常与过载处理机制 3.1 生产者快于消费者（overrun） 当前写 buffer flip 后，若旧 buffer 尚未消费 → 记录覆盖行为 引入 overrun_counter，并提供异常提示接口 if (!buffer_valid[read_idx]) { overrun_counter++; } 3.2 异常帧检测 frame_id 不连续时提示丢帧 时间戳差距过大可认为数据阻塞 四、状态重置与配置变更 支持 reset() 操作，在底层硬件重配置（如分辨率、频率）或系统热切换场景中清空缓冲状态，防止旧数据干扰：\n清空两个缓冲区 重置索引、标志位、计数器 提供 flush() 或 sync() 接口供消费者同步状态 五、调试与可测试性设计 5.1 状态查询接口 当前读/写 buffer 索引 是否有新数据 覆盖次数统计 帧 ID 与时间戳获取 5.2 测试接口 支持注入写数据并读取验证 提供 mock 驱动或生产者/消费者回调封装 六、接口定义（C++11 示例） template \u0026lt;typename T\u0026gt; class PingPongBuffer { public: bool write(const T\u0026amp; data); // 写入并 flip bool read(T\u0026amp; data); // 读取 buffer void reset(); // 重置状态 bool isFresh() const; // 是否有新数据 uint64_t getFrameId() const; size_t getOverrunCount() const; private: T buffers_[2]; std::atomic\u0026lt;int\u0026gt; write_idx_{0}; std::atomic\u0026lt;int\u0026gt; read_idx_{1}; std::atomic\u0026lt;bool\u0026gt; valid_[2]; std::atomic\u0026lt;size_t\u0026gt; overrun_counter_{0}; std::atomic\u0026lt;uint64_t\u0026gt; frame_id_{0}; }; 七、实际工程需额外考虑的问题 类别 工程关注点 多线程/中断安全 原子变量、屏蔽中断、内存屏障 缓冲策略选择 是否支持多帧、三缓冲、环形缓冲 Cache 优化 缓冲区对齐、防止 false sharing 实时性与可预期性 避免动态内存、锁等待、跨核同步代价 热更新支持 参数切换后刷新所有缓冲数据，防止错帧 八、典型应用场景 场景 是否适合 PingPong 视频/图像帧 ✅ 单帧稳定速率，高速处理 中断采集 + 任务处理 ✅ ISR → Task 间交互 高频 sensor ⚠️ 建议改用环形缓冲区 必须处理每一帧 ❌ PingPong 不适用，考虑 backpressure + 多 buffer 九、总结与推荐 优点 限制 零拷贝、快速、结构简单 无法存储多个未处理帧，易丢数据 适用于高频、可容忍丢帧场景 不适用于必须每帧处理场景 可升级为三缓冲或环形缓冲模型 ","date":"4 June, 2025","id":41,"permalink":"/posts/-pingpong-buffer-%E8%AE%BE%E8%AE%A1%E6%96%87%E6%A1%A3/","summary":"PingPongBuffer（双缓冲区）旨在解决生产者与消费者异步处理数据时的数据一致性与性能问题。适用于实时数据传输、中断采集、多线程通信等场景，具备如下核心目标：","tags":"cpp pingpong","title":"📘 PingPong Buffer 设计文档"},{"content":"📘现代C++中类型擦除技术的全面解析：原理、模式与性能 第一部分：类型擦除的起源：连接静态与动态多态 本部分旨在阐明[[类型擦除]]技术所解决的根本问题，将其定位为一种旨在克服传统C++[[多态]]技术局限性的高级[[解决方案]]。\n1.1 C++中的多态困境 在C++中，[[多态]]性——即以统一接口处理不同类型对象的能力——是构建灵活、可扩展软件系统的基石。然而，实现多态的传统方法各自存在固有的局限性，这为类型擦除技术的出现提供了动机。\nvoid * 方法 (C风格多态) 最原始的类型擦除形式是通过 void * 指针实现的。C标准库中的 qsort 函数便是典型范例，它能够对任意类型的数组进行排序，正是因为它通过 void * 接受数据。\n这种方法的本质在于将任何类型的指针转换为一个通用的、无类型的指针，从而“擦除”了编译时的类型信息。然而，这种极致的灵活性带来了巨大的代价：类型安全的完全丧失。程序员必须承担将 void * 手动 reinterpret_cast 回原始正确类型的责任。这是一个极易出错的过程，一旦类型不匹配，便会立即导致未定义行为（[[Undefined Behavior]], UB）。此外，由于[[编译器]]在处理 void * 时对底层数据类型一无所知，它无法进行任何有意义的类型驱动优化，可能导致性能下降。\n面向对象多态 (继承与虚函数) 面向对象编程（OOP）提供了C++中实现运行时多态的惯用方法。该方法依赖于一个包含虚函数（virtual functions）的公共基类，各个具体类通过继承该基类并重写虚函数来实现多态行为。\n这种模式的主要局限性在于其 侵入性（intrusive）。任何希望以多态方式使用的具体类型都 必须 公开继承自这个共同的基类。这在许多场景下是不可行或不理想的，例如，我们无法修改[[标准库类型]]（如 std::string）、[[内建类型]]（如 int）或来自第三方库的类型，让它们去继承我们的基类。\n此外，这种方法存在“类型丢失”问题。当一个派生类对象通过基类引用或指针传递时，编译器在函数内部就“丢失”了该对象的真实类型信息。从编译器的角度看，它只知道这是一个基类对象。这使得某些操作变得异常困难，尤其是多态复制。若要复制一个基类指针指向的对象，必须依赖于额外的样板代码，如 clone() 虚函数模式，因为无法直接调用派生类的拷贝构造函数。这种设计还会在本不相关的类型之间建立紧密的耦合关系，迫使它们遵从同一个基类接口。\n静态多态 (模板) 与运行时多态相对的是静态多态，主要通过C++[[模板]]（[[Templates]]）实现。模板在编译期为每个使用的具体类型生成特化代码，从而保留了完整的类型信息。这使得编译器能够执行深度优化，如函数[[内联]]，从而获得极高的性能。\n然而，模板的强大能力也伴随着一个核心限制：无法创建 [[异质容器]]（heterogeneous collections）。例如，std::vector\u0026lt;MyClass\u0026lt;int\u0026gt;\u0026gt; 和 std::vector\u0026lt;MyClass\u0026lt;double\u0026gt;\u0026gt; 是两种完全不同且不相关的类型，它们不能被存储在同一个容器中。为了处理不同类型，编译器会对模板进行“单态化”（monomorphization），为每个类型参数生成一份独立的代码实例，这可能导致最终二进制文件体积膨胀，即所谓的“代码膨胀”（code bloat）。\n1.2 在现代C++语境下定义类型擦除 “类型擦除”这一术语本身在C++社区中存在一定的模糊性，它并非一个单一、被严格定义的语言特性，而是一系列技术和模式的统称 1。广义上，\nvoid * 和继承都可以被视为某种形式的类型擦除。然而，在现代C++的讨论中，尤其是在[[Sean Parent]]和[[Klaus Iglberger]]等专家的影响下，该术语通常指代一种更具体、更强大的设计模式，这也是本报告的核心焦点。\n核心原则：现代C++类型擦除是一种旨在 将接口与其实现解耦 的技术，它为 不相关的类型 提供了 非侵入式 的 运行时多态，同时保持了 值语义（value semantics）。\n其关键特征如下：\n非侵入性 (Non-Intrusive)：被“擦除”的类型无需继承自某个公共基类。它们只需要在语法和语义上满足一个特定的概念（Concept），即所谓的“鸭子类型”（duck typing）——如果它走起来像鸭子，叫起来也像鸭子，那么它就是一只鸭子 4。 值语义 (Value Semantics)：类型擦除的包装器对象（wrapper）表现得像一个普通的值类型。它可以被复制、移动，并直接存储在标准容器中（如 std::vector），这与传统面向对象多态所要求的指针语义形成鲜明对比 6。 类型安全 (Type-Safety)：与 void* 不同，该技术是类型安全的。所有操作在运行时都会被正确地分派到对应的实现上。当尝试以错误的类型访问底层对象时，系统会以安全的方式处理（通常是抛出异常），而不会导致未定义行为 1。 为了清晰地展现这些多态技术的权衡，下表进行了总结。\n表1：C++多态技术对比\n特性/指标 C风格 (void*) 面向对象 (继承) 静态多态 (模板) 类型擦除 (现代模式) 类型安全 否 是 是 是 侵入性 非侵入式 侵入式 非侵入式 非侵入式 运行时开销 低（指针解引用） 中（虚函数表查找） 无（编译期解析） 中（虚函数表查找或函数指针调用） 值语义 否 否（需要指针） 是 是 异质容器 是 是（通过基类指针） 否 是 实现复杂度 低 中 中 高 这张表清晰地揭示了各种方法的优劣。void * 虽灵活但危险；继承虽安全但具侵入性且牺牲了值语义；模板性能优异但无法用于异质容器。现代类型擦除技术正是在这个背景下应运而生，它巧妙地结合了各方优点，提供了一种在运行时处理异质对象集合的、兼具类型安全、非侵入性和值语义的强大解决方案。\n第二部分：经典实现：Concept-Model模式 本部分将深入剖析实现类型擦除最经典、最强大的“Concept-Model”（概念-模型）模式。此模式并非临时起意的技巧，而是对多个成熟设计模式的精妙组合，从而赋予其坚实的软件工程基础。\n2.1 解构体系架构：设计模式的组合 著名C++专家[[Klaus Iglberger]]指出，“Concept-Model”模式的优雅之处在于它并非孤立存在，而是 桥接模式（Bridge）、原型模式（Prototype） 与 外部多态（External Polymorphism） 思想的有机结合。从这个视角出发，我们能更深刻地理解该技术为何如此健壮和灵活。\n句柄 (Handle)：桥接模式的抽象部分 句柄是面向客户的、公开的、非模板的类（例如，我们即将实现的 Drawable 类）。它是用户与之交互的唯一接口。\n在桥接模式中的角色：句柄扮演了桥接模式中的“抽象部分”（Abstraction）。它将客户端代码与多态的实现细节完全解耦。由于句柄类本身不是模板，其大小在编译期是固定且已知的，这使得它可以像普通值一样被复制、移动和存储，从而实现了值语义。句柄内部通常持有一个指向“概念”（Concept）接口的智能指针（如 std::unique_ptr）6。 概念 (Concept)：桥接模式的实现者接口 概念是一个内部的、私有的抽象基类（例如，DrawableConcept）。它通过纯虚函数定义了一套所有具体类型都必须满足的操作契约。\n角色：它定义了被擦除类型必须满足的“概念”。在桥接模式中，它对应“实现者接口”（Implementor）。句柄将所有操作委托给这个接口，实现了接口与实现的分离 5。 模型 (Model)：具体的实现者与适配器 模型是一个内部的、私有的模板类（例如，DrawableModel\u0026lt;T\u0026gt;），它继承自“概念”接口。\n角色：它为具体的类型 T “建模”，使其符合“概念”接口。模型内部持有一个类型为 T 的对象实例，并实现“概念”接口中声明的纯虚函数。其实现方式是将调用 转发（forward） 给内部持有的 T 对象。从这个角度看，模型也扮演了 适配器模式（Adapter） 的角色，它适配了具体类型 T 的接口以满足 Concept 接口的要求。 clone() 方法：原型模式的应用 为了实现真正的多态复制（即支持值语义的核心），必须解决传统多态中无法直接复制派生类对象的问题。\n角色：解决方案是在“概念”接口中增加一个纯虚的 clone() 方法。DrawableModel\u0026lt;T\u0026gt; 则通过调用自身的拷贝构造函数来实现这个方法，返回一个新创建的、指向 DrawableModel\u0026lt;T\u0026gt; 实例的智能指针（例如，return std::make_unique\u0026lt;Model\u0026lt;T\u0026gt;\u0026gt;(*this);）。这种“通过复制自身来创建新对象”的机制，正是 原型模式（Prototype） 的经典应用。它优雅地解决了在基类层面进行多态对象深拷贝的难题 5。 2.2 一个完整的可编译示例：Drawable 对象 下面我们将综合上述理论，提供一个完整的、经过详尽注释的C++20代码示例。该示例综合了研究资料中的优秀实践。\n#include \u0026lt;iostream\u0026gt; #include \u0026lt;vector\u0026gt; #include \u0026lt;memory\u0026gt; #include \u0026lt;string\u0026gt; #include \u0026lt;ostream\u0026gt; // --- 1. 待擦除的具体类型 --- // 这些是我们将要通过类型擦除技术统一处理的类。 // 它们之间没有任何继承关系，唯一的共同点是都提供了一个 `draw(std::ostream\u0026amp;)` 方法。 class Circle { public: explicit Circle(double radius) : m_radius(radius) {} void draw(std::ostream\u0026amp; out) const { out \u0026lt;\u0026lt; \u0026#34;Drawing a Circle with radius \u0026#34; \u0026lt;\u0026lt; m_radius \u0026lt;\u0026lt; \u0026#39;\\n\u0026#39;; } private: double m_radius; }; class Square { public: explicit Square(double side) : m_side(side) {} void draw(std::ostream\u0026amp; out) const { out \u0026lt;\u0026lt; \u0026#34;Drawing a Square with side \u0026#34; \u0026lt;\u0026lt; m_side \u0026lt;\u0026lt; \u0026#39;\\n\u0026#39;; } private: double m_side; }; class Triangle { public: explicit Triangle(double base, double height) : m_base(base), m_height(height) {} void draw(std::ostream\u0026amp; out) const { out \u0026lt;\u0026lt; \u0026#34;Drawing a Triangle with base \u0026#34; \u0026lt;\u0026lt; m_base \u0026lt;\u0026lt; \u0026#34; and height \u0026#34; \u0026lt;\u0026lt; m_height \u0026lt;\u0026lt; \u0026#39;\\n\u0026#39;; } private: double m_base; double m_height; }; // --- 2. 类型擦除包装器 (Handle) --- // `Drawable` 是公开的句柄类，用户通过它与不同形状进行交互。 // 它本身不是模板，因此可以存储在标准容器中。 class Drawable { public: // 模板构造函数，接受任何类型 T 的对象。 // 这是类型擦除的入口点。 template \u0026lt;typename T\u0026gt; Drawable(T shape) // 通过 make_unique 创建一个 Model\u0026lt;T\u0026gt; 的实例，并将其存储在 pimpl 中。 // pimpl 的类型是 Concept*，从而“擦除”了 T 的具体类型。 : pimpl(std::make_unique\u0026lt;Model\u0026lt;T\u0026gt;\u0026gt;(std::move(shape))) {} // 拷贝构造函数，实现多态复制。 Drawable(const Drawable\u0026amp; other) : pimpl(other.pimpl-\u0026gt;clone()) {} // 拷贝赋值运算符。 Drawable\u0026amp; operator=(const Drawable\u0026amp; other) { // 使用 copy-and-swap 惯用法保证强异常安全。 pimpl = other.pimpl-\u0026gt;clone(); return *this; } // 移动构造函数。 Drawable(Drawable\u0026amp;\u0026amp; other) noexcept = default; // 移动赋值运算符。 Drawable\u0026amp; operator=(Drawable\u0026amp;\u0026amp; other) noexcept = default; // 析构函数（默认实现即可，因为 unique_ptr 会自动管理内存）。 ~Drawable() = default; // 公开的 draw 方法，将调用委托给内部实现。 void draw(std::ostream\u0026amp; out) const { pimpl-\u0026gt;draw(out); } private: // --- 内部实现：Concept 和 Model --- // 2a. Concept (概念): 定义了所有可绘制对象必须遵守的内部接口。 struct Concept { virtual ~Concept() = default; virtual void draw(std::ostream\u0026amp; out) const = 0; // 原型模式：定义一个纯虚的 clone 方法用于多态复制。 virtual std::unique_ptr\u0026lt;Concept\u0026gt; clone() const = 0; }; // 2b. Model (模型): 模板类，用于将任意类型 T 适配到 Concept 接口。 template \u0026lt;typename T\u0026gt; struct Model final : Concept { // 构造函数，持有具体类型 T 的一个实例。 explicit Model(T shape) : m_shape(std::move(shape)) {} // 实现 Concept 的 draw 接口，将调用转发给持有的 T 对象。 void draw(std::ostream\u0026amp; out) const override { m_shape.draw(out); } // 实现多态复制，通过拷贝自身来创建一个新的 Model\u0026lt;T\u0026gt;。 std::unique_ptr\u0026lt;Concept\u0026gt; clone() const override { return std::make_unique\u0026lt;Model\u0026lt;T\u0026gt;\u0026gt;(*this); } T m_shape; // 持有的具体形状对象。 }; // 桥接模式的核心：句柄持有一个指向实现接口的指针。 // 这就是所谓的 \u0026#34;Pointer to Implementation\u0026#34; (PIMPL)。 std::unique_ptr\u0026lt;Concept\u0026gt; pimpl; }; // --- 3. 客户端代码 --- // 一个函数，接受一个包含不同 Drawable 对象的 vector，并依次绘制它们。 void draw_all_shapes(const std::vector\u0026lt;Drawable\u0026gt;\u0026amp; shapes) { std::cout \u0026lt;\u0026lt; \u0026#34;--- Drawing all shapes ---\\n\u0026#34;; for (const auto\u0026amp; shape : shapes) { shape.draw(std::cout); } std::cout \u0026lt;\u0026lt; \u0026#34;--------------------------\\n\\n\u0026#34;; } int main() { // 创建一个异质容器，它可以存储任何满足 \u0026#34;Drawable\u0026#34; 概念的对象。 std::vector\u0026lt;Drawable\u0026gt; document; // 添加不同类型的对象。注意，我们直接传递具体类型对象， // Drawable 的模板构造函数会自动处理类型擦除。 document.emplace_back(Circle(2.0)); document.emplace_back(Square(3.5)); document.emplace_back(Triangle(4.0, 5.0)); // 第一次绘制所有形状。 draw_all_shapes(document); // 演示值语义：可以对容器中的对象进行复制。 std::vector\u0026lt;Drawable\u0026gt; copied_document = document; // 修改原始 document 中的一个元素。 document = Square(1.0); std::cout \u0026lt;\u0026lt; \u0026#34;--- After modifying original document ---\\n\u0026#34;; draw_all_shapes(document); std::cout \u0026lt;\u0026lt; \u0026#34;--- Drawing copied document (should be unchanged) ---\\n\u0026#34;; draw_all_shapes(copied_document); return 0; } 2.3 深入底层：追踪擦除机制 为了完全理解类型擦除的工作原理，我们来追踪上述示例中的关键操作。\n构造过程: Drawable d = Circle(5.0); 一个 Circle 类型的临时对象被创建。 Drawable 的模板构造函数 template \u0026lt;typename T\u0026gt; Drawable(T shape) 被调用，其中 T 被推导为 Circle。 在构造函数体内，std::make_unique\u0026lt;Model\u0026lt;Circle\u0026gt;\u0026gt;(std::move(shape)) 执行。这会在堆上分配内存，并构造一个 Model\u0026lt;Circle\u0026gt; 对象。Circle 临时对象被移动到 Model\u0026lt;Circle\u0026gt; 的成员 m_shape 中。 std::make_unique 返回一个 std::unique_ptr\u0026lt;Model\u0026lt;Circle\u0026gt;\u0026gt;。 由于 Model\u0026lt;Circle\u0026gt; 继承自 Concept，这个 std::unique_ptr\u0026lt;Model\u0026lt;Circle\u0026gt;\u0026gt; 被隐式向上转型为 std::unique_ptr\u0026lt;Concept\u0026gt;，并被用来初始化 Drawable 对象的成员 pimpl。至此，Circle 的类型信息在 Drawable 的公开接口层面被“擦除”，只剩下 Concept 接口。 多态调用: d.draw(std::cout); 客户端代码调用 Drawable 对象的 draw 方法。 Drawable::draw 将调用转发给其 pimpl 成员：pimpl-\u0026gt;draw(out);。 pimpl 是一个 std::unique_ptr\u0026lt;Concept\u0026gt;，因此 pimpl-\u0026gt;draw(out) 是一个通过基类指针进行的虚函数调用。 C++运行时系统查找与 pimpl 指向的实际对象（即 Model\u0026lt;Circle\u0026gt; 对象）相关联的虚函数表（vtable）。 通过vtable，调用被分派到 Model\u0026lt;Circle\u0026gt;::draw 的正确实现。 Model\u0026lt;Circle\u0026gt;::draw 方法将其调用再次转发给它所持有的 m_shape 成员（一个 Circle 对象），最终执行 m_shape.draw(out)。 多态复制: Drawable d2 = d; Drawable 的拷贝构造函数 Drawable(const Drawable\u0026amp; other) 被调用，其中 other 是 d。 构造函数体执行 pimpl(other.pimpl-\u0026gt;clone())。 other.pimpl-\u0026gt;clone() 是一个虚函数调用。由于 other.pimpl 指向一个 Model\u0026lt;Circle\u0026gt; 对象，实际被调用的是 Model\u0026lt;Circle\u0026gt;::clone()。 Model\u0026lt;Circle\u0026gt;::clone() 执行 return std::make_unique\u0026lt;Model\u0026lt;T\u0026gt;\u0026gt;(*this);，其中 T 是 Circle。这会调用 Model\u0026lt;Circle\u0026gt; 的拷贝构造函数，在堆上创建一个 d.pimpl 所指向对象的完整深拷贝。 这个新创建的 std::unique_ptr\u0026lt;Model\u0026lt;Circle\u0026gt;\u0026gt; 向上转型为 std::unique_ptr\u0026lt;Concept\u0026gt;，并用于初始化 d2 的 pimpl 成员。最终，d2 成为 d 的一个完全独立的深拷贝。 第三部分：高级实现与优化策略 虽然 Concept-Model 模式功能强大，但其基础实现存在性能开销，主要源于强制的堆分配。本部分将探讨几种高级优化技术，旨在降低这些开销，提升类型擦除对象的性能。\n3.1 小缓冲区优化 (Small Buffer Optimization - SBO) 原理：SBO是针对类型擦除最重要和最常见的性能优化。其核心思想是，对于尺寸较小的对象，避免在堆上动态分配内存，而是直接将其存储在句柄对象内部预先分配的一块缓冲区中 6。只有当对象尺寸超过缓冲区大小时，才回退到传统的堆分配策略。\n实现：\n缓冲区定义：在句柄类（如 Drawable）内部，使用 std::aligned_storage（C++11/14）或 std::byte（C++17及以后）定义一块具有特定大小和对齐要求的原始内存缓冲区。 // 在 Drawable 类中 private: static constexpr size_t SBO_SIZE = 32; // 缓冲区大小 static constexpr size_t SBO_ALIGN = alignof(void*); // 对齐要求 std::aligned_storage_t\u0026lt;SBO_SIZE, SBO_ALIGN\u0026gt; m_buffer; 构造时的决策：在模板构造函数中，使用 static_assert 或 if constexpr（C++17）在编译期检查被包装的 Model\u0026lt;T\u0026gt; 对象的大小和对齐是否满足SBO条件。 template \u0026lt;typename T\u0026gt; Drawable(T shape) { using Model_t = Model\u0026lt;T\u0026gt;; if constexpr (sizeof(Model_t) \u0026lt;= SBO_SIZE \u0026amp;\u0026amp; alignof(Model_t) \u0026lt;= SBO_ALIGN) { // SBO路径：使用 placement new 在缓冲区内构造 new (\u0026amp;m_buffer) Model_t(std::move(shape)); // 还需要存储一个函数指针来调用正确的析构函数 m_destructor =(void* self) { std::destroy_at(static_cast\u0026lt;Model_t*\u0026gt;(self)); }; } else { // 堆分配路径：回退到使用智能指针 pimpl = std::make_unique\u0026lt;Model_t\u0026gt;(std::move(shape)); } } 生命周期管理：当使用SBO时，句柄对象必须负责手动管理缓冲区内对象的生命周期。这意味着在句柄的析构函数或赋值运算符中，必须显式调用存储在缓冲区中对象的析构函数 21。这通常通过存储一个析构函数指针来实现。 指针别名与 std::launder：当一个对象被销毁后，其占用的存储空间被重新用于创建新对象时，可能会违反C++的严格别名规则（strict aliasing rules）。std::launder（C++17）可以作为一种解决方案，它告知编译器这块内存的生命周期已经重新开始，从而防止编译器进行可能导致错误的激进优化。 权衡分析：SBO的优势是显著的。对于大量的小对象，它能消除堆分配的开销，减少内存碎片，并因数据局部性改善而提升缓存性能。其代价是，句柄对象 sizeof(Drawable) 的体积会增大，即使对于那些因尺寸过大而必须存储在堆上的对象，这个缓冲区依然存在，造成了一定的空间浪费。因此，SBO缓冲区的尺寸选择是一个关键的设计决策，需要根据应用的典型使用场景来权衡。\n3.2 通过函数指针进行手动虚分派 原理：作为使用C++原生虚函数表（vtable）的替代方案，句柄可以直接存储一个指向函数指针表的指针，这个表手动模拟了vtable的功能。每个函数指针对应“概念”中的一个操作 6。\n实现：\n操作表：定义一个结构体，包含所有操作的函数指针。 struct OperationsVTable { void (*draw)(const void*, std::ostream\u0026amp;); void (*destroy)(void*); std::unique_ptr\u0026lt;Concept\u0026gt; (*clone)(const void*); }; 句柄存储：句柄对象存储一个 void* 数据指针，指向具体对象，以及一个指向静态 OperationsVTable 实例的指针。 静态分派函数：为每种具体类型 T 和每个操作定义一个静态的、模板化的分派函数。 template \u0026lt;typename T\u0026gt; static void draw_impl(const void* self, std::ostream\u0026amp; out) { static_cast\u0026lt;const T*\u0026gt;(self)-\u0026gt;draw(out); } 构造：模板构造函数负责初始化 void * 数据指针，并设置vtable指针指向一个为该类型 T 特化的静态 OperationsVTable 实例。 分析：这种方法将数据（void *）与行为（OperationsVTable *）解耦。它的主要代价是句柄的大小会随着操作数量的增加而线性增长 22。对于只有一个或少数几个操作的接口，这种方法的开销可能比完整的vtable机制更小，因为它避免了vtable指针的额外间接层。\nstd::function 的实现正是这种模式的绝佳范例。\n3.3 基于策略的设计以实现最大灵活性 原理：与其在句柄类中硬编码存储策略（总是堆分配或总是SBO），不如将存储策略本身作为句柄类的一个模板参数，即策略（Policy）。这是一种强大的元编程技术，被称为基于策略的设计（Policy-Based Design）23。\n实现：\n定义策略类：创建不同的存储策略模板，每个策略类都定义了如何分配、销毁和访问被包装的对象。 struct DynamicStoragePolicy { /*... */ }; template \u0026lt;size_t Size, size_t Align\u0026gt; struct SBOStoragePolicy { /*... */ }; 参数化句柄：让句柄类接受一个存储策略作为其模板参数。 template \u0026lt;typename StoragePolicy\u0026gt; class Shape { private: StoragePolicy storage; public: template \u0026lt;typename T\u0026gt; Shape(T concrete_shape) : storage(std::move(concrete_shape)) {} void draw(std::ostream\u0026amp; out) const { storage.get()-\u0026gt;draw(out); } //... }; 使用：用户可以根据具体需求在编译时选择最合适的策略。 // 使用动态分配 using DynamicShape = Shape\u0026lt;DynamicStoragePolicy\u0026gt;; // 使用32字节的SBO using SmallShape = Shape\u0026lt;SBOStoragePolicy\u0026lt;32, alignof(void*)\u0026gt;\u0026gt;; 优势：这种方法提供了极高的灵活性，允许用户为不同的应用场景量身定制类型擦除对象的行为，从而在性能和资源使用之间做出最优的权衡。\n第四部分：C++标准库中的类型擦除 C++标准库本身就提供了几个利用类型擦除技术构建的强大组件。分析它们的设计与实现，有助于我们深入理解类型擦除的实际应用和权衡。\n4.1 案例研究：std::function - 多态可调用对象 接口分析：自C++11起，std::function（定义于 \u0026lt;functional\u0026gt; 头文件）便成为标准库的一部分。根据标准（如 ISO/IEC 14882:2011 及后续版本），std::function 是一个通用的多态函数包装器。它可以存储、复制和调用任何满足 CopyConstructible 的可调用（Callable）目标，包括普通函数指针、成员函数指针、lambda表达式以及函数对象（functors)。\n底层机制：\nstd::function 是 手动虚分派 模式的典范。它内部并不依赖于一个带有虚函数的 Concept 基类。 取而代之的是，它通常存储一小组函数指针来管理被包装的可调用对象：一个用于 调用（invoke）的指针，一个用于 构造/复制（construct/copy）的指针，以及一个用于 销毁（destroy）的指针 。 被包装的可调用对象本身，则根据其大小采用不同策略存储。对于小的可调用对象，如裸函数指针或捕获少量变量的lambda，实现通常会采用 SBO，将其直接存放在 std::function 对象内部的缓冲区中，以避免堆分配 18。对于无法放入缓冲区的大型可调用对象，则会在堆上分配内存。C++标准鼓励但不强制要求SBO的实现（见[func.wrap.func.con]）。 标准引用：std::function 的规范在C++标准中有详细定义，例如在C++20工作草案N4861的章节 [func.wrap.func] 中。\n4.2 案例研究：std::any - 类型安全的 void * 接口分析：std::any（定义于 \u0026lt;any\u0026gt; 头文件）是C++17引入的另一个类型擦除工具。标准（如 ISO/IEC 14882:2017 及后续版本）将其描述为一个类型安全的、用于存储任意单个 CopyConstructible 类型值的容器。它提供了 any_cast 用于安全地取回被存储的值，以及 type() 方法来查询被存储对象的 std::type_info。\n底层机制：\nstd::any 的实现是 Concept-Model 模式的完美体现。 其内部实现依赖于一个类似vtable的机制（可以通过继承或手动管理的函数指针表实现），来管理所含对象的生命周期（复制、移动、销毁），而无需在编译时知道其具体类型 33。 any_cast\u0026lt;T\u0026gt;(any_obj) 的工作原理是，在运行时比较模板参数 T 的 typeid 与 any_obj 内部存储的 type_info。如果两者匹配，就安全地将内部存储转换为 T 类型；如果不匹配，则抛出 std::bad_any_cast 异常。 与 std::function 类似，std::any 的实现也被标准鼓励使用 [[SBO]]，以避免为小且易于移动的类型进行堆分配。 标准引用：std::any 的规范在C++标准中有详细定义，例如在C++20工作草案N4861的章节 [any.synop] 中。\n4.3 对比分析：std::any vs. std::variant 选择 std::any 还是 std::variant 是C++程序员在处理异质数据时面临的一个基本架构决策。这个选择本质上是在一个“开放”类型集合和一个“封闭”类型集合之间做决定，并对性能、安全性和API设计产生深远影响。\n一个精辟的类比是：“any 是一个穿了马甲的 void *，而 variant 是一个穿了马甲的 union”。这个比喻抓住了两者本质的区别。\nstd::variant\u0026lt;T1, T2,...\u0026gt;：代表一个 封闭的、编译时确定的 类型集合。一个 variant 对象在任何时刻只能持有其模板参数列表中某一个类型的值。 std::any：代表一个 开放的、运行时确定的 类型集合。一个 any 对象可以持有任何满足 CopyConstructible 条件的类型的值。 下表详细对比了这两者的关键差异 35。\n表2：std::any 与 std::variant 详细对比\n特性/指标 std::any std::variant\u0026lt;Types...\u0026gt; 类型集合 开放集：可存储任何（CopyConstructible）类型。 封闭集：只能存储在模板参数列表中预定义的类型。 内存分配 可能堆分配：对于大对象或不满足SBO条件的类型，会在堆上分配内存。 仅栈分配：对象直接存储在 variant 内部。其大小为所有备选类型中最大的那个，外加一个小的类型判别符。 值访问 运行时检查：通过 std::any_cast\u0026lt;T\u0026gt; 访问，若类型不匹配则在运行时抛出 std::bad_any_cast。 编译时安全：通过 std::visit 配合访问者模式，可保证在编译期处理所有备选类型，无运行时意外。std::get 访问若类型不匹配也会抛出异常。 性能 较慢：潜在的堆分配开销、类型识别（typeid 比较）和虚分派开销。 更快：无堆分配，类型判别通常是 O(1) 的索引检查。 错误处理 运行时抛出 std::bad_any_cast 异常。 std::get 访问时抛出 std::bad_variant_access；std::visit 可在编译期保证穷尽所有情况。 主要用例 通用框架和库：当无法预知用户将存储何种类型时，如属性映射、事件系统、脚本语言绑定等。 应用级逻辑：当类型集合有限且已知时，如状态机、消息处理（代数数据类型）、错误处理（std::variant\u0026lt;Result, Error\u0026gt;）等。 总结而言，当处理一个固定的、已知的类型集合时，std::variant 因其类型安全、高性能和无堆分配的特性而成为首选。而当需要真正的通用性，处理完全未知的类型时，std::any 提供了必要的灵活性，但需要接受其潜在的性能开销。\n第五部分：类型擦除的架构级应用 超越具体的实现技巧，类型擦除是一种强大的架构工具，能够构建出松耦合、可扩展且稳定的系统。本部分将探讨其在两个关键领域的架构级应用：稳定的ABI和插件系统。\n5.1 构建稳定的应用二进制接口 (ABI) C++的ABI问题：C++标准并未规定一个统一的应用二进制接口（Application Binary Interface, ABI）。这意味着由不同编译器、不同版本的编译器，甚至同一编译器使用不同编译选项编译出的二进制文件（如库和可执行文件）之间，往往不具备二进制兼容性。类的大小、布局、成员排列、虚函数表结构、名字修饰（name mangling）等细节都可能不同，任何微小的改变都可能破坏ABI 40。\nPIMPL惯用法作为解决方案：\nPIMPL（Pointer to Implementation，指向实现的指针）是C++中用于创建稳定ABI的主要技术 43。 其机制是将一个类的所有私有成员变量和私有成员函数都移到一个独立的、前向声明的实现类（Impl）中。公开的接口类只包含一个指向这个 Impl 类的指针（通常是 std::unique_ptr）。Impl 类的完整定义仅存在于 .cpp 实现文件中。 PIMPL之所以能提供稳定的ABI，是因为公开接口类的大小和布局是固定的——它只包含一个指针。只要公开的API不变，无论其内部实现（Impl类）如何修改（例如增删私有成员），都不会影响到公开接口类的二进制布局。因此，客户端代码只需重新链接，而无需重新编译，就能使用新版本的库 43。 PIMPL作为一种特殊的类型擦除：\nPIMPL的核心是隐藏实现细节，而类型擦除的核心是隐藏类型本身。这两者之间存在深刻的联系。当我们实现一个类型擦除的句柄（如第二部分的 Drawable）时，其内部持有的 std::unique_ptr\u0026lt;Concept\u0026gt; 成员实际上就是一个PIMPL指针。它指向的“实现”是一个多态的 Concept/Model 层次结构。\n这种联系揭示了一个重要的区别：\n标准PIMPL：隐藏的是 单个具体类型 的实现细节。 用于类型擦除的PIMPL：隐藏的是 一整族不相关的类型，将它们统一到一个多态接口之后。 因此，PIMPL是实现类型擦除的底层机制。当PIMPL指向的实现是多态的时，它就构成了类型擦除模式的核心。\n5.2 设计灵活的插件系统 架构目标：一个宿主应用程序（Host Application）需要在运行时加载并与插件（通常是动态链接库，DLLs/SOs）交互，而无需重新编译宿主程序。插件为某个特定功能（如图像编解码器、游戏实体、渲染后端等）提供具体实现。\n挑战：如何在宿主和插件之间定义一个稳定的接口？如果使用传统的继承模型，宿主和插件都必须依赖于同一个基类的头文件定义。这会造成“脆弱基类问题”（brittle base class problem）：一旦基类定义发生任何改变（即使只是增加一个私有成员），所有插件的ABI都会被破坏，导致兼容性灾难。此外，跨模块的C++名字修饰问题也增加了复杂性 45。\n类型擦除作为解决方案：\n类型擦除为设计健壮的插件系统提供了完美的解决方案。\n宿主定义接口：宿主程序定义一个类型擦除的句柄类（例如，ImageCodecHandle）及其支持的操作（如 encode, decode）。这个句柄类就是提供给插件的、稳定的、公开的接口。 插件提供实现：每个插件（在其自己的DLL中）实现一个具体的编解码器（如 PNGCodec, JPEGCodec）。这些具体类型 不需要 继承自宿主头文件中的任何基类。它们只需要提供 ImageCodecHandle 所需的同名方法即可。 C风格工厂函数：插件导出一个C风格的、无名字修饰问题的工厂函数（例如，extern \u0026ldquo;C\u0026rdquo; ImageCodecHandle* create_codec();）。这个函数在其内部创建插件自己的具体编解码器对象（如 PNGCodec），并用它构造一个 ImageCodecHandle，然后返回这个句柄的指针。 运行时交互： 宿主使用操作系统API（如 dlopen/LoadLibrary）加载插件DLL。 宿主使用 dlsym/GetProcAddress 查找并获取工厂函数的地址。 宿主调用工厂函数，获得一个功能完备、但类型已被擦除的 ImageCodecHandle 实例。 之后，宿主的所有操作都通过这个句柄进行，完全与插件的具体实现类型解耦 49。 这种架构彻底避免了脆弱基类问题和名字修饰问题，实现了宿主与插件之间真正意义上的二进制级别的解耦和长期稳定性。\n第六部分：结论与未来展望 6.1 关键原则与权衡总结 C++类型擦除技术是一项强大而精妙的设计模式，它成功地在静态多态和动态多态之间架起了一座桥梁。其核心价值在于实现了 非侵入式、类型安全、具有值语义的运行时多态。这使得程序员能够编写出高度解耦、灵活且可维护的代码，尤其是在处理异构对象集合、设计插件架构和维持稳定的ABI时，其优势尤为突出。\n然而，这种灵活性和解耦能力并非没有代价。类型擦除引入了额外的间接层（无论是通过虚函数表还是函数指针），这不可避免地带来了一定的运行时性能开销。幸运的是，通过诸如小缓冲区优化（SBO）等高级技术，可以在许多常见场景下有效地缓解这些开销。最终，是否采用类型擦除，以及采用何种实现方式，是一个需要在实现复杂度、性能、内存使用和设计灵活性之间进行审慎权衡的架构决策。\n6.2 C++中类型擦除的未来 C++语言本身也在不断演进，未来可能会为类型擦除提供更直接的语言级支持，从而减少当前手动实现所需的样板代码。\n语言级运行时多态：一些提案正在探索将类型擦除作为一种语言特性。这可能涉及引入新的语法，允许程序员更直接地定义一个运行时多态接口，并让编译器自动生成底层的Concept-Model结构。这种方式类似于Rust的 dyn Trait 或Swift的 any Protocol，它们通过“胖指针”（fat pointers，一个数据指针加一个vtable指针）在需要时才构建多态对象，从而避免了传统C++虚函数对对象布局的侵入性影响 51。 反射（Reflection）：如果C++在未来的标准中引入了全面的编译时反射能力，那么类型擦除的实现将得到极大的简化。通过反射，可以自动地检查一个类型是否满足某个概念（即是否拥有所需的方法），并自动生成Model类中所有转发函数。这将彻底消除当前实现中最繁琐、最容易出错的样板代码部分，使得类型擦除的应用更加便捷和广泛。 随着C++的不断发展，我们可以期待类型擦除这一强大的设计模式将变得更加易于使用，并更深入地融入到C++程序员的日常工具箱中，成为构建下一代高性能、高灵活性软件系统的关键技术。\n参考文献 C++标准文档 ISO/IEC 14882:2011, Programming Language C++. (引入 std::function) ISO/IEC 14882:2017, Programming Language C++. (引入 std::any 和 std::variant) ISO/IEC 14882:2020, Programming Language C++. (工作草案 N4861 提供了对标准库组件实现的详细规范) 关键技术演讲与论文 Parent, S. (2017). Better Code: Runtime Polymorphism. 7 Iglberger, K. (2021). Breaking Dependencies: Type Erasure - A Design Analysis. CppCon. 7 Iglberger, K. (2022). Type Erasure - The Implementation Details. CppCon. 6 其他相关文章与库文档 Grimm, R. (2022). Type Erasure. Modernes C++. 1 Krzemieński, A. (2013). Type erasure — Part I. Andrzej\u0026rsquo;s C++ blog. 2 Reddy, S. (2021). C++ Type Erasure on the Stack. Radiant Software. 19 O\u0026rsquo;Dwyer, A. (2018). Mastering the C++17 STL. O\u0026rsquo;Reilly Media. 52 cppreference.com. Pointer to implementation. 43 Works cited Type Erasure – MC++ BLOG - Modernes C++, accessed June 23, 2025, https://www.modernescpp.com/index.php/type-erasure/ Type erasure — Part I | Andrzej\u0026rsquo;s C++ blog - WordPress.com, accessed June 23, 2025, https://akrzemi1.wordpress.com/2013/11/18/type-erasure-part-i/ C++ \u0026lsquo;Type Erasure\u0026rsquo; Explained - Dave Kilian\u0026rsquo;s Blog, accessed June 23, 2025, https://davekilian.com/cpp-type-erasure.html C++ Core Guidelines: Type Erasure : r/cpp - Reddit, accessed June 23, 2025, https://www.reddit.com/r/cpp/comments/9emvix/c_core_guidelines_type_erasure/ C++ type erasure - C++ Forum - CPlusPlus.com, accessed June 23, 2025, https://cplusplus.com/forum/articles/18756/ Type Erasure - The Implementation Details - CppCon 2022 Schedule, accessed June 23, 2025, https://cppcon.digital-medium.co.uk/wp-content/uploads/2022/09/Type-Erasure-The-Implementation-Details-Klaus-Iglberger-CppCon-2022.pdf yaozhenx/type-erasure: Implementation of Klaus Iglberger\u0026rsquo;s \u0026hellip; - GitHub, accessed June 23, 2025, https://github.com/yaozhenx/type-erasure Better polymorphic ducks - Mathieu Ropert, accessed June 23, 2025, https://mropert.github.io/2017/12/17/better_polymorphic_ducks/ std::any - cppreference.com - C++ Reference, accessed June 23, 2025, http://en.cppreference.com/w/cpp/utility/any.html Breaking Dependencies: Type Erasure - A Design Analysis - Klaus Iglberger - CppCon 2021, accessed June 23, 2025, https://www.youtube.com/watch?v=4eeESJQk-mw More C++ Idioms/Type Erasure - Wikibooks, open books for an open world, accessed June 23, 2025, https://en.wikibooks.org/wiki/More_C%2B%2B_Idioms/Type_Erasure How to use type erasure pattern to decouple polymorphic classes in C++?, accessed June 23, 2025, https://iamsorush.com/posts/cpp-type-erasure/ [C++] Use Type Erasure To Get Dynamic Polymorphic Behavior - Coding With Thomas, accessed June 23, 2025, https://www.codingwiththomas.com/blog/use-type-erasure-to-get-dynamic-polymorphic-behavior c++ type erasure - C++ Forum - CPlusPlus.com, accessed June 23, 2025, https://cplusplus.com/forum/beginner/238304/ c++ - Type erasure: Retrieving value - type check at compile time - Stack Overflow, accessed June 23, 2025, https://stackoverflow.com/questions/46041683/type-erasure-retrieving-value-type-check-at-compile-time C+ Type erasure - GitHub Gist, accessed June 23, 2025, https://gist.github.com/vladiant/3ad3ace6e010378213b127bca25b879d c++ - Templates and type erasure - Why does this program compile? - Stack Overflow, accessed June 23, 2025, https://stackoverflow.com/questions/73584172/templates-and-type-erasure-why-does-this-program-compile Experimenting with Small Buffer Optimization for C++ Lambdas \u0026hellip;, accessed June 23, 2025, https://hackernoon.com/experimenting-with-small-buffer-optimization-for-c-lambdas-d5b703fb47e4 C++ Type Erasure on the Stack - Part I, accessed June 23, 2025, https://radiantsoftware.hashnode.dev/c-type-erasure-part-i Aliasing for small buffer optimization with std::aligned_union and std - Stack Overflow, accessed June 23, 2025, https://stackoverflow.com/questions/38070348/aliasing-for-small-buffer-optimization-with-stdaligned-union-and-stdaligned Generic owning type erasure - Fekir\u0026rsquo;s Blog, accessed June 23, 2025, https://fekir.info/post/generic-owning-type-erasure/ C++ Type Erasure Demystified - Fedor G Pikus - C++Now 2024 - YouTube, accessed June 23, 2025, https://www.youtube.com/watch?v=p-qaf6OS_f4 C++ Type Erasure - The Implementation Details - Klaus Iglberger CppCon 2022 - YouTube, accessed June 23, 2025, https://www.youtube.com/watch?v=qn6OqefuH08 std::function - cppreference.com, accessed June 23, 2025, https://en.cppreference.com/w/cpp/utility/functional/function.html std::function implementation · GitHub, accessed June 23, 2025, https://gist.github.com/Junch/3ac1f1d99c8f88f7d2333062d1ebcb2a How is std::function implemented? - c++ - Stack Overflow, accessed June 23, 2025, https://stackoverflow.com/questions/18453145/how-is-stdfunction-implemented Experimenting with Small Buffer Optimization for C++ Lambdas - Buckaroo, accessed June 23, 2025, https://buckaroo.pm/blog/experimenting-with-smallbuffer-optimization Type erasure — Part II | Andrzej\u0026rsquo;s C++ blog, accessed June 23, 2025, https://akrzemi1.wordpress.com/2013/12/06/type-erasure-part-ii/ [func.wrap.func.con], accessed June 23, 2025, https://timsong-cpp.github.io/cppwp/n4861/func.wrap.func.con Draft C++ Standard: Contents, accessed June 23, 2025, https://timsong-cpp.github.io/cppwp/n4861/ std::any: How, when, and why - C++ Team Blog - Microsoft Developer Blogs, accessed June 23, 2025, https://devblogs.microsoft.com/cppblog/stdany-how-when-and-why/ Everything You Need to Know About std::any from C++17 - C++ Stories, accessed June 23, 2025, https://www.cppstories.com/2018/06/any/ kocienda/Any: Implementation and optimization of std - GitHub, accessed June 23, 2025, https://github.com/kocienda/Any How std::any Works - Fluent C++, accessed June 23, 2025, https://www.fluentcpp.com/2021/02/05/how-stdany-works/ C++ std::variant vs std::any - Stack Overflow, accessed June 23, 2025, https://stackoverflow.com/questions/56303939/c-stdvariant-vs-stdany The std::variant - C++ High Performance [Book] - O\u0026rsquo;Reilly Media, accessed June 23, 2025, https://www.oreilly.com/library/view/c-high-performance/9781787120952/bb3be0c7-90ef-4eff-9b3f-10373dc84b48.xhtml std::variant - Why not just any? – Yet Another Technical Blog, accessed June 23, 2025, http://www.mycpu.org/std-variant/ How does std::any compare to std::variant? - Meeting C++, accessed June 23, 2025, https://meetingcpp.com/blog/items/How-does-std-any-compare-to-std-variant-.html Performance of std::any - C++ High Performance [Book] - O\u0026rsquo;Reilly Media, accessed June 23, 2025, https://www.oreilly.com/library/view/c-high-performance/9781787120952/e24859e6-0730-4459-b6f3-cf02ddbc6a28.xhtml Define a Rust ABI · Issue #600 · rust-lang/rfcs - GitHub, accessed June 23, 2025, https://github.com/rust-lang/rfcs/issues/600 ABI Breaks: Not just about rebuilding : r/cpp - Reddit, accessed June 23, 2025, https://www.reddit.com/r/cpp/comments/fc2qqv/abi_breaks_not_just_about_rebuilding/ Please explain the C++ ABI - Stack Overflow, accessed June 23, 2025, https://stackoverflow.com/questions/67839008/please-explain-the-c-abi PImpl - cppreference.com, accessed June 23, 2025, https://en.cppreference.com/w/cpp/language/pimpl.html C++ Core Guidelines: Interfaces II – MC++ BLOG - Modernes C++, accessed June 23, 2025, https://www.modernescpp.com/index.php/c-core-guidelines-interfaces-ii/ c++ type erasure / type encapsulation? discover type - Stack Overflow, accessed June 23, 2025, https://stackoverflow.com/questions/9486622/c-type-erasure-type-encapsulation-discover-type Designing a plugin framework for an application with a plugin architecture : r/cpp - Reddit, accessed June 23, 2025, https://www.reddit.com/r/cpp/comments/6gbv6c/designing_a_plugin_framework_for_an_application/ Implementing A Plugin System in C or C++ [closed] - Stack Overflow, accessed June 23, 2025, https://stackoverflow.com/questions/708527/implementing-a-plugin-system-in-c-or-c Making a Plugin System - C++ Articles - CPlusPlus.com, accessed June 23, 2025, https://cplusplus.com/articles/48TbqMoL/ Type Erasure in C++: The Magic of Flexibility - HeyCoach | Blogs, accessed June 23, 2025, https://blog.heycoach.in/type-erasure-in-c/ static_vector Needs Type-Erasure - Volt Software, accessed June 23, 2025, https://volt-software.nl/posts/static-vector-needs-type-erasure/ Potential C++ extension for type erasure as a language feature : r/cpp - Reddit, accessed June 23, 2025, https://www.reddit.com/r/cpp/comments/yriwxr/potential_c_extension_for_type_erasure_as_a/ std::any versus polymorphic class types - Mastering the C++17 STL [Book] - O\u0026rsquo;Reilly Media, accessed June 23, 2025, https://www.oreilly.com/library/view/mastering-the-c17/9781787126824/7bce9721-6ba2-49e0-99e0-5f2c6ca2f989.xhtml ","date":"4 June, 2025","id":42,"permalink":"/posts/-%E7%8E%B0%E4%BB%A3c++%E4%B8%AD%E7%B1%BB%E5%9E%8B%E6%93%A6%E9%99%A4%E6%8A%80%E6%9C%AF%E7%9A%84%E5%85%A8%E9%9D%A2%E8%A7%A3%E6%9E%90%E5%8E%9F%E7%90%86%E6%A8%A1%E5%BC%8F%E4%B8%8E%E6%80%A7%E8%83%BD/","summary":"本部分旨在阐明[[类型擦除]]技术所解决的根本问题，将其定位为一种旨在克服传统C++[[多态]]技术局限性的高级[[解决方案]]。","tags":"cpp 类型擦除 #SBO","title":"📘 现代C++中类型擦除技术的全面解析：原理、模式与性能"},{"content":"告别混乱，玩转高效协作：GitHub 与 Git CLI 的“三角工作流”深度解析 在现代软件开发中，团队协作是常态。无论是参与热门的开源项目，还是在公司内部与同事并肩作战，高效的代码管理策略都是成功的基石。如果你曾对 Git 的分支操作感到困惑，或者觉得 GitHub 上的 Fork (派生) 和 Pull Request (PR) 让人望而却步，那么是时候深入了解并掌握一套强大的协作模式了——那就是 “三角工作流”（Triangular Workflow）。\n它不仅能让你的代码管理井然有序，还能大幅提升团队的协作效率。更棒的是，有了强大的 GitHub CLI (gh 命令) 作为你的得力助手，整个流程将变得前所未有的流畅和智能。\n理解“三角工作流”的核心概念：一场厨房里的协作革命 为了更好地理解“三角工作流”，我们不妨把它想象成一家星级餐馆的厨房运作模式。\n1. 主厨的食谱书：项目的“上游仓库”（Upstream Repository） 类比： 这本食谱书是餐馆的灵魂，记载了所有招牌菜的稳定、经过严格验证的配方。它是所有菜品的最终版本，不会被随意修改。 实际意义： 上游仓库就是项目的原始仓库，通常由项目维护者掌控。它的 main (或 master) 和 develop 分支包含了项目的核心代码，稳定且随时准备发布。你通常没有直接向其推送代码的权限，这是为了保证代码库的质量和稳定性。 2. 你自己的食谱本：你的“派生仓库”（Forked Repository） 类比： 作为一名新加入的厨师，你不能直接在主厨的食谱书上涂改。因此，你会抄写一本属于你自己的食谱本。这本食谱本是你个人的试验田，你可以随意在上面添加笔记、修改配方，甚至尝试全新的菜肴。 实际意义： 派生仓库是你在 GitHub 上从上游仓库复制的一个个人副本。这个副本完全属于你，你可以自由地向其推送（push）代码、创建分支，而不会影响到原始的上游仓库。这是你进行个人开发和试验的“安全沙箱”。 3. 你的新菜试验单：你的“特性分支”（Feature Branch / Topic Branch） 类比： 主厨让你开发一道新甜点。你不会直接在你自己的食谱本上修改，因为你可能需要尝试好几种配方和做法。你会拿出一张空白的试验单，专门用来记录和修改这个新甜点的配方。你可以在这张试验单上放心地试验，即使失败了，也不会弄乱你自己的食谱本。 实际意义： 特性分支是你在本地从 main 或 develop 分支创建的临时性、短生命周期分支。每当你需要开发一个新功能、修复一个 Bug 或进行任何独立的工作时，都应该创建一个新的特性分支。这能确保你的不同工作任务之间互相隔离，避免代码冲突和混乱。 4. 递交新菜建议：提交“拉取请求”（Pull Request - PR） 类比： 当你确信新甜点的配方完美无缺，并想让它成为餐馆的正式菜品时，你不会直接把它写到主厨的食谱书里。你会把你的试验单连同你的自信，一起递交给“主厨”，并说：“主厨，这是我研发的新甜点配方，请您审查！” 主厨和资深厨师会仔细审查你的配方。如果没问题，它就会被正式收录到主厨的食谱书中。 实际意义： Pull Request 是你在 GitHub 上发起的一个请求，请求项目维护者（主厨）将你派生仓库中特性分支的代码，合并到上游仓库的指定分支（通常是 develop 或 main）。这是一个代码审查和讨论的平台，确保只有高质量、符合规范的代码才能进入主项目。 “三角工作流”的实战演练：Git CLI 与 GitHub 联手 理解了核心概念，接下来我们通过 Git CLI 命令，一步步地实现这个强大的工作流：\n步骤 1: 在 GitHub 上“派生”（Fork）上游仓库 这是你拥有自己“食谱本”的第一步。\n目标： 获取一个你可以自由操作的项目副本。 操作： 访问原始项目的 GitHub 页面，点击右上角的 Fork 按钮。 结果： 你的 GitHub 账号下会出现一个与原项目同名的仓库，这就是你的派生仓库。 2. 克隆（Clone）你的派生仓库到本地 把你的“食谱本”下载到你的本地电脑。\n目标： 在你的本地电脑上创建派生仓库的工作副本。\n操作：\n打开你的 GitHub 派生仓库页面，复制其 URL (HTTPS 或 SSH)。\n在你的终端或命令行中执行：\nBash\ngit clone [你的派生仓库URL] # 示例：git clone https://github.com/your-username/project-repo.git 结果： 本地电脑上会有一个与你派生仓库内容完全一致的文件夹。\n3. 添加“上游”（Upstream）远程仓库 让你的本地 Git 知道“主厨的食谱书”在哪里。\n目标： 建立与原始项目仓库的连接，以便获取其最新更新。\n操作： 进入你刚刚克隆的本地项目文件夹，并添加上游远程：\nBash\ncd [项目文件夹名] git remote add upstream [原始项目GitHub仓库的URL] # 示例：git remote add upstream https://github.com/original-org/original-repo.git 结果： 你的本地 Git 配置中多了一个名为 upstream 的远程，它指向了原始项目。\n4. 同步最新代码并创建特性分支 确保你在最新代码的基础上开始你的“新菜试验”。\n目标： 确保你的新功能开发基于项目最新的代码状态，并保证工作隔离。\n操作：\n切换到你本地的主分支（通常是 main 或 master）：\nBash\ngit checkout main 从上游拉取最新代码到你的本地 main 分支：\nBash\ngit pull upstream main 从你本地的 main 分支创建一个新的特性分支：\nBash\ngit checkout -b feature/implement-user-profile # \u0026#39;feature/\u0026#39; 是一种常见的命名约定，表示这是一个功能分支 结果： 你现在位于一个全新的、干净的特性分支上，可以安全地开始你的新工作。\n5. 在特性分支上开发并提交更改 在你的“试验单”上记录每一步的开发过程。\n目标： 编写代码，并在每个逻辑单元完成后记录你的进度。 操作： 编写你的代码。 暂存更改：git add . (或 git add [具体文件名]) 提交更改：git commit -m \u0026quot;feat: Add basic user profile view\u0026quot; 结果： 你的代码更改被记录在当前特性分支的提交历史中。 6. 将特性分支推送到你的派生仓库 把你的“试验单”上传到你的 GitHub “食谱本”上。\n目标： 将你的本地工作同步到你在 GitHub 上的派生仓库，作为在线备份和 PR 的来源。\n操作：\nBash\ngit push origin feature/implement-user-profile # \u0026#39;origin\u0026#39; 默认就是指向你派生仓库的远程名称 结果： 你的 feature/implement-user-profile 分支及其所有提交现在已经上传到你的 GitHub 派生仓库。\nGitHub CLI 如何简化“递交新菜建议”（创建 PR）—— 你的专属“厨房助理”效率对比 在“三角工作流”中，当你辛辛苦苦完成了“新菜试验单”（特性分支）上的工作，并希望将它“递交给主厨”（创建 Pull Request - PR）时，这一步往往是许多开发者感到繁琐和困惑的环节。这里，我们将对比传统手动方式和拥有 GitHub CLI (gh 命令) 这位“厨房助理”的智能方式，看看效率的巨大差异。\n场景：你已完成“新菜试验单”并推送到你的“食谱本” 假设你已经从“主厨的食谱书”（上游仓库）派生（Fork）了你自己的“食谱本”（派生仓库），并且在本地的“试验单”（feature/new-dessert 特性分支）上完成了代码编写，并已将其推送到你的 GitHub 派生仓库。现在，你需要向“主厨的食谱书”（上游仓库）提交 Pull Request。\n1. 确定“来源”：你提交的是哪张“试验单”？ 方式 传统手动方式 使用 GitHub CLI 的智能方式 操作 浏览器中，你通常需要手动导航到你的派生仓库的该分支页面，或在 PR 创建页面手动选择源分支。 在命令行中，你只需确保你当前就在该特性分支上（例如 git checkout feature/new-dessert）。 “厨房助理” 你需要指明：“主厨，这是我这张 feature/new-dessert 的试验单！” “厨房助理”会自动识别：“好的，我知道你现在拿着 feature/new-dessert 这张试验单。” 智能体现 无智能，完全依赖你的手动选择。 上下文感知：gh 命令自动识别当前 Git 分支作为 PR 的来源。 2. 确定“去向”：这份建议要递交给哪本“主厨的食谱书”的哪个区域？ 方式 传统手动方式 使用 GitHub CLI 的智能方式 操作 浏览器中，你需要在 PR 创建页面手动选择：\u0026lt;br\u0026gt; - 目标仓库：选择“主厨的食谱书” (例如 original-org/original-repo)\u0026lt;br\u0026gt; - 目标分支：选择正确的合并目标 (例如 main 或 develop) 在命令行中，你只需输入 gh pr create。 “厨房助理” 你需要明确告诉：“主厨，这份试验单是要递交到您的‘主食谱书’的‘主菜区’（main 分支）！” “厨房助理”会自动判断：“我知道你的‘食谱本’是从这本‘主食谱书’派生来的，通常新菜建议是递交到‘主菜区’（main 或 develop 分支）。”它甚至会为你预选好。 智能体现 繁琐且易错：手动选择目标仓库和分支，如果项目有多个相似名称的分支，容易选错。 关系智能识别与自动推荐：gh 命令能理解本地 Git 配置中的远程关系（origin 和 upstream），并智能地推荐最合理的上游目标分支。这极大地减少了操作失误。 3. 填写“建议表单”并递交（创建 PR 页面） 方式 传统手动方式 使用 GitHub CLI 的智能方式 操作 打开浏览器，登录 GitHub，点击多个按钮，进入 PR 创建页面。然后，手动填写 PR 标题和描述。最后点击“Create pull request”。 在命令行中，输入 gh pr create (或 gh pr create --web)。 “厨房助理” 你需要自己跑腿，拿着手写的“建议表单”跑到主厨办公室，再逐项填写。 “厨房助理”会直接帮你打开表单，并预填好大部分信息。它知道你正在哪个项目工作，你的“试验单”是哪个，以及要递交给哪本“主食谱书”的哪个区域。你只需在弹出的浏览器页面上（或命令行提示符下）填写标题和描述即可。 智能体现 效率低下：需要在命令行和浏览器之间切换，重复性点击和填写。 流程集成与自动化：gh 命令将一系列跨工具的操作整合，实现了一键式创建 PR。特别是 --web 参数，直接在浏览器中为你预填好关键信息，让整个流程变得无比流畅。 “三角工作流”的巨大优势 掌握了这种工作流，你将体验到前所未有的协作效率和代码管理清晰度：\n代码隔离与稳定性保障： 你的个人开发完全在独立分支和派生仓库中进行，不会直接影响上游的稳定代码。这极大地降低了引入 Bug 的风险。 并行开发与高效协作： 团队成员可以同时在各自的特性分支上工作，互不干扰。通过 Pull Request 机制，团队能够有效地进行代码审查、讨论和集成。 清晰的代码历史与可追溯性： 每个功能或修复都有其独立的特性分支和 Pull Request，使得项目历史记录清晰、易于理解和回溯。 友好的开源贡献模式： 对于开源项目而言，“派生-克隆-PR”的模式是主流贡献方式，它提供了一个安全、规范的通道，鼓励更多开发者参与贡献。 GitHub CLI 带来的极致体验： gh 命令将一系列复杂的 Git 和 GitHub 操作，简化为直观的命令行指令，让开发者能够更专注于代码本身，而非繁琐的流程。 结语 “三角工作流”并非仅仅是一种技术流程，它更是一种成熟、高效的协作哲学。通过清晰的角色划分和流程规范，它使得复杂的多人协作变得井然有序。而 GitHub CLI 的出现，更是为这种工作流插上了翅膀，让你的每一次贡献都更加流畅、更加智能。\n现在，你已经全面掌握了“三角工作流”的精髓。是时候拿起你的 Git CLI，加入到全球开发者的行列中，用你的代码，让世界变得更美好！\n参考 How the GitHub CLI can now enable triangular workflows Git 2.5 增加了工作树、改进了三角工作流、性能等诸多方面 GitHub CLI 增强了对三角工作流的支持 ","date":"4 June, 2025","id":43,"permalink":"/posts/%E5%91%8A%E5%88%AB%E6%B7%B7%E4%B9%B1%E7%8E%A9%E8%BD%AC%E9%AB%98%E6%95%88%E5%8D%8F%E4%BD%9Cgithub-%E4%B8%8E-git-cli-%E7%9A%84%E4%B8%89%E8%A7%92%E5%B7%A5%E4%BD%9C%E6%B5%81%E6%B7%B1%E5%BA%A6%E8%A7%A3%E6%9E%90/","summary":"在现代软件开发中，团队协作是常态。无论是参与热门的开源项目，还是在公司内部与同事并肩作战，高效的代码管理策略都是成功的基石。如果你曾对 Git 的分支操作感到困惑，或者觉得 GitHub 上的 Fork (派生) 和 Pull Request (PR) 让人望而却步，那么是时候深入了解并掌握一套强大的协作模式了——那就是 “三角工作流”（Triangular Workflow）。","tags":"git github workflow","title":"🔊告别混乱，玩转高效协作：GitHub 与 Git CLI 的“三角工作流”深度解析"},{"content":"常用编译指令 cmake -S . -B build cmake --build build -DCMAKE_BUILD_TYPE=Debug -DCMAKE_MAKE_PROGRAM=ninja -DCMAKE_BUILD_TYPE=Debug -G Ninja -S . -B build --build 参考资料 Lastest Release Cmake Reference Documentation https://cmake.org/documentation/ Modern CMake 简体中文版 cmake 实践 [CMake-Summary-of-documentation-chinese-@fenneishi](https://github.com/fenneishi/CMake-Summary-of-documentation-chinese-) ","date":"4 June, 2025","id":44,"permalink":"/posts/cmake/","summary":"","tags":"cmake","title":"cmake"},{"content":"CMake：include_directories 与 target_include_directories 使用指南 概述 在CMake中，include_directories()和target_include_directories()都用于指定头文件搜索路径，但它们在作用范围和使用方法上有显著区别。现代CMake项目建议优先使用target_include_directories()。\n命令详解 1. include_directories() (全局作用域) ​作用范围​：影响当前目录及之后定义的所有目标\n​工作方式​：为所有目标添加公共包含路径\n​使用场景​：简单项目或旧版CMake兼容\n​语法​：\ninclude_directories([AFTER|BEFORE] [SYSTEM] dir1 [dir2 ...]) 使用示例： include_directories(include third_party/lib) add_executable(app1 src/app1.cpp) add_executable(app2 src/app2.cpp) # app1和app2都会自动包含include/和third_party/lib/路径 2. target_include_directories() (目标特定作用域) ​作用范围​：仅影响指定目标\n​工作方式​：为目标添加私有或公开包含路径\n​使用场景​：现代CMake项目推荐方式（CMake 3.0+）\n​语法​：\ntarget_include_directories(\u0026lt;target\u0026gt; [SYSTEM] [BEFORE] \u0026lt;INTERFACE|PUBLIC|PRIVATE\u0026gt; [item1...] [\u0026lt;INTERFACE|PUBLIC|PRIVATE\u0026gt; [item2...] ...]) 关键字说明： 关键字 描述 PRIVATE 仅当前目标使用（不向依赖者传递） INTERFACE 仅依赖此目标的其他目标使用（当前目标不使用） PUBLIC 当前目标和依赖者都使用（= PRIVATE + INTERFACE） 使用示例： # 共享库定义 add_library(math_lib STATIC src/math.cpp) target_include_directories(math_lib PRIVATE src # 仅编译库时使用 INTERFACE include # 库使用者的包含路径 ) # 可执行文件定义 add_executable(calculator src/main.cpp) target_include_directories(calculator PRIVATE app_include # 仅本目标使用的路径 ) target_link_libraries(calculator PRIVATE math_lib) # calculator将自动获得math_lib的include/路径 核心区别对比 ​特性​ include_directories() target_include_directories() ​作用范围​ 全局（所有目标） 目标特定 ​依赖传播​ ❌ 不支持 ✅ 通过PUBLIC/INTERFACE支持 ​现代CMake推荐度​ ❌ 不推荐 ✅ 强烈推荐 ​代码隔离性​ ❌ 差（路径污染风险） ✅ 优秀（路径隔离） ​典型用法时机​ 在目标定义前调用 在目标定义后调用 ​使用依赖关系​ 无关联 与target_link_libraries()协同使用 最佳实践指南 ​优先使用目标特定作用域​\n# 推荐 ✔ add_library(my_lib ...) target_include_directories(my_lib ...) # 避免 ✖ include_directories(...) add_library(my_lib ...) ​正确使用可见性关键字​\nPRIVATE：仅内部实现需要的头文件 INTERFACE：库的公共API头文件 PUBLIC：实现需要且使用者也需要访问的头文件 ​**结合使用target_link_libraries()**​\n# 消费者自动获得依赖项的公开头文件路径 target_link_libraries(consumer PRIVATE provider) ​处理系统头文件​\ntarget_include_directories(my_target SYSTEM PRIVATE /usr/local/custom_include) ​路径处理注意事项​\n优先使用绝对路径或生成器表达式：\ntarget_include_directories(my_lib PRIVATE \u0026#34;$\u0026lt;BUILD_INTERFACE:${CMAKE_CURRENT_SOURCE_DIR}/include\u0026gt;\u0026#34; \u0026#34;$\u0026lt;INSTALL_INTERFACE:include\u0026gt;\u0026#34; ) 迁移策略（旧项目升级） 逐步替换全局包含\n# 旧方式 include_directories(common_include) # 新方式：为每个目标单独添加 target_include_directories(target1 PRIVATE common_include) target_include_directories(target2 PRIVATE common_include) 处理子目录包含\n# 旧方式 add_subdirectory(lib) include_directories(${lib_include_dir}) # 新方式：通过目标链接传播 target_link_libraries(my_app PRIVATE lib_target) 使用接口目标统一管理\nadd_library(global_includes INTERFACE) target_include_directories(global_includes INTERFACE common_include third_party/include ) target_link_libraries(my_app PRIVATE global_includes) 总结建议 ​场景​ ​推荐方法​ 现代新项目 全部使用target_include_directories() 旧项目维护 逐步替换为目标特定方式 跨目标共享路径 创建INTERFACE库统一管理 第三方库包含 配合find_package()使用导入目标 目录范围简单包含（小型项目） 审慎使用include_directories() ​黄金法则​：在定义目标(add_executable/add_library)之后，总是优先使用target_include_directories()进行包含路径的设置，并通过适当的可见性关键字确保路径的正确传播。\n","date":"3 June, 2025","id":45,"permalink":"/posts/cmakeinclude_directories-%E4%B8%8E-target_include_directories-%E4%BD%BF%E7%94%A8%E6%8C%87%E5%8D%97/","summary":"在CMake中，include_directories()和target_include_directories()都用于指定头文件搜索路径，但它们在作用范围和使用方法上有显著区别。现代CMake项目建议优先使用target_include_directories()。","tags":"cmake","title":"CMake：include_directories 与 target_include_directories 使用指南"},{"content":"摘要\n条件编译（Conditional Compilation）是 CMake 构建系统实现跨平台、多配置、多功能模块化构建的重要机制。本文以学术论文的严谨风格，系统剖析 CMake 条件编译的原理，结合实际工程案例探讨其在大型项目中的应用，并深入分析变量作用域对条件逻辑的影响。文中还专门介绍 option(USE_FOO \u0026quot;Enable FOO support\u0026quot; OFF) 语句的行为及其在条件判断中的应用与区别。通过对官方文档与经典社区资料的引用，力求为 CMake 工程师提供全面、可复用的指导与最佳实践。\n关键词 CMake；条件编译；if；生成器表达式；变量作用域；缓存变量；目录作用域；函数作用域；option()\n1. 引言 近年来，随着跨平台 C/C++ 项目规模的不断扩张，开发者需要针对操作系统、编译器版本、构建类型（如 Debug/Release）等多种维度，灵活地控制构建过程。CMake 作为一种流行的元构建（meta-build）工具，内置了强大的条件编译能力，使得同一套 CMake 脚本能够自动适配多种环境与需求。本文旨在系统阐述 CMake 条件编译的核心原理，包括 if() 语句与生成器表达式（Generator Expressions）的区别与协同；并结合工程实践介绍常见模式。此外，针对 CMake 的动态作用域模型，深入讨论目录作用域（Directory Scope）、函数作用域（Function Scope）与缓存作用域（Cache Scope）对条件逻辑的影响，帮助读者避免常见错误、提升脚本可维护性。最后，以 option(USE_FOO \u0026quot;Enable FOO support\u0026quot; OFF) 为例，演示变量在条件判断中的常见误区与正确用法。\n2. CMake 条件编译原理 2.1 if() 条件判断语法与行为 CMake 提供了 if()、elseif()、else()、endif() 等控制结构，用来根据条件选择性地执行脚本代码。其基本语法为：\nif(\u0026lt;condition\u0026gt;) \u0026lt;commands\u0026gt; elseif(\u0026lt;condition\u0026gt;) \u0026lt;commands\u0026gt; else() \u0026lt;commands\u0026gt; endif() 其中 \u0026lt;condition\u0026gt; 可为布尔常量、数值或字符串比较、变量存在性判断、逻辑组合等多种形式。根据官方文档，以下情形会被视为“假”（False）：0/\u0026quot;0\u0026quot;、OFF/\u0026quot;OFF\u0026quot;、NO/\u0026quot;NO\u0026quot;、FALSE/\u0026quot;FALSE\u0026quot;、NOTFOUND、空字符串，或未定义变量；而 1/\u0026quot;1\u0026quot;、ON/\u0026quot;ON\u0026quot;、YES/\u0026quot;YES\u0026quot;、TRUE/\u0026quot;TRUE\u0026quot;、Y、非零数字等被视为“真”（True）(cmake.org, cmake.org)。\n在条件中若直接写 \u0026lt;variable\u0026gt;，CMake 会判别该变量是否已定义，且其值不在上述“假”列表中，则结果为真；否则为假。需特别注意的是，CMake 的 if() 并不会为布尔判断单独创建作用域，位于 if()/endif() 之间用 set() 定义的变量，会绑定到当前目录作用域并影响后续逻辑，而不会在 endif() 时销毁，这与大多数编程语言（如 C/C++）不同(cmake.org, cmake.org)。\n此外，比较操作（如 EQUAL、LESS、GREATER）、字符串比较（如 STREQUAL、STRLESS）、版本比较（如 VERSION_LESS、VERSION_GREATER）等，在遇到 \u0026lt;variable|string\u0026gt; 形式时，会先判断是否为已定义变量，再取其值进行比较；不存在时即按字面值处理。而逻辑运算符 NOT、AND、OR 则按照优先级自上而下依次解析(cmake.org, cmake.org)。\n2.2 生成器表达式（Generator Expressions）及延迟求值 除了 if() 语法，CMake 还通过生成器表达式（Generator Expressions）实现针对目标属性（target properties）和编译选项的条件化配置。这种表达式形如 $\u0026lt;condition:result\u0026gt; 或 $\u0026lt;IF:condition,true_string,false_string\u0026gt;，在构建系统生成阶段（而非配置阶段）延迟求值，以便根据实际构建上下文（如生成器类型、多配置模式、平台、编译器版本等）输出不同结果。例如：\ntarget_compile_options(MyTarget PRIVATE $\u0026lt;$\u0026lt;CONFIG:Debug\u0026gt;:-O0\u0026gt; $\u0026lt;$\u0026lt;CONFIG:Release\u0026gt;:-O3\u0026gt; ) 当构建类型为 Debug 时，$\u0026lt;CONFIG:Debug\u0026gt; 求值为 1，输出 -O0；当为 Release 时，$\u0026lt;CONFIG:Release\u0026gt; 求值为 1，输出 -O3。若使用多配置生成器（如 Visual Studio、Ninja Multi-Config），则应依赖生成器表达式判断 CONFIG，而非直接判断 ${CMAKE_BUILD_TYPE}，因为后者在构建阶段可能不准确(cmake.org, cmake.org)。\n更复杂的嵌套示例：\n$\u0026lt;$\u0026lt;AND:$\u0026lt;CXX_COMPILER_ID:GNU\u0026gt;,$\u0026lt;VERSION_GREATER_EQUAL:$\u0026lt;CXX_COMPILER_VERSION\u0026gt;,9.0\u0026gt;\u0026gt;:-Wall\u0026gt; 该表达式仅在编译器为 GNU 且版本 ≥ 9.0 时产生 -Wall，否则输出空串。由内向外依次解析 $\u0026lt;CXX_COMPILER_ID:GNU\u0026gt; 判断编译器标识，$\u0026lt;CXX_COMPILER_VERSION\u0026gt; 判断版本号，最终通过 $\u0026lt;AND:…\u0026gt; 组合逻辑(cmake.org, github.com)。\n3. 工程实践：灵活运用条件编译 3.1 平台与编译器差异的编译选项设置 在跨平台项目中，对不同操作系统、编译器提供不同编译选项或链接库路径的需求极为常见。以下示例展示两种对比做法：\n使用 if()\nif(WIN32) set(PLATFORM_LIBS ws2_32) elseif(APPLE) set(PLATFORM_LIBS \u0026#34;-framework CoreFoundation\u0026#34;) else() set(PLATFORM_LIBS pthread) endif() add_executable(MyApp main.cpp) target_link_libraries(MyApp PRIVATE ${PLATFORM_LIBS}) 代码直观，对应平台关联系统库。条件判断在配置阶段即时生效(cmake.org, cmake.org)。\n使用生成器表达式\nadd_executable(MyApp main.cpp) target_link_libraries(MyApp PRIVATE $\u0026lt;$\u0026lt;PLATFORM_ID:Windows\u0026gt;:ws2_32\u0026gt; $\u0026lt;$\u0026lt;PLATFORM_ID:Darwin\u0026gt;:\u0026#34;-framework CoreFoundation\u0026#34;\u0026gt; $\u0026lt;$\u0026lt;PLATFORM_ID:Linux\u0026gt;:pthread\u0026gt; ) 生成器表达式将平台判断“推迟”到构建系统生成阶段，脚本更为简洁。无论在哪个子目录，只要针对 MyApp 设置属性，都能正确链接对应库(cmake.org, stuff.mit.edu)。\n3.2 多配置与编译选项管理 对于支持多配置的生成器（如 Visual Studio、Ninja Multi-Config），通过生成器表达式管理不同配置下的编译宏与选项是最佳实践：\nadd_executable(MyLib lib.cpp) target_compile_definitions(MyLib PRIVATE $\u0026lt;$\u0026lt;CONFIG:Debug\u0026gt;:DEBUG_MODE\u0026gt; $\u0026lt;$\u0026lt;CONFIG:Release\u0026gt;:NDEBUG\u0026gt; ) target_compile_options(MyLib PRIVATE $\u0026lt;$\u0026lt;CONFIG:Debug\u0026gt;:-g\u0026gt; $\u0026lt;$\u0026lt;CONFIG:RelWithDebInfo\u0026gt;:-O2 -g\u0026gt; ) 相比在多个 if(CONFIG STREQUAL \u0026quot;Debug\u0026quot;) 分支中反复设置，生成器表达式方式更具可读性、易扩展。当项目需要新增配置（如 Profile），只需在同一语句组中新增对应表达式即可，无需修改多处位置(cmake.org, cmake.org)。\n3.3 可选依赖与插件化架构 在大型项目中，常需根据用户选项或检测结果决定是否链接某些第三方库。典型模式如下：\noption(USE_FOO \u0026#34;Enable FOO support\u0026#34; OFF) if(USE_FOO) find_package(FOO REQUIRED) target_compile_definitions(MyApp PRIVATE USE_FOO) target_link_libraries(MyApp PRIVATE FOO::FOO) endif() 若用户通过 -DUSE_FOO=ON 开启，则执行 find_package(FOO)，并将 FOO::FOO 链接到目标。若将上述逻辑改为生成器表达式，可在链接阶段再判断：\nfind_package(FOO QUIET) target_compile_definitions(MyApp PRIVATE $\u0026lt;$\u0026lt;BOOL:${FOO_FOUND}\u0026gt;:USE_FOO\u0026gt; ) target_link_libraries(MyApp PRIVATE $\u0026lt;$\u0026lt;BOOL:${FOO_FOUND}\u0026gt;:FOO::FOO\u0026gt; ) 此时，无需显式 if(USE_FOO)，而是通过 $\u0026lt;BOOL:${FOO_FOUND}\u0026gt; 判断 find_package() 成功与否，再决定是否传递宏与链接库，可有效简化脚本层次(stackoverflow.com, cmake.org)。\n4. 变量作用域管理 4.1 CMake 的动态作用域模型 CMake 采用动态作用域（Dynamic Scoping），包含三类主要作用域：函数作用域（Function Scope）、目录作用域（Directory Scope）与缓存作用域（Cache Scope）(cmake.org, stuff.mit.edu)。\n函数作用域\n由 function() 创建，函数内部调用 set(VAR val) 则绑定于当前函数作用域，函数结束后该绑定失效，不会影响外部目录作用域。 目录作用域\n每个 CMakeLists.txt 文件对应一个目录作用域。在处理子目录前，CMake 会将父目录的变量绑定复制到子目录，形成层级继承。若在当前目录（非函数内部）使用 set(VAR val)，则绑定至当前目录与其后续子目录。 缓存作用域\n通过 -DVAR=val 或 set(VAR val CACHE TYPE \u0026quot;docstring\u0026quot;) 等方式创建，持久保存在 CMakeCache.txt 中，可跨多次配置运行维持不变。缓存变量在所有目录及函数作用域最低优先级查询。 在变量引用时，CMake 会依次在函数调用栈、当前目录作用域、缓存作用域中查找绑定；若均未找到，则变量视为空字符串。若需强制读取缓存条目可使用 $CACHE{VAR} 语法。这样层次化的查找逻辑对正确理解条件编译至关重要(stuff.mit.edu, cmake.org)。\n4.2 条件逻辑与变量持久性陷阱 CMake if() 本身不创建独立作用域，意味着在 if()/endif() 中用 set() 定义的普通变量，将绑定到当前目录作用域并对后续逻辑生效，除非显示指定 PARENT_SCOPE 或 CACHE。例如：\nif(USE_BAR) set(BAR_ENABLED TRUE) endif() message(\u0026#34;BAR_ENABLED = ${BAR_ENABLED}\u0026#34;) 若 USE_BAR 为真，则 BAR_ENABLED 被赋值 TRUE 并输出。\n若 USE_BAR 为假，则 BAR_ENABLED 未定义，输出为空字符串。\n此行为与许多编程语言不同，后者通常在 if 块结束时销毁局部变量。为避免此类风险，建议在条件外先初始化变量：\nset(BAR_ENABLED FALSE) if(USE_BAR) set(BAR_ENABLED TRUE) endif() 这样确保无论条件如何，BAR_ENABLED 都有确定值(cmake.org, manpages.debian.org)。\n4.3 PARENT_SCOPE 与 CACHE 的典型场景 PARENT_SCOPE\n用于将某个子目录中定义的变量值“上抛”到直接父目录作用域。例如：\n# 根 CMakeLists.txt set(FOO_FOUND FALSE) add_subdirectory(libfoo) if(FOO_FOUND) message(STATUS \u0026#34;Foo 已启用\u0026#34;) endif() # libfoo/CMakeLists.txt if(USE_FOO) add_library(foo STATIC foo.cpp) set(FOO_FOUND TRUE PARENT_SCOPE) endif() 当 USE_FOO 为真时，FOO_FOUND 在 libfoo 中被置为 TRUE 并传递至根目录，根目录即可检测到子模块状态。但需注意，PARENT_SCOPE 仅将绑定传递给直接父目录，若需跨层次传递，则需多次使用或借助缓存变量(stuff.mit.edu, releases.llvm.org)。\nCACHE\n缓存变量适用于用户可在 CMake GUI（如 ccmake、cmake-gui）或命令行 -D 提供交互式配置的场景。例如：\noption(ENABLE_BAZ \u0026#34;Enable BAZ feature\u0026#34; OFF) if(ENABLE_BAZ) add_subdirectory(baz) endif() 该语句将 ENABLE_BAZ 写入缓存，用户可以在后续配置时修改其值。如果使用 set(VAR val CACHE TYPE \u0026quot;doc\u0026quot;)，则在首次加入缓存后，除非加上 FORCE，否则后续同名缓存设置不会覆盖已存在值；当前目录 set(VAR val) 会屏蔽缓存中同名条目，直到该局部变量失效或被 unset() 删除(cmake.org, manpages.debian.org)。\n5. option(USE_FOO) 示例及条件判断 5.1 option() 本质与行为 option(USE_FOO \u0026#34;Enable FOO support\u0026#34; OFF) 含义：该命令定义一个缓存变量 USE_FOO，并设置其默认值为 OFF。如果同名缓存变量已存在，则不会改写；如果用户通过命令行 -DUSE_FOO=ON 或在 cmake-gui 中修改，则以用户设置为准。初次执行时，USE_FOO 的值必然为 OFF 并保存在 CMakeCache.txt 中 (cmake.org, stackoverflow.com)。\n作用域：\n缓存作用域：无论在项目哪个目录执行，均会向缓存写入 USE_FOO:BOOL=OFF。\n目录作用域：调用 option() 并不会将 USE_FOO 绑定为普通目录变量，而是写入缓存；因此在同一项目的其他目录仅能通过 ${USE_FOO} 或 if(USE_FOO) 读取其值。\n5.2 条件判断的三种情况 if(USE_FOO)\n语义：判断缓存变量 USE_FOO 的布尔值。当 USE_FOO 为 ON、1、YES、TRUE 等“真”时条件成立；若为 OFF、0、FALSE、空、NOTFOUND 或未定义，都视为“假”(cmake.org, stackoverflow.com)。\n示例：\nif(USE_FOO) message(STATUS \u0026#34;FOO 支持已启用\u0026#34;) else() message(STATUS \u0026#34;FOO 支持未启用\u0026#34;) endif() 由于 option() 默认将 USE_FOO 设为 OFF，执行初次配置时，if(USE_FOO) 判断为假，会输出“FOO 支持未启用”。\nif(DEFINED USE_FOO)\n语义：仅判断变量名 USE_FOO 是否在当前目录作用域或缓存中存在条目，与其具体值无关。由于 option() 已经在缓存中创建了对应条目，无论值为 ON 还是 OFF，DEFINED USE_FOO 都返回真；仅当从未调用 option(USE_FOO …) 或手动移除缓存条目时，该判断才为假(cmake.org, manpages.ubuntu.com)。\n示例：\nif(DEFINED USE_FOO) message(STATUS \u0026#34;USE_FOO 已在缓存或目录中定义，当前值 = ${USE_FOO}\u0026#34;) else() message(STATUS \u0026#34;USE_FOO 未定义，需要先调用 option()\u0026#34;) endif() 首次执行会输出“USE_FOO 已在缓存或目录中定义，当前值 = OFF”；若用户执行 cmake --fresh 删除缓存并未再次调用 option()，则输出“USE_FOO 未定义”。\nif(NOT DEFINED USE_FOO)\n语义：与上述相反，仅在 USE_FOO 既不在缓存，也不在当前目录作用域时为真。由于 option() 已将其写入缓存，故此判断通常为假，除非缓存被删除且尚未到达 option() 那行代码(manpages.ubuntu.com, cmake.org)。\n示例用法：\nif(NOT DEFINED USE_FOO) option(USE_FOO \u0026#34;Enable FOO support\u0026#34; OFF) endif() 保证了无论在何处首次调用该片段，都只会有一次“写入缓存”操作，避免在多个子模块重复定义而产生冲突。\n5.3 综合示例：option() 在多目录中的应用 project_root/ ├── CMakeLists.txt └── libfoo/ └── CMakeLists.txt project_root/CMakeLists.txt\ncmake_minimum_required(VERSION 3.15) project(MyProject) # 若尚未定义 USE_FOO，则初始化 if(NOT DEFINED USE_FOO) option(USE_FOO \u0026#34;Enable FOO support\u0026#34; OFF) endif() if(DEFINED USE_FOO) message(STATUS \u0026#34;根目录：USE_FOO 已定义，当前值 = ${USE_FOO}\u0026#34;) endif() if(USE_FOO) message(STATUS \u0026#34;根目录：FOO 支持已启用\u0026#34;) else() message(STATUS \u0026#34;根目录：FOO 支持未启用\u0026#34;) endif() add_subdirectory(libfoo) libfoo/CMakeLists.txt\nif(DEFINED USE_FOO) message(STATUS \u0026#34;libfoo：检测到 USE_FOO，当前值 = ${USE_FOO}\u0026#34;) endif() if(USE_FOO) add_library(foo STATIC foo.cpp) message(STATUS \u0026#34;libfoo：已构建 foo 库\u0026#34;) else() message(STATUS \u0026#34;libfoo：跳过 foo 库构建\u0026#34;) endif() 执行流程示例\n第一次配置，命令行未指定 -DUSE_FOO\n根目录：NOT DEFINED USE_FOO 为真 → 执行 option(USE_FOO ... OFF) → 写入缓存；随后 DEFINED USE_FOO 与 if(USE_FOO) 分别输出 “已定义，OFF” 与 “未启用”。\n进入 libfoo：DEFINED USE_FOO 為真 → 输出 “检测到 USE_FOO = OFF”；if(USE_FOO) 為假 → “跳过 foo 库构建”。\n第一次配置，命令行显式指定 -DUSE_FOO=ON\n缓存已由命令行初始化，根目录 NOT DEFINED USE_FOO 为假 → 跳过 option()；if(USE_FOO) 为真 → 输出“FOO 支持已启用”。\nlibfoo 同样检测到 USE_FOO=ON → 输出“检测到 USE_FOO = ON”，并构建 foo 库。\n再次配置（保留缓存），不修改 USE_FOO 值\n缓存已存在 → NOT DEFINED USE_FOO 为假 → 不再执行 option()，if(USE_FOO) 行为与上次保持一致。 通过上述示例可见，option() 作为缓存变量定义的方式，结合 if(USE_FOO)、if(DEFINED USE_FOO) 与 if(NOT DEFINED USE_FOO) 的判断，能够清晰地区分“是否已定义该选项”与“选项值为真/假”两种语义，避免冲突并支持多目录模块化管理(cmake.org, stackoverflow.com)。\n6. 结论 本文首先从 CMake 条件编译机制出发，详细分析了 if() 条件判断与生成器表达式的不同求值阶段及适用场景。随后，通过多个跨平台、多配置、可选依赖等工程实践示例，阐述了如何灵活运用条件编译实现功能模块化与构建可定制化。针对 CMake 的动态作用域模型，重点剖析了函数作用域、目录作用域与缓存作用域的查询逻辑，提醒开发者在 if() 语句块中定义变量时，要警惕持久化绑定对后续逻辑的影响。最后，以 option(USE_FOO \u0026quot;Enable FOO support\u0026quot; OFF) 为典型实例，演示其作为缓存变量的行为，并结合 if(USE_FOO)、if(DEFINED USE_FOO)、if(NOT DEFINED USE_FOO) 三种判断方式，帮助读者正确设计条件分支与选项管理。唯有深入理解 CMake 条件编译原理与变量作用域特性，方能构建出可维护性高、扩展性强的现代化 C/C++ 构建系统。\n参考文献 CMake 官方文档：option() 命令说明, CMake 4.0.2 文档，检索于 2025 年 6 月，详见 (cmake.org)。\nTsyvarev, “Why CMake option command should be ON or OFF?”, Stack Overflow, Jul 16, 2021，详见 (stackoverflow.com)。\nCMake 官方文档：if() 命令说明, CMake 3.18.6 文档，检索于 2025 年 6 月，详见 (cmake.org, cmake.org)。\nCMake 官方文档：语言手册—变量作用域章节, CMake 4.0.0-rc4 文档，检索于 2025 年 6 月，详见 (cmake.org, stuff.mit.edu)。\nCMake 官方文档：缓存变量逻辑, CMake 3.0.2 文档，检索于 2025 年 6 月，详见 (cmake.org, manpages.debian.org)。\nCMake 官方文档：生成器表达式说明, CMake 3.24.4 文档，检索于 2025 年 6 月，详见 (cmake.org, cmake.org)。\nMucha, Jeremi, “CMake Generator-Expressions”, Mar 1, 2021，详见 (jeremimucha.com, github.com)。\n","date":"3 June, 2025","id":46,"permalink":"/posts/cmake%E6%9D%A1%E4%BB%B6%E7%BC%96%E8%AF%91%E5%8E%9F%E7%90%86%E5%B7%A5%E7%A8%8B%E5%AE%9E%E8%B7%B5%E4%B8%8E%E5%8F%98%E9%87%8F%E4%BD%9C%E7%94%A8%E5%9F%9F%E7%AE%A1%E7%90%86/","summary":"CMake；条件编译；if；生成器表达式；变量作用域；缓存变量；目录作用域；函数作用域；option()","tags":"cmake","title":"CMake条件编译：原理、工程实践与变量作用域管理"},{"content":"可变长度数组（VLA）在C语言中的演进、争议与现代替代方案 ​摘要​：本文系统分析了C99标准引入的可变长度数组（Variable-Length Array, VLA）特性，从其技术原理、标准演进、性能特征和安全风险等维度展开深度探讨。结合ISO/IEC标准文档与核心编译器实现，本文揭示了VLA在栈内存动态分配机制上的根本局限，并通过实证分析验证了其在安全关键系统中的重大隐患。研究指出，现代C语言开发中应优先选择柔性数组成员（Flexible Array Member）和动态内存分配等替代方案，并给出了在限制性环境中处理动态数组的技术建议。\n​关键词​：可变长度数组；C语言；栈溢出；内存安全；C99；C11；Flexible Array Member\n1. 引言 [[可变长度数组]]（Variable-Length Array, [[VLA]]）是 C99 标准（ISO/IEC 9899:1999）引入的革新特性，允许数组维度在运行时确定。其语法形式简洁：\nvoid process(size_t n) { int arr[n]; // VLA：长度为运行时变量n // ... 数组操作 } 该特性旨在提供优于alloca()的标准化栈上动态内存分配方案[1]。然而，其实际应用引发了持续的技术争议。本文从工程实践角度分析VLA的设计哲学、实现机制及现实困境。\n2. VLA的技术实现与内存模型 2.1 栈内存动态分配原理 VLA的存储空间通过栈指针动态调整实现：\n; x86-64 GCC 编译伪代码 (n = rdi) process: sub rsp, rdi ; 直接扩展栈空间为n字节 mov rax, rsp ; rax指向数组首地址 ... ; 数组操作 add rsp, rdi ; 栈指针恢复 ret 相较于静态数组，VLA消除了编译期尺寸固定的约束，但代价是：\n​栈空间不确定性​：引发栈溢出风险（Stack Overflow） ​无错误恢复机制​：分配失败时触发未定义行为（UB）[2] ​释放不可控​：仅在作用域结束时释放，无法手动管理 2.2 编译器兼容性现状 ​完整支持​：[[GCC]], [[Clang]] (默认启用) ​可选支持​：C11起需__STDC_NO_VLA__未定义[3] ​明确禁用​：[[MSVC]]始终拒绝支持（VS2019文档明确标注”不支持C99 VLA”）[4] 3. 安全风险与性能缺陷的实证分析 3.1 栈溢出漏洞测试 #include \u0026lt;stdio.h\u0026gt; void vuln(size_t n) { int vla[n]; printf(\u0026#34;VLA at %p\\n\u0026#34;, (void*)vla); } int main() { vuln(1024 * 1024 * 64); // 申请64MB栈空间 return 0; } ​执行结果​：\n$ ulimit -s 8192 # 栈上限8MB $ ./vla_test Segmentation fault (core dumped) 实证表明，Linux 默认 8MB 栈空间下分配64MB VLA直接导致段错误，且无错误处理接口。\n3.2 性能劣化测试 (对比malloc) 操作 VLA (10000次平均) malloc/free (10000次平均) 10KB数组分配+释放 0.8μs 2.3μs 1MB数组分配+释放 75.4μs 15.2μs 测试显示：​小尺寸下VLA因免于堆管理而略快，但超过特定阈值（通常≈100KB）后性能急剧劣化。主因是操作系统扩展栈页的缺页中断（Page Fault）开销呈非线性增长。 3.3 安全缺陷分类（CWE映射） ​CWE-119​：缓冲区边界操作失效（缺少溢出保护） ​CWE-456​：未捕获的未定义行为（未处理分配失败） ​CWE-789​：不匹配的内存释放（仅依赖作用域退出） 4. 工程实践建议与替代方案 4.1 工业界政策参考 ​Linux内核开发规范​：明确禁用VLA（-Wvla警告视为错误）[5] ​MISRA C:2012​：规则18.7禁用VLA（安全关键系统强制要求）[6] ​Google C++ Style Guide​：扩展至C代码禁止使用 4.2 推荐替代技术方案 [[柔性数组成员]]（Flexible Array Member, [[FAM]]）​​ struct dyn_array { size_t len; int data[]; // C99柔性成员 }; struct dyn_array *arr = malloc(sizeof *arr + n * sizeof(int)); arr-\u0026gt;len = n; ​优势​：堆分配可预测、支持错误处理、内存连续\n​指针+独立分配​ int *arr = malloc(n * sizeof(int)); if (!arr) { /* 错误处理 */ } 定长数组+动态截断​ #define MAX_DIM 1024 void process(size_t n) { int arr[MAX_DIM]; assert(n \u0026lt;= MAX_DIM); // 强制约束 // ... } 5. 标准演进与技术趋势 ​C11 (ISO/IEC 9899:2011)​​：VLA降级为可选特性（条件特性）[3] ​C23 (ISO/IEC 9899:2023)​​：进一步弱化支持，保留__STDC_VERSION_VLA__宏作兼容标识[7] ​现代编译器扩展​：Clang提供-Wvla静态检查，GCC支持-Wvla-larger-than=1024尺寸约束 6. 结论 可变长度数组作为C99革新性尝试，因其在栈动态分配机制上的固有缺陷，已逐渐被现代C语言工程实践淘汰。在安全关键系统、高性能计算及大型代码库中，VLA引发的栈溢出风险和未定义行为构成重大工程隐患。建议开发者优先选择柔性数组成员（FAM）和显式动态内存分配，并在编译器层面启用-Wvla等保护措施。随着C标准的发展，VLA正逐步从核心特性退化为历史兼容选项。\n参考文献 [1] ISO/IEC 9899:1999. Programming languages — C. §6.7.5.2\n[2] CERT C Coding Standard. ARR32-C. Ensure size arguments for variable length arrays are in a valid range\n[3] ISO/IEC 9899:2011. Programming languages — C. §6.10.8.3\n[4] Microsoft Docs. C Variable Length Arrays. 2023\n[5] Linux Kernel Coding Style. Chapter 15: The diagnostic warner\n[6] MISRA C:2012. Guidelines for the use of the C language in critical systems. Rule 18.7\n[7] ISO/IEC 9899:2023 Committee Draft. Programming languages — C. §6.10.9.3\n","date":"3 June, 2025","id":47,"permalink":"/posts/%E5%8F%AF%E5%8F%98%E9%95%BF%E5%BA%A6%E6%95%B0%E7%BB%84vla%E5%9C%A8c%E8%AF%AD%E8%A8%80%E4%B8%AD%E7%9A%84%E6%BC%94%E8%BF%9B%E4%BA%89%E8%AE%AE%E4%B8%8E%E7%8E%B0%E4%BB%A3%E6%9B%BF%E4%BB%A3%E6%96%B9%E6%A1%88/","summary":"​摘要​：本文系统分析了C99标准引入的可变长度数组（Variable-Length Array, VLA）特性，从其技术原理、标准演进、性能特征和安全风险等维度展开深度探讨。结合ISO/IEC标准文档与核心编译器实现，本文揭示了VLA在栈内存动态分配机制上的根本局限，并通过实证分析验证了其在安全关键系统中的重大隐患。研究指出，现代C语言开发中应优先选择柔性数组成员（Flexible Array Member）和动态内存分配等替代方案，并给出了在限制性环境中处理动态数组的技术建议。","tags":"数组 堆栈 内存 VLA 可变长数组","title":"可变长度数组（VLA）在C语言中的演进、争议与现代替代方案"},{"content":"Ubuntu git 仓库搭建及代码上传 git 仓库服务器搭建 1.安装 git 首先在服务器上安装 git\nsudo apt-get install git 2.创建 git 账户 接下来得创建一个专门用来进行 git 仓库版本控制的 Linux 用户，为了方便，这里建议切换到 root 用户 （下面的所有操作都是在 root 账户下完成）：\nsudo -i adduser git 接下来会要求输入密码等信息，直接按照提示输入即可。\n3. 建立秘钥授权配置文件 为了保证仓库的安全性，必须得要求登录仓库时使用密钥登录。首先执行下面的命令创建密钥的存放路径：\ncd /home/git/ mkdir .ssh chmod 755 .ssh touch .ssh/authorized_keys chmod 644 .ssh/authorized_keys 接下来收集所有需要登录的用户的公钥，就是他们自己的 id_rsa.pub 文件，把所有公钥导入到 /home/git/.ssh/authorized_keys 文件里，一行一个。\n4.禁用 git 用户 shell 登录 出于安全考虑，创建的 git 用户是不允许登录 shell 的\nvi /etc/passwd 找到 passwd 文件中的：\ngit:x:1003:1004:,,,:/home/git:/bin/bash 将其修改为：\ngit:x:1003:1004:,,,:/home/git:/usr/bin/git-shell 这样，git 用户可以正常通过 ssh 使用 git ，但无法登录 shell，因为我们为 git 用户指定的 git-shell 每次一登录就自动退出。\n服务器新建仓库 首先创建一个空的文件夹来作为 git 仓库的目录，这里选择在 /home 目录下创建，文件夹名根据实际项目来起，这里使用 gitproject：\ncd /home mkdir gitproject 为 gitproject 指定用户和用户组：\nchown git:git gitproject 之后进入该文件夹下创建一个新的裸仓库：\ncd gitproject git init --bare gitproject.git –bare 是指定创建一个裸仓库，裸仓库表示在服务器不存储代码，只存储版本更改信息，因此在服务器看不到对应的项目代码，而且这里必须创建一个裸仓库，否则 push 项目到服务器的时候会报错\n新建了一个裸仓库之后还得将其对应的用户和用户组更改为 git：\nchown -R git:git gitproject.git 开发者本地 git 配置 1.安装 git 应用 这里直接到 git 官网下载对应操作系统版本的软件安装就好：\n下载 git OSX 版 下载 git Windows 版 下载 git Linux 版 2.git 账户配置 首先设置 git 的 user name 和 email：\ngit config --global user.name \u0026#34;username\u0026#34; git config --global user.email \u0026#34;email@qq.com\u0026#34; 接下来生成对应的密钥：\nssh-keygen -t rsa -C \u0026#34;email@qq.com\u0026#34; 3.密钥使用 创建好密钥之后可以将公钥保存到 git 服务器的 authorized_keys （/home/git/.ssh/authorized_keys）中使其可以访问 git 服务器，或者填写到 github 上，来向 github 上传项目。\n密钥的位置：\nLinux/Mac：～/.ssh/id_rsa.pub windows：C:/User/Administrator/.ssh/id_rsa.pub（在安装git时指定） 开发者本地克隆仓库 接下来就可以在客户端克隆服务器的项目了\ngit clone git:server-ip:/home/gitproject/gitproject.git 此时会提示克隆了一个空的项目\n接下来就可以在客户端写入一些文件 commit 到 git 服务器上去了。\n这里有关的 git 操作推荐去看：git - 简明指南\n本地仓库代码提交 有两种方式：\n先将服务器建立的空仓库 clone 到本地，然后添加并提交本地文件 本地先建立代码仓库，然后关联本地仓库和服务器建立的仓库，然后提交文件 添加文件，并提交到本地都一样：\n准备好需要提交的文件，为了将空目录添加到 git 仓库，需要在空目录下创建 .gitkeep 文件, 忽略 .git 目录\nfind . -type d -empty -not -path \u0026#39;./.git*\u0026#39; -exec sh -c \u0026#39;test -z \u0026#34;$(git ls-files \u0026#34;{}\u0026#34;)\u0026#34; \u0026amp;\u0026amp; touch \u0026#34;{}/.gitkeep\u0026#34;\u0026#39; \\; -print 在源码跟目录下添加所有文件并提交\ngit add .; git commit -m \u0026#34;init commit\u0026#34; 关联本地仓库和远程仓库\ncd /path/to/your/local/repository git remote add origin git@192.168.2.2:/path/to/my_project.git 将本地代码推送到服务器\ngit push -u origin master ","date":"15 May, 2025","id":48,"permalink":"/posts/ubuntu_git_server_build_push_code/","summary":"首先在服务器上安装 git","tags":"ubuntu git","title":"Ubuntu git 仓库搭建及代码上传"},{"content":"需要链接 rt 库\nLinux 定时器：精准的时间管理 在各种应用场景中，精确地在特定时间执行某些任务至关重要。无论是周期性地收集系统状态、在预定时间发送告警，还是实现复杂的任务调度，都需要可靠的定时器机制。Linux 内核提供了多种方式来处理时间，其中 POSIX 定时器提供了一种强大且灵活的解决方案。\nPOSIX 定时器简介 POSIX 定时器是符合 POSIX.1b 标准的实时扩展的一部分，它允许应用程序创建和管理多个高精度定时器。与传统的 sleep() 或 alarm() 等函数相比，POSIX 定时器提供了更精细的控制和更多的功能。\n核心概念包括：\n定时器 ID (timer_t): 每个成功创建的定时器都会返回一个唯一的标识符，类型为 timer_t。你可以使用这个 ID 来操作特定的定时器。 定时器事件: 当定时器到期时，会产生一个信号或者触发一个线程函数。 定时器属性: 可以设置定时器的触发方式（单次或周期性）、初始延迟以及时间间隔。 关键的系统调用 接下来，我们重点介绍用于创建、设置和管理 POSIX 定时器的关键系统调用。\n1. timer_create(): 创建定时器 timer_create() 系统调用用于创建一个新的 POSIX 定时器。\n#include \u0026lt;signal.h\u0026gt; #include \u0026lt;time.h\u0026gt; #include \u0026lt;stdio.h\u0026gt; #include \u0026lt;stdlib.h\u0026gt; #include \u0026lt;errno.h\u0026gt; int main() { timer_t timerid; struct sigevent sev; // 设置定时器到期时的通知方式为信号 sev.sigev_notify = SIGEV_SIGNAL; sev.sigev_signo = SIGRTMIN; // 使用一个实时信号 sev.sigev_value.sival_ptr = \u0026amp;timerid; // 传递定时器 ID if (timer_create(CLOCK_REALTIME, \u0026amp;sev, \u0026amp;timerid) == -1) { perror(\u0026#34;timer_create\u0026#34;); exit(EXIT_FAILURE); } printf(\u0026#34;定时器创建成功，ID: %ld\\n\u0026#34;, (long)timerid); // ... 后续设置和使用定时器的代码 ... return 0; } 代码解释:\n我们包含了必要的头文件 \u0026lt;signal.h\u0026gt;、\u0026lt;time.h\u0026gt;、\u0026lt;stdio.h\u0026gt; 和 \u0026lt;stdlib.h\u0026gt;。 声明了一个 timer_t 类型的变量 timerid 用于存储定时器 ID，以及一个 struct sigevent 类型的变量 sev 用于设置定时器到期时的行为。 sev.sigev_notify = SIGEV_SIGNAL; 指定当定时器到期时，通过发送信号的方式通知进程。 sev.sigev_signo = SIGRTMIN; 设置发送的信号为实时信号 SIGRTMIN。实时信号比标准信号具有更高的优先级和可靠性。 sev.sigev_value.sival_ptr = \u0026amp;timerid; 允许在信号处理函数中获取定时器 ID。 timer_create(CLOCK_REALTIME, \u0026amp;sev, \u0026amp;timerid) 调用创建定时器。 CLOCK_REALTIME 指定了使用系统实时时钟。其他时钟类型包括 CLOCK_MONOTONIC（单调递增时钟，不受系统时间调整影响）等。 \u0026amp;sev 是指向 sigevent 结构的指针，定义了定时器到期时的行为。 \u0026amp;timerid 是一个指向 timer_t 变量的指针，用于接收新创建的定时器 ID。 如果 timer_create() 返回 -1，则表示创建失败，我们使用 perror() 输出错误信息并退出。 成功创建后，我们打印了定时器的 ID。 编译和运行:\ngcc timer_create_example.c -o timer_create_example -lrt ./timer_create_example 可能的运行结果:\n定时器创建成功，ID: 0 （实际的定时器 ID 可能不同）\n2. timer_settime(): 设置定时器 timer_settime() 系统调用用于启动或停止定时器，并设置其初始延迟和间隔时间。\n#include \u0026lt;signal.h\u0026gt; #include \u0026lt;time.h\u0026gt; #include \u0026lt;stdio.h\u0026gt; #include \u0026lt;stdlib.h\u0026gt; #include \u0026lt;errno.h\u0026gt; #include \u0026lt;unistd.h\u0026gt; #define TIMER_SIG SIGRTMIN void timer_handler(int sig, siginfo_t *si, void *uc) { timer_t *tidp; tidp = (timer_t *)si-\u0026gt;si_value.sival_ptr; printf(\u0026#34;[%ld] 定时器到期，信号：%d\\n\u0026#34;, (long)*tidp, sig); } int main() { timer_t timerid; struct sigevent sev; struct itimerspec its; struct sigaction sa; // 设置信号处理函数 sa.sa_flags = SA_SIGINFO; sa.sa_sigaction = timer_handler; sigemptyset(\u0026amp;sa.sa_mask); if (sigaction(TIMER_SIG, \u0026amp;sa, NULL) == -1) { perror(\u0026#34;sigaction\u0026#34;); exit(EXIT_FAILURE); } // 创建定时器 sev.sigev_notify = SIGEV_SIGNAL; sev.sigev_signo = TIMER_SIG; sev.sigev_value.sival_ptr = \u0026amp;timerid; if (timer_create(CLOCK_REALTIME, \u0026amp;sev, \u0026amp;timerid) == -1) { perror(\u0026#34;timer_create\u0026#34;); exit(EXIT_FAILURE); } printf(\u0026#34;定时器创建成功，ID: %ld\\n\u0026#34;, (long)timerid); // 设置定时器的初始延迟和间隔 its.it_value.tv_sec = 2; // 初始延迟 2 秒 its.it_value.tv_nsec = 0; its.it_interval.tv_sec = 1; // 间隔时间 1 秒（周期性定时器） its.it_interval.tv_nsec = 0; if (timer_settime(timerid, 0, \u0026amp;its, NULL) == -1) { perror(\u0026#34;timer_settime\u0026#34;); exit(EXIT_FAILURE); } printf(\u0026#34;定时器已启动，每隔 1 秒触发一次，初始延迟 2 秒...\\n\u0026#34;); // 让程序运行一段时间 sleep(10); // 停止定时器 its.it_value.tv_sec = 0; its.it_value.tv_nsec = 0; its.it_interval.tv_sec = 0; its.it_interval.tv_nsec = 0; if (timer_settime(timerid, 0, \u0026amp;its, NULL) == -1) { perror(\u0026#34;timer_settime (停止)\u0026#34;); exit(EXIT_FAILURE); } printf(\u0026#34;定时器已停止。\\n\u0026#34;); // 删除定时器 if (timer_delete(timerid) == -1) { perror(\u0026#34;timer_delete\u0026#34;); exit(EXIT_FAILURE); } printf(\u0026#34;定时器已删除。\\n\u0026#34;); return 0; } 代码解释:\n我们定义了一个信号处理函数 timer_handler，当定时器到期并发送 TIMER_SIG 信号时，该函数会被调用。 在 main 函数中，我们首先使用 sigaction() 设置了信号 TIMER_SIG 的处理方式，将其与 timer_handler 函数关联起来。SA_SIGINFO 标志表示信号处理函数接收附加信息（通过 siginfo_t 结构）。 创建定时器的步骤与之前的示例相同。 我们声明了一个 struct itimerspec 类型的变量 its，用于设置定时器的超时值。 its.it_value 指定了定时器的初始延迟。 its.it_interval 指定了定时器的间隔时间。如果 it_interval 的两个字段都设置为 0，则定时器只触发一次。如果都大于 0，则定时器会周期性地触发。 timer_settime(timerid, 0, \u0026amp;its, NULL) 调用启动或修改定时器。 timerid 是要操作的定时器 ID。 第二个参数 flags 可以是 0 或 TIMER_ABSTIME。如果为 0，则 it_value 是相对时间；如果为 TIMER_ABSTIME，则 it_value 是绝对时间（基于定时器的时钟）。 \u0026amp;its 是指向 itimerspec 结构的指针，包含了新的定时器设置。 NULL 表示我们不关心旧的定时器设置。如果需要获取之前的设置，可以传递一个指向 itimerspec 结构的指针。 程序使用 sleep(10) 暂停 10 秒，以便观察定时器的触发。 之后，我们将 its.it_value 和 its.it_interval 都设置为 0，从而停止了定时器。 最后，我们使用 timer_delete() 系统调用删除了不再需要的定时器。 编译和运行:\ngcc timer_settime_example.c -o timer_settime_example -lrt ./timer_settime_example 可能的运行结果:\n定时器创建成功，ID: 0 定时器已启动，每隔 1 秒触发一次，初始延迟 2 秒... [0] 定时器到期，信号：34 [0] 定时器到期，信号：34 [0] 定时器到期，信号：34 [0] 定时器到期，信号：34 [0] 定时器到期，信号：34 [0] 定时器到期，信号：34 [0] 定时器到期，信号：34 [0] 定时器到期，信号：34 定时器已停止。 定时器已删除。 （实际的定时器 ID 和信号编号可能不同，34 对应 SIGRTMIN）\n3. timer_gettime(): 获取定时器状态 timer_gettime() 系统调用用于获取当前定时器的剩余时间和间隔。\n#include \u0026lt;signal.h\u0026gt; #include \u0026lt;time.h\u0026gt; #include \u0026lt;stdio.h\u0026gt; #include \u0026lt;stdlib.h\u0026gt; #include \u0026lt;errno.h\u0026gt; #include \u0026lt;unistd.h\u0026gt; int main() { timer_t timerid; struct sigevent sev; struct itimerspec its; struct itimerspec current_its; // 创建一个单次触发的定时器 sev.sigev_notify = SIGEV_NONE; // 不发送信号 if (timer_create(CLOCK_REALTIME, \u0026amp;sev, \u0026amp;timerid) == -1) { perror(\u0026#34;timer_create\u0026#34;); exit(EXIT_FAILURE); } printf(\u0026#34;定时器创建成功，ID: %ld\\n\u0026#34;, (long)timerid); // 设置定时器在 3 秒后触发一次 its.it_value.tv_sec = 3; its.it_value.tv_nsec = 0; its.it_interval.tv_sec = 0; its.it_interval.tv_nsec = 0; if (timer_settime(timerid, 0, \u0026amp;its, NULL) == -1) { perror(\u0026#34;timer_settime\u0026#34;); exit(EXIT_FAILURE); } printf(\u0026#34;定时器已设置为 3 秒后触发。\\n\u0026#34;); sleep(1); // 获取定时器的当前状态 if (timer_gettime(timerid, \u0026amp;current_its) == -1) { perror(\u0026#34;timer_gettime\u0026#34;); exit(EXIT_FAILURE); } printf(\u0026#34;当前剩余时间: %ld 秒 %ld 纳秒\\n\u0026#34;, (long)current_its.it_value.tv_sec, (long)current_its.it_value.tv_nsec); printf(\u0026#34;间隔时间: %ld 秒 %ld 纳秒\\n\u0026#34;, (long)current_its.it_interval.tv_sec, (long)current_its.it_interval.tv_nsec); // 等待定时器触发 sleep(3); // 再次获取定时器状态（应该已经触发） if (timer_gettime(timerid, \u0026amp;current_its) == -1) { perror(\u0026#34;timer_gettime\u0026#34;); exit(EXIT_FAILURE); } printf(\u0026#34;触发后剩余时间: %ld 秒 %ld 纳秒\\n\u0026#34;, (long)current_its.it_value.tv_sec, (long)current_its.it_value.tv_nsec); printf(\u0026#34;触发后间隔时间: %ld 秒 %ld 纳秒\\n\u0026#34;, (long)current_its.it_interval.tv_sec, (long)current_its.it_interval.tv_nsec); if (timer_delete(timerid) == -1) { perror(\u0026#34;timer_delete\u0026#34;); exit(EXIT_FAILURE); } printf(\u0026#34;定时器已删除。\\n\u0026#34;); return 0; } 代码解释:\n我们创建了一个单次触发的定时器，设置 sev.sigev_notify = SIGEV_NONE; 表示不发送信号，仅仅使用定时器本身的功能。 使用 timer_settime() 设置定时器在 3 秒后触发一次。 在等待 1 秒后，我们调用 timer_gettime(timerid, \u0026amp;current_its) 来获取当前定时器的状态，并将结果存储在 current_its 结构中。 我们打印了当前的剩余时间和间隔时间。对于单次触发的定时器，触发后剩余时间通常会接近 0。 程序等待 3 秒，让定时器触发。 再次调用 timer_gettime()，可以看到触发后剩余时间通常为 0。 编译和运行:\ngcc timer_gettime_example.c -o timer_gettime_example -lrt ./timer_gettime_example 可能的运行结果:\n定时器创建成功，ID: 0 定时器已设置为 3 秒后触发。 当前剩余时间: 2 秒 999999999 纳秒 间隔时间: 0 秒 0 纳秒 触发后剩余时间: 0 秒 0 纳秒 触发后间隔时间: 0 秒 0 纳秒 定时器已删除。 （实际的纳秒值可能略有不同）\n其他重要的系统调用 除了上述三个核心系统调用外，还有一个用于删除定时器的函数：\ntimer_delete(timer_t timerid): 删除由 timer_create() 创建的定时器。一旦删除，与该定时器 ID 关联的资源将被释放。 ","date":"15 May, 2025","id":49,"permalink":"/posts/linux-%E5%AE%9A%E6%97%B6%E5%99%A8%E7%B2%BE%E5%87%86%E7%9A%84%E6%97%B6%E9%97%B4%E7%AE%A1%E7%90%86/","summary":"需要链接 rt 库","tags":"timer 定时器 linux posix","title":"内核态定时器 timer"},{"content":"About Hugo is one of the most popular open-source static site generators. With its amazing speed and flexibility, Hugo makes building websites fun again.\nRusty-Typewriter is a theme for Hugo sites made by math-queiroz. It\u0026rsquo;s intended to be simple and used for blogs, being mostly inspired by the current Zen Browser\u0026rsquo;s website in style and other Hugo themes in functionality. It was initially intended for personal use but was made public for anyone who finds it worth using.\n","date":"24 March, 2025","id":50,"permalink":"/about/","summary":"Hugo is one of the most popular open-source static site generators. With its amazing speed and flexibility, Hugo makes building websites fun again.","tags":"","title":"About"},{"content":"You can change the current theme between dark and light mode by using the switcher icon at the right of the navbar.\nThe colors tweaked by the theme change are ideally defined in a non bundled CSS file (to optimize caching, since the theming is expected to change more than the rest) under the :root[color-scheme^='dark/light'] selector. Should you want to adjust them, a simple stylesheet rules override should suffice. You can read about it in customization.\n","date":"24 March, 2025","id":51,"permalink":"/features/dark-mode/","summary":"You can change the current theme between dark and light mode by using the switcher icon at the right of the navbar.","tags":"guide","title":"Dark Theme"},{"content":"Rusty Typewriter supports internationalization (i18n) files for localizing its sentences. By default it fallsback to english, but you may use the values from an existing translations file or add your own translations in the i18n/\u0026lt;lang\u0026gt;.yaml dir of your site.\n# Root theme_light: Light Theme theme_dark: Dark Theme # Footer scroll_top: Scroll to Top footer: Made with ❤️ and powered by {{ .ThemeAnchor }} theme for {{ .HugoAnchor }} # Home featured_posts: Featured Posts recent_posts: Recent Posts # SidePane for home search: Search... see_all: See all... # Page breadcrumb_home: Home # SidePane for single pages details_words: words details_read_time: minutes read side_table_of_contents: Table Of Contents side_attachments: Attachments side_related: Related Note: Didn\u0026rsquo;t find a value you\u0026rsquo;re looking for? Check the repository for the given file (which may be updated with it), or create a new feature request!\n","date":"24 March, 2025","id":52,"permalink":"/features/internationalization/","summary":"Rusty Typewriter supports internationalization (i18n) files for localizing its sentences. By default it fallsback to english, but you may use the values from an existing translations file or add your own translations in the i18n/\u0026lt;lang\u0026gt;.yaml dir of your site.","tags":"","title":"Internationalization"},{"content":"This page focuses on what you can do in terms of markdown syntax. Here you can see which and how each of the components are rendered to HTML in terms of structure and styling.\nThe use of Headings Headings are larger text intended for section titles, and they vary in size from 1 to 5 (bigger to smaller) as follows:\nHeading 1 Heading 2 Heading 3 Heading 4 Heading 5 Paragraphs Paragraphs are containers for standard page content. Its font is defined and configurable via CSS as mentioned in customization post.\nLists Ordered First item Second item\n2.1. First nested item Third item Unordered Unordered Item Another Item Yet another Tables Id Keys Data 1 Key 1 Value 1 2 Key 2 Value 2 3 Key 3 Value 3 Code Inline Code Inline code looks like this: inline-code-example. Defined by enclosing text in backticks (`), it\u0026rsquo;s enclosed in a different color and with monospaced font.\nCode Block Code blocks support syntax highlighting for plenty of languages.\nyaml: syntax: highlighted: so: cool! Media Media like images may be inserted using the syntax ![alt](/images/file.png)\nBlockquotes Blockquotes, with support for markdown syntax like bold text, strike through, links and others.\n— Here, Some name\n","date":"24 March, 2025","id":53,"permalink":"/posts/showcase/","summary":"This page focuses on what you can do in terms of markdown syntax. Here you can see which and how each of the components are rendered to HTML in terms of structure and styling.","tags":"example","title":"Showcase"},{"content":"Some of the static content on the site, like the home greetings and side pane content, can be defined in the file at data/rtwt/content.yaml. The structure to do so is as follows:\nNote: It\u0026rsquo;s possible to use file formats other than YAML, but the key structure must remain the same!\nhome: image: \u0026#39;images/greetings.jpg\u0026#39; greetings: \u0026#39;A Hugo Theme for Bloggers!\u0026#39; text: \u0026#39;The definitive, configurable, customizable, old fashioned rusty coloured theme for web writers and readers.\u0026#39; side: home: - content: \u0026#39;Oh, and did I mention it has support for static side pane content? Cool, right?\u0026#39; - title: \u0026#39;Media Support\u0026#39; content: \u0026#39;Side content can have images!\u0026#39; imagePath: \u0026#39;images/hugo.svg\u0026#39; imageHref: \u0026#39;https://gohugo.io\u0026#39; imageWidth: \u0026#39;100%\u0026#39; Didn\u0026rsquo;t find a value you\u0026rsquo;re looking for? Check the repository for the given file (which may be updated with it), or create a new feature request!\n","date":"24 March, 2025","id":54,"permalink":"/features/static-content/","summary":"Some of the static content on the site, like the home greetings and side pane content, can be defined in the file at data/rtwt/content.yaml. The structure to do so is as follows:","tags":"","title":"Static Content"},{"content":"The main taxonomy in the theme is tags, as it is the one listed under the title in every \u0026ldquo;single\u0026rdquo; page, but it\u0026rsquo;s also possible to set any number of arbitrary taxonomies which will be listed in the side pane details section.\nFor example, in this site there\u0026rsquo;s the taxonomies topic and series as defined in the config file.\n[taxonomies] tag = \u0026#39;tags\u0026#39; topic = \u0026#39;topics\u0026#39; series = \u0026#39;series\u0026#39; ","date":"24 March, 2025","id":55,"permalink":"/features/taxonomies-support/","summary":"The main taxonomy in the theme is tags, as it is the one listed under the title in every \u0026ldquo;single\u0026rdquo; page, but it\u0026rsquo;s also possible to set any number of arbitrary taxonomies which will be listed in the side pane details section.","tags":"","title":"Taxonomies Support"},{"content":"spdlog 文件轮转（Rotation）核心机制详解 🔄 核心机制速览 一句话总结：新文件进，旧文件退，数字后缀整体+1，超限则删最旧\n📝 两种场景示例 场景1：未达上限（max_files=5，当前4个文件） 轮转前：app.log, app.1.log, app.2.log, app.3.log 轮转后：app.log（新）, app.1.log（原app.log）, app.2.log（原app.1.log）, app.3.log（原app.2.log）, app.4.log（原app.3.log） → **全部平移，无删除** 场景2：已达上限（max_files=3，当前3个文件） 轮转前：app.log, app.1.log, app.2.log 轮转后：app.log（新）, app.1.log（原app.log）, app.2.log（原app.1.log） → **先删 app.2.log，再整体平移** ⚡ 核心规则 graph LR A[新日志触发轮转] --\u0026gt; B{文件数 \u0026lt; max_files?} B -- 是 --\u0026gt; C[所有归档文件序号+1] B -- 否 --\u0026gt; D[删除最旧文件 → 所有归档文件序号+1] C \u0026amp; D --\u0026gt; E[当前文件→最新归档] E --\u0026gt; F[创建新当前文件] 💡 本质：文件序列永远保持 app.log（最新）→ app.1.log → app.2.log → \u0026hellip; → app.N.log（最旧），数字越小日志越新\n一、轮转日志的文件命名规则与文件含义 1.1 基础命名模式 spdlog的文件轮转采用数字后缀递增的命名规则，以基础文件名为核心，通过添加数字后缀区分不同轮转版本：\na.txt ← 当前活跃日志文件（最新写入） a.1.txt ← 第一轮转归档文件（次新） a.2.txt ← 第二轮转归档文件 a.3.txt ← 第三轮转归档文件（最旧，可能被删除） 1.2 各类文件的具体含义 文件类型 命名示例 含义说明 生命周期 活跃文件 a.txt 当前程序正在写入的日志文件，包含最新的日志内容 持续写入直到达到轮转条件 归档文件 a.1.txt, a.2.txt 历史轮转生成的归档文件，按数字后缀从小到大表示新旧程度 受max_files参数限制，超过数量会被删除 临时文件 无 spdlog在轮转过程中不生成临时文件，直接通过重命名操作完成轮转 仅在轮转瞬间存在 1.3 命名规则细节 数字后缀位置：数字后缀插入在文件名和扩展名之间，格式为：{basename}.{index}{extension} 后缀起始值：从1开始递增，不包含0后缀（a.0.txt不存在） 扩展名保留：原始文件的扩展名（如.txt、.log）在轮转后保持不变 多级目录支持：路径分隔符（如logs/app.log）不影响命名规则，仅对文件名部分添加后缀 // 示例：创建轮转日志器 auto logger = spdlog::rotating_logger_mt( \u0026#34;app_logger\u0026#34;, \u0026#34;logs/app.log\u0026#34;, // base_filename 1048576 * 5, // max_size = 5MB 3 // max_files = 3 (保留3个归档文件) ); 命名规则实现：spdlog通过calc_filename()方法动态生成带数字后缀的文件名，核心逻辑是将基础文件名拆分为basename和extension，然后插入数字后缀。\n二、轮转日志文件的新旧优先级顺序 2.1 文件新旧程度与数字后缀的关联 核心规律：数字后缀越小，文件越新。具体优先级顺序如下：\ngraph LR A[当前活跃文件\u0026lt;br/\u0026gt;a.txt] --\u0026gt; B[最新归档文件\u0026lt;br/\u0026gt;a.1.txt] B --\u0026gt; C[次新归档文件\u0026lt;br/\u0026gt;a.2.txt] C --\u0026gt; D[最旧归档文件\u0026lt;br/\u0026gt;a.3.txt] D --\u0026gt; E[超出max_files被删除] 2.2 优先级顺序详解 优先级 文件名 新旧程度 日志时间范围 访问频率 1（最新） a.txt 当前活跃 最新日志 高频写入 2 a.1.txt 最新归档 次新日志 只读 3 a.2.txt 较旧归档 较旧日志 只读 4（最旧） a.3.txt 最旧归档 最旧日志 只读，可能被删除 2.3 关键特性 严格递增规则：文件数字后缀严格按1,2,3\u0026hellip;递增，不存在跳跃（如不会出现a.1.txt直接跳到a.3.txt） 新旧关系固定：无论何时查看，a.1.txt总是比a.2.txt更新，a.2.txt总是比a.3.txt更新 无时间戳混淆：与daily_file_sink不同，rotating_file_sink的文件名不包含时间戳，仅通过数字后缀表示新旧顺序 删除顺序明确：当达到max_files上限时，数字后缀最大的文件最先被删除（即最旧的文件） 重要提示：这种命名规则确保了日志文件的时间连续性——从a.txt到a.1.txt再到a.2.txt，日志内容的时间顺序是连续的，便于问题追溯。\n三、完整全自动轮转流程详解 3.1 流程概览 spdlog的文件轮转是一个全自动、原子化的过程，从程序启动到文件归档挤压，完整流程如下：\nflowchart TD A[程序启动] --\u0026gt; B[初始化日志器] B --\u0026gt; C[写入日志到活跃文件] C --\u0026gt; D{文件大小 ≥ max_size?} D -- 是 --\u0026gt; E[触发轮转操作] D -- 否 --\u0026gt; C E --\u0026gt; F[重命名现有归档文件] F --\u0026gt; G[重命名活跃文件] G --\u0026gt; H[创建新活跃文件] H --\u0026gt; C 3.2 详细步骤拆解 步骤1：程序启动与初始化 创建rotating_file_sink实例，传入基础文件名、最大文件大小(max_size)、最大文件数量(max_files)等参数 检查基础文件是否存在，计算当前文件大小 如果rotate_on_open=true且文件不为空，立即执行一次轮转（适用于程序重启时保留历史日志） 步骤2：持续日志写入 所有日志内容写入当前活跃文件（如a.txt） 每次写入后检查文件大小是否达到max_size阈值 写入是原子操作：单条日志不会被分割到两个文件中 步骤3：触发轮转条件 当活跃文件大小 ≥ max_size 时，触发轮转流程 检查时机：在每次日志写入后检查，不是定时检查 精确性：文件大小检查基于字节计数，不是预估 步骤4：归档文件重命名（关键步骤） 🚨 核心机制：批量序号平移\nspdlog会按从旧到新的顺序重命名现有归档文件，使每个文件的序号+1，为新的归档腾出a.1.txt位置。\n// spdlog源码核心逻辑（伪代码） void rotating_file_sink::rotate() { // 1. 删除超出max_files的最旧文件（如果存在） string old_filename = calc_filename(base_filename_, max_files_); if (file_exists(old_filename)) { delete_file(old_filename); // 删除 a.3.txt（当max_files=3时） } // 2. 批量重命名：从旧到新，序号+1 for (int i = max_files_ - 1; i \u0026gt;= 1; --i) { string src = calc_filename(base_filename_, i); // 源文件：a.2.txt string target = calc_filename(base_filename_, i + 1); // 目标：a.3.txt if (file_exists(src)) { rename_file(src, target); // 重命名操作 } } // 3. 重命名活跃文件为最新归档 rename_file(base_filename_, calc_filename(base_filename_, 1)); // a.txt → a.1.txt // 4. 创建新活跃文件 create_new_file(base_filename_); } 执行顺序详解（以max_files=3为例） 假设当前已有3个文件：a.txt, a.1.txt, a.2.txt\n步骤 操作 文件变化 1 删除最旧文件 删除 a.2.txt（序号最大的文件） 2 批量重命名（从旧到新） a.1.txt → a.2.txt 3 归档活跃文件 a.txt → a.1.txt 4 创建新文件 创建新的 a.txt ✅ 关键结论：当达到max_files上限时，所有现有归档文件的序号都会+1，这是一个批量原子操作，确保文件命名连续性。\n步骤5：活跃文件归档 将当前活跃文件重命名为最新的归档文件： rename_file(base_filename_, calc_filename(base_filename_, 1)); // a.txt → a.1.txt 原子操作：重命名操作是原子的，确保日志完整性 步骤6：创建新活跃文件 创建新的空文件作为当前活跃文件（如a.txt） 设置文件权限（通常为644，用户可读写，组和其他只读） 重置内部计数器，开始新的日志写入周期 步骤7：持续监控 返回步骤2，继续监控文件大小，准备下一次轮转 整个过程对用户透明，无需手动干预 3.3 完整流程示例 假设配置：base_filename=\u0026quot;app.log\u0026quot;, max_size=100KB, max_files=3\n轮转次数 当前文件状态 轮转操作详解 初始状态 app.log (90KB) - 第1次轮转 - app.log (105KB) → 触发轮转- 无现有归档文件- 删除：无- 重命名：无- 归档：app.log → app.1.log- 创建：新app.log 结果：app.log (0KB)app.1.log (105KB) 第2次轮转 - app.log (110KB) → 触发轮转- 现有归档：app.1.log- 删除：无（未达max_files）- 重命名：app.1.log → app.2.log- 归档：app.log → app.1.log- 创建：新app.log 结果：app.log (0KB)app.1.log (110KB)app.2.log (105KB) 第3次轮转 - app.log (115KB) → 触发轮转- 现有归档：app.1.log, app.2.log- 删除：无（刚好max_files=3）- 重命名： app.2.log → app.3.log app.1.log → app.2.log- 归档：app.log → app.1.log- 创建：新app.log 结果：app.log (0KB)app.1.log (115KB)app.2.log (110KB)app.3.log (105KB) 第4次轮转 - app.log (120KB) → 触发轮转- 现有归档：app.1.log, app.2.log, app.3.log- 删除：app.3.log（最旧，超出max_files）- 批量重命名： app.2.log → app.3.log app.1.log → app.2.log- 归档：app.log → app.1.log- 创建：新app.log 结果：app.log (0KB)app.1.log (120KB)app.2.log (115KB)app.3.log (110KB)（105KB的最旧日志被永久删除） 流程特点：整个轮转过程是同步阻塞的，在轮转完成前不会接受新的日志写入，确保数据一致性。\n四、轮转机制关键细节与避坑指南 4.1 核心硬性规则 文件系统操作原子性 重命名操作：rename_file()函数保证重命名的原子性，避免日志丢失 删除策略：只在重命名前删除目标文件（如果存在），确保不会误删其他文件 权限保留：归档文件继承原始文件的权限设置，不会改变访问控制 文件数量限制 max_files参数包含活跃文件，实际归档文件数量 = max_files - 1 当max_files = 1时，不进行轮转，只截断文件（不推荐） 最小值限制：max_files必须 ≥ 1，否则构造函数抛出异常 文件大小精确控制 轮转阈值基于精确字节计数，不是预估或定时检查 单条日志可能使文件超过max_size，但会在下一条日志写入前触发轮转 max_size必须 \u0026gt; 0，典型值为1MB-100MB 文件重命名的原子性与性能 🔥 重要性能特性：\n串行执行：文件重命名操作是串行执行的，不是并行的 I/O阻塞：在重命名完成前，所有日志写入会被阻塞 大文件风险：当归档文件很大时（如1GB），重命名操作可能耗时数百毫秒 文件系统影响：在NTFS/FAT32（Windows）上比ext4/XFS（Linux）更慢 性能测试数据参考（机械硬盘，10个100MB文件）：\n操作 平均耗时 影响 单次重命名 15-50ms 可接受 10次批量重命名 150-500ms 可能导致请求超时 100次批量重命名 1.5-5s 严重服务中断 优化建议：\n// 生产环境推荐配置：限制max_files auto logger = spdlog::rotating_logger_mt( \u0026#34;prod_logger\u0026#34;, \u0026#34;logs/app.log\u0026#34;, 1024 * 1024 * 100, // 100MB 5, // ⚠️ 严格控制max_files≤10 false ); 4.2 两种核心轮转方式对比 特性 rotating_file_sink（按大小） daily_file_sink（按时间） 轮转触发条件 文件大小达到max_size 日期变化（通常是午夜） 文件命名规则 a.txt, a.1.txt, a.2.txt a_2024-01-14.txt, a_2024-01-15.txt 文件数量控制 通过max_files精确控制 通过max_files控制保留天数 适用场景 高频日志、大小敏感场景 按天分析、时间范围查询场景 性能开销 每次写入检查大小，轮转时重命名多个文件 每次写入检查日期，轮转时只创建新文件 日志连续性 按大小分割，同一天日志可能在多个文件 按天分割，单文件包含完整一天日志 选择建议：高频服务推荐rotating_file_sink，批处理/数据分析推荐daily_file_sink\n4.3 多线程安全版本使用 线程安全保证 rotating_file_sink_mt：使用std::mutex保证线程安全，适用于多线程环境 rotating_file_sink_st：无锁版本，仅适用于单线程环境，性能更高 全局日志器：通过spdlog::rotating_logger_mt()创建的Logger内部使用rotating_file_sink_mt 性能优化建议 // 多线程环境正确用法 auto mt_logger = spdlog::rotating_logger_mt( \u0026#34;thread_safe_logger\u0026#34;, \u0026#34;logs/app.log\u0026#34;, 1048576 * 10, // 10MB 5 ); // 避免频繁构造Logger static auto logger = spdlog::get(\u0026#34;thread_safe_logger\u0026#34;); if (!logger) { logger = spdlog::rotating_logger_mt(\u0026#34;thread_safe_logger\u0026#34;, \u0026#34;logs/app.log\u0026#34;, 1048576 * 10, 5); } 线程安全陷阱 混合使用：不要在同一个日志器中混用_mt和_st版本 外部同步：如果使用_st版本，需要外部保证线程安全 注册表竞争：首次获取Logger时可能有竞争，建议在程序初始化时创建 4.4 关键配置参数详解 参数 类型 默认值 说明 避坑指南 base_filename string - 基础文件名，如\u0026quot;logs/app.log\u0026quot; 确保目录存在，否则创建失败 max_size size_t - 轮转阈值（字节），如1024*1024*5（5MB） 必须 \u0026gt; 0，建议≥4KB（文件系统块大小） max_files size_t - 最大保留文件数（含活跃文件） 必须≥1，建议≥2 rotate_on_open bool false 启动时如文件非空则立即轮转 调试时设为true，生产环境通常false truncate bool false 创建文件时是否截断（daily_file_sink特有） rotating_file_sink忽略此参数 4.5 归档文件属性与访问 文件权限 Linux/Unix：归档文件权限通常为644（rw-r\u0026ndash;r\u0026ndash;） Windows：继承父目录权限，通常为完全控制 权限继承：归档文件继承活跃文件的权限，不会改变ACL 文件状态 只读属性：归档文件在轮转后不会自动设置为只读，仍可被修改 文件锁：轮转过程中不锁定归档文件，外部程序可同时读取 建议操作：不要修改归档文件内容，避免破坏日志完整性 4.6 正确的日志阅读顺序 时间顺序阅读 先读活跃文件：a.txt（最新日志） 按数字升序读取：a.1.txt → a.2.txt → a.3.txt 合并分析：将多个文件内容按时间顺序合并分析 工具推荐 # 按时间顺序合并所有日志 cat app.3.txt app.2.txt app.1.txt app.txt | less # 使用grep搜索特定内容 grep \u0026#34;ERROR\u0026#34; app.*.txt # 使用tail实时监控 tail -f app.txt 常见错误 错误顺序：从a.3.txt开始读，会先看到最旧日志 忽略活跃文件：只读归档文件，错过最新日志 文件覆盖：手动重命名文件破坏轮转机制 4.7 高频避坑知识点 批量重命名的文件系统限制 Windows文件锁：如果其他进程（如日志分析工具）正在读取app.2.log，重命名会失败 解决方案：使用std::filesystem::rename的异常处理，或改用copy+delete策略 NFS/CIFS网络文件系统：重命名操作可能比本地文件系统慢10-100倍 解决方案：避免在共享存储上使用大max_files值 磁盘空间不足：重命名操作不需要额外空间，但如果使用copy+delete策略会需要 极端情况处理 // spdlog源码中的异常处理逻辑（简化版） try { for (int i = max_files_ - 1; i \u0026gt;= 1; --i) { auto src = calc_filename(i); auto target = calc_filename(i + 1); if (os::path_exists(src)) { os::rename(src, target); // 可能抛出异常 } } } catch (const std::exception\u0026amp; ex) { // spdlog会记录错误但不中断程序 SPDLOG_ERROR(\u0026#34;Rotation rename failed: {}\u0026#34;, ex.what()); // ⚠️ 此时文件命名可能不连续，需要人工干预 } Windows特有问题 权限拒绝：高轮转率时，Windows可能因杀毒软件扫描导致重命名失败 解决方案：增加轮转间隔，或使用copytruncate模式（需要外部配置） 路径长度限制：Windows路径最大260字符，超长路径轮转失败 解决方案：使用短路径名，或启用长路径支持 性能陷阱 高频轮转：设置过小的max_size（如1KB）导致频繁轮转，性能急剧下降 建议：max_size ≥ 1MB，根据日志量调整 大量归档文件：max_files过大（如1000）导致轮转时重命名操作耗时 建议：max_files ≤ 10，按需清理旧日志 配置陷阱 目录不存在：基础文件所在目录不存在，创建失败 解决方案：启动前确保目录存在，或使用spdlog的自动创建目录功能 权限不足：程序无权在目标目录创建/删除文件 解决方案：检查目录权限，使用绝对路径 跨平台兼容性 文件锁差异：Linux允许删除打开的文件，Windows不允许 建议：轮转前确保文件关闭，spdlog内部已处理 路径分隔符：Windows使用\\，Linux使用/ 建议：使用spdlog的跨平台路径处理，避免硬编码分隔符 终极建议：在生产环境使用前，务必在测试环境验证轮转机制，特别是边界条件（如磁盘满、权限问题等）。监控轮转操作的耗时，当单次轮转超过100ms时触发告警。\n附录：最佳实践配置示例 #include \u0026#34;spdlog/spdlog.h\u0026#34; #include \u0026#34;spdlog/sinks/rotating_file_sink.h\u0026#34; void setup_production_logger() { try { // 50MB大小限制，保留7个文件（约350MB总空间） auto logger = spdlog::rotating_logger_mt( \u0026#34;prod_logger\u0026#34;, \u0026#34;/var/log/myapp/app.log\u0026#34;, 1024 * 1024 * 50, // 50MB 7, // 7个文件（6个归档 + 1个活跃） false // 启动时不立即轮转 ); // 设置日志级别（生产环境通常WARNING以上） logger-\u0026gt;set_level(spdlog::level::warn); // 设置格式：[时间] [级别] [线程] 消息 logger-\u0026gt;set_pattern(\u0026#34;[%Y-%m-%d %H:%M:%S.%e] [%^%l%$] [%t] %v\u0026#34;); // 注册为默认logger spdlog::set_default_logger(logger); SPDLOG_INFO(\u0026#34;Logger initialized with rotation policy\u0026#34;); } catch (const spdlog_ex\u0026amp; ex) { std::cerr \u0026lt;\u0026lt; \u0026#34;Log initialization failed: \u0026#34; \u0026lt;\u0026lt; ex.what() \u0026lt;\u0026lt; std::endl; throw; } } # 推荐的日志目录结构 /var/log/myapp/ ├── app.log # 当前活跃文件 ├── app.1.log # 最新归档 ├── app.2.log # 次新归档 ├── app.3.log # ... ├── app.4.log ├── app.5.log ├── app.6.log # 最旧归档（max_files=7） └── app.log.rotation_lock # （可选）轮转锁文件 ","date":"14 January, 2025","id":56,"permalink":"/posts/--spdlog-%E6%96%87%E4%BB%B6%E8%BD%AE%E8%BD%ACrotation%E6%A0%B8%E5%BF%83%E6%9C%BA%E5%88%B6%E8%AF%A6%E8%A7%A3/","summary":"一句话总结：新文件进，旧文件退，数字后缀整体+1，超限则删最旧","tags":"spdlog log","title":"📘spdlog 文件轮转（Rotation）核心机制详解"},{"content":"Git Tag 使用与推送技术文档 适用对象：日常使用 Git/GitHub 的研发工程师 使用场景：版本发布、里程碑标记、回滚定位、团队协作\n1. 文档目的 在项目开发与发布过程中，Git Tag（标签） 是标记版本里程碑的核心工具，例如：\nv1.0.0：正式发布版本 v2.1.0-beta：测试版本 v1.0.1：紧急修复版本 本技术文档用于统一团队对 Git Tag 的认知、创建方式、推送流程与规范，避免以下常见问题：\n本地创建 Tag 后无法推送到 GitHub 正式版本误用轻量标签 标签删除不规范导致远程残留 团队成员标签不同步 2. Git Tag 类型说明（重点） Git 支持两种标签类型，必须按场景正确选择。\n2.1 轻量标签（Lightweight Tag） 定义：\n仅是某个 commit 的别名 不包含作者、时间、备注等信息 特点：\n创建速度快 结构简单 不可追溯变更背景 适用场景：\n临时测试版本 内部调试标记 本地个人使用 示例：\ngit tag v1.0.0 2.2 附注标签（Annotated Tag，推荐） 定义：\nGit 官方推荐的标准标签类型 包含完整元数据（作者、时间、备注） 特点：\n信息完整、可追溯 GitHub Releases 页面可直接展示 支持生成发布说明 适用场景（强制）：\n正式版本发布 对外发布版本 生产环境部署版本 示例：\ngit tag -a v1.0.0 -m \u0026#34;正式发布 v1.0.0，新增登录与支付功能\u0026#34; ✅ 规范建议：\n正式版本 必须使用附注标签 轻量标签仅限本地或临时用途 3. 创建 Git Tag 3.1 给最新 Commit 创建标签 轻量标签 git tag v1.0.0 附注标签（推荐） git tag -a v1.0.0 -m \u0026#34;发布 v1.0.0：完成核心功能\u0026#34; 3.2 给历史 Commit 补打标签 适用场景：\n漏打历史版本标签 补充测试/回溯版本 操作步骤 查看提交记录 git log --oneline 给指定 commit 打标签 git tag -a v0.9.0 a3f2d4e -m \u0026#34;补打 v0.9.0 测试版本\u0026#34; 4. 推送 Tag 到 GitHub（核心） ⚠️ 重要说明： Git 默认 不会 推送 Tag，必须显式执行推送命令。\n4.1 推送单个标签（推荐） git push origin v1.0.0 适用场景：\n正式发布 精准控制版本推送 4.2 推送所有本地标签（谨慎） git push origin --tags 风险说明：\n会推送所有未同步的标签 可能包含临时或错误标签 建议：\n使用前确认本地标签干净 5. 查看与同步 Tag 5.1 查看本地标签 git tag # 仅标签名 git tag -n # 标签名 + 备注 5.2 查看远程标签 git ls-remote --tags origin 5.3 拉取远程标签（团队协作必备） git fetch origin --tags # 或 git pull origin --tags 6. 删除 Tag（高风险操作） ❗ 删除顺序错误会导致远程删除失败\n6.1 删除本地标签 git tag -d v1.0.0 6.2 删除远程标签 git push origin --delete v1.0.0 兼容旧写法：\ngit push origin :refs/tags/v1.0.0 7. 常见问题排查 7.1 无权限推送 Tag 原因：未配置 GitHub 权限\n解决方案：\nHTTPS：使用 Personal Access Token SSH：确认 SSH Key 已配置 ssh -T git@github.com 7.2 标签已存在（tag already exists） 原因：远程存在同名标签\n解决方案：\n标签正确：直接使用 标签错误：删除后重新创建 7.3 拉取后本地无标签 git fetch origin --tags 8. 版本号命名规范（强烈推荐） 8.1 语义化版本格式 v主版本号.次版本号.修订号 示例：\nv1.0.0 v1.2.3 v2.0.0-beta 8.2 规则说明 字段 含义 主版本 不兼容变更 次版本 向后兼容的新功能 修订号 Bug 修复 9. 高频命令速查表 # 创建标签 git tag v1.0.0 git tag -a v1.0.0 -m \u0026#34;备注\u0026#34; # 推送标签 git push origin v1.0.0 git push origin --tags # 查看标签 git tag git tag -n git ls-remote --tags origin # 同步标签 git fetch origin --tags # 删除标签 git tag -d v1.0.0 git push origin --delete v1.0.0 10. 总结（团队规范建议） ✅ 正式版本 统一使用附注标签 ✅ 推送标签需显式执行 git push origin tag ✅ 删除标签遵循：先本地 → 后远程 ✅ 标签命名遵循语义化版本规范 该文档可作为：\n团队 Git 规范附件 新人入职必读 Release 流程参考文档 维护人：研发效能 / 平台团队\n","date":"10 January, 2025","id":57,"permalink":"/posts/--git-tag-%E4%BD%BF%E7%94%A8%E4%B8%8E%E6%8E%A8%E9%80%81%E6%8A%80%E6%9C%AF%E6%96%87%E6%A1%A3/","summary":"在项目开发与发布过程中，Git Tag（标签） 是标记版本里程碑的核心工具，例如：","tags":"linux kernel driver intel ethernet i210 PCIe","title":"📘Git Tag 使用与推送技术文档"},{"content":"\n引言：跨语言调用的\u0026quot;隐形陷阱\u0026quot; 如果你曾在C++项目中调用过C语言编写的库，大概率遇到过这样的链接错误：\nundefined reference to `foo(int)\u0026#39; 明明头文件包含了，函数也实现了，为何编译器找不到符号？这背后的罪魁祸首，正是C++的名字修饰（Name Mangling） 机制——C和C++编译器对函数符号的编码规则截然不同，导致跨语言调用时出现\u0026quot;声明与实现对不上号\u0026quot;的尴尬局面。\n而__BEGIN_DECLS与__END_DECLS这对宏，正是解决该问题的\u0026quot;黄金搭档\u0026quot;。它们看似简单，却蕴含着C/C++混合编程的核心设计思想。本文将从头文件设计、源文件实现、软件风格规范三个维度，带你全方位吃透这对宏的使用逻辑与最佳实践。\n一、跨语言兼容的核心矛盾：名字修饰的坑 要理解__BEGIN_DECLS的价值，首先要搞懂C和C++在编译链接阶段的本质差异：\n1. 符号编码规则差异 C编译器（如GCC）：函数名直接作为链接符号，不携带参数类型信息。例如void foo(int)编译后符号为_foo（不同编译器前缀可能不同，但无额外类型编码）； C++编译器（如G++）：为支持函数重载和模板，会将函数名+参数类型编码为复杂符号。例如void foo(int)编译后符号为_Z3fooi（Z表示编码开始，3表示函数名长度，foo是函数名，i表示int类型）。 2. 跨语言调用的致命问题 当C++代码调用C语言实现的函数时：\nC++编译器按自己的规则修饰函数名（如_Z3fooi）； C语言编译的库中，函数符号是原始形态（如_foo）； 链接器找不到匹配的符号，直接报错\u0026quot;未定义引用\u0026quot;。 而C++提供的extern \u0026quot;C\u0026quot;语法，正是用来解决这个问题——它告诉C++编译器：\u0026quot;{}内的代码按C语言规则编译，不要进行名字修饰\u0026quot;。\n3. __BEGIN_DECLS的本质：宏封装的\u0026quot;兼容性桥梁\u0026quot; __BEGIN_DECLS与__END_DECLS本质上是对extern \u0026quot;C\u0026quot;的封装，核心目标是：让同一份声明在C和C++环境下均合法，且编译链接行为一致。\n其原始定义（来自sys/cdefs.h）如下，逻辑非常简洁：\n#ifdef\t__cplusplus # define __BEGIN_DECLS\textern \u0026#34;C\u0026#34; { // C++环境：开启C规则 # define __END_DECLS\t} // C++环境：关闭C规则 #else # define __BEGIN_DECLS // C环境：空宏（无意义） # define __END_DECLS // C环境：空宏（无意义） #endif 二、头文件维度：接口契约的兼容设计 头文件（.h/.hpp）是跨语言调用的\u0026quot;接口契约\u0026quot;，__BEGIN_DECLS的核心应用场景也在这里。一份合格的跨语言头文件，必须满足\u0026quot;C编译器能过，C++编译器也能过\u0026quot;的基本要求。\n1. 头文件使用规范：三大核心原则 （1）宏的引入与位置 必须将__BEGIN_DECLS定义在公共基础头文件（如sys/cdefs.h或项目自定义的common/cdefs.h）中，避免在多个头文件重复定义； 宏调用必须放在头文件保护宏内部，防止重复包含导致extern \u0026quot;C\u0026quot;嵌套（C++编译器不允许重复包裹）。 ✅ 正确示例：\n// foo.h（跨语言头文件） #ifndef FOO_H #define FOO_H #include \u0026lt;sys/cdefs.h\u0026gt; // 引入基础宏定义 __BEGIN_DECLS // 放在保护宏内部，包裹C风格声明 // 跨语言调用的函数声明 int foo(int a); // 跨语言兼容的类型定义 typedef unsigned int u32; // 跨语言兼容的枚举 enum ErrorCode { ERR_OK = 0, ERR_IO = 1 }; __END_DECLS // 结束C风格声明 // C++专属代码（不包裹） template \u0026lt;typename T\u0026gt; T max(T a, T b) { return a \u0026gt; b ? a : b; } class Bar { public: void func(); }; #endif // FOO_H ❌ 错误示例（宏位置错误）：\n// 错误：__BEGIN_DECLS在保护宏外部，可能重复包裹 #include \u0026lt;sys/cdefs.h\u0026gt; __BEGIN_DECLS #ifndef FOO_H #define FOO_H int foo(int a); #endif __END_DECLS （2）包裹范围：仅含C风格声明 extern \u0026quot;C\u0026quot;不支持任何C++专属特性，因此宏包裹的内容必须严格限制为：\n普通函数声明（无重载、无默认参数）； typedef类型定义； 枚举（enum）； 结构体/联合体（不含成员函数）。 ❌ 禁止包裹这些内容：\n__BEGIN_DECLS // 错误：extern \u0026#34;C\u0026#34;不支持模板 template \u0026lt;typename T\u0026gt; T min(T a, T b); // 错误：extern \u0026#34;C\u0026#34;不支持类 class Foo {}; // 错误：extern \u0026#34;C\u0026#34;不支持函数重载 void bar(int a); void bar(float a); __END_DECLS （3）单向兼容：优先满足C语法 头文件设计需遵循\u0026quot;C优先\u0026quot;原则：\nC编译器不认识extern \u0026quot;C\u0026quot;，因此宏在C环境下必须为空； 避免在宏包裹范围内使用C++专属关键字（如bool、namespace）； 若需使用布尔类型，优先用C风格的typedef enum { false, true } bool;而非C++的bool。 2. 头文件保护宏与宏的配合 跨语言头文件必须同时满足：\n头文件保护宏（#ifndef FOO_H）：防止重复包含； __BEGIN_DECLS：保证跨语言兼容； 两者顺序不可颠倒，必须是\u0026quot;保护宏包裹宏调用\u0026quot;。 三、源文件维度：实现层的编译链接适配 源文件（.c/.cpp）是接口的实现载体，其编译规则需与头文件的声明规则严格匹配，否则仍会出现链接错误。\n1. 不同源文件类型的处理方式 源文件类型 编译器 是否需要宏包裹 核心逻辑 .c（C实现） GCC/Clang（C编译器） 不需要（宏展开为空） 直接实现头文件声明的函数，编译后生成C风格符号（无修饰） .cpp（C++实现C接口） G++/Clang++（C++编译器） 不需要（头文件已包裹） 实现头文件中声明的C风格函数，内部可使用C++特性，但对外符号按C规则生成 .cpp（纯C++实现） G++/Clang++（C++编译器） 不需要（与跨语言无关） 实现C++专属逻辑，生成修饰后的符号 示例1：C语言实现C接口（foo.c） #include \u0026#34;foo.h\u0026#34; // 直接实现，无需任何宏修饰 int foo(int a) { return a * 2; } // 实现C风格枚举相关逻辑 enum ErrorCode check_io() { return ERR_OK; } 示例2：C++实现C接口（foo.cpp） #include \u0026#34;foo.h\u0026#34; #include \u0026lt;iostream\u0026gt; // 可使用C++特性 // 实现头文件中声明的C风格函数 int foo(int a) { std::cout \u0026lt;\u0026lt; \u0026#34;C++实现的C接口：\u0026#34; \u0026lt;\u0026lt; a \u0026lt;\u0026lt; std::endl; // 内部允许C++语法 return a * 2; } 2. 编译链接效果验证 通过nm命令查看目标文件的符号表，可直观验证效果：\nC编译（foo.c）：nm foo.o → 输出 00000000 T foo（无修饰符号）； C++编译未加extern \u0026quot;C\u0026quot;：nm foo.o → 输出 00000000 T _Z3fooi（修饰符号）； C++编译加extern \u0026quot;C\u0026quot;：nm foo.o → 输出 00000000 T foo（与C一致）。 3. 源文件避坑指南 不要在.cpp文件的实现中重复包裹__BEGIN_DECLS（冗余且可能触发语法错误）； C风格函数的实现中，避免使用C++专属特性（如重载、模板、类成员访问），即使编译通过也会破坏兼容性； 若同一源文件同时实现C接口和C++接口，需严格区分：C接口的声明必须在头文件的宏包裹范围内，C++接口则无需。 四、软件风格维度：规范与可维护性 __BEGIN_DECLS的使用不仅是技术问题，更是团队协作中\u0026quot;一致性\u0026quot;的体现。良好的风格能降低维护成本，避免踩坑。\n1. 命名风格规范 宏命名：遵循系统库风格，使用双下划线开头（__BEGIN_DECLS），区分普通业务宏； 避免使用单下划线+大写字母开头的宏（如_BEGIN_DECLS）——C标准规定这类标识符为编译器保留，可能引发冲突； 宏定义的注释：必须说明宏的用途，尤其是跨编译器兼容逻辑。 ✅ 规范的宏定义注释：\n// sys/cdefs.h #ifdef __cplusplus // __BEGIN_DECLS: 开启C风格声明（适配C++编译器，禁用名字修饰） # define __BEGIN_DECLS extern \u0026#34;C\u0026#34; { // __END_DECLS: 结束C风格声明 # define __END_DECLS } #else // C编译器无需特殊处理，宏展开为空 # define __BEGIN_DECLS # define __END_DECLS #endif 2. 代码组织风格 宏调用单独占行，包裹的声明保持统一缩进（与项目代码风格一致，通常4个空格）： __BEGIN_DECLS int foo(int a); // 缩进对齐，可读性更强 typedef unsigned int u32; void bar(const char* s); __END_DECLS 避免单行包裹（可读性差）： __BEGIN_DECLS int foo(int a); __END_DECLS // 不推荐 3. 跨平台兼容风格 编译器适配：__cplusplus是C++标准宏，GCC、Clang、MSVC均支持，无需额外区分编译器； MSVC兼容：MSVC的extern \u0026quot;C\u0026quot;语法与GCC一致，但头文件可添加#pragma once增强兼容性（建议与#ifndef双重保护）； 精简条件编译：避免过度嵌套#ifdef（如区分GCC和MSVC），原始的双层#ifdef __cplusplus已足够。 4. 团队协作规范 编码规范明确：在团队《C/C++编码规范》中添加条款：\u0026ldquo;所有跨C/C++调用的头文件，必须使用__BEGIN_DECLS/__END_DECLS包裹C风格声明\u0026rdquo;； 代码审查要点： 宏是否放在头文件保护宏内部； 是否包裹了C++专属特性； 源文件是否重复包裹宏； 文档说明：在项目接口文档中明确标记哪些函数是跨语言兼容的（宏包裹范围内的声明）。 五、典型场景与踩坑实录 1. 高频应用场景 （1）系统库头文件（如Linux的stdio.h） 系统库需要同时支持C和C++程序调用，因此所有标准函数声明均用__BEGIN_DECLS包裹：\n__BEGIN_DECLS int printf(const char *__format, ...); size_t fread(void *__ptr, size_t __size, size_t __nitems, FILE *__stream); __END_DECLS （2）C语言算法库供C++调用 用C编写的高效算法库（如排序、加密），通过宏包裹头文件声明，让C++项目无缝调用，同时保留C的性能优势。\n（3）C++库暴露C接口给其他语言 C++库需提供接口给Python、Go等语言调用时，需通过__BEGIN_DECLS暴露C风格接口（其他语言通常只支持C调用规则）。\n2. 常见踩坑案例 踩坑1：包裹了C++模板 __BEGIN_DECLS template \u0026lt;typename T\u0026gt; T max(T a, T b) { return a \u0026gt; b ? a : b; } __END_DECLS ❌ 错误原因：extern \u0026quot;C\u0026quot;不支持模板，C++编译器直接报错。\n踩坑2：宏在保护宏外部 #include \u0026lt;sys/cdefs.h\u0026gt; __BEGIN_DECLS #ifndef FOO_H #define FOO_H int foo(int a); #endif __END_DECLS ❌ 错误原因：重复包含时，__BEGIN_DECLS会被多次展开，导致extern \u0026quot;C\u0026quot; { {嵌套，触发语法错误。\n踩坑3：C++源文件重复包裹 // foo.cpp #include \u0026#34;foo.h\u0026#34; __BEGIN_DECLS int foo(int a) { return a * 2; } __END_DECLS ❌ 错误原因：头文件已包裹声明，实现层重复包裹会导致extern \u0026quot;C\u0026quot;嵌套，部分编译器报错。\n六、最佳实践总结 头文件最佳实践 基础宏统一定义在公共头文件（如common/cdefs.h），业务头文件仅引用； 宏必须放在头文件保护宏内部，避免重复包裹； 仅包裹C风格声明，排除C++专属特性（模板、类、重载）。 源文件最佳实践 C实现（.c）直接实现声明，无需宏修饰； C++实现C接口（.cpp）仅需头文件声明宏，实现层不重复包裹； 编译后用nm命令验证符号是否为C风格。 风格规范最佳实践 宏命名遵循系统库风格（__BEGIN_DECLS），避免保留标识符冲突； 代码缩进对齐，宏定义添加清晰注释； 团队规范中明确宏的使用规则，代码审查重点覆盖。 结语 __BEGIN_DECLS与__END_DECLS看似简单，却浓缩了C/C++跨语言兼容的核心设计思想——用最小的代码改动，解决最核心的编译链接矛盾。\n它们不仅是技术层面的\u0026quot;兼容性桥梁\u0026quot;，更是团队协作中\u0026quot;一致性\u0026quot;的体现。掌握这对宏的使用逻辑，不仅能避免跨语言调用的常见坑，更能深刻理解C/C++编译链接的本质差异。\n如果你在实际开发中遇到过跨语言兼容的奇葩问题，或者有更好的实践经验，欢迎在评论区留言交流～\n参考资料\nC++标准文档：extern \u0026quot;C\u0026quot;语法规范 Linux内核源码：sys/cdefs.h宏定义 GCC手册：名字修饰与跨语言调用章节 ","date":"18 December, 2024","id":58,"permalink":"/posts/c-c++-%E8%B7%A8%E8%AF%AD%E8%A8%80%E5%85%BC%E5%AE%B9%E7%9A%84%E5%AE%8C%E6%95%B4%E9%80%BB%E8%BE%91/","summary":"","tags":"跨语言开发 编程规范 头文件设计","title":"C C++ 跨语言兼容的完整逻辑"},{"content":"告别全局污染：Modern CMake 的目标级隔离规范 🚀 引言：为什么你的构建系统总在“内耗”？ 如果你维护着一个历史悠久或规模庞大的 C/C++ 项目，你很可能在顶层 CMakeLists.txt 中见到过像 add_definitions 或 include_directories 这样的命令。\n这是一种典型的**目录级作用域（Directory Scope）**配置风格，它带来的问题是灾难性的：全局污染（Global Pollution）。\n全局污染会隐式地将配置强加给所有目标，包括第三方库和测试程序，导致依赖关系模糊、模块间隔离失效，最终演变成难以维护的“技术债务”。\nModern CMake 的核心哲学是 Target-Centric（以目标为中心）。所有的配置和属性都必须精确地绑定到需要它的 Target 上。本规范旨在全面推行目标级隔离，构建一个健壮、可预测的工程体系。\n1. 核心问题清单：必须隔离的 5 大污染源 我们必须将以下五类配置从全局变量或目录级命令中移除，并转移到 Target 属性中。\n1.1. 宏定义污染 (Macro Definitions) 痛点： add_definitions() 将宏（如 -DDEBUG 或 -DVERSION_ABC）扩散到所有子目录下的所有 Target。\n❌ 遗留写法 ✅ 推荐写法 适用场景说明 add_definitions(-DCTRX8188) target_compile_definitions(IfxRfe PRIVATE CTRX8188) 优先使用 PRIVATE，如果该宏被头文件引用，则使用 PUBLIC。宏定义仅作用于指定目标。 1.2. 语言标准污染 (Language Standard) 痛点： CMAKE_C_STANDARD 全局变量强制所有 Target 使用相同的语言标准，限制了新旧代码共存或测试程序使用更高标准。\n❌ 遗留写法 ✅ 推荐写法 A (特性优先) ✅ 推荐写法 B (严格属性) set(CMAKE_C_STANDARD 99) target_compile_features(IfxRfe PRIVATE c_std_99) set_target_properties(IfxRfe PROPERTIES C_STANDARD 99 C_STANDARD_REQUIRED ON) set(CMAKE_CXX_STANDARD 17) target_compile_features(MyApp PRIVATE cxx_std_17) set_target_properties(MyApp PROPERTIES CXX_STANDARD 17 CXX_STANDARD_REQUIRED ON) 1.3. 头文件路径污染 (Include Directories) 痛点： include_directories() 是最危险的命令之一，它将头文件路径暴露给目录下所有 Target，导致隐式依赖。\n❌ 遗留写法 ✅ 推荐写法 适用场景说明 include_directories(./includes) target_include_directories(IfxRfe PUBLIC ./includes) 使用 target_include_directories 明确声明路径是该 Target 的公共接口还是私有实现。 1.4. 编译选项污染 (Compile Options) 痛点： add_compile_options() 或设置 CMAKE_C_FLAGS 会将像 -Wall、-Werror 或 -O3 这样的选项，无差别地应用到所有代码，可能导致第三方库因警告而编译失败。\n❌ 遗留写法 ✅ 推荐写法 适用场景说明 add_compile_options(-Werror) target_compile_options(IfxRfe PRIVATE -Werror) 推荐使用 Generator Expressions 结合配置，如 $\u0026lt;CONFIG:Release\u0026gt;:-O3。 1.5. 链接库污染 (Link Libraries) 痛点： link_libraries() 强制当前目录下的所有 Target 链接某个库。\n❌ 遗留写法 ✅ 推荐写法 适用场景说明 link_libraries(CommonUtils) target_link_libraries(IfxRfe PRIVATE CommonUtils) 使用 target_link_libraries 明确定义依赖拓扑，避免不必要的链接。 2. Target 作用域的精髓：PRIVATE, PUBLIC, INTERFACE 使用 target_... 系列命令时，必须理解三个作用域关键字：\n关键字 作用范围 依赖传递性 适用场景 PRIVATE 仅作用于当前 Target 自身的源码编译。 无。链接我的 Target 不会继承该属性。 内部实现的宏、私有头文件路径、内部编译选项。 PUBLIC 作用于当前 Target 自身，并传递给链接它的 Target。 有。链接我的 Target 会继承该属性。 对外暴露的 API 头文件路径、库使用的语言标准。 INTERFACE 仅传递给链接它的 Target，对当前 Target 自身无效。 有。链接我的 Target 会继承该属性。 纯头文件库（Header-only Library）的属性。 实践原则： 永远遵循最小权限原则。默认使用 PRIVATE，只有当 Target 的公共头文件（API）需要某个配置（如宏或 include 路径）时，才升级为 PUBLIC。\n3. 迁移与审查行动计划 为了使项目构建系统更加健壮，我们制定以下行动计划：\n全局审计：使用脚本工具或手动在项目根目录搜索以下遗留命令：\nadd_definitions include_directories link_libraries set(CMAKE_C_STANDARD 或 set(CMAKE_CXX_STANDARD add_compile_options 定位与下沉：将发现的所有全局/目录级配置，准确地迁移到它们所属的 add_executable() 或 add_library() Target 下方，并使用 target_... 命令替代。\n验证隔离：确保在移除旧的全局配置后，所有依赖关系都是显式且完整的。任何由隐式依赖导致的编译失败都应被视为一次成功的重构，并用 PUBLIC 或 PRIVATE 关系修复。\n","date":"10 December, 2024","id":59,"permalink":"/posts/%E5%91%8A%E5%88%AB%E5%85%A8%E5%B1%80%E6%B1%A1%E6%9F%93modern-cmake-%E7%9A%84%E7%9B%AE%E6%A0%87%E7%BA%A7%E9%9A%94%E7%A6%BB%E8%A7%84%E8%8C%83/","summary":"如果你维护着一个历史悠久或规模庞大的 C/C++ 项目，你很可能在顶层 CMakeLists.txt 中见到过像 add_definitions 或 include_directories 这样的命令。","tags":"CMake 构建系统 C++ 最佳实践","title":"告别全局污染：Modern CMake 的目标级隔离规范"},{"content":"重点学习 errnum 转 str 的实现方法\n妙 妙 妙 perror stdio-common/perror.c\nperror (const char *s) static void perror_internal (FILE *fp, const char *s, int errnum) __strerror_r string/_strerror.c\n/* Return a string describing the errno code in ERRNUM. */ char * __strerror_r (int errnum, char *buf, size_t buflen) { char *err = (char *) __get_errlist (errnum); if (__glibc_unlikely (err == NULL)) { __snprintf (buf, buflen, \u0026#34;%s%d\u0026#34;, _(\u0026#34;Unknown error \u0026#34;), errnum); return buf; } return _(err); } __get_errlist stdio-common/errlist.c\nconst char * __get_errlist (int errnum) { int mapped = ERR_MAP (errnum); if (mapped \u0026gt;= 0 \u0026amp;\u0026amp; mapped \u0026lt; _sys_errlist_internal_len) return _sys_errlist_internal[mapped]; return NULL; } _sys_errlist_internal stdio-common/errlist-data-gen.c\nconst char *const _sys_errlist_internal[] = { #define _S(n, str) [ERR_MAP(n)] = str, #include \u0026lt;errlist.h\u0026gt; #undef _S }; const size_t _sys_errlist_internal_len = array_length (_sys_errlist_internal); _S sysdeps/gnu/errlist.h\n_S(0, N_(\u0026#34;Success\u0026#34;)) #ifdef EPERM /* TRANS Only the owner of the file (or other resource) TRANS or processes with special privileges can perform the operation. */ _S(EPERM, N_(\u0026#34;Operation not permitted\u0026#34;)) #endif #ifdef ENOENT /* TRANS This is a ``file doesn\u0026#39;t exist\u0026#39;\u0026#39; error TRANS for ordinary files that are referenced in contexts where they are TRANS expected to already exist. */ _S(ENOENT, N_(\u0026#34;No such file or directory\u0026#34;)) #endif #ifdef ESRCH /* TRANS No process matches the specified process ID. */ _S(ESRCH, N_(\u0026#34;No such process\u0026#34;)) #endif #ifdef EINTR /* TRANS An asynchronous signal occurred and prevented TRANS completion of the call. When this happens, you should try the call TRANS again. TRANS TRANS You can choose to have functions resume after a signal that is handled, TRANS rather than failing with @code{EINTR}; see @ref{Interrupted TRANS Primitives}. */ _S(EINTR, N_(\u0026#34;Interrupted system call\u0026#34;)) #endif #ifdef EIO /* TRANS Usually used for physical read or write errors. */ _S(EIO, N_(\u0026#34;Input/output error\u0026#34;)) #endif #ifdef ENXIO /* TRANS The system tried to use the device TRANS represented by a file you specified, and it couldn\u0026#39;t find the device. TRANS This can mean that the device file was installed incorrectly, or that TRANS the physical device is missing or not correctly attached to the TRANS computer. */ _S(ENXIO, N_(\u0026#34;No such device or address\u0026#34;)) #endif #ifdef E2BIG /* TRANS Used when the arguments passed to a new program TRANS being executed with one of the @code{exec} functions (@pxref{Executing a TRANS File}) occupy too much memory space. This condition never arises on TRANS @gnuhurdsystems{}. */ _S(E2BIG, N_(\u0026#34;Argument list too long\u0026#34;)) #endif #ifdef ENOEXEC /* TRANS Invalid executable file format. This condition is detected by the TRANS @code{exec} functions; see @ref{Executing a File}. */ _S(ENOEXEC, N_(\u0026#34;Exec format error\u0026#34;)) #endif #ifdef EBADF /* TRANS For example, I/O on a descriptor that has been TRANS closed or reading from a descriptor open only for writing (or vice TRANS versa). */ _S(EBADF, N_(\u0026#34;Bad file descriptor\u0026#34;)) #endif #ifdef ECHILD /* TRANS This error happens on operations that are TRANS supposed to manipulate child processes, when there aren\u0026#39;t any processes TRANS to manipulate. */ _S(ECHILD, N_(\u0026#34;No child processes\u0026#34;)) #endif #ifdef EDEADLK /* TRANS Allocating a system resource would have resulted in a TRANS deadlock situation. The system does not guarantee that it will notice TRANS all such situations. This error means you got lucky and the system TRANS noticed; it might just hang. @xref{File Locks}, for an example. */ _S(EDEADLK, N_(\u0026#34;Resource deadlock avoided\u0026#34;)) #endif #ifdef ENOMEM /* TRANS The system cannot allocate more virtual memory TRANS because its capacity is full. */ _S(ENOMEM, N_(\u0026#34;Cannot allocate memory\u0026#34;)) #endif #ifdef EACCES /* TRANS The file permissions do not allow the attempted operation. */ _S(EACCES, N_(\u0026#34;Permission denied\u0026#34;)) #endif #ifdef EFAULT /* TRANS An invalid pointer was detected. TRANS On @gnuhurdsystems{}, this error never happens; you get a signal instead. */ _S(EFAULT, N_(\u0026#34;Bad address\u0026#34;)) #endif #ifdef ENOTBLK /* TRANS A file that isn\u0026#39;t a block special file was given in a situation that TRANS requires one. For example, trying to mount an ordinary file as a file TRANS system in Unix gives this error. */ _S(ENOTBLK, N_(\u0026#34;Block device required\u0026#34;)) #endif #ifdef EBUSY /* TRANS A system resource that can\u0026#39;t be shared is already in use. TRANS For example, if you try to delete a file that is the root of a currently TRANS mounted filesystem, you get this error. */ _S(EBUSY, N_(\u0026#34;Device or resource busy\u0026#34;)) #endif #ifdef EEXIST /* TRANS An existing file was specified in a context where it only TRANS makes sense to specify a new file. */ _S(EEXIST, N_(\u0026#34;File exists\u0026#34;)) #endif #ifdef EXDEV /* TRANS An attempt to make an improper link across file systems was detected. TRANS This happens not only when you use @code{link} (@pxref{Hard Links}) but TRANS also when you rename a file with @code{rename} (@pxref{Renaming Files}). */ _S(EXDEV, N_(\u0026#34;Invalid cross-device link\u0026#34;)) #endif #ifdef ENODEV /* TRANS The wrong type of device was given to a function that expects a TRANS particular sort of device. */ _S(ENODEV, N_(\u0026#34;No such device\u0026#34;)) #endif #ifdef ENOTDIR /* TRANS A file that isn\u0026#39;t a directory was specified when a directory is required. */ _S(ENOTDIR, N_(\u0026#34;Not a directory\u0026#34;)) #endif #ifdef EISDIR /* TRANS You cannot open a directory for writing, TRANS or create or remove hard links to it. */ _S(EISDIR, N_(\u0026#34;Is a directory\u0026#34;)) #endif #ifdef EINVAL /* TRANS This is used to indicate various kinds of problems TRANS with passing the wrong argument to a library function. */ _S(EINVAL, N_(\u0026#34;Invalid argument\u0026#34;)) #endif #ifdef EMFILE /* TRANS The current process has too many files open and can\u0026#39;t open any more. TRANS Duplicate descriptors do count toward this limit. TRANS TRANS In BSD and GNU, the number of open files is controlled by a resource TRANS limit that can usually be increased. If you get this error, you might TRANS want to increase the @code{RLIMIT_NOFILE} limit or make it unlimited; TRANS @pxref{Limits on Resources}. */ _S(EMFILE, N_(\u0026#34;Too many open files\u0026#34;)) #endif #ifdef ENFILE /* TRANS There are too many distinct file openings in the entire system. Note TRANS that any number of linked channels count as just one file opening; see TRANS @ref{Linked Channels}. This error never occurs on @gnuhurdsystems{}. */ _S(ENFILE, N_(\u0026#34;Too many open files in system\u0026#34;)) #endif #ifdef ENOTTY /* TRANS Inappropriate I/O control operation, such as trying to set terminal TRANS modes on an ordinary file. */ _S(ENOTTY, N_(\u0026#34;Inappropriate ioctl for device\u0026#34;)) #endif #ifdef ETXTBSY /* TRANS An attempt to execute a file that is currently open for writing, or TRANS write to a file that is currently being executed. Often using a TRANS debugger to run a program is considered having it open for writing and TRANS will cause this error. (The name stands for ``text file busy\u0026#39;\u0026#39;.) This TRANS is not an error on @gnuhurdsystems{}; the text is copied as necessary. */ _S(ETXTBSY, N_(\u0026#34;Text file busy\u0026#34;)) #endif #ifdef EFBIG /* TRANS The size of a file would be larger than allowed by the system. */ _S(EFBIG, N_(\u0026#34;File too large\u0026#34;)) #endif #ifdef ENOSPC /* TRANS Write operation on a file failed because the TRANS disk is full. */ _S(ENOSPC, N_(\u0026#34;No space left on device\u0026#34;)) #endif #ifdef ESPIPE /* TRANS Invalid seek operation (such as on a pipe). */ _S(ESPIPE, N_(\u0026#34;Illegal seek\u0026#34;)) #endif #ifdef EROFS /* TRANS An attempt was made to modify something on a read-only file system. */ _S(EROFS, N_(\u0026#34;Read-only file system\u0026#34;)) #endif #ifdef EMLINK /* TRANS The link count of a single file would become too large. TRANS @code{rename} can cause this error if the file being renamed already has TRANS as many links as it can take (@pxref{Renaming Files}). */ _S(EMLINK, N_(\u0026#34;Too many links\u0026#34;)) #endif #ifdef EPIPE /* TRANS There is no process reading from the other end of a pipe. TRANS Every library function that returns this error code also generates a TRANS @code{SIGPIPE} signal; this signal terminates the program if not handled TRANS or blocked. Thus, your program will never actually see @code{EPIPE} TRANS unless it has handled or blocked @code{SIGPIPE}. */ _S(EPIPE, N_(\u0026#34;Broken pipe\u0026#34;)) #endif #ifdef EDOM /* TRANS Used by mathematical functions when an argument value does TRANS not fall into the domain over which the function is defined. */ _S(EDOM, N_(\u0026#34;Numerical argument out of domain\u0026#34;)) #endif #ifdef ERANGE /* TRANS Used by mathematical functions when the result value is TRANS not representable because of overflow or underflow. */ _S(ERANGE, N_(\u0026#34;Numerical result out of range\u0026#34;)) #endif #ifdef EAGAIN /* TRANS The call might work if you try again TRANS later. The macro @code{EWOULDBLOCK} is another name for @code{EAGAIN}; TRANS they are always the same in @theglibc{}. TRANS TRANS This error can happen in a few different situations: TRANS TRANS @itemize @bullet TRANS @item TRANS An operation that would block was attempted on an object that has TRANS non-blocking mode selected. Trying the same operation again will block TRANS until some external condition makes it possible to read, write, or TRANS connect (whatever the operation). You can use @code{select} to find out TRANS when the operation will be possible; @pxref{Waiting for I/O}. TRANS TRANS @strong{Portability Note:} In many older Unix systems, this condition TRANS was indicated by @code{EWOULDBLOCK}, which was a distinct error code TRANS different from @code{EAGAIN}. To make your program portable, you should TRANS check for both codes and treat them the same. TRANS TRANS @item TRANS A temporary resource shortage made an operation impossible. @code{fork} TRANS can return this error. It indicates that the shortage is expected to TRANS pass, so your program can try the call again later and it may succeed. TRANS It is probably a good idea to delay for a few seconds before trying it TRANS again, to allow time for other processes to release scarce resources. TRANS Such shortages are usually fairly serious and affect the whole system, TRANS so usually an interactive program should report the error to the user TRANS and return to its command loop. TRANS @end itemize */ _S(EAGAIN, N_(\u0026#34;Resource temporarily unavailable\u0026#34;)) #endif #ifdef EINPROGRESS /* TRANS An operation that cannot complete immediately was initiated on an object TRANS that has non-blocking mode selected. Some functions that must always TRANS block (such as @code{connect}; @pxref{Connecting}) never return TRANS @code{EAGAIN}. Instead, they return @code{EINPROGRESS} to indicate that TRANS the operation has begun and will take some time. Attempts to manipulate TRANS the object before the call completes return @code{EALREADY}. You can TRANS use the @code{select} function to find out when the pending operation TRANS has completed; @pxref{Waiting for I/O}. */ _S(EINPROGRESS, N_(\u0026#34;Operation now in progress\u0026#34;)) #endif #ifdef EALREADY /* TRANS An operation is already in progress on an object that has non-blocking TRANS mode selected. */ _S(EALREADY, N_(\u0026#34;Operation already in progress\u0026#34;)) #endif #ifdef ENOTSOCK /* TRANS A file that isn\u0026#39;t a socket was specified when a socket is required. */ _S(ENOTSOCK, N_(\u0026#34;Socket operation on non-socket\u0026#34;)) #endif #ifdef EMSGSIZE /* TRANS The size of a message sent on a socket was larger than the supported TRANS maximum size. */ _S(EMSGSIZE, N_(\u0026#34;Message too long\u0026#34;)) #endif #ifdef EPROTOTYPE /* TRANS The socket type does not support the requested communications protocol. */ _S(EPROTOTYPE, N_(\u0026#34;Protocol wrong type for socket\u0026#34;)) #endif #ifdef ENOPROTOOPT /* TRANS You specified a socket option that doesn\u0026#39;t make sense for the TRANS particular protocol being used by the socket. @xref{Socket Options}. */ _S(ENOPROTOOPT, N_(\u0026#34;Protocol not available\u0026#34;)) #endif #ifdef EPROTONOSUPPORT /* TRANS The socket domain does not support the requested communications protocol TRANS (perhaps because the requested protocol is completely invalid). TRANS @xref{Creating a Socket}. */ _S(EPROTONOSUPPORT, N_(\u0026#34;Protocol not supported\u0026#34;)) #endif #ifdef ESOCKTNOSUPPORT /* TRANS The socket type is not supported. */ _S(ESOCKTNOSUPPORT, N_(\u0026#34;Socket type not supported\u0026#34;)) #endif #ifdef EOPNOTSUPP /* TRANS The operation you requested is not supported. Some socket functions TRANS don\u0026#39;t make sense for all types of sockets, and others may not be TRANS implemented for all communications protocols. On @gnuhurdsystems{}, this TRANS error can happen for many calls when the object does not support the TRANS particular operation; it is a generic indication that the server knows TRANS nothing to do for that call. */ _S(EOPNOTSUPP, N_(\u0026#34;Operation not supported\u0026#34;)) #endif #ifdef EPFNOSUPPORT /* TRANS The socket communications protocol family you requested is not supported. */ _S(EPFNOSUPPORT, N_(\u0026#34;Protocol family not supported\u0026#34;)) #endif #ifdef EAFNOSUPPORT /* TRANS The address family specified for a socket is not supported; it is TRANS inconsistent with the protocol being used on the socket. @xref{Sockets}. */ _S(EAFNOSUPPORT, N_(\u0026#34;Address family not supported by protocol\u0026#34;)) #endif #ifdef EADDRINUSE /* TRANS The requested socket address is already in use. @xref{Socket Addresses}. */ _S(EADDRINUSE, N_(\u0026#34;Address already in use\u0026#34;)) #endif #ifdef EADDRNOTAVAIL /* TRANS The requested socket address is not available; for example, you tried TRANS to give a socket a name that doesn\u0026#39;t match the local host name. TRANS @xref{Socket Addresses}. */ _S(EADDRNOTAVAIL, N_(\u0026#34;Cannot assign requested address\u0026#34;)) #endif #ifdef ENETDOWN /* TRANS A socket operation failed because the network was down. */ _S(ENETDOWN, N_(\u0026#34;Network is down\u0026#34;)) #endif #ifdef ENETUNREACH /* TRANS A socket operation failed because the subnet containing the remote host TRANS was unreachable. */ _S(ENETUNREACH, N_(\u0026#34;Network is unreachable\u0026#34;)) #endif #ifdef ENETRESET /* TRANS A network connection was reset because the remote host crashed. */ _S(ENETRESET, N_(\u0026#34;Network dropped connection on reset\u0026#34;)) #endif #ifdef ECONNABORTED /* TRANS A network connection was aborted locally. */ _S(ECONNABORTED, N_(\u0026#34;Software caused connection abort\u0026#34;)) #endif #ifdef ECONNRESET /* TRANS A network connection was closed for reasons outside the control of the TRANS local host, such as by the remote machine rebooting or an unrecoverable TRANS protocol violation. */ _S(ECONNRESET, N_(\u0026#34;Connection reset by peer\u0026#34;)) #endif #ifdef ENOBUFS /* TRANS The kernel\u0026#39;s buffers for I/O operations are all in use. In GNU, this TRANS error is always synonymous with @code{ENOMEM}; you may get one or the TRANS other from network operations. */ _S(ENOBUFS, N_(\u0026#34;No buffer space available\u0026#34;)) #endif #ifdef EISCONN /* TRANS You tried to connect a socket that is already connected. TRANS @xref{Connecting}. */ _S(EISCONN, N_(\u0026#34;Transport endpoint is already connected\u0026#34;)) #endif #ifdef ENOTCONN /* TRANS The socket is not connected to anything. You get this error when you TRANS try to transmit data over a socket, without first specifying a TRANS destination for the data. For a connectionless socket (for datagram TRANS protocols, such as UDP), you get @code{EDESTADDRREQ} instead. */ _S(ENOTCONN, N_(\u0026#34;Transport endpoint is not connected\u0026#34;)) #endif #ifdef EDESTADDRREQ /* TRANS No default destination address was set for the socket. You get this TRANS error when you try to transmit data over a connectionless socket, TRANS without first specifying a destination for the data with @code{connect}. */ _S(EDESTADDRREQ, N_(\u0026#34;Destination address required\u0026#34;)) #endif #ifdef ESHUTDOWN /* TRANS The socket has already been shut down. */ _S(ESHUTDOWN, N_(\u0026#34;Cannot send after transport endpoint shutdown\u0026#34;)) #endif #ifdef ETOOMANYREFS _S(ETOOMANYREFS, N_(\u0026#34;Too many references: cannot splice\u0026#34;)) #endif #ifdef ETIMEDOUT /* TRANS A socket operation with a specified timeout received no response during TRANS the timeout period. */ _S(ETIMEDOUT, N_(\u0026#34;Connection timed out\u0026#34;)) #endif #ifdef ECONNREFUSED /* TRANS A remote host refused to allow the network connection (typically because TRANS it is not running the requested service). */ _S(ECONNREFUSED, N_(\u0026#34;Connection refused\u0026#34;)) #endif #ifdef ELOOP /* TRANS Too many levels of symbolic links were encountered in looking up a file name. TRANS This often indicates a cycle of symbolic links. */ _S(ELOOP, N_(\u0026#34;Too many levels of symbolic links\u0026#34;)) #endif #ifdef ENAMETOOLONG /* TRANS Filename too long (longer than @code{PATH_MAX}; @pxref{Limits for TRANS Files}) or host name too long (in @code{gethostname} or TRANS @code{sethostname}; @pxref{Host Identification}). */ _S(ENAMETOOLONG, N_(\u0026#34;File name too long\u0026#34;)) #endif #ifdef EHOSTDOWN /* TRANS The remote host for a requested network connection is down. */ _S(EHOSTDOWN, N_(\u0026#34;Host is down\u0026#34;)) #endif /* TRANS The remote host for a requested network connection is not reachable. */ #ifdef EHOSTUNREACH _S(EHOSTUNREACH, N_(\u0026#34;No route to host\u0026#34;)) #endif #ifdef ENOTEMPTY /* TRANS Directory not empty, where an empty directory was expected. Typically, TRANS this error occurs when you are trying to delete a directory. */ _S(ENOTEMPTY, N_(\u0026#34;Directory not empty\u0026#34;)) #endif #ifdef EUSERS /* TRANS The file quota system is confused because there are too many users. TRANS @c This can probably happen in a GNU system when using NFS. */ _S(EUSERS, N_(\u0026#34;Too many users\u0026#34;)) #endif #ifdef EDQUOT /* TRANS The user\u0026#39;s disk quota was exceeded. */ _S(EDQUOT, N_(\u0026#34;Disk quota exceeded\u0026#34;)) #endif #ifdef ESTALE /* TRANS This indicates an internal confusion in the TRANS file system which is due to file system rearrangements on the server host TRANS for NFS file systems or corruption in other file systems. TRANS Repairing this condition usually requires unmounting, possibly repairing TRANS and remounting the file system. */ _S(ESTALE, N_(\u0026#34;Stale file handle\u0026#34;)) #endif #ifdef EREMOTE /* TRANS An attempt was made to NFS-mount a remote file system with a file name that TRANS already specifies an NFS-mounted file. TRANS (This is an error on some operating systems, but we expect it to work TRANS properly on @gnuhurdsystems{}, making this error code impossible.) */ _S(EREMOTE, N_(\u0026#34;Object is remote\u0026#34;)) #endif #ifdef ENOLCK /* TRANS This is used by the file locking facilities; see TRANS @ref{File Locks}. This error is never generated by @gnuhurdsystems{}, but TRANS it can result from an operation to an NFS server running another TRANS operating system. */ _S(ENOLCK, N_(\u0026#34;No locks available\u0026#34;)) #endif #ifdef ENOSYS /* TRANS This indicates that the function called is TRANS not implemented at all, either in the C library itself or in the TRANS operating system. When you get this error, you can be sure that this TRANS particular function will always fail with @code{ENOSYS} unless you TRANS install a new version of the C library or the operating system. */ _S(ENOSYS, N_(\u0026#34;Function not implemented\u0026#34;)) #endif #ifdef EILSEQ /* TRANS While decoding a multibyte character the function came along an invalid TRANS or an incomplete sequence of bytes or the given wide character is invalid. */ _S(EILSEQ, N_(\u0026#34;Invalid or incomplete multibyte or wide character\u0026#34;)) #endif #ifdef EBADMSG _S(EBADMSG, N_(\u0026#34;Bad message\u0026#34;)) #endif #ifdef EIDRM _S(EIDRM, N_(\u0026#34;Identifier removed\u0026#34;)) #endif #ifdef EMULTIHOP _S(EMULTIHOP, N_(\u0026#34;Multihop attempted\u0026#34;)) #endif #ifdef ENODATA _S(ENODATA, N_(\u0026#34;No data available\u0026#34;)) #endif #ifdef ENOLINK _S(ENOLINK, N_(\u0026#34;Link has been severed\u0026#34;)) #endif #ifdef ENOMSG _S(ENOMSG, N_(\u0026#34;No message of desired type\u0026#34;)) #endif #ifdef ENOSR _S(ENOSR, N_(\u0026#34;Out of streams resources\u0026#34;)) #endif #ifdef ENOSTR _S(ENOSTR, N_(\u0026#34;Device not a stream\u0026#34;)) #endif #ifdef EOVERFLOW _S(EOVERFLOW, N_(\u0026#34;Value too large for defined data type\u0026#34;)) #endif #ifdef EPROTO _S(EPROTO, N_(\u0026#34;Protocol error\u0026#34;)) #endif #ifdef ETIME _S(ETIME, N_(\u0026#34;Timer expired\u0026#34;)) #endif #ifdef ECANCELED /* TRANS An asynchronous operation was canceled before it TRANS completed. @xref{Asynchronous I/O}. When you call @code{aio_cancel}, TRANS the normal result is for the operations affected to complete with this TRANS error; @pxref{Cancel AIO Operations}. */ _S(ECANCELED, N_(\u0026#34;Operation canceled\u0026#34;)) #endif #ifdef EOWNERDEAD _S(EOWNERDEAD, N_(\u0026#34;Owner died\u0026#34;)) #endif #ifdef ENOTRECOVERABLE _S(ENOTRECOVERABLE, N_(\u0026#34;State not recoverable\u0026#34;)) #endif #ifdef ERESTART _S(ERESTART, N_(\u0026#34;Interrupted system call should be restarted\u0026#34;)) #endif #ifdef ECHRNG _S(ECHRNG, N_(\u0026#34;Channel number out of range\u0026#34;)) #endif #ifdef EL2NSYNC _S(EL2NSYNC, N_(\u0026#34;Level 2 not synchronized\u0026#34;)) #endif #ifdef EL3HLT _S(EL3HLT, N_(\u0026#34;Level 3 halted\u0026#34;)) #endif #ifdef EL3RST _S(EL3RST, N_(\u0026#34;Level 3 reset\u0026#34;)) #endif #ifdef ELNRNG _S(ELNRNG, N_(\u0026#34;Link number out of range\u0026#34;)) #endif #ifdef EUNATCH _S(EUNATCH, N_(\u0026#34;Protocol driver not attached\u0026#34;)) #endif #ifdef ENOCSI _S(ENOCSI, N_(\u0026#34;No CSI structure available\u0026#34;)) #endif #ifdef EL2HLT _S(EL2HLT, N_(\u0026#34;Level 2 halted\u0026#34;)) #endif #ifdef EBADE _S(EBADE, N_(\u0026#34;Invalid exchange\u0026#34;)) #endif #ifdef EBADR _S(EBADR, N_(\u0026#34;Invalid request descriptor\u0026#34;)) #endif #ifdef EXFULL _S(EXFULL, N_(\u0026#34;Exchange full\u0026#34;)) #endif #ifdef ENOANO _S(ENOANO, N_(\u0026#34;No anode\u0026#34;)) #endif #ifdef EBADRQC _S(EBADRQC, N_(\u0026#34;Invalid request code\u0026#34;)) #endif #ifdef EBADSLT _S(EBADSLT, N_(\u0026#34;Invalid slot\u0026#34;)) #endif #if defined EDEADLOCK \u0026amp;\u0026amp; EDEADLOCK != EDEADLK _S (EDEADLOCK, N_ (\u0026#34;File locking deadlock error\u0026#34;)) #endif #ifdef EBFONT _S(EBFONT, N_(\u0026#34;Bad font file format\u0026#34;)) #endif #ifdef ENONET _S(ENONET, N_(\u0026#34;Machine is not on the network\u0026#34;)) #endif #ifdef ENOPKG _S(ENOPKG, N_(\u0026#34;Package not installed\u0026#34;)) #endif #ifdef EADV _S(EADV, N_(\u0026#34;Advertise error\u0026#34;)) #endif #ifdef ESRMNT _S(ESRMNT, N_(\u0026#34;Srmount error\u0026#34;)) #endif #ifdef ECOMM _S(ECOMM, N_(\u0026#34;Communication error on send\u0026#34;)) #endif #ifdef EDOTDOT _S(EDOTDOT, N_(\u0026#34;RFS specific error\u0026#34;)) #endif #ifdef ENOTUNIQ _S(ENOTUNIQ, N_(\u0026#34;Name not unique on network\u0026#34;)) #endif #ifdef EBADFD _S(EBADFD, N_(\u0026#34;File descriptor in bad state\u0026#34;)) #endif #ifdef EREMCHG _S(EREMCHG, N_(\u0026#34;Remote address changed\u0026#34;)) #endif #ifdef ELIBACC _S(ELIBACC, N_(\u0026#34;Can not access a needed shared library\u0026#34;)) #endif #ifdef ELIBBAD _S(ELIBBAD, N_(\u0026#34;Accessing a corrupted shared library\u0026#34;)) #endif #ifdef ELIBSCN _S(ELIBSCN, N_(\u0026#34;.lib section in a.out corrupted\u0026#34;)) #endif #ifdef ELIBMAX _S(ELIBMAX, N_(\u0026#34;Attempting to link in too many shared libraries\u0026#34;)) #endif #ifdef ELIBEXEC _S(ELIBEXEC, N_(\u0026#34;Cannot exec a shared library directly\u0026#34;)) #endif #ifdef ESTRPIPE _S(ESTRPIPE, N_(\u0026#34;Streams pipe error\u0026#34;)) #endif #ifdef EUCLEAN _S(EUCLEAN, N_(\u0026#34;Structure needs cleaning\u0026#34;)) #endif #ifdef ENOTNAM _S(ENOTNAM, N_(\u0026#34;Not a XENIX named type file\u0026#34;)) #endif #ifdef ENAVAIL _S(ENAVAIL, N_(\u0026#34;No XENIX semaphores available\u0026#34;)) #endif #ifdef EISNAM _S(EISNAM, N_(\u0026#34;Is a named type file\u0026#34;)) #endif #ifdef EREMOTEIO _S(EREMOTEIO, N_(\u0026#34;Remote I/O error\u0026#34;)) #endif #ifdef ENOMEDIUM _S(ENOMEDIUM, N_(\u0026#34;No medium found\u0026#34;)) #endif #ifdef EMEDIUMTYPE _S(EMEDIUMTYPE, N_(\u0026#34;Wrong medium type\u0026#34;)) #endif #ifdef ENOKEY _S(ENOKEY, N_(\u0026#34;Required key not available\u0026#34;)) #endif #ifdef EKEYEXPIRED _S(EKEYEXPIRED, N_(\u0026#34;Key has expired\u0026#34;)) #endif #ifdef EKEYREVOKED _S(EKEYREVOKED, N_(\u0026#34;Key has been revoked\u0026#34;)) #endif #ifdef EKEYREJECTED _S(EKEYREJECTED, N_(\u0026#34;Key was rejected by service\u0026#34;)) #endif #ifdef ERFKILL _S(ERFKILL, N_(\u0026#34;Operation not possible due to RF-kill\u0026#34;)) #endif #ifdef EHWPOISON _S(EHWPOISON, N_(\u0026#34;Memory page has hardware error\u0026#34;)) #endif #ifdef EBADRPC _S(EBADRPC, N_(\u0026#34;RPC struct is bad\u0026#34;)) #endif #ifdef EFTYPE /* TRANS The file was the wrong type for the TRANS operation, or a data file had the wrong format. TRANS TRANS On some systems @code{chmod} returns this error if you try to set the TRANS sticky bit on a non-directory file; @pxref{Setting Permissions}. */ _S(EFTYPE, N_(\u0026#34;Inappropriate file type or format\u0026#34;)) #endif #ifdef EPROCUNAVAIL _S(EPROCUNAVAIL, N_(\u0026#34;RPC bad procedure for program\u0026#34;)) #endif #ifdef EAUTH _S(EAUTH, N_(\u0026#34;Authentication error\u0026#34;)) #endif #ifdef EDIED /* TRANS On @gnuhurdsystems{}, opening a file returns this error when the file is TRANS translated by a program and the translator program dies while starting TRANS up, before it has connected to the file. */ _S(EDIED, N_(\u0026#34;Translator died\u0026#34;)) #endif #ifdef ERPCMISMATCH _S(ERPCMISMATCH, N_(\u0026#34;RPC version wrong\u0026#34;)) #endif #ifdef EGREGIOUS /* TRANS You did @strong{what}? */ _S(EGREGIOUS, N_(\u0026#34;You really blew it this time\u0026#34;)) #endif #ifdef EPROCLIM /* TRANS This means that the per-user limit on new process would be exceeded by TRANS an attempted @code{fork}. @xref{Limits on Resources}, for details on TRANS the @code{RLIMIT_NPROC} limit. */ _S(EPROCLIM, N_(\u0026#34;Too many processes\u0026#34;)) #endif #ifdef EGRATUITOUS /* TRANS This error code has no purpose. */ _S(EGRATUITOUS, N_(\u0026#34;Gratuitous error\u0026#34;)) #endif #if defined (ENOTSUP) \u0026amp;\u0026amp; ENOTSUP != EOPNOTSUPP /* TRANS A function returns this error when certain parameter TRANS values are valid, but the functionality they request is not available. TRANS This can mean that the function does not implement a particular command TRANS or option value or flag bit at all. For functions that operate on some TRANS object given in a parameter, such as a file descriptor or a port, it TRANS might instead mean that only @emph{that specific object} (file TRANS descriptor, port, etc.) is unable to support the other parameters given; TRANS different file descriptors might support different ranges of parameter TRANS values. TRANS TRANS If the entire function is not available at all in the implementation, TRANS it returns @code{ENOSYS} instead. */ _S(ENOTSUP, N_(\u0026#34;Not supported\u0026#34;)) #endif #ifdef EPROGMISMATCH _S(EPROGMISMATCH, N_(\u0026#34;RPC program version wrong\u0026#34;)) #endif #ifdef EBACKGROUND /* TRANS On @gnuhurdsystems{}, servers supporting the @code{term} protocol return TRANS this error for certain operations when the caller is not in the TRANS foreground process group of the terminal. Users do not usually see this TRANS error because functions such as @code{read} and @code{write} translate TRANS it into a @code{SIGTTIN} or @code{SIGTTOU} signal. @xref{Job Control}, TRANS for information on process groups and these signals. */ _S(EBACKGROUND, N_(\u0026#34;Inappropriate operation for background process\u0026#34;)) #endif #ifdef EIEIO /* TRANS Go home and have a glass of warm, dairy-fresh milk. TRANS @c Okay. Since you are dying to know, I\u0026#39;ll tell you. TRANS @c This is a joke, obviously. There is a children\u0026#39;s song which begins, TRANS @c \u0026#34;Old McDonald had a farm, e-i-e-i-o.\u0026#34; Every time I see the (real) TRANS @c errno macro EIO, I think about that song. Probably most of my TRANS @c compatriots who program on Unix do, too. One of them must have stayed TRANS @c up a little too late one night and decided to add it to Hurd or Glibc. TRANS @c Whoever did it should be castigated, but it made me laugh. TRANS @c --jtobey@channel1.com TRANS @c TRANS @c \u0026#34;bought the farm\u0026#34; means \u0026#34;died\u0026#34;. -jtobey TRANS @c TRANS @c Translators, please do not translate this litteraly, translate it into TRANS @c an idiomatic funny way of saying that the computer died. */ _S(EIEIO, N_(\u0026#34;Computer bought the farm\u0026#34;)) #endif #if defined (EWOULDBLOCK) \u0026amp;\u0026amp; EWOULDBLOCK != EAGAIN /* TRANS In @theglibc{}, this is another name for @code{EAGAIN} (above). TRANS The values are always the same, on every operating system. TRANS TRANS C libraries in many older Unix systems have @code{EWOULDBLOCK} as a TRANS separate error code. */ _S(EWOULDBLOCK, N_(\u0026#34;Operation would block\u0026#34;)) #endif #ifdef ENEEDAUTH _S(ENEEDAUTH, N_(\u0026#34;Need authenticator\u0026#34;)) #endif #ifdef ED /* TRANS The experienced user will know what is wrong. TRANS @c This error code is a joke. Its perror text is part of the joke. TRANS @c Don\u0026#39;t change it. */ _S(ED, N_(\u0026#34;?\u0026#34;)) #endif #ifdef EPROGUNAVAIL _S(EPROGUNAVAIL, N_(\u0026#34;RPC program not available\u0026#34;)) #endif ","date":"1 January, 2024","id":60,"permalink":"/posts/perror_func/","summary":"重点学习 errnum 转 str 的实现方法","tags":"c perror errnum glibc RTFSC","title":"perror"},{"content":"配置前的状态 windows 11 + wsl + ubuntu 18.04 windows 可以识别 adb devices\nC:\\Users\u0026gt;adb devices List of devices attached fada-018b4209f24d0001 device wsl 识别不到 adb devices\nluyang@LUYANG:~$ adb devices * daemon not running; starting now at tcp:5037 * daemon started successfully List of devices attached Windows 安装工具包 windows 安装 usbipd-win\nWSL 安装工具包 WSL ubuntu 安装 adb 工具\nsudo apt install android-tools-adb 在WSL中，安装 USB/IP 的用户空间工具和 USB 硬件标识符的数据库。\nsudo apt install linux-tools-5.15.0-87-generic hwdata # 注意 linux-tools 相应的要改成你实际安装的版本 sudo update-alternatives --install /usr/local/bin/usbip usbip /usr/lib/linux-tools/5.15.0-87-generic/usbip 20 关于 linux-tools 查看当前 ubuntu 系统版本支持的 linux-tools generic版本\n~$ sudo apt-cache search linux-tools linux-aws-tools-5.15.0-1004 - Linux kernel version specific tools for version 5.15.0-1004 linux-azure-tools-5.15.0-1003 - Linux kernel version specific tools for version 5.15.0-1003 linux-gcp-tools-5.15.0-1003 - Linux kernel version specific tools for version 5.15.0-1003 linux-gke-tools-5.15.0-1002 - Linux kernel version specific tools for version 5.15.0-1002 linux-ibm-tools-5.15.0-1002 - Linux kernel version specific tools for version 5.15.0-1002 linux-intel-iotg-tools-5.15.0-1004 - Linux kernel version specific tools for version 5.15.0-1004 linux-kvm-tools-5.15.0-1004 - Linux kernel version specific tools for version 5.15.0-1004 linux-lowlatency-tools-5.15.0-24 - Linux kernel version specific tools for version 5.15.0-24 linux-oem-5.17-tools-5.17.0-1003 - Linux kernel version specific tools for version 5.17.0-1003 linux-oracle-tools-5.15.0-1002 - Oracle Linux kernel version specific tools for version 5.15.0-1002 linux-tools-5.15.0-1002-gke - Linux kernel version specific tools for version 5.15.0-1002 linux-tools-5.15.0-1002-ibm - Linux kernel version specific tools for version 5.15.0-1002 linux-tools-5.15.0-1002-oracle - Oracle Linux kernel version specific tools for version 5.15.0-1002 linux-tools-5.15.0-1003-azure - Linux kernel version specific tools for version 5.15.0-1003 linux-tools-5.15.0-1003-gcp - Linux kernel version specific tools for version 5.15.0-1003 linux-tools-5.15.0-1004-aws - Linux kernel version specific tools for version 5.15.0-1004 linux-tools-5.15.0-1004-intel-iotg - Linux kernel version specific tools for version 5.15.0-1004 linux-tools-5.15.0-1004-kvm - Linux kernel version specific tools for version 5.15.0-1004 linux-tools-5.15.0-24-lowlatency - Linux kernel version specific tools for version 5.15.0-24 linux-tools-5.15.0-25 - Linux kernel version specific tools for version 5.15.0-25 linux-tools-5.15.0-25-generic - Linux kernel version specific tools for version 5.15.0-25 linux-tools-5.17.0-1003-oem - Linux kernel version specific tools for version 5.17.0-1003 linux-tools-aws - Linux kernel versioned tools for Amazon Web Services (AWS) systems. linux-tools-azure - Linux kernel versioned tools for Azure systems. linux-tools-common - Linux kernel version specific tools for version 5.15.0 linux-tools-gcp - Google Cloud Platform (GCP) Linux kernel tools linux-tools-generic - Generic Linux kernel tools linux-tools-generic-hwe-20.04 - Generic Linux kernel tools (dummy transitional package) linux-tools-generic-hwe-20.04-edge - Generic Linux kernel tools (dummy transitional package) linux-tools-generic-hwe-22.04 - Generic Linux kernel tools linux-tools-generic-hwe-22.04-edge - Generic Linux kernel tools linux-tools-gke - Linux kernel versioned tools for gke systems. linux-tools-gke-5.15 - Linux kernel versioned tools for gke systems. linux-tools-host - Linux kernel VM host tools linux-tools-ibm - IBM Cloud Platform (ibm) Linux kernel tools linux-tools-intel-iotg - Intel-Iotg Linux kernel tools linux-tools-kvm - Linux kernel versioned tools for virtual systems. linux-tools-lowlatency - lowlatency Linux kernel tools linux-tools-lowlatency-hwe-20.04 - lowlatency Linux kernel tools (dummy transitional package) linux-tools-lowlatency-hwe-20.04-edge - lowlatency Linux kernel tools (dummy transitional package) linux-tools-lowlatency-hwe-22.04 - lowlatency Linux kernel tools linux-tools-lowlatency-hwe-22.04-edge - lowlatency Linux kernel tools linux-tools-oem-20.04 - OEM Linux kernel tools (dummy transitional package) linux-tools-oem-22.04 - OEM Linux kernel tools linux-tools-oracle - Linux kernel versioned tools for Oracle systems. linux-tools-virtual - Virtual Linux kernel tools linux-tools-virtual-hwe-20.04 - Virtual Linux kernel tools (dummy transitional package) linux-tools-virtual-hwe-20.04-edge - Virtual Linux kernel tools (dummy transitional package) linux-tools-virtual-hwe-22.04 - Virtual Linux kernel tools linux-tools-virtual-hwe-22.04-edge - Virtual Linux kernel tools linux-aws-5.19-tools-5.19.0-1024 - Linux kernel version specific tools for version 5.19.0-1024 linux-aws-5.19-tools-5.19.0-1025 - Linux kernel version specific tools for version 5.19.0-1025 linux-aws-5.19-tools-5.19.0-1026 - Linux kernel version specific tools for version 5.19.0-1026 linux-aws-5.19-tools-5.19.0-1027 - Linux kernel version specific tools for version 5.19.0-1027 linux-aws-5.19-tools-5.19.0-1028 - Linux kernel version specific tools for version 5.19.0-1028 linux-aws-5.19-tools-5.19.0-1029 - Linux kernel version specific tools for version 5.19.0-1029 linux-aws-6.2-tools-6.2.0-1005 - Linux kernel version specific tools for version 6.2.0-1005 linux-aws-6.2-tools-6.2.0-1006 - Linux kernel version specific tools for version 6.2.0-1006 linux-aws-6.2-tools-6.2.0-1007 - Linux kernel version specific tools for version 6.2.0-1007 linux-aws-6.2-tools-6.2.0-1008 - Linux kernel version specific tools for version 6.2.0-1008 linux-aws-6.2-tools-6.2.0-1009 - Linux kernel version specific tools for version 6.2.0-1009 linux-aws-6.2-tools-6.2.0-1010 - Linux kernel version specific tools for version 6.2.0-1010 linux-aws-6.2-tools-6.2.0-1011 - Linux kernel version specific tools for version 6.2.0-1011 linux-aws-6.2-tools-6.2.0-1012 - Linux kernel version specific tools for version 6.2.0-1012 linux-aws-6.2-tools-6.2.0-1013 - Linux kernel version specific tools for version 6.2.0-1013 linux-aws-6.2-tools-6.2.0-1014 - Linux kernel version specific tools for version 6.2.0-1014 linux-aws-tools-5.15.0-1035 - Linux kernel version specific tools for version 5.15.0-1035 linux-aws-tools-5.15.0-1036 - Linux kernel version specific tools for version 5.15.0-1036 linux-aws-tools-5.15.0-1037 - Linux kernel version specific tools for version 5.15.0-1037 linux-aws-tools-5.15.0-1038 - Linux kernel version specific tools for version 5.15.0-1038 linux-aws-tools-5.15.0-1039 - Linux kernel version specific tools for version 5.15.0-1039 linux-aws-tools-5.15.0-1040 - Linux kernel version specific tools for version 5.15.0-1040 linux-aws-tools-5.15.0-1042 - Linux kernel version specific tools for version 5.15.0-1042 linux-aws-tools-5.15.0-1043 - Linux kernel version specific tools for version 5.15.0-1043 linux-aws-tools-5.15.0-1044 - Linux kernel version specific tools for version 5.15.0-1044 linux-aws-tools-5.15.0-1045 - Linux kernel version specific tools for version 5.15.0-1045 linux-aws-tools-5.15.0-1047 - Linux kernel version specific tools for version 5.15.0-1047 linux-aws-tools-5.15.0-1048 - Linux kernel version specific tools for version 5.15.0-1048 linux-azure-5.19-tools-5.19.0-1025 - Linux kernel version specific tools for version 5.19.0-1025 linux-azure-5.19-tools-5.19.0-1026 - Linux kernel version specific tools for version 5.19.0-1026 linux-azure-5.19-tools-5.19.0-1027 - Linux kernel version specific tools for version 5.19.0-1027 linux-azure-6.2-tools-6.2.0-1005 - Linux kernel version specific tools for version 6.2.0-1005 linux-azure-6.2-tools-6.2.0-1006 - Linux kernel version specific tools for version 6.2.0-1006 linux-azure-6.2-tools-6.2.0-1007 - Linux kernel version specific tools for version 6.2.0-1007 linux-azure-6.2-tools-6.2.0-1008 - Linux kernel version specific tools for version 6.2.0-1008 linux-azure-6.2-tools-6.2.0-1011 - Linux kernel version specific tools for version 6.2.0-1011 linux-azure-6.2-tools-6.2.0-1012 - Linux kernel version specific tools for version 6.2.0-1012 linux-azure-6.2-tools-6.2.0-1014 - Linux kernel version specific tools for version 6.2.0-1014 linux-azure-6.2-tools-6.2.0-1015 - Linux kernel version specific tools for version 6.2.0-1015 linux-azure-tools-5.15.0-1035 - Linux kernel version specific tools for version 5.15.0-1035 linux-azure-tools-5.15.0-1036 - Linux kernel version specific tools for version 5.15.0-1036 linux-azure-tools-5.15.0-1037 - Linux kernel version specific tools for version 5.15.0-1037 linux-azure-tools-5.15.0-1038 - Linux kernel version specific tools for version 5.15.0-1038 linux-azure-tools-5.15.0-1039 - Linux kernel version specific tools for version 5.15.0-1039 linux-azure-tools-5.15.0-1040 - Linux kernel version specific tools for version 5.15.0-1040 linux-azure-tools-5.15.0-1041 - Linux kernel version specific tools for version 5.15.0-1041 linux-azure-tools-5.15.0-1042 - Linux kernel version specific tools for version 5.15.0-1042 linux-azure-tools-5.15.0-1044 - Linux kernel version specific tools for version 5.15.0-1044 linux-azure-tools-5.15.0-1045 - Linux kernel version specific tools for version 5.15.0-1045 linux-azure-tools-5.15.0-1046 - Linux kernel version specific tools for version 5.15.0-1046 linux-azure-tools-5.15.0-1047 - Linux kernel version specific tools for version 5.15.0-1047 linux-azure-tools-5.15.0-1049 - Linux kernel version specific tools for version 5.15.0-1049 linux-azure-tools-5.15.0-1050 - Linux kernel version specific tools for version 5.15.0-1050 linux-gcp-5.19-tools-5.19.0-1022 - Linux kernel version specific tools for version 5.19.0-1022 linux-gcp-5.19-tools-5.19.0-1024 - Linux kernel version specific tools for version 5.19.0-1024 linux-gcp-5.19-tools-5.19.0-1025 - Linux kernel version specific tools for version 5.19.0-1025 linux-gcp-5.19-tools-5.19.0-1026 - Linux kernel version specific tools for version 5.19.0-1026 linux-gcp-5.19-tools-5.19.0-1027 - Linux kernel version specific tools for version 5.19.0-1027 linux-gcp-5.19-tools-5.19.0-1030 - Linux kernel version specific tools for version 5.19.0-1030 linux-gcp-6.2-tools-6.2.0-1009 - Linux kernel version specific tools for version 6.2.0-1009 linux-gcp-6.2-tools-6.2.0-1010 - Linux kernel version specific tools for version 6.2.0-1010 linux-gcp-6.2-tools-6.2.0-1011 - Linux kernel version specific tools for version 6.2.0-1011 linux-gcp-6.2-tools-6.2.0-1012 - Linux kernel version specific tools for version 6.2.0-1012 linux-gcp-6.2-tools-6.2.0-1013 - Linux kernel version specific tools for version 6.2.0-1013 linux-gcp-6.2-tools-6.2.0-1014 - Linux kernel version specific tools for version 6.2.0-1014 linux-gcp-6.2-tools-6.2.0-1016 - Linux kernel version specific tools for version 6.2.0-1016 linux-gcp-6.2-tools-6.2.0-1017 - Linux kernel version specific tools for version 6.2.0-1017 linux-gcp-tools-5.15.0-1034 - Linux kernel version specific tools for version 5.15.0-1034 linux-gcp-tools-5.15.0-1035 - Linux kernel version specific tools for version 5.15.0-1035 linux-gcp-tools-5.15.0-1036 - Linux kernel version specific tools for version 5.15.0-1036 linux-gcp-tools-5.15.0-1037 - Linux kernel version specific tools for version 5.15.0-1037 linux-gcp-tools-5.15.0-1038 - Linux kernel version specific tools for version 5.15.0-1038 linux-gcp-tools-5.15.0-1039 - Linux kernel version specific tools for version 5.15.0-1039 linux-gcp-tools-5.15.0-1040 - Linux kernel version specific tools for version 5.15.0-1040 linux-gcp-tools-5.15.0-1041 - Linux kernel version specific tools for version 5.15.0-1041 linux-gcp-tools-5.15.0-1042 - Linux kernel version specific tools for version 5.15.0-1042 linux-gcp-tools-5.15.0-1044 - Linux kernel version specific tools for version 5.15.0-1044 linux-gcp-tools-5.15.0-1045 - Linux kernel version specific tools for version 5.15.0-1045 linux-gke-tools-5.15.0-1027 - Linux kernel version specific tools for version 5.15.0-1027 linux-gke-tools-5.15.0-1028 - Linux kernel version specific tools for version 5.15.0-1028 linux-gke-tools-5.15.0-1030 - Linux kernel version specific tools for version 5.15.0-1030 linux-gke-tools-5.15.0-1032 - Linux kernel version specific tools for version 5.15.0-1032 linux-gke-tools-5.15.0-1033 - Linux kernel version specific tools for version 5.15.0-1033 linux-gke-tools-5.15.0-1034 - Linux kernel version specific tools for version 5.15.0-1034 linux-gke-tools-5.15.0-1035 - Linux kernel version specific tools for version 5.15.0-1035 linux-gke-tools-5.15.0-1036 - Linux kernel version specific tools for version 5.15.0-1036 linux-gke-tools-5.15.0-1037 - Linux kernel version specific tools for version 5.15.0-1037 linux-gke-tools-5.15.0-1038 - Linux kernel version specific tools for version 5.15.0-1038 linux-gke-tools-5.15.0-1039 - Linux kernel version specific tools for version 5.15.0-1039 linux-gke-tools-5.15.0-1040 - Linux kernel version specific tools for version 5.15.0-1040 linux-gke-tools-5.15.0-1041 - Linux kernel version specific tools for version 5.15.0-1041 linux-gke-tools-5.15.0-1042 - Linux kernel version specific tools for version 5.15.0-1042 linux-gke-tools-5.15.0-1044 - Linux kernel version specific tools for version 5.15.0-1044 linux-gke-tools-5.15.0-1045 - Linux kernel version specific tools for version 5.15.0-1045 linux-hwe-5.19-tools-5.19.0-41 - Linux kernel version specific tools for version 5.19.0-41 linux-hwe-5.19-tools-5.19.0-42 - Linux kernel version specific tools for version 5.19.0-42 linux-hwe-5.19-tools-5.19.0-43 - Linux kernel version specific tools for version 5.19.0-43 linux-hwe-5.19-tools-5.19.0-45 - Linux kernel version specific tools for version 5.19.0-45 linux-hwe-5.19-tools-5.19.0-46 - Linux kernel version specific tools for version 5.19.0-46 linux-hwe-5.19-tools-5.19.0-50 - Linux kernel version specific tools for version 5.19.0-50 linux-hwe-6.2-tools-6.2.0-25 - Linux kernel version specific tools for version 6.2.0-25 linux-hwe-6.2-tools-6.2.0-26 - Linux kernel version specific tools for version 6.2.0-26 linux-hwe-6.2-tools-6.2.0-31 - Linux kernel version specific tools for version 6.2.0-31 linux-hwe-6.2-tools-6.2.0-32 - Linux kernel version specific tools for version 6.2.0-32 linux-hwe-6.2-tools-6.2.0-33 - Linux kernel version specific tools for version 6.2.0-33 linux-hwe-6.2-tools-6.2.0-34 - Linux kernel version specific tools for version 6.2.0-34 linux-hwe-6.2-tools-6.2.0-35 - Linux kernel version specific tools for version 6.2.0-35 linux-ibm-tools-5.15.0-1030 - Linux kernel version specific tools for version 5.15.0-1030 linux-ibm-tools-5.15.0-1031 - Linux kernel version specific tools for version 5.15.0-1031 linux-ibm-tools-5.15.0-1032 - Linux kernel version specific tools for version 5.15.0-1032 linux-ibm-tools-5.15.0-1033 - Linux kernel version specific tools for version 5.15.0-1033 linux-ibm-tools-5.15.0-1034 - Linux kernel version specific tools for version 5.15.0-1034 linux-ibm-tools-5.15.0-1035 - Linux kernel version specific tools for version 5.15.0-1035 linux-ibm-tools-5.15.0-1036 - Linux kernel version specific tools for version 5.15.0-1036 linux-ibm-tools-5.15.0-1037 - Linux kernel version specific tools for version 5.15.0-1037 linux-ibm-tools-5.15.0-1038 - Linux kernel version specific tools for version 5.15.0-1038 linux-ibm-tools-5.15.0-1040 - Linux kernel version specific tools for version 5.15.0-1040 linux-ibm-tools-5.15.0-1041 - Linux kernel version specific tools for version 5.15.0-1041 linux-intel-iotg-tools-5.15.0-1028 - Linux kernel version specific tools for version 5.15.0-1028 linux-intel-iotg-tools-5.15.0-1030 - Linux kernel version specific tools for version 5.15.0-1030 linux-intel-iotg-tools-5.15.0-1031 - Linux kernel version specific tools for version 5.15.0-1031 linux-intel-iotg-tools-5.15.0-1033 - Linux kernel version specific tools for version 5.15.0-1033 linux-intel-iotg-tools-5.15.0-1034 - Linux kernel version specific tools for version 5.15.0-1034 linux-intel-iotg-tools-5.15.0-1035 - Linux kernel version specific tools for version 5.15.0-1035 linux-intel-iotg-tools-5.15.0-1036 - Linux kernel version specific tools for version 5.15.0-1036 linux-intel-iotg-tools-5.15.0-1037 - Linux kernel version specific tools for version 5.15.0-1037 linux-intel-iotg-tools-5.15.0-1038 - Linux kernel version specific tools for version 5.15.0-1038 linux-intel-iotg-tools-5.15.0-1039 - Linux kernel version specific tools for version 5.15.0-1039 linux-intel-iotg-tools-5.15.0-1040 - Linux kernel version specific tools for version 5.15.0-1040 linux-intel-iotg-tools-5.15.0-1043 - Linux kernel version specific tools for version 5.15.0-1043 linux-kvm-tools-5.15.0-1033 - Linux kernel version specific tools for version 5.15.0-1033 linux-kvm-tools-5.15.0-1034 - Linux kernel version specific tools for version 5.15.0-1034 linux-kvm-tools-5.15.0-1035 - Linux kernel version specific tools for version 5.15.0-1035 linux-kvm-tools-5.15.0-1037 - Linux kernel version specific tools for version 5.15.0-1037 linux-kvm-tools-5.15.0-1038 - Linux kernel version specific tools for version 5.15.0-1038 linux-kvm-tools-5.15.0-1039 - Linux kernel version specific tools for version 5.15.0-1039 linux-kvm-tools-5.15.0-1040 - Linux kernel version specific tools for version 5.15.0-1040 linux-kvm-tools-5.15.0-1041 - Linux kernel version specific tools for version 5.15.0-1041 linux-kvm-tools-5.15.0-1042 - Linux kernel version specific tools for version 5.15.0-1042 linux-kvm-tools-5.15.0-1044 - Linux kernel version specific tools for version 5.15.0-1044 linux-kvm-tools-5.15.0-1045 - Linux kernel version specific tools for version 5.15.0-1045 linux-lowlatency-hwe-5.19-tools-5.19.0-1024 - Linux kernel version specific tools for version 5.19.0-1024 linux-lowlatency-hwe-5.19-tools-5.19.0-1025 - Linux kernel version specific tools for version 5.19.0-1025 linux-lowlatency-hwe-5.19-tools-5.19.0-1027 - Linux kernel version specific tools for version 5.19.0-1027 linux-lowlatency-hwe-5.19-tools-5.19.0-1028 - Linux kernel version specific tools for version 5.19.0-1028 linux-lowlatency-hwe-5.19-tools-5.19.0-1030 - Linux kernel version specific tools for version 5.19.0-1030 linux-lowlatency-hwe-6.2-tools-6.2.0-1008 - Linux kernel version specific tools for version 6.2.0-1008 linux-lowlatency-hwe-6.2-tools-6.2.0-1009 - Linux kernel version specific tools for version 6.2.0-1009 linux-lowlatency-hwe-6.2-tools-6.2.0-1011 - Linux kernel version specific tools for version 6.2.0-1011 linux-lowlatency-hwe-6.2-tools-6.2.0-1012 - Linux kernel version specific tools for version 6.2.0-1012 linux-lowlatency-hwe-6.2-tools-6.2.0-1013 - Linux kernel version specific tools for version 6.2.0-1013 linux-lowlatency-hwe-6.2-tools-6.2.0-1014 - Linux kernel version specific tools for version 6.2.0-1014 linux-lowlatency-hwe-6.2-tools-6.2.0-1015 - Linux kernel version specific tools for version 6.2.0-1015 linux-lowlatency-tools-5.15.0-72 - Linux kernel version specific tools for version 5.15.0-72 linux-lowlatency-tools-5.15.0-73 - Linux kernel version specific tools for version 5.15.0-73 linux-lowlatency-tools-5.15.0-75 - Linux kernel version specific tools for version 5.15.0-75 linux-lowlatency-tools-5.15.0-76 - Linux kernel version specific tools for version 5.15.0-76 linux-lowlatency-tools-5.15.0-78 - Linux kernel version specific tools for version 5.15.0-78 linux-lowlatency-tools-5.15.0-79 - Linux kernel version specific tools for version 5.15.0-79 linux-lowlatency-tools-5.15.0-82 - Linux kernel version specific tools for version 5.15.0-82 linux-lowlatency-tools-5.15.0-83 - Linux kernel version specific tools for version 5.15.0-83 linux-lowlatency-tools-5.15.0-84 - Linux kernel version specific tools for version 5.15.0-84 linux-lowlatency-tools-5.15.0-86 - Linux kernel version specific tools for version 5.15.0-86 linux-lowlatency-tools-5.15.0-87 - Linux kernel version specific tools for version 5.15.0-87 linux-nvidia-6.2-tools-6.2.0-1003 - Linux kernel version specific tools for version 6.2.0-1003 linux-nvidia-6.2-tools-6.2.0-1009 - Linux kernel version specific tools for version 6.2.0-1009 linux-nvidia-6.2-tools-6.2.0-1010 - Linux kernel version specific tools for version 6.2.0-1010 linux-nvidia-tools-5.15.0-1025 - Linux kernel version specific tools for version 5.15.0-1025 linux-nvidia-tools-5.15.0-1026 - Linux kernel version specific tools for version 5.15.0-1026 linux-nvidia-tools-5.15.0-1027 - Linux kernel version specific tools for version 5.15.0-1027 linux-nvidia-tools-5.15.0-1028 - Linux kernel version specific tools for version 5.15.0-1028 linux-nvidia-tools-5.15.0-1029 - Linux kernel version specific tools for version 5.15.0-1029 linux-nvidia-tools-5.15.0-1030 - Linux kernel version specific tools for version 5.15.0-1030 linux-nvidia-tools-5.15.0-1031 - Linux kernel version specific tools for version 5.15.0-1031 linux-nvidia-tools-5.15.0-1032 - Linux kernel version specific tools for version 5.15.0-1032 linux-nvidia-tools-5.15.0-1033 - Linux kernel version specific tools for version 5.15.0-1033 linux-nvidia-tools-5.15.0-1037 - Linux kernel version specific tools for version 5.15.0-1037 linux-nvidia-tools-5.15.0-1039 - Linux kernel version specific tools for version 5.15.0-1039 linux-oem-5.17-tools-5.17.0-1031 - Linux kernel version specific tools for version 5.17.0-1031 linux-oem-5.17-tools-5.17.0-1032 - Linux kernel version specific tools for version 5.17.0-1032 linux-oem-5.17-tools-5.17.0-1033 - Linux kernel version specific tools for version 5.17.0-1033 linux-oem-5.17-tools-5.17.0-1034 - Linux kernel version specific tools for version 5.17.0-1034 linux-oem-5.17-tools-5.17.0-1035 - Linux kernel version specific tools for version 5.17.0-1035 linux-oem-6.0-tools-6.0.0-1016 - Linux kernel version specific tools for version 6.0.0-1016 linux-oem-6.0-tools-6.0.0-1017 - Linux kernel version specific tools for version 6.0.0-1017 linux-oem-6.0-tools-6.0.0-1018 - Linux kernel version specific tools for version 6.0.0-1018 linux-oem-6.0-tools-6.0.0-1019 - Linux kernel version specific tools for version 6.0.0-1019 linux-oem-6.0-tools-6.0.0-1020 - Linux kernel version specific tools for version 6.0.0-1020 linux-oem-6.0-tools-6.0.0-1021 - Linux kernel version specific tools for version 6.0.0-1021 linux-oem-6.1-tools-6.1.0-1012 - Linux kernel version specific tools for version 6.1.0-1012 linux-oem-6.1-tools-6.1.0-1013 - Linux kernel version specific tools for version 6.1.0-1013 linux-oem-6.1-tools-6.1.0-1014 - Linux kernel version specific tools for version 6.1.0-1014 linux-oem-6.1-tools-6.1.0-1015 - Linux kernel version specific tools for version 6.1.0-1015 linux-oem-6.1-tools-6.1.0-1016 - Linux kernel version specific tools for version 6.1.0-1016 linux-oem-6.1-tools-6.1.0-1017 - Linux kernel version specific tools for version 6.1.0-1017 linux-oem-6.1-tools-6.1.0-1019 - Linux kernel version specific tools for version 6.1.0-1019 linux-oem-6.1-tools-6.1.0-1020 - Linux kernel version specific tools for version 6.1.0-1020 linux-oem-6.1-tools-6.1.0-1021 - Linux kernel version specific tools for version 6.1.0-1021 linux-oem-6.1-tools-6.1.0-1022 - Linux kernel version specific tools for version 6.1.0-1022 linux-oem-6.1-tools-6.1.0-1023 - Linux kernel version specific tools for version 6.1.0-1023 linux-oem-6.1-tools-6.1.0-1024 - Linux kernel version specific tools for version 6.1.0-1024 linux-oem-6.5-tools-6.5.0-1003 - Linux kernel version specific tools for version 6.5.0-1003 linux-oem-6.5-tools-6.5.0-1004 - Linux kernel version specific tools for version 6.5.0-1004 linux-oracle-5.19-tools-5.19.0-1023 - Oracle Linux kernel version specific tools for version 5.19.0-1023 linux-oracle-5.19-tools-5.19.0-1024 - Oracle Linux kernel version specific tools for version 5.19.0-1024 linux-oracle-5.19-tools-5.19.0-1025 - Oracle Linux kernel version specific tools for version 5.19.0-1025 linux-oracle-5.19-tools-5.19.0-1026 - Oracle Linux kernel version specific tools for version 5.19.0-1026 linux-oracle-5.19-tools-5.19.0-1027 - Oracle Linux kernel version specific tools for version 5.19.0-1027 linux-oracle-6.2-tools-6.2.0-1013 - Oracle Linux kernel version specific tools for version 6.2.0-1013 linux-oracle-6.2-tools-6.2.0-1014 - Oracle Linux kernel version specific tools for version 6.2.0-1014 linux-oracle-tools-5.15.0-1035 - Oracle Linux kernel version specific tools for version 5.15.0-1035 linux-oracle-tools-5.15.0-1036 - Oracle Linux kernel version specific tools for version 5.15.0-1036 linux-oracle-tools-5.15.0-1037 - Oracle Linux kernel version specific tools for version 5.15.0-1037 linux-oracle-tools-5.15.0-1038 - Oracle Linux kernel version specific tools for version 5.15.0-1038 linux-oracle-tools-5.15.0-1039 - Oracle Linux kernel version specific tools for version 5.15.0-1039 linux-oracle-tools-5.15.0-1040 - Oracle Linux kernel version specific tools for version 5.15.0-1040 linux-oracle-tools-5.15.0-1041 - Oracle Linux kernel version specific tools for version 5.15.0-1041 linux-oracle-tools-5.15.0-1042 - Oracle Linux kernel version specific tools for version 5.15.0-1042 linux-oracle-tools-5.15.0-1044 - Oracle Linux kernel version specific tools for version 5.15.0-1044 linux-oracle-tools-5.15.0-1045 - Oracle Linux kernel version specific tools for version 5.15.0-1045 linux-oracle-tools-5.15.0-1046 - Oracle Linux kernel version specific tools for version 5.15.0-1046 linux-tools-5.15.0-1025-nvidia - Linux kernel version specific tools for version 5.15.0-1025 linux-tools-5.15.0-1025-nvidia-lowlatency - Linux kernel version specific tools for version 5.15.0-1025 linux-tools-5.15.0-1026-nvidia - Linux kernel version specific tools for version 5.15.0-1026 linux-tools-5.15.0-1026-nvidia-lowlatency - Linux kernel version specific tools for version 5.15.0-1026 linux-tools-5.15.0-1027-gke - Linux kernel version specific tools for version 5.15.0-1027 linux-tools-5.15.0-1027-nvidia - Linux kernel version specific tools for version 5.15.0-1027 linux-tools-5.15.0-1027-nvidia-lowlatency - Linux kernel version specific tools for version 5.15.0-1027 linux-tools-5.15.0-1028-gke - Linux kernel version specific tools for version 5.15.0-1028 linux-tools-5.15.0-1028-intel-iotg - Linux kernel version specific tools for version 5.15.0-1028 linux-tools-5.15.0-1028-nvidia - Linux kernel version specific tools for version 5.15.0-1028 linux-tools-5.15.0-1028-nvidia-lowlatency - Linux kernel version specific tools for version 5.15.0-1028 linux-tools-5.15.0-1029-nvidia - Linux kernel version specific tools for version 5.15.0-1029 linux-tools-5.15.0-1029-nvidia-lowlatency - Linux kernel version specific tools for version 5.15.0-1029 linux-tools-5.15.0-1030-gke - Linux kernel version specific tools for version 5.15.0-1030 linux-tools-5.15.0-1030-ibm - Linux kernel version specific tools for version 5.15.0-1030 linux-tools-5.15.0-1030-intel-iotg - Linux kernel version specific tools for version 5.15.0-1030 linux-tools-5.15.0-1030-nvidia - Linux kernel version specific tools for version 5.15.0-1030 linux-tools-5.15.0-1030-nvidia-lowlatency - Linux kernel version specific tools for version 5.15.0-1030 linux-tools-5.15.0-1031-ibm - Linux kernel version specific tools for version 5.15.0-1031 linux-tools-5.15.0-1031-intel-iotg - Linux kernel version specific tools for version 5.15.0-1031 linux-tools-5.15.0-1031-nvidia - Linux kernel version specific tools for version 5.15.0-1031 linux-tools-5.15.0-1031-nvidia-lowlatency - Linux kernel version specific tools for version 5.15.0-1031 linux-tools-5.15.0-1032-gke - Linux kernel version specific tools for version 5.15.0-1032 linux-tools-5.15.0-1032-ibm - Linux kernel version specific tools for version 5.15.0-1032 linux-tools-5.15.0-1032-nvidia - Linux kernel version specific tools for version 5.15.0-1032 linux-tools-5.15.0-1032-nvidia-lowlatency - Linux kernel version specific tools for version 5.15.0-1032 linux-tools-5.15.0-1033-gke - Linux kernel version specific tools for version 5.15.0-1033 linux-tools-5.15.0-1033-ibm - Linux kernel version specific tools for version 5.15.0-1033 linux-tools-5.15.0-1033-intel-iotg - Linux kernel version specific tools for version 5.15.0-1033 linux-tools-5.15.0-1033-kvm - Linux kernel version specific tools for version 5.15.0-1033 linux-tools-5.15.0-1033-nvidia - Linux kernel version specific tools for version 5.15.0-1033 linux-tools-5.15.0-1033-nvidia-lowlatency - Linux kernel version specific tools for version 5.15.0-1033 linux-tools-5.15.0-1034-gcp - Linux kernel version specific tools for version 5.15.0-1034 linux-tools-5.15.0-1034-gke - Linux kernel version specific tools for version 5.15.0-1034 linux-tools-5.15.0-1034-ibm - Linux kernel version specific tools for version 5.15.0-1034 linux-tools-5.15.0-1034-intel-iotg - Linux kernel version specific tools for version 5.15.0-1034 linux-tools-5.15.0-1034-kvm - Linux kernel version specific tools for version 5.15.0-1034 linux-tools-5.15.0-1035-aws - Linux kernel version specific tools for version 5.15.0-1035 linux-tools-5.15.0-1035-azure - Linux kernel version specific tools for version 5.15.0-1035 linux-tools-5.15.0-1035-gcp - Linux kernel version specific tools for version 5.15.0-1035 linux-tools-5.15.0-1035-gke - Linux kernel version specific tools for version 5.15.0-1035 linux-tools-5.15.0-1035-ibm - Linux kernel version specific tools for version 5.15.0-1035 linux-tools-5.15.0-1035-intel-iotg - Linux kernel version specific tools for version 5.15.0-1035 linux-tools-5.15.0-1035-kvm - Linux kernel version specific tools for version 5.15.0-1035 linux-tools-5.15.0-1035-oracle - Oracle Linux kernel version specific tools for version 5.15.0-1035 linux-tools-5.15.0-1036-aws - Linux kernel version specific tools for version 5.15.0-1036 linux-tools-5.15.0-1036-azure - Linux kernel version specific tools for version 5.15.0-1036 linux-tools-5.15.0-1036-gcp - Linux kernel version specific tools for version 5.15.0-1036 linux-tools-5.15.0-1036-gke - Linux kernel version specific tools for version 5.15.0-1036 linux-tools-5.15.0-1036-ibm - Linux kernel version specific tools for version 5.15.0-1036 linux-tools-5.15.0-1036-intel-iotg - Linux kernel version specific tools for version 5.15.0-1036 linux-tools-5.15.0-1036-oracle - Oracle Linux kernel version specific tools for version 5.15.0-1036 linux-tools-5.15.0-1037-aws - Linux kernel version specific tools for version 5.15.0-1037 linux-tools-5.15.0-1037-azure - Linux kernel version specific tools for version 5.15.0-1037 linux-tools-5.15.0-1037-gcp - Linux kernel version specific tools for version 5.15.0-1037 linux-tools-5.15.0-1037-gke - Linux kernel version specific tools for version 5.15.0-1037 linux-tools-5.15.0-1037-ibm - Linux kernel version specific tools for version 5.15.0-1037 linux-tools-5.15.0-1037-intel-iotg - Linux kernel version specific tools for version 5.15.0-1037 linux-tools-5.15.0-1037-kvm - Linux kernel version specific tools for version 5.15.0-1037 linux-tools-5.15.0-1037-nvidia - Linux kernel version specific tools for version 5.15.0-1037 linux-tools-5.15.0-1037-nvidia-lowlatency - Linux kernel version specific tools for version 5.15.0-1037 linux-tools-5.15.0-1037-oracle - Oracle Linux kernel version specific tools for version 5.15.0-1037 linux-tools-5.15.0-1038-aws - Linux kernel version specific tools for version 5.15.0-1038 linux-tools-5.15.0-1038-azure - Linux kernel version specific tools for version 5.15.0-1038 linux-tools-5.15.0-1038-gcp - Linux kernel version specific tools for version 5.15.0-1038 linux-tools-5.15.0-1038-gke - Linux kernel version specific tools for version 5.15.0-1038 linux-tools-5.15.0-1038-ibm - Linux kernel version specific tools for version 5.15.0-1038 linux-tools-5.15.0-1038-intel-iotg - Linux kernel version specific tools for version 5.15.0-1038 linux-tools-5.15.0-1038-kvm - Linux kernel version specific tools for version 5.15.0-1038 linux-tools-5.15.0-1038-oracle - Oracle Linux kernel version specific tools for version 5.15.0-1038 linux-tools-5.15.0-1039-aws - Linux kernel version specific tools for version 5.15.0-1039 linux-tools-5.15.0-1039-azure - Linux kernel version specific tools for version 5.15.0-1039 linux-tools-5.15.0-1039-gcp - Linux kernel version specific tools for version 5.15.0-1039 linux-tools-5.15.0-1039-gke - Linux kernel version specific tools for version 5.15.0-1039 linux-tools-5.15.0-1039-intel-iotg - Linux kernel version specific tools for version 5.15.0-1039 linux-tools-5.15.0-1039-kvm - Linux kernel version specific tools for version 5.15.0-1039 linux-tools-5.15.0-1039-nvidia - Linux kernel version specific tools for version 5.15.0-1039 linux-tools-5.15.0-1039-nvidia-lowlatency - Linux kernel version specific tools for version 5.15.0-1039 linux-tools-5.15.0-1039-oracle - Oracle Linux kernel version specific tools for version 5.15.0-1039 linux-tools-5.15.0-1040-aws - Linux kernel version specific tools for version 5.15.0-1040 linux-tools-5.15.0-1040-azure - Linux kernel version specific tools for version 5.15.0-1040 linux-tools-5.15.0-1040-gcp - Linux kernel version specific tools for version 5.15.0-1040 linux-tools-5.15.0-1040-gke - Linux kernel version specific tools for version 5.15.0-1040 linux-tools-5.15.0-1040-ibm - Linux kernel version specific tools for version 5.15.0-1040 linux-tools-5.15.0-1040-intel-iotg - Linux kernel version specific tools for version 5.15.0-1040 linux-tools-5.15.0-1040-kvm - Linux kernel version specific tools for version 5.15.0-1040 linux-tools-5.15.0-1040-oracle - Oracle Linux kernel version specific tools for version 5.15.0-1040 linux-tools-5.15.0-1041-azure - Linux kernel version specific tools for version 5.15.0-1041 linux-tools-5.15.0-1041-gcp - Linux kernel version specific tools for version 5.15.0-1041 linux-tools-5.15.0-1041-gke - Linux kernel version specific tools for version 5.15.0-1041 linux-tools-5.15.0-1041-ibm - Linux kernel version specific tools for version 5.15.0-1041 linux-tools-5.15.0-1041-kvm - Linux kernel version specific tools for version 5.15.0-1041 linux-tools-5.15.0-1041-oracle - Oracle Linux kernel version specific tools for version 5.15.0-1041 linux-tools-5.15.0-1042-aws - Linux kernel version specific tools for version 5.15.0-1042 linux-tools-5.15.0-1042-azure - Linux kernel version specific tools for version 5.15.0-1042 linux-tools-5.15.0-1042-gcp - Linux kernel version specific tools for version 5.15.0-1042 linux-tools-5.15.0-1042-gke - Linux kernel version specific tools for version 5.15.0-1042 linux-tools-5.15.0-1042-kvm - Linux kernel version specific tools for version 5.15.0-1042 linux-tools-5.15.0-1042-oracle - Oracle Linux kernel version specific tools for version 5.15.0-1042 linux-tools-5.15.0-1043-aws - Linux kernel version specific tools for version 5.15.0-1043 linux-tools-5.15.0-1043-intel-iotg - Linux kernel version specific tools for version 5.15.0-1043 linux-tools-5.15.0-1044-aws - Linux kernel version specific tools for version 5.15.0-1044 linux-tools-5.15.0-1044-azure - Linux kernel version specific tools for version 5.15.0-1044 linux-tools-5.15.0-1044-gcp - Linux kernel version specific tools for version 5.15.0-1044 linux-tools-5.15.0-1044-gke - Linux kernel version specific tools for version 5.15.0-1044 linux-tools-5.15.0-1044-kvm - Linux kernel version specific tools for version 5.15.0-1044 linux-tools-5.15.0-1044-oracle - Oracle Linux kernel version specific tools for version 5.15.0-1044 linux-tools-5.15.0-1045-aws - Linux kernel version specific tools for version 5.15.0-1045 linux-tools-5.15.0-1045-azure - Linux kernel version specific tools for version 5.15.0-1045 linux-tools-5.15.0-1045-gcp - Linux kernel version specific tools for version 5.15.0-1045 linux-tools-5.15.0-1045-gke - Linux kernel version specific tools for version 5.15.0-1045 linux-tools-5.15.0-1045-kvm - Linux kernel version specific tools for version 5.15.0-1045 linux-tools-5.15.0-1045-oracle - Oracle Linux kernel version specific tools for version 5.15.0-1045 linux-tools-5.15.0-1046-azure - Linux kernel version specific tools for version 5.15.0-1046 linux-tools-5.15.0-1046-oracle - Oracle Linux kernel version specific tools for version 5.15.0-1046 linux-tools-5.15.0-1047-aws - Linux kernel version specific tools for version 5.15.0-1047 linux-tools-5.15.0-1047-azure - Linux kernel version specific tools for version 5.15.0-1047 linux-tools-5.15.0-1048-aws - Linux kernel version specific tools for version 5.15.0-1048 linux-tools-5.15.0-1049-azure - Linux kernel version specific tools for version 5.15.0-1049 linux-tools-5.15.0-1050-azure - Linux kernel version specific tools for version 5.15.0-1050 linux-tools-5.15.0-72 - Linux kernel version specific tools for version 5.15.0-72 linux-tools-5.15.0-72-generic - Linux kernel version specific tools for version 5.15.0-72 linux-tools-5.15.0-72-lowlatency - Linux kernel version specific tools for version 5.15.0-72 linux-tools-5.15.0-73 - Linux kernel version specific tools for version 5.15.0-73 linux-tools-5.15.0-73-generic - Linux kernel version specific tools for version 5.15.0-73 linux-tools-5.15.0-73-lowlatency - Linux kernel version specific tools for version 5.15.0-73 linux-tools-5.15.0-75 - Linux kernel version specific tools for version 5.15.0-75 linux-tools-5.15.0-75-generic - Linux kernel version specific tools for version 5.15.0-75 linux-tools-5.15.0-75-lowlatency - Linux kernel version specific tools for version 5.15.0-75 linux-tools-5.15.0-76-lowlatency - Linux kernel version specific tools for version 5.15.0-76 linux-tools-5.15.0-78 - Linux kernel version specific tools for version 5.15.0-78 linux-tools-5.15.0-78-generic - Linux kernel version specific tools for version 5.15.0-78 linux-tools-5.15.0-78-lowlatency - Linux kernel version specific tools for version 5.15.0-78 linux-tools-5.15.0-79 - Linux kernel version specific tools for version 5.15.0-79 linux-tools-5.15.0-79-generic - Linux kernel version specific tools for version 5.15.0-79 linux-tools-5.15.0-79-lowlatency - Linux kernel version specific tools for version 5.15.0-79 linux-tools-5.15.0-82 - Linux kernel version specific tools for version 5.15.0-82 linux-tools-5.15.0-82-generic - Linux kernel version specific tools for version 5.15.0-82 linux-tools-5.15.0-82-lowlatency - Linux kernel version specific tools for version 5.15.0-82 linux-tools-5.15.0-83 - Linux kernel version specific tools for version 5.15.0-83 linux-tools-5.15.0-83-generic - Linux kernel version specific tools for version 5.15.0-83 linux-tools-5.15.0-83-lowlatency - Linux kernel version specific tools for version 5.15.0-83 linux-tools-5.15.0-84 - Linux kernel version specific tools for version 5.15.0-84 linux-tools-5.15.0-84-generic - Linux kernel version specific tools for version 5.15.0-84 linux-tools-5.15.0-84-lowlatency - Linux kernel version specific tools for version 5.15.0-84 linux-tools-5.15.0-86 - Linux kernel version specific tools for version 5.15.0-86 linux-tools-5.15.0-86-generic - Linux kernel version specific tools for version 5.15.0-86 linux-tools-5.15.0-86-lowlatency - Linux kernel version specific tools for version 5.15.0-86 linux-tools-5.15.0-87 - Linux kernel version specific tools for version 5.15.0-87 linux-tools-5.15.0-87-generic - Linux kernel version specific tools for version 5.15.0-87 linux-tools-5.15.0-87-lowlatency - Linux kernel version specific tools for version 5.15.0-87 linux-tools-5.17.0-1031-oem - Linux kernel version specific tools for version 5.17.0-1031 linux-tools-5.17.0-1032-oem - Linux kernel version specific tools for version 5.17.0-1032 linux-tools-5.17.0-1033-oem - Linux kernel version specific tools for version 5.17.0-1033 linux-tools-5.17.0-1034-oem - Linux kernel version specific tools for version 5.17.0-1034 linux-tools-5.17.0-1035-oem - Linux kernel version specific tools for version 5.17.0-1035 linux-tools-5.19.0-1022-gcp - Linux kernel version specific tools for version 5.19.0-1022 linux-tools-5.19.0-1023-oracle - Oracle Linux kernel version specific tools for version 5.19.0-1023 linux-tools-5.19.0-1024-aws - Linux kernel version specific tools for version 5.19.0-1024 linux-tools-5.19.0-1024-gcp - Linux kernel version specific tools for version 5.19.0-1024 linux-tools-5.19.0-1024-lowlatency - Linux kernel version specific tools for version 5.19.0-1024 linux-tools-5.19.0-1024-oracle - Oracle Linux kernel version specific tools for version 5.19.0-1024 linux-tools-5.19.0-1025-aws - Linux kernel version specific tools for version 5.19.0-1025 linux-tools-5.19.0-1025-azure - Linux kernel version specific tools for version 5.19.0-1025 linux-tools-5.19.0-1025-gcp - Linux kernel version specific tools for version 5.19.0-1025 linux-tools-5.19.0-1025-lowlatency - Linux kernel version specific tools for version 5.19.0-1025 linux-tools-5.19.0-1025-oracle - Oracle Linux kernel version specific tools for version 5.19.0-1025 linux-tools-5.19.0-1026-aws - Linux kernel version specific tools for version 5.19.0-1026 linux-tools-5.19.0-1026-azure - Linux kernel version specific tools for version 5.19.0-1026 linux-tools-5.19.0-1026-gcp - Linux kernel version specific tools for version 5.19.0-1026 linux-tools-5.19.0-1026-oracle - Oracle Linux kernel version specific tools for version 5.19.0-1026 linux-tools-5.19.0-1027-aws - Linux kernel version specific tools for version 5.19.0-1027 linux-tools-5.19.0-1027-azure - Linux kernel version specific tools for version 5.19.0-1027 linux-tools-5.19.0-1027-gcp - Linux kernel version specific tools for version 5.19.0-1027 linux-tools-5.19.0-1027-lowlatency - Linux kernel version specific tools for version 5.19.0-1027 linux-tools-5.19.0-1027-oracle - Oracle Linux kernel version specific tools for version 5.19.0-1027 linux-tools-5.19.0-1028-aws - Linux kernel version specific tools for version 5.19.0-1028 linux-tools-5.19.0-1028-lowlatency - Linux kernel version specific tools for version 5.19.0-1028 linux-tools-5.19.0-1029-aws - Linux kernel version specific tools for version 5.19.0-1029 linux-tools-5.19.0-1030-gcp - Linux kernel version specific tools for version 5.19.0-1030 linux-tools-5.19.0-1030-lowlatency - Linux kernel version specific tools for version 5.19.0-1030 linux-tools-5.19.0-41-generic - Linux kernel version specific tools for version 5.19.0-41 linux-tools-5.19.0-42-generic - Linux kernel version specific tools for version 5.19.0-42 linux-tools-5.19.0-43-generic - Linux kernel version specific tools for version 5.19.0-43 linux-tools-5.19.0-45-generic - Linux kernel version specific tools for version 5.19.0-45 linux-tools-5.19.0-46-generic - Linux kernel version specific tools for version 5.19.0-46 linux-tools-5.19.0-50-generic - Linux kernel version specific tools for version 5.19.0-50 linux-tools-6.0.0-1016-oem - Linux kernel version specific tools for version 6.0.0-1016 linux-tools-6.0.0-1017-oem - Linux kernel version specific tools for version 6.0.0-1017 linux-tools-6.0.0-1018-oem - Linux kernel version specific tools for version 6.0.0-1018 linux-tools-6.0.0-1019-oem - Linux kernel version specific tools for version 6.0.0-1019 linux-tools-6.0.0-1020-oem - Linux kernel version specific tools for version 6.0.0-1020 linux-tools-6.0.0-1021-oem - Linux kernel version specific tools for version 6.0.0-1021 linux-tools-6.1.0-1012-oem - Linux kernel version specific tools for version 6.1.0-1012 linux-tools-6.1.0-1013-oem - Linux kernel version specific tools for version 6.1.0-1013 linux-tools-6.1.0-1014-oem - Linux kernel version specific tools for version 6.1.0-1014 linux-tools-6.1.0-1015-oem - Linux kernel version specific tools for version 6.1.0-1015 linux-tools-6.1.0-1016-oem - Linux kernel version specific tools for version 6.1.0-1016 linux-tools-6.1.0-1017-oem - Linux kernel version specific tools for version 6.1.0-1017 linux-tools-6.1.0-1019-oem - Linux kernel version specific tools for version 6.1.0-1019 linux-tools-6.1.0-1020-oem - Linux kernel version specific tools for version 6.1.0-1020 linux-tools-6.1.0-1021-oem - Linux kernel version specific tools for version 6.1.0-1021 linux-tools-6.1.0-1022-oem - Linux kernel version specific tools for version 6.1.0-1022 linux-tools-6.1.0-1023-oem - Linux kernel version specific tools for version 6.1.0-1023 linux-tools-6.1.0-1024-oem - Linux kernel version specific tools for version 6.1.0-1024 linux-tools-6.2.0-1003-nvidia - Linux kernel version specific tools for version 6.2.0-1003 linux-tools-6.2.0-1005-aws - Linux kernel version specific tools for version 6.2.0-1005 linux-tools-6.2.0-1005-azure - Linux kernel version specific tools for version 6.2.0-1005 linux-tools-6.2.0-1006-aws - Linux kernel version specific tools for version 6.2.0-1006 linux-tools-6.2.0-1006-azure - Linux kernel version specific tools for version 6.2.0-1006 linux-tools-6.2.0-1007-aws - Linux kernel version specific tools for version 6.2.0-1007 linux-tools-6.2.0-1007-azure - Linux kernel version specific tools for version 6.2.0-1007 linux-tools-6.2.0-1008-aws - Linux kernel version specific tools for version 6.2.0-1008 linux-tools-6.2.0-1008-azure - Linux kernel version specific tools for version 6.2.0-1008 linux-tools-6.2.0-1008-lowlatency - Linux kernel version specific tools for version 6.2.0-1008 linux-tools-6.2.0-1009-aws - Linux kernel version specific tools for version 6.2.0-1009 linux-tools-6.2.0-1009-gcp - Linux kernel version specific tools for version 6.2.0-1009 linux-tools-6.2.0-1009-lowlatency - Linux kernel version specific tools for version 6.2.0-1009 linux-tools-6.2.0-1009-nvidia - Linux kernel version specific tools for version 6.2.0-1009 linux-tools-6.2.0-1010-aws - Linux kernel version specific tools for version 6.2.0-1010 linux-tools-6.2.0-1010-gcp - Linux kernel version specific tools for version 6.2.0-1010 linux-tools-6.2.0-1010-nvidia - Linux kernel version specific tools for version 6.2.0-1010 linux-tools-6.2.0-1011-aws - Linux kernel version specific tools for version 6.2.0-1011 linux-tools-6.2.0-1011-azure - Linux kernel version specific tools for version 6.2.0-1011 linux-tools-6.2.0-1011-gcp - Linux kernel version specific tools for version 6.2.0-1011 linux-tools-6.2.0-1011-lowlatency - Linux kernel version specific tools for version 6.2.0-1011 linux-tools-6.2.0-1012-aws - Linux kernel version specific tools for version 6.2.0-1012 linux-tools-6.2.0-1012-azure - Linux kernel version specific tools for version 6.2.0-1012 linux-tools-6.2.0-1012-gcp - Linux kernel version specific tools for version 6.2.0-1012 linux-tools-6.2.0-1012-lowlatency - Linux kernel version specific tools for version 6.2.0-1012 linux-tools-6.2.0-1013-aws - Linux kernel version specific tools for version 6.2.0-1013 linux-tools-6.2.0-1013-gcp - Linux kernel version specific tools for version 6.2.0-1013 linux-tools-6.2.0-1013-lowlatency - Linux kernel version specific tools for version 6.2.0-1013 linux-tools-6.2.0-1013-oracle - Oracle Linux kernel version specific tools for version 6.2.0-1013 linux-tools-6.2.0-1014-aws - Linux kernel version specific tools for version 6.2.0-1014 linux-tools-6.2.0-1014-azure - Linux kernel version specific tools for version 6.2.0-1014 linux-tools-6.2.0-1014-gcp - Linux kernel version specific tools for version 6.2.0-1014 linux-tools-6.2.0-1014-lowlatency - Linux kernel version specific tools for version 6.2.0-1014 linux-tools-6.2.0-1014-oracle - Oracle Linux kernel version specific tools for version 6.2.0-1014 linux-tools-6.2.0-1015-azure - Linux kernel version specific tools for version 6.2.0-1015 linux-tools-6.2.0-1015-lowlatency - Linux kernel version specific tools for version 6.2.0-1015 linux-tools-6.2.0-1016-gcp - Linux kernel version specific tools for version 6.2.0-1016 linux-tools-6.2.0-1017-gcp - Linux kernel version specific tools for version 6.2.0-1017 linux-tools-6.2.0-25-generic - Linux kernel version specific tools for version 6.2.0-25 linux-tools-6.2.0-26-generic - Linux kernel version specific tools for version 6.2.0-26 linux-tools-6.2.0-31-generic - Linux kernel version specific tools for version 6.2.0-31 linux-tools-6.2.0-32-generic - Linux kernel version specific tools for version 6.2.0-32 linux-tools-6.2.0-33-generic - Linux kernel version specific tools for version 6.2.0-33 linux-tools-6.2.0-34-generic - Linux kernel version specific tools for version 6.2.0-34 linux-tools-6.2.0-35-generic - Linux kernel version specific tools for version 6.2.0-35 linux-tools-6.5.0-1003-oem - Linux kernel version specific tools for version 6.5.0-1003 linux-tools-6.5.0-1004-oem - Linux kernel version specific tools for version 6.5.0-1004 linux-tools-aws-edge - Linux kernel versioned tools for Amazon Web Services (AWS) systems. linux-tools-aws-lts-22.04 - Linux kernel versioned tools for Amazon Web Services (AWS) systems. linux-tools-azure-edge - Linux kernel versioned tools for Azure systems. linux-tools-azure-fde - Linux kernel versioned tools for Azure systems. linux-tools-azure-fde-edge - Linux kernel versioned tools for Azure systems. linux-tools-azure-fde-lts-22.04 - Linux kernel versioned tools for Azure systems. linux-tools-azure-lts-22.04 - Linux kernel versioned tools for Azure systems. linux-tools-gcp-edge - Google Cloud Platform (GCP) Linux kernel tools linux-tools-gcp-lts-22.04 - Google Cloud Platform (GCP) Linux kernel tools linux-tools-nvidia - Linux kernel tools for Nvidia systems. linux-tools-nvidia-6.2 - Nvidia Linux kernel tools linux-tools-nvidia-edge - Nvidia Linux kernel tools linux-tools-nvidia-hwe-22.04 - Nvidia Linux kernel tools linux-tools-nvidia-hwe-22.04-edge - Nvidia Linux kernel tools linux-tools-nvidia-lowlatency - Linux kernel tools for Nvidia systems. linux-tools-oem-22.04a - OEM Linux kernel tools (dummy transitional package) linux-tools-oem-22.04b - OEM Linux kernel tools (dummy transitional package) linux-tools-oem-22.04c - OEM Linux kernel tools linux-tools-oem-22.04d - OEM Linux kernel tools linux-tools-oracle-edge - Linux kernel versioned tools for Oracle systems. linux-tools-oracle-lts-22.04 - Linux kernel versioned tools for Oracle systems. linux-gkeop-tools-5.15.0-1019 - Linux kernel version specific tools for version 5.15.0-1019 linux-gkeop-tools-5.15.0-1020 - Linux kernel version specific tools for version 5.15.0-1020 linux-gkeop-tools-5.15.0-1021 - Linux kernel version specific tools for version 5.15.0-1021 linux-gkeop-tools-5.15.0-1022 - Linux kernel version specific tools for version 5.15.0-1022 linux-gkeop-tools-5.15.0-1023 - Linux kernel version specific tools for version 5.15.0-1023 linux-gkeop-tools-5.15.0-1024 - Linux kernel version specific tools for version 5.15.0-1024 linux-gkeop-tools-5.15.0-1025 - Linux kernel version specific tools for version 5.15.0-1025 linux-gkeop-tools-5.15.0-1026 - Linux kernel version specific tools for version 5.15.0-1026 linux-gkeop-tools-5.15.0-1027 - Linux kernel version specific tools for version 5.15.0-1027 linux-gkeop-tools-5.15.0-1028 - Linux kernel version specific tools for version 5.15.0-1028 linux-gkeop-tools-5.15.0-1030 - Linux kernel version specific tools for version 5.15.0-1030 linux-gkeop-tools-5.15.0-1031 - Linux kernel version specific tools for version 5.15.0-1031 linux-nvidia-5.19-tools-5.19.0-1010 - Linux kernel version specific tools for version 5.19.0-1010 linux-nvidia-5.19-tools-5.19.0-1014 - Linux kernel version specific tools for version 5.19.0-1014 linux-oracle-5.19-tools-5.19.0-1022 - Oracle Linux kernel version specific tools for version 5.19.0-1022 linux-realtime-tools-5.15.0-1032 - Linux kernel version specific tools for version 5.15.0-1032 linux-tools-5.15.0-1019-gkeop - Linux kernel version specific tools for version 5.15.0-1019 linux-tools-5.15.0-1020-gkeop - Linux kernel version specific tools for version 5.15.0-1020 linux-tools-5.15.0-1021-gkeop - Linux kernel version specific tools for version 5.15.0-1021 linux-tools-5.15.0-1022-gkeop - Linux kernel version specific tools for version 5.15.0-1022 linux-tools-5.15.0-1023-gkeop - Linux kernel version specific tools for version 5.15.0-1023 linux-tools-5.15.0-1024-gkeop - Linux kernel version specific tools for version 5.15.0-1024 linux-tools-5.15.0-1025-gkeop - Linux kernel version specific tools for version 5.15.0-1025 linux-tools-5.15.0-1026-gkeop - Linux kernel version specific tools for version 5.15.0-1026 linux-tools-5.15.0-1027-gkeop - Linux kernel version specific tools for version 5.15.0-1027 linux-tools-5.15.0-1028-gkeop - Linux kernel version specific tools for version 5.15.0-1028 linux-tools-5.15.0-1030-gkeop - Linux kernel version specific tools for version 5.15.0-1030 linux-tools-5.15.0-1031-gkeop - Linux kernel version specific tools for version 5.15.0-1031 linux-tools-5.15.0-1032-realtime - Linux kernel version specific tools for version 5.15.0-1032 linux-tools-5.19.0-1010-nvidia - Linux kernel version specific tools for version 5.19.0-1010 linux-tools-5.19.0-1010-nvidia-lowlatency - Linux kernel version specific tools for version 5.19.0-1010 linux-tools-5.19.0-1014-nvidia - Linux kernel version specific tools for version 5.19.0-1014 linux-tools-5.19.0-1014-nvidia-lowlatency - Linux kernel version specific tools for version 5.19.0-1014 linux-tools-5.19.0-1022-oracle - Oracle Linux kernel version specific tools for version 5.19.0-1022 linux-tools-gkeop - Generic Linux kernel tools linux-tools-gkeop-5.15 - Generic Linux kernel tools linux-tools-nvidia-5.19 - Nvidia-5.19 Linux kernel tools linux-tools-nvidia-lowlatency-5.19 - Nvidia-5.19 Linux kernel tools linux-tools-nvidia-lowlatency-edge - Nvidia-5.19 Linux kernel tools linux-tools-realtime - Linux kernel versioned tools for real-time systems. linux-tools-azure-fde-5.19-edge - Linux kernel versioned tools for Azure systems. uname -a 查看当前 linux 内核版本号\n~$ uname -a Linux LUYANG 5.15.90.1-microsoft-standard-WSL2 #1 SMP Fri Jan 27 02:56:13 UTC 2023 x86_64 x86_64 x86_64 GNU/Linux 因此我选择了 linux-tools-5.15.0-87-generic\nlinux-tools-5.15.0-72 - Linux kernel version specific tools for version 5.15.0-72 linux-tools-5.15.0-72-generic - Linux kernel version specific tools for version 5.15.0-72 linux-tools-5.15.0-72-lowlatency - Linux kernel version specific tools for version 5.15.0-72 linux-tools-5.15.0-73 - Linux kernel version specific tools for version 5.15.0-73 linux-tools-5.15.0-73-generic - Linux kernel version specific tools for version 5.15.0-73 linux-tools-5.15.0-73-lowlatency - Linux kernel version specific tools for version 5.15.0-73 linux-tools-5.15.0-75 - Linux kernel version specific tools for version 5.15.0-75 linux-tools-5.15.0-75-generic - Linux kernel version specific tools for version 5.15.0-75 linux-tools-5.15.0-75-lowlatency - Linux kernel version specific tools for version 5.15.0-75 linux-tools-5.15.0-76-lowlatency - Linux kernel version specific tools for version 5.15.0-76 linux-tools-5.15.0-78 - Linux kernel version specific tools for version 5.15.0-78 linux-tools-5.15.0-78-generic - Linux kernel version specific tools for version 5.15.0-78 linux-tools-5.15.0-78-lowlatency - Linux kernel version specific tools for version 5.15.0-78 linux-tools-5.15.0-79 - Linux kernel version specific tools for version 5.15.0-79 linux-tools-5.15.0-79-generic - Linux kernel version specific tools for version 5.15.0-79 linux-tools-5.15.0-79-lowlatency - Linux kernel version specific tools for version 5.15.0-79 linux-tools-5.15.0-82 - Linux kernel version specific tools for version 5.15.0-82 linux-tools-5.15.0-82-generic - Linux kernel version specific tools for version 5.15.0-82 linux-tools-5.15.0-82-lowlatency - Linux kernel version specific tools for version 5.15.0-82 linux-tools-5.15.0-83 - Linux kernel version specific tools for version 5.15.0-83 linux-tools-5.15.0-83-generic - Linux kernel version specific tools for version 5.15.0-83 linux-tools-5.15.0-83-lowlatency - Linux kernel version specific tools for version 5.15.0-83 linux-tools-5.15.0-84 - Linux kernel version specific tools for version 5.15.0-84 linux-tools-5.15.0-84-generic - Linux kernel version specific tools for version 5.15.0-84 linux-tools-5.15.0-84-lowlatency - Linux kernel version specific tools for version 5.15.0-84 linux-tools-5.15.0-86 - Linux kernel version specific tools for version 5.15.0-86 linux-tools-5.15.0-86-generic - Linux kernel version specific tools for version 5.15.0-86 linux-tools-5.15.0-86-lowlatency - Linux kernel version specific tools for version 5.15.0-86 linux-tools-5.15.0-87 - Linux kernel version specific tools for version 5.15.0-87 linux-tools-5.15.0-87-generic - Linux kernel version specific tools for version 5.15.0-87 linux-tools-5.15.0-87-lowlatency - Linux kernel version specific tools for version 5.15.0-87 windows 利用 usbipd bind \u0026amp; attach adb device Notice： usbipd.exe 命令需要在管理员身份运行的 powershell 中执行  usbipd.exe wsl -h usbipd-win 3.2.0 Description: Convenience commands for attaching and detaching devices to Windows Subsystem for Linux. Usage: usbipd wsl [command] [options] Options: -?, -h, --help Show help and usage information Commands: attach Attach a USB device to a WSL instance detach Detach a USB device from a WSL instance list List USB devices  usbipd.exe wsl attach -h usbipd-win 3.2.0 Description: Attaches a USB device to a WSL instance. The first time a device is attached this command will include a \u0026#39;bind\u0026#39;, for which administrator privileges are required. Subsequent attaches can be done with standard user privileges. Exactly one of the options \u0026#39;--busid\u0026#39; or \u0026#39;--hardware-id\u0026#39; is required. Usage: usbipd wsl attach [options] Options: -a, --auto-attach Automatically re-attach when the device is detached or unplugged -b, --busid \u0026lt;BUSID\u0026gt; Attach device having \u0026lt;BUSID\u0026gt; -d, --distribution \u0026lt;NAME\u0026gt; Name of the WSL distribution to attach to -i, --hardware-id \u0026lt;VID:PID\u0026gt; Attach device having \u0026lt;VID\u0026gt;:\u0026lt;PID\u0026gt; -?, -h, --help Show help and usage information  usbipd wsl list BUSID VID:PID DEVICE STATE 2-1 30c9:0096 HP 5MP Camera, HP IR Camera, Camera DFU Device Not attached 2-10 8087:0033 英特尔(R) 无线 Bluetooth(R) Not attached 4-2 18d1:4ee4 bst usb gadget function Not attached usbipd: warning: USB filter \u0026#39;USBPcap\u0026#39; is known to be incompatible with this software; \u0026#39;bind --force\u0026#39; will be required. usbipd wsl attach -b \u0026lt;busid\u0026gt; usbipd wsl attach -i \u0026lt;VID:PID\u0026gt;  usbipd.exe wsl attach -i 18d1:4ee4 usbipd: info: Device with hardware-id \u0026#39;18d1:4ee4\u0026#39; found at busid \u0026#39;2-3\u0026#39;. usbipd: info: Using default WSL distribution \u0026#39;Ubuntu\u0026#39;; specify the \u0026#39;--distribution\u0026#39; option to select a different one. usbipd: warning: USB filter \u0026#39;USBPcap\u0026#39; is known to be incompatible with this software; \u0026#39;bind --force\u0026#39; will be required. usbip: error: Attach Request for 2-3 failed - Device busy (exported) usbipd: error: Failed to attach device with busid \u0026#39;2-3\u0026#39;.  usbipd.exe bind -h usbipd-win 3.2.0 Description: Registers a single USB device for sharing, so it can be attached to other machines. Unless the --force option is used, shared devices remain available to the host until they are attached to another machine. Exactly one of the options \u0026#39;--busid\u0026#39; or \u0026#39;--hardware-id\u0026#39; is required. Usage: usbipd bind [options] Options: -b, --busid \u0026lt;BUSID\u0026gt; Share device having \u0026lt;BUSID\u0026gt; -f, --force Force binding; the host cannot use the device -i, --hardware-id \u0026lt;VID:PID\u0026gt; Share device having \u0026lt;VID\u0026gt;:\u0026lt;PID\u0026gt; -?, -h, --help Show help and usage information  usbipd.exe bind -i 18d1:4ee4 -f usbipd: info: Device with hardware-id \u0026#39;18d1:4ee4\u0026#39; found at busid \u0026#39;2-3\u0026#39;. usbipd: warning: A reboot may be required before the changes take effect. 按照说明重启电脑之后：\n usbipd.exe bind -i 18d1:4ee4 -f usbipd: info: Device with hardware-id \u0026#39;18d1:4ee4\u0026#39; found at busid \u0026#39;2-3\u0026#39;. usbipd: info: Device with busid \u0026#39;2-3\u0026#39; was already shared. 此时管理员身份运行 powershell 执行如下命令：\n usbipd.exe wsl attach -i 18d1:4ee4 -a usbipd: info: Device with hardware-id \u0026#39;18d1:4ee4\u0026#39; found at busid \u0026#39;2-3\u0026#39;. usbipd: info: Using default WSL distribution \u0026#39;Ubuntu\u0026#39;; specify the \u0026#39;--distribution\u0026#39; option to select a different one. usbipd: info: Starting endless attach loop; press Ctrl+C to quit. Attached Detached usbip: error: Attach Request for 2-3 failed - Device not found Attached 加上 -a 选项后 attach 命令不会退出，会持续监听 -i 指定的设备，插拔该 usb 设备会自动 attach。如上命令可以看出有一个插拔的过程。\nluyang@LUYANG:~$ adb devices * daemon not running; starting now at tcp:5037 * daemon started successfully List of devices attached fada-018b0e6b656d0002 device 参考链接 https://devblogs.microsoft.com/commandline/connecting-usb-devices-to-wsl/\n","date":"26 October, 2023","id":61,"permalink":"/posts/windows_wsl_ubuntu_adb_%E9%85%8D%E7%BD%AE/","summary":"windows 可以识别 adb devices","tags":"android adb wsl usb usbip","title":"Windows WSL ubuntu adb 配置"},{"content":"下载一份 Linux 内核代码，拷贝一份 toos/spi/spidev_test.c 文件（只需要这一个文件）\n要在Android 7.1上编译spidev_test.c，可以参考以下步骤：\n准备工作 ~~确保内核支持SPI设备：~~\n在内核配置中启用SPI设备支持，确保CONFIG_SPI和CONFIG_SPI_SPIDEV选项被启用。 修改设备树文件，添加SPI控制器和SPI设备节点。 创建Android.mk文件：\n在system/extras目录下创建一个名为spi的文件夹。 将spidev_test.c文件复制到spi文件夹中。 在spi文件夹中创建一个Android.mk文件，内容如下： LOCAL_PATH := $(call my-dir) include $(CLEAR_VARS) LOCAL_MODULE := spidev_test LOCAL_SRC_FILES := spidev_test.c LOCAL_MODULE_TAGS := optional include $(BUILD_EXECUTABLE) 编译步骤 编译spidev_test： 打开终端，切换到spi目录。 执行mm命令进行编译。这将在out/target/product/\u0026lt;your_device\u0026gt;/symbols/system目录下生成可执行文件spidev_test。 将可执行文件推送到设备： 使用adb push命令将spidev_test推送到设备上的某个目录，例如： adb push out/target/product/\u0026lt;your_device\u0026gt;/symbols/system/spidev_test /data/ 在设备上运行测试程序： 使用adb shell连接到设备，切换到包含spidev_test的目录，并运行程序： adb shell cd /data/ chmod 777 spidev_test ./spidev_test 注意事项 确保设备上已经正确配置了SPI设备节点，例如/dev/spidevX.Y，其中X是SPI控制器编号，Y是设备编号。 如果在编译或运行过程中遇到问题，检查内核配置和设备树文件是否正确设置，并确保所有必要的权限和依赖项都已满足。 adb 指定被操作设备 如果 PC 当前连接了多个正在运行 adb 的设备，可以通过 adb -s 指定操作特定设备\n\u0026gt;adb devices List of devices attached J6-9f81e1412b08443 device EE02FL9SR5 device adb -s \u0026lt;序列号\u0026gt; shell ","date":"26 June, 2023","id":62,"permalink":"/posts/android-7.1-build-spidev_test.c/","summary":"下载一份 Linux 内核代码，拷贝一份 toos/spi/spidev_test.c 文件（只需要这一个文件）","tags":"SPI spidev","title":"Android 7.1 build spidev_test.c"},{"content":"Sites http://www.duckduckgo.com - Search engine http://www.google.com - Search engine + more http://www.theregister.com - IT news http://slashdot.org - News for nerds http://news.ycombinator.com - Hacker news https://www.usenix.org/publications/login - USENIX ;login: magazine http://queue.acm.org - ACMqueue http://lwn.net/ - Linux Weekly News https://perf.wiki.kernel.org - Linux perf_events wiki https://ebpf.io - eBPF homepage http://seclists.org - Computer security mailing lists (Bugtraq, Full-Disclosure) http://www.insecure.org/tools.html - Top 75 security tools http://cryptome.org - Computer security and intelligence http://www.ietf.org/rfc.html - RFCs (network protocols) http://shelldorado.com - Shell scripting resource http://www.cpan.org - CPAN, Perl libraries http://www.povray.org - POV-Ray, a free computer graphics tool http://www.apcmag.com - Australian Personal Computer Magazine http://www.thangorodrim.net - Angband and Zangband http://www.confluence.org - Photos from every confluence (latitude/longitude) http://www.gutenberg.net - Project Gutenberg, book collection http://www.vim.org - Text editor http://mail.openjdk.java.net/pipermail/hotspot-compiler-dev - hotspot compiler dev mailing list Homepages https://www.bell-labs.com/usr/dmr/www - Dennis Ritchie\u0026rsquo;s home page http://www.ozatwar.com/ausarmy/ernestgregg.htm - Ernest Gregg, my grandfather, who served in Z Special Unit Blogs http://www.beginningwithi.com - Deirdré Straughan, which has many Brendan Gregg tagged posts https://netflixtechblog.com - Netflix tech blog https://jvns.ca - Julia Evans homepage and blog http://mechanical-sympathy.blogspot.com - Martin Thompson\u0026rsquo;s performance blog http://www.mysqlperformanceblog.com - MySQL Performance Blog http://taosecurity.blogspot.com - Computer security tips and reviews Other https://www.twitch.tv/somecodingguy - Ex-colleague live streamer https://www.twitch.tv/theprimeagen - Colleague live streamer ","date":"26 June, 2023","id":63,"permalink":"/posts/brendangregg_bookmarks/","summary":"","tags":"bookmark","title":"BrendanGregg_bookmarks"},{"content":"系统信息 $ lsb_release -a No LSB modules are available. Distributor ID: Ubuntu Description: Ubuntu 20.04.6 LTS Release: 20.04 Codename: focal $ uname -a Linux kang-HP-ProBook-440-14-inch-G10-Notebook-PC 5.15.0-67-generic #74~20.04.1-Ubuntu SMP Wed Feb 22 14:52:34 UTC 2023 x86_64 x86_64 x86_64 GNU/Linux 安装依赖 sudo apt update \u0026amp;\u0026amp; sudo apt upgrade sudo apt install binutils build-essential gcc make perl net-tools libncurses-dev \\ openssh-server git fakeroot libssl-dev bc flex libelf-dev bison \\ dwarves zstd Linux 源码下载 官网：https://www.kernel.org/pub/ Git：https://git.kernel.org/ ftp：http://ftp.sjtu.edu.cn/sites/ftp.kernel.org/pub/linux/kernel/ 拷贝 .config 配置文件 解压源代码并进入源码根目录，然后执行\ncp /boot/config-$(uname -r) .config 修改 .config 文件，左侧为修改后，解决编译报错问题\n编译 make menuconfig # 弹出的不做任何修改，直接保存。 make -j16 sudo make modules_install sudo make install $ sudo make modules_install SYMLINK /lib/modules/6.11.7/build INSTALL /lib/modules/6.11.7/modules.order INSTALL /lib/modules/6.11.7/modules.builtin INSTALL /lib/modules/6.11.7/modules.builtin.modinfo INSTALL /lib/modules/6.11.7/kernel/arch/x86/events/amd/amd-uncore.ko SIGN /lib/modules/6.11.7/kernel/arch/x86/events/amd/amd-uncore.ko INSTALL /lib/modules/6.11.7/kernel/arch/x86/events/intel/intel-cstate.ko SIGN /lib/modules/6.11.7/kernel/arch/x86/events/intel/intel-cstate.ko INSTALL /lib/modules/6.11.7/kernel/arch/x86/events/rapl.ko SIGN /lib/modules/6.11.7/kernel/arch/x86/events/rapl.ko INSTALL /lib/modules/6.11.7/kernel/arch/x86/kernel/cpu/mce/mce-inject.ko SIGN /lib/modules/6.11.7/kernel/arch/x86/kernel/cpu/mce/mce-inject.ko INSTALL /lib/modules/6.11.7/kernel/arch/x86/kernel/msr.ko SIGN /lib/modules/6.11.7/kernel/arch/x86/kernel/msr.ko INSTALL /lib/modules/6.11.7/kernel/arch/x86/kernel/cpuid.ko SIGN /lib/modules/6.11.7/kernel/arch/x86/kernel/cpuid.ko INSTALL /lib/modules/6.11.7/kernel/arch/x86/crypto/twofish-x86_64.ko SIGN /lib/modules/6.11.7/kernel/arch/x86/crypto/twofish-x86_64.ko INSTALL /lib/modules/6.11.7/kernel/arch/x86/crypto/twofish-x86_64-3way.ko SIGN /lib/modules/6.11.7/kernel/arch/x86/crypto/twofish-x86_64-3way.ko ...... $ sudo make install INSTALL /boot run-parts: executing /etc/kernel/postinst.d/initramfs-tools 6.11.7 /boot/vmlinuz-6.11.7 update-initramfs: Generating /boot/initrd.img-6.11.7 W: Possible missing firmware /lib/firmware/rtl_nic/rtl8126a-2.fw for module r8169 run-parts: executing /etc/kernel/postinst.d/unattended-upgrades 6.11.7 /boot/vmlinuz-6.11.7 run-parts: executing /etc/kernel/postinst.d/update-notifier 6.11.7 /boot/vmlinuz-6.11.7 run-parts: executing /etc/kernel/postinst.d/xx-update-initrd-links 6.11.7 /boot/vmlinuz-6.11.7 I: /boot/initrd.img.old is now a symlink to initrd.img-5.15.0-126-generic I: /boot/initrd.img is now a symlink to initrd.img-6.11.7 run-parts: executing /etc/kernel/postinst.d/zz-shim 6.11.7 /boot/vmlinuz-6.11.7 run-parts: executing /etc/kernel/postinst.d/zz-update-grub 6.11.7 /boot/vmlinuz-6.11.7 Sourcing file `/etc/default/grub\u0026#39; Sourcing file `/etc/default/grub.d/init-select.cfg\u0026#39; Generating grub configuration file ... Found linux image: /boot/vmlinuz-6.11.7 Found initrd image: /boot/initrd.img-6.11.7 Found linux image: /boot/vmlinuz-5.15.0-126-generic Found initrd image: /boot/initrd.img-5.15.0-126-generic Found linux image: /boot/vmlinuz-5.15.0-67-generic Found initrd image: /boot/initrd.img-5.15.0-67-generic Adding boot menu entry for UEFI Firmware Settings done $ sudo update-grub Sourcing file `/etc/default/grub\u0026#39; Sourcing file `/etc/default/grub.d/init-select.cfg\u0026#39; Generating grub configuration file ... Found linux image: /boot/vmlinuz-6.11.7 Found initrd image: /boot/initrd.img-6.11.7 Found linux image: /boot/vmlinuz-5.15.0-126-generic Found initrd image: /boot/initrd.img-5.15.0-126-generic Found linux image: /boot/vmlinuz-5.15.0-67-generic Found initrd image: /boot/initrd.img-5.15.0-67-generic Adding boot menu entry for UEFI Firmware Settings done 解决 WIFI 不工作 git://git.kernel.org/pub/scm/linux/kernel/git/firmware/linux-firmware.git sudo cp iwlwifi-* /lib/firmware/` sudo reboot ","date":"26 June, 2023","id":64,"permalink":"/posts/ubuntu_2004_%E5%8D%87%E7%BA%A7%E5%86%85%E6%A0%B8/","summary":"解压源代码并进入源码根目录，然后执行","tags":"ubuntu","title":"ubuntu 20.04 升级内核"},{"content":"安装 subversion sudo apt-get remove --purge subversion sudo apt-get update sudo apt-get install subversion 创建 SVN 用户 sudo adduser svn sudo adduser svn sudo sudo su svn 创建仓库目录 sudo mkdir /svn sudo mkdir /svn/repos sudo mkdir /svn/repos/public sudo chmod 777 -R /svn/repos/public sudo chown svn:svn -R /svn 创建版本库 sudo svnadmin create /svn/repos/public $ ls -lah /svn/repos/public total 32K drwxrwxrwx 6 svn svn 4.0K 6月 19 14:15 . drwxr-xr-x 3 svn svn 4.0K 6月 19 14:15 .. drwxr-xr-x 2 root root 4.0K 6月 19 14:15 conf drwxr-sr-x 6 root root 4.0K 6月 19 14:15 db -r--r--r-- 1 root root 2 6月 19 14:15 format drwxr-xr-x 2 root root 4.0K 6月 19 14:15 hooks drwxr-xr-x 2 root root 4.0K 6月 19 14:15 locks -rw-r--r-- 1 root root 246 6月 19 14:15 README.txt cd /svn/repos/public sudo chmod -R 777 db cd conf sudo cp svnserve.conf svnserve.conf.bak sudo vim svnserve.conf 取消注释：\n$ sudo diff -u svnserve.conf svnserve.conf.bak --- svnserve.conf 2023-06-19 13:27:33.473464875 +0800 +++ svnserve.conf.bak 2023-06-19 13:26:30.071350251 +0800 @@ -16,15 +16,15 @@ ### The sample settings below are the defaults and specify that anonymous ### users have read-only access to the repository, while authenticated ### users have read and write access to the repository. -anon-access = read -auth-access = write +# anon-access = read +# auth-access = write ### The password-db option controls the location of the password ### database file. Unless you specify a path starting with a /, ### the file\u0026#39;s location is relative to the directory containing ### this configuration file. ### If SASL is enabled (see below), this file will NOT be used. ### Uncomment the line below to use the default password file. -password-db = passwd +# password-db = passwd ### The authz-db option controls the location of the authorization ### rules for path-based access control. Unless you specify a path ### starting with a /, the file\u0026#39;s location is relative to the @@ -33,7 +33,7 @@ ### file in a Subversion repository. If you don\u0026#39;t specify an authz-db, ### no path-based access control is done. ### Uncomment the line below to use the default authorization file. -authz-db = authz +# authz-db = authz ### The groups-db option controls the location of the file with the ### group definitions and allows maintaining groups separately from the ### authorization rules. The groups-db file is of the same format as the 说明：（去掉前面的#，并且顶格）\nanon-access = none 匿名用户不可读 auth-access = write 权限用户可写 password-db = passwd 密码文件为 passwd authz-db = authz 权限文件为 authz 修改 passwd sudo cp passwd passwd.bak sudo vim passwd $ cat /svn/repos/public/conf/passwd ### This file is an example password file for svnserve. ### Its format is similar to that of svnserve.conf. As shown in the ### example below it contains one section labelled [users]. ### The name and password for each user follow, one account per line. [users] hanmeimei = iampassword lilei = helloworld 新增用户格式：名字 = 密码\n修改 authz sudo cp authz authz.bak sudo vim authz $ cat /svn/repos/public/conf/authz ### This file is an example authorization file for svnserve. ### Its format is identical to that of mod_authz_svn authorization ### files. ### As shown below each section defines authorizations for the path and ### (optional) repository specified by the section name. ### The authorizations follow. An authorization line can refer to: ### - a single user, ### - a group of users defined in a special [groups] section, ### - an alias defined in a special [aliases] section, ### - all authenticated users, using the \u0026#39;$authenticated\u0026#39; token, ### - only anonymous users, using the \u0026#39;$anonymous\u0026#39; token, ### - anyone, using the \u0026#39;*\u0026#39; wildcard. ### ### A match can be inverted by prefixing the rule with \u0026#39;~\u0026#39;. Rules can ### grant read (\u0026#39;r\u0026#39;) access, read-write (\u0026#39;rw\u0026#39;) access, or no access ### (\u0026#39;\u0026#39;). [aliases] # joe = /C=XZ/ST=Dessert/L=Snake City/O=Snake Oil, Ltd./OU=Research Institute/CN=Joe Average [groups] students = hanmeimei,lilei # harry_and_sally = harry,sally # harry_sally_and_joe = harry,sally,\u0026amp;joe # [/foo/bar] # harry = rw # \u0026amp;joe = r # * = # [repository:/baz/fuz] # @harry_and_sally = rw # * = r [public:/] @students = rw * = 启动服务 sudo su svn sudo svnserve -d -r /svn --listen-port 81 下载安装 windows 小乌龟 https://tortoisesvn.net/downloads.zh.html\n访问 svn 服务器 svn://10.0.0.:81/public ","date":"26 June, 2023","id":65,"permalink":"/posts/svn/","summary":"取消注释：","tags":"svn","title":"ubuntu 搭建 svn 服务器"},{"content":"适用于 Windows terminal + powershell\n安装 oh-my-posh Microsoft Store 中搜索并安装：oh-my-posh by jandedobbeleer\n使用图标字体 Nerd Fonts - Iconic font aggregator, glyphs/icons collection, \u0026amp; fonts patcher\n去这里下载一个自己喜欢的字体，并配置 windows terminal power shell profile 使用该字体。\n配置 profile 判断当前的 shell 类型：oh-my-posh get shell\nPS C:\\Users\\luyang\\Desktop\u0026gt; oh-my-posh get shell powershell 修改配置文件：\nnotepad $PROFILE 添加如下内容：\noh-my-posh init pwsh | Invoke-Expression 如果 notepad $PROFILE 报错，说配置文件不存在需要自己创建一个：\nNew-Item -Path $PROFILE -Type File -Force 加载配置：\n. $PROFILE Q\u0026amp;A 运行报错：\nWindows PowerShell 版权所有（C） Microsoft Corporation。保留所有权利。 安装最新的 PowerShell，了解新功能和改进！https://aka.ms/PSWindows . : 无法加载文件 C:\\Users\\luyang\\Documents\\WindowsPowerShell\\Microsoft.PowerShell_profile.ps1，因为在此系统上禁止运行脚 本。有关详细信息，请参阅 https:/go.microsoft.com/fwlink/?LinkID=135170 中的 about_Execution_Policies。 所在位置 行:1 字符: 3 + . \u0026#39;C:\\Users\\luyang\\Documents\\WindowsPowerShell\\Microsoft.PowerShell_pr ... + ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ + CategoryInfo : SecurityError: (:) []，PSSecurityException + FullyQualifiedErrorId : UnauthorizedAccess 原因：PowerShell 默认禁止运行脚本，PowerShell 默认禁止运行脚本;\nRestricted 表示在 PowerShell 中运行脚本是禁止的\nPS C:\\Users\\luyang\u0026gt; get-ExecutionPolicy Restricted 解决方案：\n以管理员身份运行 windows PowerShell，执行如下命令，并选择 Y, 之后再运行 PowerShell 即可恢复正常。\nset-ExecutionPolicy RemoteSigned PS C:\\WINDOWS\\system32\u0026gt; set-ExecutionPolicy RemoteSigned 执行策略更改 执行策略可帮助你防止执行不信任的脚本。更改执行策略可能会产生安全风险，如 https:/go.microsoft.com/fwlink/?LinkID=135170 中的 about_Execution_Policies 帮助主题所述。是否要更改执行策略? [Y] 是(Y) [A] 全是(A) [N] 否(N) [L] 全否(L) [S] 暂停(S) [?] 帮助 (默认值为“N”): Y PS C:\\WINDOWS\\system32\u0026gt; 参考 Windows | Oh My Posh Change your prompt | Oh My Posh Nerd Fonts - Iconic font aggregator, glyphs/icons collection, \u0026amp; fonts patcher ","date":"26 June, 2023","id":66,"permalink":"/posts/windows-terminal-%E5%AE%89%E8%A3%85%E9%85%8D%E7%BD%AE-oh-my-posh/","summary":"适用于 Windows terminal + powershell","tags":"terminal oh-my-posh","title":"Windows terminal 安装配置 oh-my-posh"},{"content":" ","date":"1 June, 2023","id":67,"permalink":"/posts/asan/","summary":"","tags":"cpp memory","title":"asan"},{"content":"sudo find /usr /lib /lib64 -name \u0026#34;libasan6.so\u0026#34; NI-VISA Driver Wizard 生成了一个 .INF 文件。右键该文件安装的过程中提示错误：第三方 INF 不包含数字签名信息。\nDriver Wizard 生成的 INF 文件，必须为其创建 Windows Catalog (.cat)文件并进行数字签名，然后才能在Windows 10(或更高版本)机器上安装INF文件。\n打开 Windows Terminal 在 .INF 文件所在目录下执行如下命令，生成 Windows Catalog 文件：\nInf2Cat /driver:. /os:10_X64 Windows 平台依赖环境安装 visual studio 2022 WDK Windows Driver Kit Windows SDK Linux 平台依赖环境安装 sudo apt install openssl 准备证书 目的：Linux 平台使用OpenSSL生成带有基本约束扩展的证书\n创建文件 openssl.cnf，内容如下 [req] req_extensions = v3_req distinguished_name = req_distinguished_name [v3_req] basicConstraints = CA:FALSE [req_distinguished_name] countryName = US stateOrProvinceName = California organizationName = DeadBeef commonName = DeadBeef.com 请求签发 CSR openssl req -new -x509 -key private.key -out certificate.crt -days 36500 -config openssl.cnf 生成自签名证书 openssl pkcs12 -export -in certificate.crt -inkey private.key -out yourfile.pfx Windows Catalog 签名 将上前面生成的证书相关的文件，全部拷贝到 Windows 目录，跟 .INF .cat 文件放在一起。\nsigntool.exe sign /fdws /f yourfile.pfx /p 123456 prefix.cat 安装证书 右键 openssl 生成的 certificate.crt 文件进行 安装证书，如何安装 cert 自行百度\n存储位置： 本地计算机 将说有的证书都放入下列存储：浏览 受信任的根证书颁发机构 安装 INF 右键点击 .inf 文件，选择安装.\n参考链接 NI-VISA 2022 Q3 Readme #Creating and Digitally Signing Catalog Files Windows 8和10上使用驱动程序开发向导中的* .inf文件 windows-sdk WDK Inf2Cat Creating a Catalog File for Test-Signing a Driver Package Openssl生成自签名证书，简单步骤 ","date":"1 June, 2023","id":68,"permalink":"/posts/openssl/","summary":"NI-VISA Driver Wizard 生成了一个 .INF 文件。右键该文件安装的过程中提示错误：第三方 INF 不包含数字签名信息。","tags":"openssl wdk 签名 证书","title":"openssl 创建自签名证书,对 Windows Catalog 进行签名"},{"content":"🐧 Ubuntu 下 Docker 环境一键部署指南 这是一份在 [[Linux]] 发行版 Ubuntu 上安装 [[Docker]] 官方社区版 (Docker-CE) 的完整指南。我们将通过分步详解和最终的一键脚本，实现一个干净、快速的 [[Docker]] 环境搭建。\n[!NOTE] 为什么要使用官方仓库? 使用 Docker 官方的 apt 仓库可以确保你获得最新、最安全的版本，并能方便地安装 [[Docker Compose]] 等官方插件。\n🛠️ 分步详解：Docker 安装全过程 第一步：清理旧环境 一个最佳实践是先清理系统中可能存在的旧版本或冲突的容器运行时，以避免潜在问题。\nfor pkg in docker.io docker-doc docker-compose podman-docker containerd runc; do sudo apt-get remove $pkg; done 说明: 这个 for 循环会尝试卸载一系列已知的旧版 Docker 相关软件包。即使某个包未安装，命令也会安全地跳过。 第二步：设置 Docker 的官方 APT 仓库 这是整个过程中最核心的一步，目的是让系统信任并从 Docker 官方源下载软件。\n1. 安装基础依赖 我们需要 curl 来下载文件，gnupg 来处理密钥。\nsudo apt-get update sudo apt-get install ca-certificates curl gnupg 2. 添加 Docker 官方 GPG 密钥 [!TIP] GPG 密钥的作用? GPG (GNU Privacy Guard) 密钥用于对软件包进行数字签名。添加 Docker 的官方密钥后，我们的系统在安装 Docker 软件包时会进行验证，确保软件包来自官方且在传输过程中未被篡改，这是保障系统安全的关键一步。\n# 创建用于存放密钥的目录 sudo install -m 0755 -d /etc/apt/keyrings # 下载 GPG 密钥并存放到指定位置 curl -fsSL [https://download.docker.com/linux/ubuntu/gpg](https://download.docker.com/linux/ubuntu/gpg) | sudo gpg --dearmor -o /etc/apt/keyrings/docker.gpg # 赋予密钥文件可读权限 sudo chmod a+r /etc/apt/keyrings/docker.gpg 3. 将 Docker 仓库写入系统源列表 这条命令会自动检测你的系统架构和 Ubuntu 版本代号，生成对应的仓库配置。\necho \\ \u0026#34;deb [arch=\u0026#34;$(dpkg --print-architecture)\u0026#34; signed-by=/etc/apt/keyrings/docker.gpg] [https://download.docker.com/linux/ubuntu](https://download.docker.com/linux/ubuntu) \\ \u0026#34;$(. /etc/os-release \u0026amp;\u0026amp; echo \u0026#34;$VERSION_CODENAME\u0026#34;)\u0026#34; stable\u0026#34; | \\ sudo tee /etc/apt/sources.list.d/docker.list \u0026gt; /dev/null $(dpkg --print-architecture): 动态获取系统架构, 如 amd64。 $(. /etc/os-release \u0026amp;\u0026amp; echo \u0026quot;$VERSION_CODENAME\u0026quot;): 动态获取 Ubuntu 版本代号, 如 jammy。 第三步：安装 Docker 引擎 现在万事俱备，可以正式安装 Docker 了。\n# 再次更新 apt 包索引，以加载刚刚添加的 Docker 仓库 sudo apt-get update # 安装 Docker 引擎、CLI、containerd 和其他关键插件 sudo apt-get install docker-ce docker-ce-cli containerd.io docker-buildx-plugin docker-compose-plugin 第四步：配置用户权限 默认情况下，docker 命令需要 sudo 权限。为了方便日常使用，我们将当前用户添加到 docker 用户组。\nsudo usermod -aG docker $USER [!IMPORTANT] 必须重新登录！ 执行此命令后，你必须完全退出当前终端会话并重新登录 (或者直接重启系统)，用户组的变更才会生效。否则你仍然会遇到权限不足的错误。\n✅ 验证安装 重新登录后，运行经典的 hello-world 镜像来验证 Docker 是否安装成功。\ndocker run hello-world 如果一切正常，你将看到来自 Docker 的欢迎信息。\nHello from Docker! This message shows that your installation appears to be working correctly. ... 🚀 一键部署脚本 (Gist) 我们将上述所有步骤整合到了一个 Shell 脚本中，你可以通过 curl 直接下载并执行。\n[!WARNING] 安全提示 从网络通过管道 (|) 直接执行脚本是一种高效但有潜在风险的操作。在生产环境或处理敏感数据的机器上，强烈建议先审查脚本内容，再执行。\n一键安装命令:\ncurl -fsSL https://gist.githubusercontent.com/luyoungcn/706898e7d33543160b96023c46d8acc3/raw/fac1b8893b5ddd9ad7c883b32145fdb00047c9a4/install-docker-ubuntu.sh | sh 脚本源地址: https://gist.github.com/706898e7d33543160b96023c46d8acc3\n📚 相关概念 [[Containerization]] [[Docker Images and Containers]] [[Dockerfile]] [[Docker Compose]] for pkg in docker.io docker-doc docker-compose podman-docker containerd runc; do sudo apt-get remove $pkg; done sudo apt-get update sudo apt-get install ca-certificates curl gnupg sudo install -m 0755 -d /etc/apt/keyrings curl -fsSL https://download.docker.com/linux/ubuntu/gpg | sudo gpg --dearmor -o /etc/apt/keyrings/docker.gpg sudo chmod a+r /etc/apt/keyrings/docker.gpg echo \\ \u0026#34;deb [arch=\u0026#34;$(dpkg --print-architecture)\u0026#34; signed-by=/etc/apt/keyrings/docker.gpg] https://download.docker.com/linux/ubuntu \\ \u0026#34;$(. /etc/os-release \u0026amp;\u0026amp; echo \u0026#34;$VERSION_CODENAME\u0026#34;)\u0026#34; stable\u0026#34; | \\ sudo tee /etc/apt/sources.list.d/docker.list \u0026gt; /dev/null sudo apt-get update sudo apt-get install docker-ce docker-ce-cli containerd.io docker-buildx-plugin docker-compose-plugin sudo usermod -aG docker $USER ","date":"1 June, 2023","id":69,"permalink":"/posts/docker-%E7%8E%AF%E5%A2%83%E6%90%AD%E5%BB%BA/","summary":"这是一份在 [[Linux]] 发行版 Ubuntu 上安装 [[Docker]] 官方社区版 (Docker-CE) 的完整指南。我们将通过分步详解和最终的一键脚本，实现一个干净、快速的 [[Docker]] 环境搭建。","tags":"docker","title":"docker 环境搭建"},{"content":"R1 - Gerrit 环境搭建 环境说明 ubuntu 20.04 Gerrit 3.8.0 openjdk version \u0026ldquo;11.0.19\u0026rdquo; 2023-04-18 安装依赖软件包 sudo apt install openjdk-11-jdk openjdk-11-jdk-headless openjdk-11-jre openjdk-11-jre-headless 创建 Gerrit 用户 sudo adduser gerrit sudo usermod -a -G sudo gerrit sudo su gerrit mkdir ~/gerrit java -jar gerrit-3.8.0.war init -d ~/gerrit 安装 Gerrit $ java -jar gerrit-3.8.0.war init -d ~/gerrit Using secure store: com.google.gerrit.server.securestore.DefaultSecureStore [2023-06-03 12:19:03,027] [main] INFO com.google.gerrit.server.config.GerritServerConfigProvider : No /home/gerrit/gerrit/etc/gerrit.config; assuming defaults *** Gerrit Code Review 3.8.0 *** Create \u0026#39;/home/gerrit/gerrit\u0026#39; [Y/n]? Y *** Git Repositories *** Location of Git repositories [git]: *** JGit Configuration *** Auto-configured \u0026#34;receive.autogc = false\u0026#34; to disable auto-gc after git-receive-pack. *** Index *** Type [lucene]: *** User Authentication *** Authentication method [openid/?]: ? Supported options are: openid openid_sso http http_ldap client_ssl_cert_ldap ldap ldap_bind custom_extension development_become_any_account oauth Authentication method [openid/?]: http Get username from custom HTTP header [y/N]? y Username HTTP header [SM_USER]: SSO logout URL : Enable signed push support [y/N]? y Use case insensitive usernames [Y/n]? Y *** Review Labels *** Install Verified label [y/N]? N *** Email Delivery *** SMTP server hostname [localhost]: SMTP server port [(default)]: SMTP encryption [none/?]: SMTP username : *** Container Process *** Run as [gerrit]: Java runtime [/usr/lib/jvm/java-11-openjdk-amd64]: Copy gerrit-3.8.0.war to /home/gerrit/gerrit/bin/gerrit.war [Y/n]? Y Copying gerrit-3.8.0.war to /home/gerrit/gerrit/bin/gerrit.war *** SSH Daemon *** Listen on address [*]: Listen on port [29418]: Generating SSH host key ... rsa... ed25519... ecdsa 256... ecdsa 384... ecdsa 521... done *** HTTP Daemon *** Behind reverse proxy [y/N]? y Proxy uses SSL (https://) [y/N]? N Subdirectory on proxy server [/]: Listen on address [*]: Listen on port [8081]: Canonical URL [http://luyang-VirtualBox/]: *** Cache *** *** Plugins *** Installing plugins. Install plugin codemirror-editor version v3.8.0 [y/N]? y Installed codemirror-editor v3.8.0 Install plugin commit-message-length-validator version v3.8.0 [y/N]? y Installed commit-message-length-validator v3.8.0 Install plugin delete-project version v3.8.0 [y/N]? y Installed delete-project v3.8.0 Install plugin download-commands version v3.8.0 [y/N]? y Installed download-commands v3.8.0 Install plugin gitiles version v3.8.0 [y/N]? y Installed gitiles v3.8.0 Install plugin hooks version v3.8.0 [y/N]? y Installed hooks v3.8.0 Install plugin plugin-manager version v3.8.0 [y/N]? y Installed plugin-manager v3.8.0 Install plugin replication version v3.8.0 [y/N]? y Installed replication v3.8.0 Install plugin reviewnotes version v3.8.0 [y/N]? y Installed reviewnotes v3.8.0 Install plugin singleusergroup version v3.8.0 [y/N]? y Installed singleusergroup v3.8.0 Install plugin webhooks version v3.8.0 [y/N]? y Installed webhooks v3.8.0 Initializing plugins. ============================================================================ Welcome to the Gerrit community Find more information on the homepage: https://www.gerritcodereview.com Discuss Gerrit on the mailing list: https://groups.google.com/g/repo-discuss ============================================================================ Initialized /home/gerrit/gerrit Init complete, reindexing accounts,changes,groups,projects with: reindex --site-path /home/gerrit/gerrit --threads 1 --index accounts --index changes --index groups --index projectsReindexed 0 documents in accounts index in 0.0s (0.0/s) Index accounts in version 12 is ready Reindexing groups: 100% (2/2) Reindexed 2 documents in groups index in 0.2s (9.9/s) Index groups in version 9 is ready Reindexing changes: Slicing projects: 100% (2/2), done Reindexed 0 documents in changes index in 0.0s (0.0/s) Index changes in version 82 is ready Reindexing projects: 100% (2/2) Reindexed 2 documents in projects index in 0.1s (25.0/s) Index projects in version 5 is ready Executing /home/gerrit/gerrit/bin/gerrit.sh start Starting Gerrit Code Review: WARNING: Could not adjust Gerrit\u0026#39;s process for the kernel\u0026#39;s out-of-memory killer. This may be caused by /home/gerrit/gerrit/bin/gerrit.sh not being run as root. Consider changing the OOM score adjustment manually for Gerrit\u0026#39;s PID=4510 with e.g.: echo \u0026#39;-1000\u0026#39; | sudo tee /proc/4510/oom_score_adj OK Waiting for server on luyang-VirtualBox:80 ... OK Please open the following URL in the browser: http://luyang-VirtualBox/#/admin/projects/ 配置 Gerrit etc/gerrit.config\n[gerrit] basePath = git canonicalWebUrl = http://192.168.56.104:8080 serverId = d00cca90-af13-4298-9273-72d50cce94ce [container] javaOptions = \u0026#34;-Dflogger.backend_factory=com.google.common.flogger.backend.log4j.Log4jBackendFactory#getInstance\u0026#34; javaOptions = \u0026#34;-Dflogger.logging_context=com.google.gerrit.server.logging.LoggingContext#getInstance\u0026#34; user = gerrit javaHome = /usr/lib/jvm/java-11-openjdk-amd64 [index] type = lucene [auth] type = HTTP httpHeader = SM_USER userNameCaseInsensitive = true [receive] enableSignedPush = true [sendemail] enable = true smtpServer = smtp.qq.com smtpServerPort = 465 smtpEncryption = SSL sslVerify = true smtpUser = 193944320@qq.com smtpPass = fjas;jfa;sdjfalk from = [SCM]\u0026lt;193944320@qq.com\u0026gt; [sshd] listenAddress = *:29418 [httpd] listenUrl = proxy-http://*:8081/ [cache] directory = cache 安装配置 Nginx sudo apt install nginx /etc/nginx/conf.d/gerrit.conf\nserver { listen *:8080; server_name 192.168.56.104; allow all; deny all; auth_basic \u0026#34;Welcomme to Gerrit Code Review Site!\u0026#34;; auth_basic_user_file /home/gerrit/gerrit/etc/gerrit.password; location / { proxy_redirect off; proxy_pass http://192.168.56.104:8081; proxy_set_header X-Forwarded-For $remote_addr; proxy_set_header Host $host; } } ","date":"1 June, 2023","id":70,"permalink":"/posts/gerrit/","summary":"etc/gerrit.config","tags":"android repo gerrit CodeReview","title":"gerrit 环境搭建"},{"content":"Install vcpkg https://github.com/microsoft/vcpkg#quick-start-windows\npowershell 终端执行如下命令：\ngit clone https://github.com/microsoft/vcpkg .\\vcpkg\\bootstrap-vcpkg.bat Install Package # To install the libraries for your project, run: # This will install x86 libraries by default. .\\vcpkg\\vcpkg install [packages to install] # To install x64, run: .\\vcpkg\\vcpkg install [package name]:x64-windows Tab-Completion/Auto-Completion https://github.com/microsoft/vcpkg#tab-completionauto-completion\nvcpkg supports auto-completion of commands, package names, and options in both powershell and bash. To enable tab-completion in the shell of your choice, run:\n\u0026gt; .\\vcpkg integrate powershell VS/MSBuild 项目 (用户范围的集成) https://learn.microsoft.com/zh-cn/vcpkg/examples/installing-and-using-packages#msbuild\n使用 vcpkg 的建议且最高效的方法是通过用户范围的集成，使系统可用于你生成的所有项目。 首次在给定计算机上使用时，用户范围的集成将提示管理员进行访问，但之后不再需要该集成，并且集成按用户进行配置。\nPowerShell 终端执行：\nPS D:\\src\\vcpkg\u0026gt; .\\vcpkg integrate install Applied user-wide integration for this vcpkg root. All C++ projects can now #include any installed libraries. Linking will be handled automatically. Installing new libraries will make them instantly available. 需要重启 Visual Studio 或执行生成以使用更改更新 Intellisense。\n现在只需在 Visual Studio 中使用“文件 -\u0026gt; 新建项目”，该库将自动可用。 对于 SQLite，可以尝试其 C/C++ 示例。\n若要删除用户的集成，可以使用 .\\vcpkg integrate remove。\nVcpkg with CLion https://github.com/microsoft/vcpkg#vcpkg-with-clion\nOpen the Toolchains settings (File \u0026gt; Settings on Windows and Linux, CLion \u0026gt; Preferences on macOS), and go to the CMake settings (Build, Execution, Deployment \u0026gt; CMake). Finally, in CMake options, add the following line:\n-DCMAKE_TOOLCHAIN_FILE=[vcpkg root]/scripts/buildsystems/vcpkg.cmake You must add this line to each profile.\nInstall cppzmq package .\\vcpkg\\vcpkg install cppzmq:x64-windows To find and use cppzmq in CMakeLists.txt if (WIN32) find_package(cppzmq REQUIRED) endif (WIN32) ","date":"16 May, 2023","id":71,"permalink":"/posts/vcpkg_windows/","summary":"https://github.com/microsoft/vcpkg#quick-start-windows","tags":"windows vcpkg clion visual_studio","title":"windows vcpkg"},{"content":"ZeroMQ REQ/RSP 模式与 zmq_poll 深度解析 摘要 本文档旨在深入探讨 ZeroMQ (简称 ZMQ) 中经典的 REQ/RSP（请求/响应）模式，特别是结合 zmq_poll 使用时的机制、底层原理和最佳实践。我们将结合 ZMQ 的核心设计思想与源码结构，对 poll 的工作方式进行详尽的分析，并提供生产级的标准 C++ 使用模板，以帮助开发者在实际项目中构建高效、稳定且具备高可用性的分布式应用。\n1. ZeroMQ REQ/RSP 模式简介 1.1 模式定义 REQ/RSP 模式是 ZMQ 中最基础也最严格的通信模式之一。它构建了一个严格的、轮流进行的请求-响应工作流，在网络的两端形成一个分布式的有限状态机（Distributed Finite State Machine, FSM）。\nREQ (Requester) Socket: 扮演客户端的角色。其协议行为被严格规定：必须首先调用 zmq_send() 发送一个请求，然后必须调用 zmq_recv() 等待一个响应。在成功收到响应之前，任何再次发送的尝试都会立即失败并返回错误码 EFSM (Error: Finite State Machine)，因为套接字正处于“等待响应”的状态。这种严格性保证了请求不会被无序发送。 RSP (Responder) Socket: 扮演服务端的角色。其行为同样被严格规定：必须首先调用 zmq_recv() 等待一个请求，然后必须调用 zmq_send() 发送一个响应。在一个请求被响应之前，它不会接收新的请求。在一个响应发送后，它必须等待下一个新请求的到来。 真实世界类比: 想象一下在银行柜台办理业务。顾客（REQ）必须先提交申请（send），然后等待柜员办理完成并返回结果（recv）。在等待期间，顾客不能提交第二个申请。同样，柜员（RSP）必须先接收一个申请（recv），处理后返还结果（send），然后才能服务下一位顾客。\n这种严格的“你问我答”模式是其最大的优点也是缺点。优点在于它极大地简化了简单RPC（远程过程调用）场景的编程模型，逻辑清晰。缺点在于其同步性和严格的锁定步骤，如果响应方出现故障或网络丢包，请求方会无限期地“卡”在等待状态，导致整个应用失去响应。这正是 zmq_poll 机制存在的根本原因。\n1.2 底层状态机（State Machine） 理解 REQ/RSP 的关键在于理解其背后的状态机。这个状态机不是在程序代码中显式定义的，而是由 ZMQ 在套接字内部强制执行的。\nREQ Socket 状态机: send_ready: 初始状态，可以发送请求。 send_request: 调用 zmq_send() 后，内部状态切换至 expect_reply。 expect_reply: 等待接收响应。此时，再次调用 zmq_send() 将立即失败，返回 EFSM。这是为了防止客户端在未得到确认的情况下发出大量请求，从而压垮服务端。 receive_reply: 成功调用 zmq_recv() 接收到响应后，状态机自动回到 send_ready 状态，可以发起下一次请求。 RSP Socket 状态机: receive_ready: 初始状态，可以接收请求。 receive_request: 成功调用 zmq_recv() 接收到一个请求后，内部状态切换至 send_reply。此时，再次调用 zmq_recv() 将会阻塞（如果配置为阻塞模式），因为它期望程序接下来发送一个响应。 send_reply: 可以调用 zmq_send() 发送响应。 reply_sent: 发送响应后，状态机自动回到 receive_ready 状态，准备处理来自任何已连接客户端的下一个请求。 重要细节: 当一个 RSP 套接字连接到多个 REQ 客户端时，它仍然是串行处理。它从一个客户端接收请求，发送响应，然后才能从另一个（或同一个）客户端接收下一个请求。ZMQ 内部会自动处理来自不同客户端的请求排队。如果你需要并发处理请求，应当选择更高级的模式，如 DEALER/ROUTER。\npoll 机制之所以如此重要，正是因为它提供了一种优雅的方式来与这个严格的状态机交互，允许我们探测套接字的状态（“现在能读吗？”）而不会因盲目调用 recv 而陷入阻塞，也不会因错误调用 send 而违反状态机规则。\n2. zmq_poll 的说明及底层原理 2.1 zmq_poll 是什么？ zmq_poll 是 ZMQ 提供的 I/O 多路复用机制。它的接口和行为类似于操作系统底层的 poll() 或 epoll() 系统调用，但其内在机制和抽象层次完全不同。它是一个面向消息的、跨平台的、可用于多种传输协议的轮询器。\n面向消息: 它检查的是“是否有一条完整的消息可读/可写”，而不是“底层文件描述符是否就绪”。这是它与系统 poll 的核心区别。 跨平台: ZMQ 在内部处理了 epoll (Linux)、kqueue (BSD/macOS)、IOCP (Windows) 等不同操作系统的高性能 I/O 模型的差异，为用户提供了统一的 zmq_poll 接口。 协议无关: zmq_poll 不仅能用于 tcp://，也能用于 inproc://（进程内线程间通信）或 ipc://（进程间通信）等非网络传输协议。 可读事件 (ZMQ_POLLIN): 表示在该套接字上至少有一条完整的消息已被 ZMQ 的 I/O 线程完全接收并放入了该套接字的内部接收队列中，等待用户线程通过 zmq_recv() 来提取。调用 zmq_recv() 不会阻塞。 可写事件 (ZMQ_POLLOUT): 表示通过 zmq_send() 发送消息的操作不会阻塞。这通常意味着套接字的内部发送队列未满（未达到高水位标记 HWM），或者对于某些模式，它已准备好接受下一条消息。 2.2 zmq_poll 的底层实现细节 (深入源码讲解) ZMQ 的 poll 远非对系统 poll/epoll 的简单封装。它是一个精巧的、跨线程的协调机制，其核心在于解耦了应用程序的用户线程与 ZMQ 内部的 I/O 线程。\n关键内部组件 要理解 poll，首先要了解几个 ZMQ 内部设计的基石：\n用户线程 (User Thread): 即执行 zmq_poll()、zmq_send()、zmq_recv() 调用的应用程序线程。 I/O 线程 (I/O Thread): 由 zmq::context_t 创建和管理的后台线程池（可以配置线程数量）。每个 I/O 线程都运行一个事件循环，其内部包含一个系统级的 I/O 多路复用器（如 epoll），专门负责与物理网络进行异步数据读写。更多的 I/O 线程可以更好地处理大量并发的、缓慢的连接。 套接字 (zmq::socket_base_t): ZMQ Socket 的基类，它像一个数据交换中心，内部持有两个关键的无锁队列 (Lock-Free Queue)： inbox (入站邮箱): 用于存放由 I/O 线程接收并根据 ZMTP 协议完整重组后的消息。 outbox (出站邮箱): 用于存放用户线程希望发送的消息，等待 I/O 线程来提取并发往网络。 无锁设计是 ZMQ 高性能的关键，它使得用户线程（生产者）和 I/O 线程（消费者）可以高效地在这些队列上操作，而无需使用昂贵的互斥锁，从而最大程度地减少了线程间的争用。 邮箱 (zmq::mailbox_t): 这是实现跨线程信令的核心。可以将其理解为一个高效的、带通知功能的命令队列。当用户线程需要等待事件时，它不是直接休眠，而是通过邮箱“订阅”事件。当 I/O 线程产生了该事件，它会通过邮箱“通知”用户线程。其内部通常由一个无锁队列和一个**条件变量（Condition Variable）**构成，这是一种极其高效的线程同步原语，能让等待的线程完全让出 CPU，避免了“忙等待”式的资源浪费。 zmq_poll 的工作流程 zmq_poll 的执行过程可以优雅地分为两个路径：快速路径 (Fast Path) 和 阻塞路径 (Blocking Path)。\n1. 快速路径 (非阻塞检查)\n这是最高效、最常见的路径。当用户线程调用 zmq_poll() 时：\npoll 函数会立即遍历所有待检查的 socket。 对于每一个要检查 ZMQ_POLLIN 的 socket，它会调用类似 socket-\u0026gt;has_in() 的内部函数。这个函数的作用是以原子方式检查该 socket 的 inbox 队列的指针或计数器，判断其是否非空。 这是一个纯粹的 CPU 内存操作，速度极快，不涉及任何系统调用或内核上下文切换。 如果检查发现任何一个 socket 的 inbox 中有消息（例如，消息在 poll 被调用前 1 毫秒刚刚到达），poll 会立刻设置对应的 revents 标志，并带着找到的事件数量返回。应用几乎没有感到任何延迟。 2. 阻塞路径 (等待与唤醒)\n如果在快速路径检查中，所有 socket 的 inbox 都为空，并且 timeout 参数不为0，poll 就会进入一个精心设计的阻塞路径：\n订阅与等待: a. 用户线程会向每个被轮询的 socket 的邮箱 (mailbox_t) 发送一个 \u0026ldquo;订阅\u0026rdquo; 命令。这个命令本质上是在 socket 内部的一个订阅者列表中注册自己，表示“如果未来有 ZMQ_POLLIN 事件发生，请通知我这个特定的用户线程”。 b. 完成所有订阅后，用户线程会在一个专用的、与自身线程关联的邮箱上调用 wait() 方法，并传入 timeout。此时，用户线程会阻塞在条件变量上，进入高效的睡眠状态，完全让出 CPU。 I/O 线程的工作: a. 与此同时，某个 I/O 线程正在后台默默工作。其内部的 epoll_wait (或等效调用) 返回，表示网络上有数据到达。 b. I/O 线程读取网络数据。由于 TCP是流协议，数据可能是零散的。I/O 线程会根据 ZMTP (ZeroMQ Message Transport Protocol) 的帧格式，将这些数据分片缓存并重组。ZMTP 定义了清晰的消息边界，所以 I/O 线程能准确知道何时一条完整的 ZMQ 消息被成功构建。 c. 当一条完整的 ZMQ 消息（可能包含多个部分）被成功构建后，I/O 线程会将其作为一个原子单元推入目标 socket 的 inbox 无锁队列。 d. 唤醒用户线程 (关键步骤): 在将消息放入 inbox 之后，I/O 线程会检查该 socket 的订阅者列表。如果发现有用户线程正在等待此事件，它会向该用户线程的邮箱发送一个激活信号 (signal)。这个信号非常轻量，通常只是一个原子操作，它会唤醒之前阻塞在条件变量上的用户线程。 唤醒后的处理: a. 用户线程从 wait() 中被唤醒，就像闹钟响了一样。 b. 它会再次进入快速路径，重新扫描所有被轮询 socket 的 inbox。 c. 这一次，由于 I/O 线程已经放入了新消息，扫描会成功发现事件。 d. poll 设置 revents 标志并返回。 超时: 如果在指定的 timeout 时间内，没有任何 I/O 线程发送唤醒信号，用户线程的 wait() 会超时返回，zmq_poll 最终返回 0，表示没有任何事件发生。 源码概念总结 // 伪代码，更详细地示意 ZMQ 内部逻辑 // zmq_poll 的核心实现 int zmq_poll(zmq_pollitem_t *items, int nitems, long timeout) { // === 1. 快速路径 (Fast Path) === // 立即、无锁地检查所有套接字的队列。 int events_found = 0; for (item in items) { zmq::socket_base_t* s = resolve_socket(item-\u0026gt;socket); // 检查 inbox 是否有完整消息 if ((item-\u0026gt;events \u0026amp; ZMQ_POLLIN) \u0026amp;\u0026amp; s-\u0026gt;has_in()) { item-\u0026gt;revents |= ZMQ_POLLIN; events_found++; } // 对 ZMQ_POLLOUT 的检查也类似 (检查 outbox 是否有空间，未达HWM) if ((item-\u0026gt;events \u0026amp; ZMQ_POLLOUT) \u0026amp;\u0026amp; s-\u0026gt;has_out()) { item-\u0026gt;revents |= ZMQ_POLLOUT; events_found++; } } // 如果快速路径找到了事件，或用户指定不等待，直接返回。 if (events_found \u0026gt; 0 || timeout == 0) { return events_found; } // === 2. 阻塞路径 (Blocking Path) === // a. 向每个 socket 的 mailbox 发送 \u0026#34;订阅\u0026#34; 命令，注册回调。 for (item in items) { item-\u0026gt;socket-\u0026gt;subscribe_events(my_user_thread_mailbox); } // b. 在用户线程自己的 mailbox 上阻塞等待，直到被唤醒或超时。 // 此操作让出 CPU，进入睡眠。 bool awakened = my_user_thread_mailbox-\u0026gt;wait(timeout); // c. 不论是唤醒还是超时，都需要取消订阅，清理注册。 for (item in items) { item-\u0026gt;socket-\u0026gt;unsubscribe_events(my_user_thread_mailbox); } // d. 如果是被唤醒（而非超时），说明可能有事件，必须再次执行快速路径检查来确认。 if (awakened) { // 再次扫描所有 socket 的 inbox/outbox // ... 逻辑同快速路径 ... return events_found; // 返回找到的事件数 } // e. 如果是超时，说明等待期间无事发生，返回 0。 return 0; } // I/O 线程中的消息处理逻辑 void zmq::io_thread_t::in_event() { // 1. 从 TCP socket 读取数据流，根据 ZMTP 协议重组为完整消息 msg。 // 2. 将完整的消息 msg 原子性地推入目标 socket 的 inbox 队列。 target_socket-\u0026gt;inbox-\u0026gt;push(msg); // 3. 发送信号：检查 socket 的订阅列表，并向所有订阅了此事件的 // 用户线程的 mailbox 发送一个轻量级的唤醒信号。 target_socket-\u0026gt;mailbox-\u0026gt;signal(); } 结论: zmq_poll 的高效源于其精妙的异步协作模型：它尽可能地在无锁的快速路径上解决问题，只在绝对必要时才通过高效的条件变量机制让用户线程休眠，并通过轻量级的异步信号进行唤醒。它关心的是逻辑上完整的消息，而非底层的原始数据，这正是 ZMQ 强大之处的体现。\n3. ZMQ REQ/RSP 与 poll 深入对比 在 REQ/RSP 模式下，客户端（REQ）的健壮性至关重要。如果服务器宕机、网络中断或响应丢失，一个设计不佳的客户端将会永久阻塞。\n处理方式 优点 缺点 后果与影响 适用场景 直接阻塞 recv 代码最简单，逻辑直观。 极其脆弱，完全没有错误处理能力。 进程挂起。遇到网络问题或服务器故障时，线程将无限期阻塞，导致应用假死，无法服务也无法正常关闭。 仅限教学示例。严禁在任何生产或需要可靠性的环境中使用。 poll + 超时 健壮、可靠、可恢复。 代码比阻塞方式稍复杂。 高可用性。应用可以从网络故障中恢复，可以实现重试、故障转移、记录日志等高级行为。 绝对的推荐用法。是构建所有生产级 ZMQ 应用的标准实践。 非阻塞 recv + 循环 (ZMQ_DONTWAIT) 可以避免阻塞。 极度低效，是典型的反模式。 资源枯竭。会造成“忙等待”，CPU 占用率飙升至 100%，浪费大量电力，并可能导致操作系统调度出现问题，影响其他进程。 几乎无任何适用场景。应始终用 poll 替代。 poll 在 REQ/RSP 中的核心价值： 超时处理与故障检测: 这是 poll 最重要的价值。客户端（REQ）在发送请求后，使用带超时的 poll 等待响应。如果超时，就可以合理地推断出响应丢失或服务端无响应。例如，一个服务器在收到请求后，计算过程中崩溃了，客户端的 poll 将会超时，从而让客户端知道任务失败，可以进行记录日志、告警或后续处理，而不是无限期地挂起。 实现可靠的重试机制 (Lazy Pirate Pattern): poll 是实现“懒惰海盗模式”这一经典 ZMQ 可靠性模式的基础。这个模式之所以叫“懒惰海盗”，是因为它采取了一种“简单粗暴”但极其有效的恢复策略：当请求超时后，它不尝试在原有的、状态已损坏的连接上进行复杂的修复，而是像一个懒惰的海盗一样，直接抛弃旧船（销毁旧的 socket），换一艘新船（创建全新的 socket），然后重新杨帆起航（重发请求）。poll 的超时机制正是触发“换船”这一动作的信号。 保护状态机与管理多路请求: poll 确保你总是在正确的时机调用 zmq_recv()。你只会在 poll 明确告诉你 ZMQ_POLLIN 事件发生后才去接收消息，这完美地契合了 REQ/RSP 的状态机，从根本上避免了 EFSM 错误。更进一步，如果一个应用程序需要同时与多个不同的服务（每个服务一个 REQ socket）通信，poll 可以在单个线程里同时监视所有这些 socket 的返回事件，从而高效地管理多路并发请求。 4. ZMQ 标准使用模板 (C++ with zmq.hpp) 下面提供一个健壮的、可用于生产环境的 REQ/RSP + poll 的 C++ 模板。我们使用现代 C++ 的 ZMQ 封装库 zmq.hpp，它提供了更安全、更易用的 RAII 风格接口。\n4.1 服务端 (RSP) 模板 服务端通常是被动的，其主要职责就是等待并响应。因此，在简单的场景下，直接使用阻塞的 recv 是可以接受的，因为“阻塞等待”正是它的设计意图。\n然而，即使是服务端，在更复杂的应用中也可能需要 poll。例如，一个服务器可能需要同时监听一个用于接收客户端业务请求的 RSP socket，以及一个用于接收管理员“优雅停机”命令的 SUB socket。这时，就必须使用 poll 来同时监视两个 socket 上的事件。\n#include \u0026lt;zmq.hpp\u0026gt; #include \u0026lt;string\u0026gt; #include \u0026lt;iostream\u0026gt; #include \u0026lt;thread\u0026gt; #include \u0026lt;chrono\u0026gt; int main() { // 1. 初始化 ZMQ 上下文 zmq::context_t context(1); // 2. 创建 RSP 套接字并绑定 zmq::socket_t responder(context, zmq::socket_type::rsp); try { responder.bind(\u0026#34;tcp://*:5555\u0026#34;); } catch (const zmq::error_t\u0026amp; e) { std::cerr \u0026lt;\u0026lt; \u0026#34;Bind failed: \u0026#34; \u0026lt;\u0026lt; e.what() \u0026lt;\u0026lt; std::endl; return 1; } std::cout \u0026lt;\u0026lt; \u0026#34;Server started, listening on tcp://*:5555\u0026#34; \u0026lt;\u0026lt; std::endl; while (true) { try { // 3. 等待请求。对于简单服务端，阻塞在这里是符合逻辑的。 zmq::message_t request; // recv() 会返回一个 std::optional\u0026lt;size_t\u0026gt;，可以检查其是否有值 auto result = responder.recv(request, zmq::recv_flags::none); // 检查 recv 是否成功接收到消息 if (result.has_value()) { std::cout \u0026lt;\u0026lt; \u0026#34;Received request: [\u0026#34; \u0026lt;\u0026lt; request.to_string_view() \u0026lt;\u0026lt; \u0026#34;]\u0026#34; \u0026lt;\u0026lt; std::endl; // 模拟业务处理，例如数据库查询或复杂计算 std::this_thread::sleep_for(std::chrono::seconds(1)); // 4. 发送响应。这是 RSP 状态机的要求。 responder.send(zmq::buffer(\u0026#34;World\u0026#34;), zmq::send_flags::none); } } catch (const zmq::error_t\u0026amp; e) { // 当 zmq::context_t 被销毁时，所有阻塞的调用都会被中断， // 并抛出 ETERM 异常。这是实现优雅停机的关键。 if (e.num() == ETERM) { std::cout \u0026lt;\u0026lt; \u0026#34;Context terminated, server is shutting down.\u0026#34; \u0026lt;\u0026lt; std::endl; break; } std::cerr \u0026lt;\u0026lt; \u0026#34;ZMQ Error during server loop: \u0026#34; \u0026lt;\u0026lt; e.what() \u0026lt;\u0026lt; std::endl; } } return 0; } 4.2 健壮的客户端 (REQ) 模板 - Lazy Pirate Pattern 客户端是 poll 发挥核心作用的地方。这个模板完整地展示了如何实现超时、重试和状态恢复。\n#include \u0026lt;zmq.hpp\u0026gt; #include \u0026lt;string\u0026gt; #include \u0026lt;iostream\u0026gt; #include \u0026lt;vector\u0026gt; #include \u0026lt;chrono\u0026gt; // 定义常量，使其更易于配置和维护 constexpr int REQUEST_TIMEOUT_MS = 2500; // 请求超时时间 (ms) constexpr int MAX_RETRIES = 3; // 最大重试次数 const std::string SERVER_ENDPOINT = \u0026#34;tcp://localhost:5555\u0026#34;; /** * @brief 创建一个新的 REQ socket 并连接到服务端。 * 这个函数封装了 socket 的创建和配置，用于重试逻辑中。 * @param context ZMQ 的上下文 * @return 配置好的 ZMQ socket */ zmq::socket_t create_and_connect_socket(zmq::context_t\u0026amp; context) { zmq::socket_t socket(context, zmq::socket_type::req); socket.connect(SERVER_ENDPOINT); // 设置 ZMQ_LINGER 套接字选项为 0。 // 这意味着当 socket 被 close() 时，任何待发送的消息都会被立即丢弃。 // 在我们的重试场景中，这是期望的行为，因为我们即将用新 socket 重发请求。 socket.set(zmq::sockopt::linger, 0); return socket; } int main() { // 1. 初始化 ZMQ 上下文 zmq::context_t context(1); std::cout \u0026lt;\u0026lt; \u0026#34;Client started, attempting to connect to server at \u0026#34; \u0026lt;\u0026lt; SERVER_ENDPOINT \u0026lt;\u0026lt; std::endl; // 创建初始的 socket zmq::socket_t requester = create_and_connect_socket(context); int retries_left = MAX_RETRIES; int request_num = 0; while (retries_left \u0026gt; 0) { // 2. 构造并发送请求 std::string request_str = \u0026#34;Hello-\u0026#34; + std::to_string(++request_num); std::cout \u0026lt;\u0026lt; \u0026#34;Sending request #\u0026#34; \u0026lt;\u0026lt; request_num \u0026lt;\u0026lt; \u0026#34;: [\u0026#34; \u0026lt;\u0026lt; request_str \u0026lt;\u0026lt; \u0026#34;]...\u0026#34; \u0026lt;\u0026lt; std::endl; requester.send(zmq::buffer(request_str), zmq::send_flags::none); // 3. 使用 zmq::poll 等待响应，这是模式的核心 std::vector\u0026lt;zmq::pollitem_t\u0026gt; poll_items = { // poll_items[0] // socket: 要监视的套接字 // fd: (忽略，用于非ZMQ套接字) // events: 我们感兴趣的事件 (这里是 ZMQ_POLLIN - 可读) // revents: (输出) 实际发生的事件 { requester, 0, ZMQ_POLLIN, 0 } }; // 调用 poll，超时时间为我们定义的常量 int rc = zmq::poll(poll_items, std::chrono::milliseconds(REQUEST_TIMEOUT_MS)); // 4. 根据 poll 的返回值处理结果 if (rc \u0026gt; 0 \u0026amp;\u0026amp; poll_items[0].revents \u0026amp; ZMQ_POLLIN) { // 成功：poll 返回值大于0，且 revents 标志位被设置 zmq::message_t reply; auto result = requester.recv(reply, zmq::recv_flags::none); if (result.has_value()) { std::cout \u0026lt;\u0026lt; \u0026#34;Server replied: [\u0026#34; \u0026lt;\u0026lt; reply.to_string_view() \u0026lt;\u0026lt; \u0026#34;]\u0026#34; \u0026lt;\u0026lt; std::endl; // 成功收到响应，任务完成，退出重试循环 retries_left = 0; } } else { // 失败：poll 返回0 (超时) 或 -1 (错误) retries_left--; std::cerr \u0026lt;\u0026lt; \u0026#34;No response from server, request timed out.\u0026#34; \u0026lt;\u0026lt; std::endl; if (retries_left == 0) { std::cerr \u0026lt;\u0026lt; \u0026#34;Server seems to be offline. Aborting after \u0026#34; \u0026lt;\u0026lt; MAX_RETRIES \u0026lt;\u0026lt; \u0026#34; retries.\u0026#34; \u0026lt;\u0026lt; std::endl; break; // 耗尽重试次数，退出循环 } std::cout \u0026lt;\u0026lt; \u0026#34;Reconnecting to server... (\u0026#34; \u0026lt;\u0026lt; retries_left \u0026lt;\u0026lt; \u0026#34; retries left)\u0026#34; \u0026lt;\u0026lt; std::endl; // **关键: 状态恢复 (State Recovery)** // 旧的 socket 内部状态机已卡在 \u0026#34;expect_reply\u0026#34; 状态。 // 必须销毁它并创建一个全新的 socket 来重置状态机。 // 在 C++ 中，`zmq.hpp` 的 RAII 特性让此操作非常简单： // 将新 socket 赋值给旧变量时，旧 socket 的析构函数会被自动调用，从而关闭它。 requester = create_and_connect_socket(context); } } // 上下文和套接字会在作用域结束时由 zmq.hpp 的析构函数自动安全地销毁 return 0; } 客户端模板的关键点说明： 超时与重试循环: 整个通信逻辑被包裹在一个 while 循环中，这是实现重试机制的骨架。 zmq::poll: 这是等待响应的核心。它将不确定的网络等待转换成一个有明确结果（成功、超时、错误）的同步调用。 状态恢复: 这是模板的精髓，也是新手最容易犯错的地方。绝对不能在 poll 超时后，尝试在同一个 REQ socket 上再次调用 send()。这会立即导致 EFSM 错误。最干净、最可靠、也是官方推荐的处理方式就是销毁并重建 socket。这确保了状态机被完全重置到一个干净的初始状态，让你能够安全地重新发起请求。 5. 总结 zmq_poll 并不仅仅是 ZMQ 提供的一个工具函数，它是在 ZMQ 强大的异步内核之上，构建健壮、可靠、有状态应用程序的核心桥梁。它优雅地解决了用户线程的同步逻辑与 ZMQ 内部 I/O 线程的异步事件之间的交互问题。\n理解 poll 的工作原理——即检查的是完整的、已入队的消息而非底层网络数据流——是真正掌握 ZMQ 的关键。\n在实践中，开发者应始终遵循以下黄金法则：\n永远不要在生产代码中使用无限阻塞的 recv，尤其是在客户端。 在 REQ 客户端侧，必须使用带超时的 zmq_poll 来等待响应，这是构建任何有意义的错误处理和恢复能力的前提。 在 poll 超时后，必须通过销毁并重建 REQ socket 来可靠地重置状态机，然后才能安全地进行重试。 虽然本文档聚焦于最基础的 REQ/RSP 模式，但其中蕴含的关于状态机管理、异步协作和故障恢复的原则，是高效、正确地使用 ZMQ 所有高级模式的基石。通过遵循本文档提供的分析和标准模板，开发者可以更有信心地构建出能够从容应对真实世界网络复杂性的、具备高可用性的 ZeroMQ 应用程序。\n","date":"16 May, 2023","id":72,"permalink":"/posts/zeromq-req-rsp-%E6%A8%A1%E5%BC%8F%E4%B8%8E-zmq-poll-%E6%B7%B1%E5%BA%A6%E8%A7%A3%E6%9E%90/","summary":"本文档旨在深入探讨 ZeroMQ (简称 ZMQ) 中经典的 REQ/RSP（请求/响应）模式，特别是结合 zmq_poll 使用时的机制、底层原理和最佳实践。我们将结合 ZMQ 的核心设计思想与源码结构，对 poll 的工作方式进行详尽的分析，并提供生产级的标准 C++ 使用模板，以帮助开发者在实际项目中构建高效、稳定且具备高可用性的分布式应用。","tags":"zmq request response poll epoll 多路复用 阻塞 通信","title":"ZeroMQ REQ/RSP 模式与 `zmq_poll` 深度解析"},{"content":"基本用法 date $ date 2023年 02月 09日 星期四 16:22:29 CST 精确到 ms $ date +\u0026#39;%d/%m/%Y %H:%M:%S:%3N\u0026#39; 09/02/2023 16:23:20:252 精确到 ns $ date +\u0026#39;%d/%m/%Y %H:%M:%S:%N\u0026#39; 09/02/2023 16:23:24:918036405 ","date":"9 February, 2023","id":73,"permalink":"/posts/linux_date_cmd/","summary":"","tags":"linux date","title":"Linux date 命令用法"},{"content":"目录 安装卸载列出 WSL 发行版 WSL kernel 客制化 wsl 挂载 ext4 移动硬盘 安装卸载列出 WSL 发行版 # 列出当前已安装的所有WSL发行版（包括正在运行和已停止的） wsl --list # 列出微软官方提供的、可在线安装的所有WSL发行版 wsl --list --online # 安装指定的WSL发行版，这里是Ubuntu 24.04版本 wsl --install -d Ubuntu-24.04 # 彻底卸载并删除名为Ubuntu-24.04的WSL发行版（数据会全部清除） wsl --unregister Ubuntu-24.04 C:\\Users\\max_h\u0026gt;wsl --list 适用于 Linux 的 Windows 子系统分发: Ubuntu-24.04 (默认) Ubuntu-20.04 C:\\Users\\max_h\u0026gt;wsl --list --online 以下是可安装的有效分发的列表。 使用 \u0026#39;wsl.exe --install \u0026lt;Distro\u0026gt;\u0026#39; 安装。 NAME FRIENDLY NAME Ubuntu Ubuntu Debian Debian GNU/Linux kali-linux Kali Linux Rolling Ubuntu-18.04 Ubuntu 18.04 LTS Ubuntu-20.04 Ubuntu 20.04 LTS Ubuntu-22.04 Ubuntu 22.04 LTS Ubuntu-24.04 Ubuntu 24.04 LTS OracleLinux_7_9 Oracle Linux 7.9 OracleLinux_8_7 Oracle Linux 8.7 OracleLinux_9_1 Oracle Linux 9.1 openSUSE-Leap-15.6 openSUSE Leap 15.6 SUSE-Linux-Enterprise-15-SP5 SUSE Linux Enterprise 15 SP5 SUSE-Linux-Enterprise-15-SP6 SUSE Linux Enterprise 15 SP6 openSUSE-Tumbleweed openSUSE Tumbleweed C:\\Users\\max_h\u0026gt;wsl --install -d Ubuntu-24.04 Ubuntu 24.04 LTS 已安装。 正在启动 Ubuntu 24.04 LTS... Installing, this may take a few minutes... Please create a default UNIX user account. The username does not need to match your Windows username. For more information visit: https://aka.ms/wslusers Enter new UNIX username: luyang New password: Retype new password: passwd: password updated successfully Installation successful! To run a command as administrator (user \u0026#34;root\u0026#34;), use \u0026#34;sudo \u0026lt;command\u0026gt;\u0026#34;. See \u0026#34;man sudo_root\u0026#34; for details. Welcome to Ubuntu 24.04.1 LTS (GNU/Linux 5.15.167.4-microsoft-standard-WSL2 x86_64) * Documentation: https://help.ubuntu.com * Management: https://landscape.canonical.com * Support: https://ubuntu.com/pro System information as of Wed Mar 19 14:19:04 CST 2025 System load: 0.21 Processes: 31 Usage of /: 0.1% of 1006.85GB Users logged in: 0 Memory usage: 3% IPv4 address for eth0: 172.20.24.196 Swap usage: 0% This message is shown once a day. To disable it please create the /home/luyang/.hushlogin file. C:\\Users\\max_h\u0026gt;wsl --unregister Ubuntu-24.04 正在注销。 操作成功完成。 C:\\Users\\max_h\u0026gt;wsl --list 适用于 Linux 的 Windows 子系统没有安装的分发版。 使用 \u0026#39;wsl.exe --list --online\u0026#39; 列出可用的分发版 和 \u0026#39;wsl.exe --install \u0026lt;Distro\u0026gt;\u0026#39; 进行安装。 也可以通过访问 Microsoft Store 来安装分发版: https://aka.ms/wslstore 错误代码: Wsl/WSL_E_DEFAULT_DISTRO_NOT_FOUND WSL kernel 客制化 首先运行 wsl 通过如下命令确认当前内核版本：\nuname -a Linux x 6.6.87.2-microsoft-standard-WSL2+ #1 SMP PREEMPT_DYNAMIC Sun Jun 15 21:13:48 CST 2025 x86_64 x86_64 x86_64 GNU/Linux 克隆源代码 git clone https://github.com/microsoft/WSL2-Linux-Kernel.git --depth=1 -b linux-msft-wsl-6.6.y cd WSL2-Linux-Kernel git tag -l | grep \u0026#34;6.6.87\u0026#34; git checkout -b my-6.6.87.2-kernel linux-msft-wsl-6.6.87.2 --depth=1 clones only the latest commit to save time and space. -b linux-msft-wsl-6.6.y specifies the branch to clone. 目前 github https://github.com/microsoft/WSL2-Linux-Kernel 主要版本：\nlinux-msft-wsl-6.6.y linux-msft-wsl-4.19.y linux-msft-wsl-5.4.y linux-msft-wsl-5.10.y linux-msft-wsl-5.15.y linux-msft-wsl-6.1.y master \u0026hellip; 安装编译环境 sudo apt update \u0026amp;\u0026amp; sudo apt install build-essential flex bison libssl-dev libelf-dev bc python3 pahole cpio 配置内核 cp /proc/config.gz config.gz gunzip config.gz cp config .config make menuconfig make -j sudo make modules_install -j sudo make install -j cp vmlinux /mnt/c/Users/luyang/ 配置 WSL 注意用户名根据实际进行修改\nwindow 用户目录下（例如：C:\\Users\\luyang）创建文件： .wslconfig\n文件内容如下：\n[wsl2] kernel=C:\\\\Users\\\\luyang\\\\vmlinux # Limits VM memory to use no more than 16GB. # Set this based on your host\u0026#39;s total RAM. For a 32GB host, 16GB is a good start. memory=16GB # How much swap space to add to the WSL 2 VM. # 0 for no swap file. A good starting point is equal to or double your memory setting. # For a build like Cuttlefish, you might need a lot, e.g., 20GB or more. swap=20GB # Absolute Windows path to the swap virtual hard disk. # This file will be created/managed by WSL. Ensure the path exists. # Use double backslashes for Windows paths. swapFile=C:\\\\wsl_swap\\\\wsl-swap.vhdx # How many processors to assign to the WSL 2 VM. # Set this to a reasonable number of your CPU cores, e.g., half or two-thirds. # For heavy builds, too many cores with insufficient RAM can also lead to OOM. processors=8 wsl 挂载 ext4 移动硬盘 windows powershell 管理员权限运行\nPS C:\\Users\\luyang\u0026gt; GET-CimInstance -query \u0026#34;SELECT * from Win32_DiskDrive\u0026#34; DeviceID Caption Partitions Size Model -------- ------- ---------- ---- ----- \\\\.\\PHYSICALDRIVE2 WD Green SN350 1TB 1 1000202273280 WD Green SN350 1TB \\\\.\\PHYSICALDRIVE1 WDC WD40EJRX-89AKWY0 1 4000784417280 WDC WD40EJRX-89AKWY0 \\\\.\\PHYSICALDRIVE0 WDC WD10EZEX-08WN4A0 3 1000202273280 WDC WD10EZEX-08WN4A0 windows 挂载\nPS C:\\Windows\\system32\u0026gt; wsl --mount \\\\.\\PHYSICALDRIVE3 --bare 操作成功完成。 wsl 终端挂载\nsudo fdisk -l Device Boot Start End Sectors Size Id Type /dev/sdc1 2048 1000148991 1000146944 476.9G 83 Linux sudo mount -t ext4 /dev/sdc1 /mnt wsl 终端卸载\nsudo umount -t ext4 /dev/sdc1 /mnt windows 卸载\nwsl --unmount \\\\.\\PHYSICALDRIVE3 --bare WSL 端口映射 查询当前已经转发的端口 如何查看当前 windows -\u0026gt; WSL 配置了哪些端口转发？ 以管理员身份运行 PowerShell:\nPS C:\\WINDOWS\\system32\u0026gt; netsh interface portproxy show all 侦听 ipv4: 连接到 ipv4: 地址 端口 地址 端口 --------------- ---------- --------------- ---------- 0.0.0.0 8080 172.18.150.174 80 0.0.0.0 9999 172.25.198.88 9999 127.0.0.1 562 172.25.198.88 562 0.0.0.0 562 172.25.198.88 562 0.0.0.0 4865 172.25.198.88 4865 0.0.0.0 6666 172.25.198.88 6666 确认 WSL IP 地址 WSL 终端运行:\n$ ifconfig docker0: flags=4163\u0026lt;UP,BROADCAST,RUNNING,MULTICAST\u0026gt; mtu 1500 inet 172.17.0.1 netmask 255.255.0.0 broadcast 172.17.255.255 inet6 fe80::42:d3ff:fe45:67a4 prefixlen 64 scopeid 0x20\u0026lt;link\u0026gt; ether 02:42:d3:45:67:a4 txqueuelen 0 (Ethernet) RX packets 12553 bytes 108393702 (108.3 MB) RX errors 0 dropped 0 overruns 0 frame 0 TX packets 15258 bytes 1786658 (1.7 MB) TX errors 0 dropped 0 overruns 0 carrier 0 collisions 0 eth0: flags=4163\u0026lt;UP,BROADCAST,RUNNING,MULTICAST\u0026gt; mtu 1500 inet 172.25.198.88 netmask 255.255.240.0 broadcast 172.25.207.255 inet6 fe80::215:5dff:feec:a420 prefixlen 64 scopeid 0x20\u0026lt;link\u0026gt; ether 00:15:5d:ec:a4:20 txqueuelen 1000 (Ethernet) RX packets 201105667 bytes 290122284896 (290.1 GB) RX errors 0 dropped 0 overruns 0 frame 0 TX packets 55298591 bytes 3209600213 (3.2 GB) TX errors 0 dropped 0 overruns 0 carrier 0 collisions 0 lo: flags=73\u0026lt;UP,LOOPBACK,RUNNING\u0026gt; mtu 65536 inet 127.0.0.1 netmask 255.0.0.0 inet6 ::1 prefixlen 128 scopeid 0x10\u0026lt;host\u0026gt; loop txqueuelen 1000 (Local Loopback) RX packets 217290 bytes 624612200 (624.6 MB) RX errors 0 dropped 0 overruns 0 frame 0 TX packets 217290 bytes 624612200 (624.6 MB) TX errors 0 dropped 0 overruns 0 carrier 0 collisions 0 veth11e7cb7: flags=4163\u0026lt;UP,BROADCAST,RUNNING,MULTICAST\u0026gt; mtu 1500 inet6 fe80::fcfb:17ff:fe7d:ad3 prefixlen 64 scopeid 0x20\u0026lt;link\u0026gt; ether fe:fb:17:7d:0a:d3 txqueuelen 0 (Ethernet) RX packets 12553 bytes 108569444 (108.5 MB) RX errors 0 dropped 0 overruns 0 frame 0 TX packets 15279 bytes 1788224 (1.7 MB) TX errors 0 dropped 0 overruns 0 carrier 0 collisions 0 如上: eth0 172.25.198.88\n增加端口4864映射 netsh interface portproxy add v4tov4 listenaddress=0.0.0.0 listenport=4864 connectaddress=172.25.198.88 4864 PS C:\\WINDOWS\\system32\u0026gt; netsh interface portproxy show all 侦听 ipv4: 连接到 ipv4: 地址 端口 地址 端口 --------------- ---------- --------------- ---------- 0.0.0.0 8080 172.18.150.174 80 0.0.0.0 9999 172.25.198.88 9999 127.0.0.1 562 172.25.198.88 562 0.0.0.0 562 172.25.198.88 562 0.0.0.0 4865 172.25.198.88 4865 0.0.0.0 6666 172.25.198.88 6666 0.0.0.0 4864 172.25.198.88 4864 删除端口4864映射 netsh interface portproxy delete v4tov4 listenport=4864 listenaddress=0.0.0.0 PS C:\\WINDOWS\\system32\u0026gt; netsh interface portproxy show all 侦听 ipv4: 连接到 ipv4: 地址 端口 地址 端口 --------------- ---------- --------------- ---------- 0.0.0.0 8080 172.18.150.174 80 0.0.0.0 9999 172.25.198.88 9999 127.0.0.1 562 172.25.198.88 562 0.0.0.0 562 172.25.198.88 562 0.0.0.0 4865 172.25.198.88 4865 0.0.0.0 6666 172.25.198.88 6666 From: https://learn.microsoft.com/en-us/windows/wsl/networking\nHere\u0026rsquo;s an example of using the Netsh interface portproxy Windows command to add a port proxy that listens on your host port and connects that port proxy to the IP address for the WSL 2 VM.\nnetsh interface portproxy add v4tov4 listenport=\u0026lt;yourPortToForward\u0026gt; listenaddress=0.0.0.0 connectport=\u0026lt;yourPortToConnectToInWSL\u0026gt; connectaddress=(wsl hostname -I) In this example, you will need to update \u0026lt;yourPortToForward\u0026gt; to a port number, for example listenport=4000. listenaddress=0.0.0.0 means that incoming requests will be accepted from ANY IP address. The Listen Address specifies the IPv4 address for which to listen and can be changed to values that include: IP address, computer NetBIOS name, or computer DNS name. If an address isn\u0026rsquo;t specified, the default is the local computer. You need to update the \u0026lt;yourPortToConnectToInWSL\u0026gt; value to a port number where you want WSL to connect, for example connectport=4000. Lastly, the connectaddress value needs to be the IP address of your Linux distribution installed via WSL 2 (the WSL 2 VM address), which can be found by entering the command: wsl.exe hostname -I.\nSo this command may look something like:\nnetsh interface portproxy add v4tov4 listenport=4000 listenaddress=0.0.0.0 connectport=4000 connectaddress=192.168.101.100 To obtain the IP address, use:\nwsl hostname -I for the IP address of your Linux distribution installed via WSL 2 (the WSL 2 VM address) cat /etc/resolv.conf for the IP address of the Windows machine as seen from WSL 2 (the WSL 2 VM) Using listenaddress=0.0.0.0 will listen on all IPv4 ports.\nUsing a lowercase \u0026#34;i\u0026#34; with the hostname command will generate a different result than using an uppercase \u0026#34;I\u0026#34;. wsl hostname -i is your local machine (127.0.1.1 is a placeholder diagnostic address), whereas wsl hostname -I will return your local machine\u0026#39;s IP address as seen by other machines and should be used to identify the connectaddress of your Linux distribution running via WSL 2. ","date":"9 February, 2023","id":74,"permalink":"/posts/wsl-%E4%B8%BB%E9%A1%B5/","summary":"首先运行 wsl 通过如下命令确认当前内核版本：","tags":"windows wsl linux ext4 usbipd","title":"wsl 主页"},{"content":"黑芝麻平台交叉编译 openssl 前置条件 编译环境：黑芝麻 Linux23 Docker 开发环境，已经默认配置了交叉编译环境。\n源码下载 wget https://www.openssl.org/source/openssl-1.1.1k.tar.gz tar -xzvf openssl-1.1.1k.tar.gz cd openssl-1.1.1k 配置 准备目标文件安装目录：\nmkdir _INSTALL 查看帮助手册：\nroot@028337952dd7:/home/misc/openssl-1.1.1k# ./Configure Usage: Configure [no-\u0026lt;cipher\u0026gt; ...] [enable-\u0026lt;cipher\u0026gt; ...] [-Dxxx] [-lxxx] [-Lxxx] [-fxxx] [-Kxxx] [no-hw-xxx|no-hw] [[no-]threads] [[no-]shared] [[no-]zlib|zlib-dynamic] [no-asm] [no-egd] [sctp] [386] [--prefix=DIR] [--openssldir=OPENSSLDIR] [--with-xxx[=vvv]] [--config=FILE] os/compiler[:flags] pick os/compiler from: BS2000-OSD BSD-generic32 BSD-generic64 BSD-ia64 BSD-sparc64 BSD-sparcv8 BSD-x86 BSD-x86-elf BSD-x86_64 Cygwin Cygwin-i386 Cygwin-i486 Cygwin-i586 Cygwin-i686 Cygwin-x86 Cygwin-x86_64 DJGPP MPE/iX-gcc UEFI UWIN VC-CE VC-WIN32 VC-WIN32-ARM VC-WIN32-ONECORE VC-WIN64-ARM VC-WIN64A VC-WIN64A-ONECORE VC-WIN64A-masm VC-WIN64I aix-cc aix-gcc aix64-cc aix64-gcc android-arm android-arm64 android-armeabi android-mips android-mips64 android-x86 android-x86_64 android64 android64-aarch64 android64-mips64 android64-x86_64 bsdi-elf-gcc cc darwin-i386-cc darwin-ppc-cc darwin64-arm64-cc darwin64-ppc-cc darwin64-x86_64-cc gcc haiku-x86 haiku-x86_64 hpux-ia64-cc hpux-ia64-gcc hpux-parisc-cc hpux-parisc-gcc hpux-parisc1_1-cc hpux-parisc1_1-gcc hpux64-ia64-cc hpux64-ia64-gcc hpux64-parisc2-cc hpux64-parisc2-gcc hurd-x86 ios-cross ios-xcrun ios64-cross ios64-xcrun iossimulator-xcrun iphoneos-cross irix-mips3-cc irix-mips3-gcc irix64-mips4-cc irix64-mips4-gcc linux-aarch64 linux-alpha-gcc linux-aout linux-arm64ilp32 linux-armv4 linux-c64xplus linux-elf linux-generic32 linux-generic64 linux-ia64 linux-mips32 linux-mips64 linux-ppc linux-ppc64 linux-ppc64le linux-sparcv8 linux-sparcv9 linux-x32 linux-x86 linux-x86-clang linux-x86_64 linux-x86_64-clang linux32-s390x linux64-mips64 linux64-s390x linux64-sparcv9 mingw mingw64 nextstep nextstep3.3 sco5-cc sco5-gcc solaris-sparcv7-cc solaris-sparcv7-gcc solaris-sparcv8-cc solaris-sparcv8-gcc solaris-sparcv9-cc solaris-sparcv9-gcc solaris-x86-gcc solaris64-sparcv9-cc solaris64-sparcv9-gcc solaris64-x86_64-cc solaris64-x86_64-gcc tru64-alpha-cc tru64-alpha-gcc uClinux-dist uClinux-dist64 unixware-2.0 unixware-2.1 unixware-7 unixware-7-gcc vms-alpha vms-alpha-p32 vms-alpha-p64 vms-ia64 vms-ia64-p32 vms-ia64-p64 vos-gcc vxworks-mips vxworks-ppc405 vxworks-ppc60x vxworks-ppc750 vxworks-ppc750-debug vxworks-ppc860 vxworks-ppcgen vxworks-simlinux NOTE: If in doubt, on Unix-ish systems use \u0026#39;./config\u0026#39;. 上面提示如果编译 Unix-ish x86 平台目标文件，直接使用 ./config\n更多详细说明参考：INSTALL 文件。\n我们的需求是：编译黑芝麻嵌入式平台 aarh64 目标文件，安装到当前目录下的 _INSTALL 目录\nroot@028337952dd7:/home/misc/openssl-1.1.1k# ./Configure linux-aarch64 --prefix=/home/misc/openssl-1.1.1k_bst/openssl-1.1.1k/build Configuring OpenSSL version 1.1.1k (0x101010bfL) for linux-aarch64 Using os-specific seed configuration Creating configdata.pm Creating Makefile ********************************************************************** *** *** *** OpenSSL has been successfully configured *** *** *** *** If you encounter a problem while building, please open an *** *** issue on GitHub \u0026lt;https://github.com/openssl/openssl/issues\u0026gt; *** *** and include the output from the following command: *** *** *** *** perl configdata.pm --dump *** *** *** *** (If you are new to OpenSSL, you might want to consult the *** *** \u0026#39;Troubleshooting\u0026#39; section in the INSTALL file first) *** *** *** ********************************************************************** root@028337952dd7:/home/misc/openssl-1.1.1k# 注意如上语句中：Configuring OpenSSL version 1.1.1k (0x101010bfL) for linux-aarch64 目标平台很重要，如果指定错误可能导致编译失败。\n踩坑记录 1 - 编译器指定异常 按照上述配置完成之后，编译失败：\nroot@028337952dd7:/home/misc/openssl-1.1.1k# make -j /opt/bstos/linux-23/sysroots/x86_64-bstsdk-linux/usr/bin/perl.real \u0026#34;-I.\u0026#34; -Mconfigdata \u0026#34;util/dofile.pl\u0026#34; \\ \u0026#34;-oMakefile\u0026#34; include/crypto/bn_conf.h.in \u0026gt; include/crypto/bn_conf.h /opt/bstos/linux-23/sysroots/x86_64-bstsdk-linux/usr/bin/perl.real \u0026#34;-I.\u0026#34; -Mconfigdata \u0026#34;util/dofile.pl\u0026#34; \\ \u0026#34;-oMakefile\u0026#34; include/crypto/dso_conf.h.in \u0026gt; include/crypto/dso_conf.h /opt/bstos/linux-23/sysroots/x86_64-bstsdk-linux/usr/bin/perl.real \u0026#34;-I.\u0026#34; -Mconfigdata \u0026#34;util/dofile.pl\u0026#34; \\ \u0026#34;-oMakefile\u0026#34; include/openssl/opensslconf.h.in \u0026gt; include/openssl/opensslconf.h make depend \u0026amp;\u0026amp; make _all make[1]: Entering directory \u0026#39;/home/misc/openssl-1.1.1k\u0026#39; make[1]: Leaving directory \u0026#39;/home/misc/openssl-1.1.1k\u0026#39; make[1]: Entering directory \u0026#39;/home/misc/openssl-1.1.1k\u0026#39; aarch64-bst-linux-aarch64-bst-linux-gcc --sysroot=/opt/bstos/linux-23/sysroots/aarch64-bst-linux -I. -Iinclude -fPIC -pthread -O2 -pipe -g -feliminate-unused-debug-types -DOPENSSL_USE_NODELETE -DOPENSSL_PIC -DOPENSSL_CPUID_OBJ -DOPENSSL_BN_ASM_MONT -DSHA1_ASM -DSHA256_ASM -DSHA512_ASM -DKECCAK1600_ASM -DVPAES_ASM -DECP_NISTZ256_ASM -DPOLY1305_ASM -DOPENSSLDIR=\u0026#34;\\\u0026#34;/home/misc/openssl-1.1.1k_bst/openssl-1.1.1k/build/ssl\\\u0026#34;\u0026#34; -DENGINESDIR=\u0026#34;\\\u0026#34;/home/misc/openssl-1.1.1k_bst/openssl-1.1.1k/build/lib/engines-1.1\\\u0026#34;\u0026#34; -DNDEBUG -c -o apps/app_rand.o apps/app_rand.c aarch64-bst-linux-aarch64-bst-linux-gcc --sysroot=/opt/bstos/linux-23/sysroots/aarch64-bst-linux -I. -Iinclude -fPIC -pthread -O2 -pipe -g -feliminate-unused-debug-types -DOPENSSL_USE_NODELETE -DOPENSSL_PIC -DOPENSSL_CPUID_OBJ -DOPENSSL_BN_ASM_MONT -DSHA1_ASM -DSHA256_ASM -DSHA512_ASM -DKECCAK1600_ASM -DVPAES_ASM -DECP_NISTZ256_ASM -DPOLY1305_ASM -DOPENSSLDIR=\u0026#34;\\\u0026#34;/home/misc/openssl-1.1.1k_bst/openssl-1.1.1k/build/ssl\\\u0026#34;\u0026#34; -DENGINESDIR=\u0026#34;\\\u0026#34;/home/misc/openssl-1.1.1k_bst/openssl-1.1.1k/build/lib/engines-1.1\\\u0026#34;\u0026#34; -DNDEBUG -c -o apps/apps.o apps/apps.c aarch64-bst-linux-aarch64-bst-linux-gcc --sysroot=/opt/bstos/linux-23/sysroots/aarch64-bst-linux -I. -Iinclude -fPIC -pthread -O2 -pipe -g -feliminate-unused-debug-types -DOPENSSL_USE_NODELETE -DOPENSSL_PIC -DOPENSSL_CPUID_OBJ -DOPENSSL_BN_ASM_MONT -DSHA1_ASM -DSHA256_ASM -DSHA512_ASM -DKECCAK1600_ASM -DVPAES_ASM -DECP_NISTZ256_ASM -DPOLY1305_ASM -DOPENSSLDIR=\u0026#34;\\\u0026#34;/home/misc/openssl-1.1.1k_bst/openssl-1.1.1k/build/ssl\\\u0026#34;\u0026#34; -DENGINESDIR=\u0026#34;\\\u0026#34;/home/misc/openssl-1.1.1k_bst/openssl-1.1.1k/build/lib/engines-1.1\\\u0026#34;\u0026#34; -DNDEBUG -c -o apps/bf_prefix.o apps/bf_prefix.c aarch64-bst-linux-aarch64-bst-linux-gcc --sysroot=/opt/bstos/linux-23/sysroots/aarch64-bst-linux -I. -Iinclude -fPIC -pthread -O2 -pipe -g -feliminate-unused-debug-types -DOPENSSL_USE_NODELETE -DOPENSSL_PIC -DOPENSSL_CPUID_OBJ -DOPENSSL_BN_ASM_MONT -DSHA1_ASM -DSHA256_ASM -DSHA512_ASM -DKECCAK1600_ASM -DVPAES_ASM -DECP_NISTZ256_ASM -DPOLY1305_ASM -DOPENSSLDIR=\u0026#34;\\\u0026#34;/home/misc/openssl-1.1.1k_bst/openssl-1.1.1k/build/ssl\\\u0026#34;\u0026#34; -DENGINESDIR=\u0026#34;\\\u0026#34;/home/misc/openssl-1.1.1k_bst/openssl-1.1.1k/build/lib/engines-1.1\\\u0026#34;\u0026#34; -DNDEBUG -c -o apps/opt.o apps/opt.c /bin/sh: 1: aarch64-bst-linux-aarch64-bst-linux-gcc: not found /bin/sh: 1: Makefile:700: recipe for target \u0026#39;apps/app_rand.o\u0026#39; failed /bin/sh: 1: aarch64-bst-linux-aarch64-bst-linux-gcc: not foundaarch64-bst-linux-aarch64-bst-linux-gcc: not foundmake[1]: *** [apps/app_rand.o] Error 127 make[1]: *** Waiting for unfinished jobs.... Makefile:704: recipe for target \u0026#39;apps/bf_prefix.o\u0026#39; failed make[1]: *** [apps/bf_prefix.o] Error 127 /bin/sh: 1: aarch64-bst-linux-aarch64-bst-linux-gcc: not found Makefile:702: recipe for target \u0026#39;apps/apps.o\u0026#39; failed make[1]: *** [apps/apps.o] Error 127 Makefile:706: recipe for target \u0026#39;apps/opt.o\u0026#39; failed make[1]: *** [apps/opt.o] Error 127 make[1]: Leaving directory \u0026#39;/home/misc/openssl-1.1.1k\u0026#39; Makefile:172: recipe for target \u0026#39;all\u0026#39; failed make: *** [all] Error 2 关键错误信息： not foundaarch64-bst-linux-aarch64-bst-linux-gcc\n查看 Makefile 有如下内容：\nCROSS_COMPILE=aarch64-bst-linux- CC=$(CROSS_COMPILE)aarch64-bst-linux-gcc --sysroot=/opt/bstos/linux-23/sysroots/aarch64-bst-linux CXX=$(CROSS_COMPILE)aarch64-bst-linux-g++ --sysroot=/opt/bstos/linux-23/sysroots/aarch64-bst-linux 所以看出问题所在了，这里手动修改 Makefile 直接将 CROSS_COMPILE 不要赋值即可 CROSS_COMPILE=\n重新编译通过。\nmake -j make install 踩坑记录 2 - 平台配置失败 举一个失败的例子，使用 config 命令配置 linux-x86_64：\nroot@028337952dd7:/home/misc/openssl-1.1.1k# ./config --prefix=/home/misc/openssl-1.1.1k_bst/openssl-1.1.1k/build Operating system: x86_64-whatever-linux2 Configuring OpenSSL version 1.1.1k (0x101010bfL) for linux-x86_64 Using os-specific seed configuration Creating configdata.pm Creating Makefile ********************************************************************** *** *** *** OpenSSL has been successfully configured *** *** *** *** If you encounter a problem while building, please open an *** *** issue on GitHub \u0026lt;https://github.com/openssl/openssl/issues\u0026gt; *** *** and include the output from the following command: *** *** *** *** perl configdata.pm --dump *** *** *** *** (If you are new to OpenSSL, you might want to consult the *** *** \u0026#39;Troubleshooting\u0026#39; section in the INSTALL file first) *** *** *** ********************************************************************** 由于配置的平台是 x86_64 增加了 -m64 编译选项，但是交叉编译器不支持导致编译失败：\nroot@028337952dd7:/home/misc/openssl-1.1.1k# make -j /opt/bstos/linux-23/sysroots/x86_64-bstsdk-linux/usr/bin/perl.real \u0026#34;-I.\u0026#34; -Mconfigdata \u0026#34;util/dofile.pl\u0026#34; \\ \u0026#34;-oMakefile\u0026#34; include/crypto/bn_conf.h.in \u0026gt; include/crypto/bn_conf.h /opt/bstos/linux-23/sysroots/x86_64-bstsdk-linux/usr/bin/perl.real \u0026#34;-I.\u0026#34; -Mconfigdata \u0026#34;util/dofile.pl\u0026#34; \\ \u0026#34;-oMakefile\u0026#34; include/crypto/dso_conf.h.in \u0026gt; include/crypto/dso_conf.h /opt/bstos/linux-23/sysroots/x86_64-bstsdk-linux/usr/bin/perl.real \u0026#34;-I.\u0026#34; -Mconfigdata \u0026#34;util/dofile.pl\u0026#34; \\ \u0026#34;-oMakefile\u0026#34; include/openssl/opensslconf.h.in \u0026gt; include/openssl/opensslconf.h make depend \u0026amp;\u0026amp; make _all make[1]: Entering directory \u0026#39;/home/misc/openssl-1.1.1k\u0026#39; make[1]: Leaving directory \u0026#39;/home/misc/openssl-1.1.1k\u0026#39; make[1]: Entering directory \u0026#39;/home/misc/openssl-1.1.1k\u0026#39; aarch64-bst-linux-aarch64-bst-linux-gcc --sysroot=/opt/bstos/linux-23/sysroots/aarch64-bst-linux -I. -Iinclude -fPIC -pthread -m64 -O2 -pipe -g -feliminate-unused-debug-types -DOPENSSL_USE_NODELETE -DL_ENDIAN -DOPENSSL_PIC -DOPENSSL_CPUID_OBJ -DOPENSSL_IA32_SSE2 -DOPENSSL_BN_ASM_MONT -DOPENSSL_BN_ASM_MONT5 -DOPENSSL_BN_ASM_GF2m -DSHA1_ASM -DSHA256_ASM -DSHA512_ASM -DKECCAK1600_ASM -DRC4_ASM -DMD5_ASM -DAESNI_ASM -DVPAES_ASM -DGHASH_ASM -DECP_NISTZ256_ASM -DX25519_ASM -DPOLY1305_ASM -DOPENSSLDIR=\u0026#34;\\\u0026#34;/home/misc/openssl-1.1.1k_bst/openssl-1.1.1k/build/ssl\\\u0026#34;\u0026#34; -DENGINESDIR=\u0026#34;\\\u0026#34;/home/misc/openssl-1.1.1k_bst/openssl-1.1.1k/build/lib/engines-1.1\\\u0026#34;\u0026#34; -DNDEBUG -c -o apps/app_rand.o apps/app_rand.c aarch64-bst-linux-aarch64-bst-linux-gcc --sysroot=/opt/bstos/linux-23/sysroots/aarch64-bst-linux -I. -Iinclude -fPIC -pthread -m64 -O2 -pipe -g -feliminate-unused-debug-types -DOPENSSL_USE_NODELETE -DL_ENDIAN -DOPENSSL_PIC -DOPENSSL_CPUID_OBJ -DOPENSSL_IA32_SSE2 -DOPENSSL_BN_ASM_MONT -DOPENSSL_BN_ASM_MONT5 -DOPENSSL_BN_ASM_GF2m -DSHA1_ASM -DSHA256_ASM -DSHA512_ASM -DKECCAK1600_ASM -DRC4_ASM -DMD5_ASM -DAESNI_ASM -DVPAES_ASM -DGHASH_ASM -DECP_NISTZ256_ASM -DX25519_ASM -DPOLY1305_ASM -DOPENSSLDIR=\u0026#34;\\\u0026#34;/home/misc/openssl-1.1.1k_bst/openssl-1.1.1k/build/ssl\\\u0026#34;\u0026#34; -DENGINESDIR=\u0026#34;\\\u0026#34;/home/misc/openssl-1.1.1k_bst/openssl-1.1.1k/build/lib/engines-1.1\\\u0026#34;\u0026#34; -DNDEBUG -c -o apps/apps.o apps/apps.c aarch64-bst-linux-aarch64-bst-linux-gcc --sysroot=/opt/bstos/linux-23/sysroots/aarch64-bst-linux -I. -Iinclude -fPIC -pthread -m64 -O2 -pipe -g -feliminate-unused-debug-types -DOPENSSL_USE_NODELETE -DL_ENDIAN -DOPENSSL_PIC -DOPENSSL_CPUID_OBJ -DOPENSSL_IA32_SSE2 -DOPENSSL_BN_ASM_MONT -DOPENSSL_BN_ASM_MONT5 -DOPENSSL_BN_ASM_GF2m -DSHA1_ASM -DSHA256_ASM -DSHA512_ASM -DKECCAK1600_ASM -DRC4_ASM -DMD5_ASM -DAESNI_ASM -DVPAES_ASM -DGHASH_ASM -DECP_NISTZ256_ASM -DX25519_ASM -DPOLY1305_ASM -DOPENSSLDIR=\u0026#34;\\\u0026#34;/home/misc/openssl-1.1.1k_bst/openssl-1.1.1k/build/ssl\\\u0026#34;\u0026#34; -DENGINESDIR=\u0026#34;\\\u0026#34;/home/misc/openssl-1.1.1k_bst/openssl-1.1.1k/build/lib/engines-1.1\\\u0026#34;\u0026#34; -DNDEBUG -c -o apps/bf_prefix.o apps/bf_prefix.c /bin/sh: 1: aarch64-bst-linux-aarch64-bst-linux-gcc: not found Makefile:700: recipe for target \u0026#39;apps/app_rand.o\u0026#39; failed make[1]: *** [apps/app_rand.o] Error 127 make[1]: *** Waiting for unfinished jobs.... /bin/sh: 1: aarch64-bst-linux-aarch64-bst-linux-gcc: not found Makefile:702: recipe for target \u0026#39;apps/apps.o\u0026#39; failed make[1]: *** [apps/apps.o] Error 127 /bin/sh: 1: aarch64-bst-linux-aarch64-bst-linux-gcc: not found Makefile:704: recipe for target \u0026#39;apps/bf_prefix.o\u0026#39; failed make[1]: *** [apps/bf_prefix.o] Error 127 make[1]: Leaving directory \u0026#39;/home/misc/openssl-1.1.1k\u0026#39; Makefile:172: recipe for target \u0026#39;all\u0026#39; failed make: *** [all] Error 2 root@028337952dd7:/home/misc/openssl-1.1.1k# vim Makefile root@028337952dd7:/home/misc/openssl-1.1.1k# make -j make depend \u0026amp;\u0026amp; make _all make[1]: Entering directory \u0026#39;/home/misc/openssl-1.1.1k\u0026#39; make[1]: Leaving directory \u0026#39;/home/misc/openssl-1.1.1k\u0026#39; make[1]: Entering directory \u0026#39;/home/misc/openssl-1.1.1k\u0026#39; aarch64-bst-linux-gcc --sysroot=/opt/bstos/linux-23/sysroots/aarch64-bst-linux -I. -Iinclude -fPIC -pthread -m64 -O2 -pipe -g -feliminate-unused-debug-types -DOPENSSL_USE_NODELETE -DL_ENDIAN -DOPENSSL_PIC -DOPENSSL_CPUID_OBJ -DOPENSSL_IA32_SSE2 -DOPENSSL_BN_ASM_MONT -DOPENSSL_BN_ASM_MONT5 -DOPENSSL_BN_ASM_GF2m -DSHA1_ASM -DSHA256_ASM -DSHA512_ASM -DKECCAK1600_ASM -DRC4_ASM -DMD5_ASM -DAESNI_ASM -DVPAES_ASM -DGHASH_ASM -DECP_NISTZ256_ASM -DX25519_ASM -DPOLY1305_ASM -DOPENSSLDIR=\u0026#34;\\\u0026#34;/home/misc/openssl-1.1.1k_bst/openssl-1.1.1k/build/ssl\\\u0026#34;\u0026#34; -DENGINESDIR=\u0026#34;\\\u0026#34;/home/misc/openssl-1.1.1k_bst/openssl-1.1.1k/build/lib/engines-1.1\\\u0026#34;\u0026#34; -DNDEBUG -c -o apps/app_rand.o apps/app_rand.c aarch64-bst-linux-gcc --sysroot=/opt/bstos/linux-23/sysroots/aarch64-bst-linux -I. -Iinclude -fPIC -pthread -m64 -O2 -pipe -g -feliminate-unused-debug-types -DOPENSSL_USE_NODELETE -DL_ENDIAN -DOPENSSL_PIC -DOPENSSL_CPUID_OBJ -DOPENSSL_IA32_SSE2 -DOPENSSL_BN_ASM_MONT -DOPENSSL_BN_ASM_MONT5 -DOPENSSL_BN_ASM_GF2m -DSHA1_ASM -DSHA256_ASM -DSHA512_ASM -DKECCAK1600_ASM -DRC4_ASM -DMD5_ASM -DAESNI_ASM -DVPAES_ASM -DGHASH_ASM -DECP_NISTZ256_ASM -DX25519_ASM -DPOLY1305_ASM -DOPENSSLDIR=\u0026#34;\\\u0026#34;/home/misc/openssl-1.1.1k_bst/openssl-1.1.1k/build/ssl\\\u0026#34;\u0026#34; -DENGINESDIR=\u0026#34;\\\u0026#34;/home/misc/openssl-1.1.1k_bst/openssl-1.1.1k/build/lib/engines-1.1\\\u0026#34;\u0026#34; -DNDEBUG -c -o apps/apps.o apps/apps.c aarch64-bst-linux-gcc --sysroot=/opt/bstos/linux-23/sysroots/aarch64-bst-linux -I. -Iinclude -fPIC -pthread -m64 -O2 -pipe -g -feliminate-unused-debug-types -DOPENSSL_USE_NODELETE -DL_ENDIAN -DOPENSSL_PIC -DOPENSSL_CPUID_OBJ -DOPENSSL_IA32_SSE2 -DOPENSSL_BN_ASM_MONT -DOPENSSL_BN_ASM_MONT5 -DOPENSSL_BN_ASM_GF2m -DSHA1_ASM -DSHA256_ASM -DSHA512_ASM -DKECCAK1600_ASM -DRC4_ASM -DMD5_ASM -DAESNI_ASM -DVPAES_ASM -DGHASH_ASM -DECP_NISTZ256_ASM -DX25519_ASM -DPOLY1305_ASM -DOPENSSLDIR=\u0026#34;\\\u0026#34;/home/misc/openssl-1.1.1k_bst/openssl-1.1.1k/build/ssl\\\u0026#34;\u0026#34; -DENGINESDIR=\u0026#34;\\\u0026#34;/home/misc/openssl-1.1.1k_bst/openssl-1.1.1k/build/lib/engines-1.1\\\u0026#34;\u0026#34; -DNDEBUG -c -o apps/bf_prefix.o apps/bf_prefix.c aarch64-bst-linux-gcc --sysroot=/opt/bstos/linux-23/sysroots/aarch64-bst-linux -I. -Iinclude -fPIC -pthread -m64 -O2 -pipe -g -feliminate-unused-debug-types -DOPENSSL_USE_NODELETE -DL_ENDIAN -DOPENSSL_PIC -DOPENSSL_CPUID_OBJ -DOPENSSL_IA32_SSE2 -DOPENSSL_BN_ASM_MONT -DOPENSSL_BN_ASM_MONT5 -DOPENSSL_BN_ASM_GF2m -DSHA1_ASM -DSHA256_ASM -DSHA512_ASM -DKECCAK1600_ASM -DRC4_ASM -DMD5_ASM -DAESNI_ASM -DVPAES_ASM -DGHASH_ASM -DECP_NISTZ256_ASM -DX25519_ASM -DPOLY1305_ASM -DOPENSSLDIR=\u0026#34;\\\u0026#34;/home/misc/openssl-1.1.1k_bst/openssl-1.1.1k/build/ssl\\\u0026#34;\u0026#34; -DENGINESDIR=\u0026#34;\\\u0026#34;/home/misc/openssl-1.1.1k_bst/openssl-1.1.1k/build/lib/engines-1.1\\\u0026#34;\u0026#34; -DNDEBUG -c -o apps/opt.o apps/opt.c aarch64-bst-linux-gcc --sysroot=/opt/bstos/linux-23/sysroots/aarch64-bst-linux -I. -Iinclude -fPIC -pthread -m64 -O2 -pipe -g -feliminate-unused-debug-types -DOPENSSL_USE_NODELETE -DL_ENDIAN -DOPENSSL_PIC -DOPENSSL_CPUID_OBJ -DOPENSSL_IA32_SSE2 -DOPENSSL_BN_ASM_MONT -DOPENSSL_BN_ASM_MONT5 -DOPENSSL_BN_ASM_GF2m -DSHA1_ASM -DSHA256_ASM -DSHA512_ASM -DKECCAK1600_ASM -DRC4_ASM -DMD5_ASM -DAESNI_ASM -DVPAES_ASM -DGHASH_ASM -DECP_NISTZ256_ASM -DX25519_ASM -DPOLY1305_ASM -DOPENSSLDIR=\u0026#34;\\\u0026#34;/home/misc/openssl-1.1.1k_bst/openssl-1.1.1k/build/ssl\\\u0026#34;\u0026#34; -DENGINESDIR=\u0026#34;\\\u0026#34;/home/misc/openssl-1.1.1k_bst/openssl-1.1.1k/build/lib/engines-1.1\\\u0026#34;\u0026#34; -DNDEBUG -c -o apps/s_cb.o apps/s_cb.c aarch64-bst-linux-gcc --sysroot=/opt/bstos/linux-23/sysroots/aarch64-bst-linux -I. -Iinclude -fPIC -pthread -m64 -O2 -pipe -g -feliminate-unused-debug-types -DOPENSSL_USE_NODELETE -DL_ENDIAN -DOPENSSL_PIC -DOPENSSL_CPUID_OBJ -DOPENSSL_IA32_SSE2 -DOPENSSL_BN_ASM_MONT -DOPENSSL_BN_ASM_MONT5 -DOPENSSL_BN_ASM_GF2m -DSHA1_ASM -DSHA256_ASM -DSHA512_ASM -DKECCAK1600_ASM -DRC4_ASM -DMD5_ASM -DAESNI_ASM -DVPAES_ASM -DGHASH_ASM -DECP_NISTZ256_ASM -DX25519_ASM -DPOLY1305_ASM -DOPENSSLDIR=\u0026#34;\\\u0026#34;/home/misc/openssl-1.1.1k_bst/openssl-1.1.1k/build/ssl\\\u0026#34;\u0026#34; -DENGINESDIR=\u0026#34;\\\u0026#34;/home/misc/openssl-1.1.1k_bst/openssl-1.1.1k/build/lib/engines-1.1\\\u0026#34;\u0026#34; -DNDEBUG -c -o apps/s_socket.o apps/s_socket.c aarch64-bst-linux-gcc --sysroot=/opt/bstos/linux-23/sysroots/aarch64-bst-linux -I. -Iinclude -fPIC -pthread -m64 -O2 -pipe -g -feliminate-unused-debug-types -DOPENSSL_USE_NODELETE -DL_ENDIAN -DOPENSSL_PIC -DOPENSSL_CPUID_OBJ -DOPENSSL_IA32_SSE2 -DOPENSSL_BN_ASM_MONT -DOPENSSL_BN_ASM_MONT5 -DOPENSSL_BN_ASM_GF2m -DSHA1_ASM -DSHA256_ASM -DSHA512_ASM -DKECCAK1600_ASM -DRC4_ASM -DMD5_ASM -DAESNI_ASM -DVPAES_ASM -DGHASH_ASM -DECP_NISTZ256_ASM -DX25519_ASM -DPOLY1305_ASM -DOPENSSLDIR=\u0026#34;\\\u0026#34;/home/misc/openssl-1.1.1k_bst/openssl-1.1.1k/build/ssl\\\u0026#34;\u0026#34; -DENGINESDIR=\u0026#34;\\\u0026#34;/home/misc/openssl-1.1.1k_bst/openssl-1.1.1k/build/lib/engines-1.1\\\u0026#34;\u0026#34; -DNDEBUG -c -o crypto/aes/aes_cbc.o crypto/aes/aes_cbc.c aarch64-bst-linux-gcc --sysroot=/opt/bstos/linux-23/sysroots/aarch64-bst-linux -I. -Iinclude -fPIC -pthread -m64 -O2 -pipe -g -feliminate-unused-debug-types -DOPENSSL_USE_NODELETE -DL_ENDIAN -DOPENSSL_PIC -DOPENSSL_CPUID_OBJ -DOPENSSL_IA32_SSE2 -DOPENSSL_BN_ASM_MONT -DOPENSSL_BN_ASM_MONT5 -DOPENSSL_BN_ASM_GF2m -DSHA1_ASM -DSHA256_ASM -DSHA512_ASM -DKECCAK1600_ASM -DRC4_ASM -DMD5_ASM -DAESNI_ASM -DVPAES_ASM -DGHASH_ASM -DECP_NISTZ256_ASM -DX25519_ASM -DPOLY1305_ASM -DOPENSSLDIR=\u0026#34;\\\u0026#34;/home/misc/openssl-1.1.1k_bst/openssl-1.1.1k/build/ssl\\\u0026#34;\u0026#34; -DENGINESDIR=\u0026#34;\\\u0026#34;/home/misc/openssl-1.1.1k_bst/openssl-1.1.1k/build/lib/engines-1.1\\\u0026#34;\u0026#34; -DNDEBUG -c -o crypto/aes/aes_cfb.o crypto/aes/aes_cfb.c aarch64-bst-linux-gcc --sysroot=/opt/bstos/linux-23/sysroots/aarch64-bst-linux -I. -Iinclude -fPIC -pthread -m64 -O2 -pipe -g -feliminate-unused-debug-types -DOPENSSL_USE_NODELETE -DL_ENDIAN -DOPENSSL_PIC -DOPENSSL_CPUID_OBJ -DOPENSSL_IA32_SSE2 -DOPENSSL_BN_ASM_MONT -DOPENSSL_BN_ASM_MONT5 -DOPENSSL_BN_ASM_GF2m -DSHA1_ASM -DSHA256_ASM -DSHA512_ASM -DKECCAK1600_ASM -DRC4_ASM -DMD5_ASM -DAESNI_ASM -DVPAES_ASM -DGHASH_ASM -DECP_NISTZ256_ASM -DX25519_ASM -DPOLY1305_ASM -DOPENSSLDIR=\u0026#34;\\\u0026#34;/home/misc/openssl-1.1.1k_bst/openssl-1.1.1k/build/ssl\\\u0026#34;\u0026#34; -DENGINESDIR=\u0026#34;\\\u0026#34;/home/misc/openssl-1.1.1k_bst/openssl-1.1.1k/build/lib/engines-1.1\\\u0026#34;\u0026#34; -DNDEBUG -c -o crypto/aes/aes_core.o crypto/aes/aes_core.c aarch64-bst-linux-gcc --sysroot=/opt/bstos/linux-23/sysroots/aarch64-bst-linux -I. -Iinclude -fPIC -pthread -m64 -O2 -pipe -g -feliminate-unused-debug-types -DOPENSSL_USE_NODELETE -DL_ENDIAN -DOPENSSL_PIC -DOPENSSL_CPUID_OBJ -DOPENSSL_IA32_SSE2 -DOPENSSL_BN_ASM_MONT -DOPENSSL_BN_ASM_MONT5 -DOPENSSL_BN_ASM_GF2m -DSHA1_ASM -DSHA256_ASM -DSHA512_ASM -DKECCAK1600_ASM -DRC4_ASM -DMD5_ASM -DAESNI_ASM -DVPAES_ASM -DGHASH_ASM -DECP_NISTZ256_ASM -DX25519_ASM -DPOLY1305_ASM -DOPENSSLDIR=\u0026#34;\\\u0026#34;/home/misc/openssl-1.1.1k_bst/openssl-1.1.1k/build/ssl\\\u0026#34;\u0026#34; -DENGINESDIR=\u0026#34;\\\u0026#34;/home/misc/openssl-1.1.1k_bst/openssl-1.1.1k/build/lib/engines-1.1\\\u0026#34;\u0026#34; -DNDEBUG -c -o crypto/aes/aes_ecb.o crypto/aes/aes_ecb.c aarch64-bst-linux-gcc --sysroot=/opt/bstos/linux-23/sysroots/aarch64-bst-linux -I. -Iinclude -fPIC -pthread -m64 -O2 -pipe -g -feliminate-unused-debug-types -DOPENSSL_USE_NODELETE -DL_ENDIAN -DOPENSSL_PIC -DOPENSSL_CPUID_OBJ -DOPENSSL_IA32_SSE2 -DOPENSSL_BN_ASM_MONT -DOPENSSL_BN_ASM_MONT5 -DOPENSSL_BN_ASM_GF2m -DSHA1_ASM -DSHA256_ASM -DSHA512_ASM -DKECCAK1600_ASM -DRC4_ASM -DMD5_ASM -DAESNI_ASM -DVPAES_ASM -DGHASH_ASM -DECP_NISTZ256_ASM -DX25519_ASM -DPOLY1305_ASM -DOPENSSLDIR=\u0026#34;\\\u0026#34;/home/misc/openssl-1.1.1k_bst/openssl-1.1.1k/build/ssl\\\u0026#34;\u0026#34; -DENGINESDIR=\u0026#34;\\\u0026#34;/home/misc/openssl-1.1.1k_bst/openssl-1.1.1k/build/lib/engines-1.1\\\u0026#34;\u0026#34; -DNDEBUG -c -o crypto/aes/aes_ige.o crypto/aes/aes_ige.c aarch64-bst-linux-gcc: error: unrecognized command line option \u0026#39;-m64\u0026#39; aarch64-bst-linux-gcc: error: unrecognized command line option \u0026#39;-m64\u0026#39; aarch64-bst-linux-gcc: error: unrecognized command line option \u0026#39;-m64\u0026#39; aarch64-bst-linux-gcc --sysroot=/opt/bstos/linux-23/sysroots/aarch64-bst-linux -I. -Iinclude -fPIC -pthread -m64 -O2 -pipe -g -feliminate-unused-debug-types -DOPENSSL_USE_NODELETE -DL_ENDIAN -DOPENSSL_PIC -DOPENSSL_CPUID_OBJ -DOPENSSL_IA32_SSE2 -DOPENSSL_BN_ASM_MONT -DOPENSSL_BN_ASM_MONT5 -DOPENSSL_BN_ASM_GF2m -DSHA1_ASM -DSHA256_ASM -DSHA512_ASM -DKECCAK1600_ASM -DRC4_ASM -DMD5_ASM -DAESNI_ASM -DVPAES_ASM -DGHASH_ASM -DECP_NISTZ256_ASM -DX25519_ASM -DPOLY1305_ASM -DOPENSSLDIR=\u0026#34;\\\u0026#34;/home/misc/openssl-1.1.1k_bst/openssl-1.1.1k/build/ssl\\\u0026#34;\u0026#34; -DENGINESDIR=\u0026#34;\\\u0026#34;/home/misc/openssl-1.1.1k_bst/openssl-1.1.1k/build/lib/engines-1.1\\\u0026#34;\u0026#34; -DNDEBUG -c -o crypto/aes/aes_misc.o crypto/aes/aes_misc.c aarch64-bst-linux-gcc: error: unrecognized command line option \u0026#39;-m64\u0026#39; Makefile:700: recipe for target \u0026#39;apps/app_rand.o\u0026#39; failed make[1]: *** [apps/app_rand.o] Error 1 make[1]: *** Waiting for unfinished jobs.... Makefile:702: recipe for target \u0026#39;apps/apps.o\u0026#39; failed make[1]: *** [apps/apps.o] Error 1 Makefile:704: recipe for target \u0026#39;apps/bf_prefix.o\u0026#39; failed make[1]: *** [apps/bf_prefix.o] Error 1 Makefile:706: recipe for target \u0026#39;apps/opt.o\u0026#39; failed make[1]: *** [apps/opt.o] Error 1 aarch64-bst-linux-gcc: error: unrecognized command line option \u0026#39;-m64\u0026#39; aarch64-bst-linux-gcc: error: unrecognized command line option \u0026#39;-m64\u0026#39; aarch64-bst-linux-gcc: error: unrecognized command line option \u0026#39;-m64\u0026#39; Makefile:708: recipe for target \u0026#39;apps/s_cb.o\u0026#39; failed make[1]: *** [apps/s_cb.o] Error 1 aarch64-bst-linux-gcc: error: unrecognized command line option \u0026#39;-m64\u0026#39; Makefile:724: recipe for target \u0026#39;crypto/aes/aes_cfb.o\u0026#39; failed make[1]: *** [crypto/aes/aes_cfb.o] Error 1 aarch64-bst-linux-gcc: error: unrecognized command line option \u0026#39;-m64\u0026#39; aarch64-bst-linux-gcc: error: unrecognized command line option \u0026#39;-m64\u0026#39; Makefile:710: recipe for target \u0026#39;apps/s_socket.o\u0026#39; failed aarch64-bst-linux-gcc: error: unrecognized command line option \u0026#39;-m64\u0026#39; make[1]: *** [apps/s_socket.o] Error 1 Makefile:722: recipe for target \u0026#39;crypto/aes/aes_cbc.o\u0026#39; failed make[1]: *** [crypto/aes/aes_cbc.o] Error 1 Makefile:726: recipe for target \u0026#39;crypto/aes/aes_core.o\u0026#39; failed make[1]: *** [crypto/aes/aes_core.o] Error 1 Makefile:730: recipe for target \u0026#39;crypto/aes/aes_ige.o\u0026#39; failed make[1]: *** [crypto/aes/aes_ige.o] Error 1 Makefile:728: recipe for target \u0026#39;crypto/aes/aes_ecb.o\u0026#39; failed make[1]: *** [crypto/aes/aes_ecb.o] Error 1 aarch64-bst-linux-gcc: error: unrecognized command line option \u0026#39;-m64\u0026#39; Makefile:732: recipe for target \u0026#39;crypto/aes/aes_misc.o\u0026#39; failed make[1]: *** [crypto/aes/aes_misc.o] Error 1 make[1]: Leaving directory \u0026#39;/home/misc/openssl-1.1.1k\u0026#39; Makefile:172: recipe for target \u0026#39;all\u0026#39; failed make: *** [all] Error 2 ","date":"9 February, 2023","id":75,"permalink":"/posts/%E9%BB%91%E8%8A%9D%E9%BA%BB%E5%B9%B3%E5%8F%B0%E4%BA%A4%E5%8F%89%E7%BC%96%E8%AF%91-openssl/","summary":"编译环境：黑芝麻 Linux23 Docker 开发环境，已经默认配置了交叉编译环境。","tags":"linux bst openssl","title":"黑芝麻平台交叉编译 openssl"},{"content":"I2C 寄存器读写命令 探测设备 i2cdetect HELLO@WORLD:~# i2cdetect Error: No i2c-bus specified! Usage: i2cdetect [-y] [-a] [-q|-r] I2CBUS [FIRST LAST] i2cdetect -F I2CBUS i2cdetect -l I2CBUS is an integer or an I2C bus name If provided, FIRST and LAST limit the probing range. # I2CBUS: 0 1 2 ... # Notice: -r 参数很重要，不带 -r 参数有些设备探测不到 i2cdetect -y -r \u0026lt;I2CBUS\u0026gt; 对于8bit的reg, value 可以使用 i2cget / i2cset i2cget HELLO@WORLD:~# i2cget Usage: i2cget [-f] [-y] I2CBUS CHIP-ADDRESS [DATA-ADDRESS [MODE]] I2CBUS is an integer or an I2C bus name ADDRESS is an integer (0x03 - 0x77) MODE is one of: b (read byte data, default) w (read word data) c (write byte/read byte) Append p for SMBus PEC # SLAVE_ADDRESS: 使用i2cdetect 出来的结果 i2cget -y -f \u0026lt;I2CBUS\u0026gt; \u0026lt;SLAVE_ADDRESS\u0026gt; \u0026lt;REG\u0026gt; i2cset HELLO@WORLD:~# i2cset Usage: i2cset [-f] [-y] [-m MASK] [-r] I2CBUS CHIP-ADDRESS DATA-ADDRESS [VALUE] ... [MODE] I2CBUS is an integer or an I2C bus name ADDRESS is an integer (0x03 - 0x77) MODE is one of: c (byte, no value) b (byte data, default) w (word data) i (I2C block data) s (SMBus block data) Append p for SMBus PEC i2cset -y -f \u0026lt;I2CBUS\u0026gt; \u0026lt;SLAVE_ADDRESS\u0026gt; \u0026lt;REG\u0026gt; \u0026lt;VALUE\u0026gt; 对于16bit+的reg, value 需要使用 i2ctransfer i2ctransfer root@J3Pilot-B:~# i2ctransfer Usage: i2ctransfer [-f] [-y] [-v] [-V] I2CBUS DESC [DATA] [DESC [DATA]]... I2CBUS is an integer or an I2C bus name DESC describes the transfer in the form: {r|w}LENGTH[@address] 1) read/write-flag 2) LENGTH (range 0-65535) 3) I2C address (use last one if omitted) DATA are LENGTH bytes for a write message. They can be shortened by a suffix: = (keep value constant until LENGTH) + (increase value by 1 until LENGTH) - (decrease value by 1 until LENGTH) p (use pseudo random generator until LENGTH with value as seed) Example (bus 0, read 8 byte at offset 0x64 from EEPROM at 0x50): # i2ctransfer 0 w1@0x50 0x64 r8 Example (same EEPROM, at offset 0x42 write 0xff 0xfe ... 0xf0): # i2ctransfer 0 w17@0x50 0x42 0xff- # W3 写三个参数 16bit 寄存器 （2 Bytes）+ value（1 Byte） # i2c bus 0 # slave address 0x36 i2ctransfer -y -f 0 w3@0x33 0x3B 0x9D 0x01 # w2 （16bit寄存器）写两个参数 0x4F 0x0C 寄存器（0x4F0C）到 0x36 slave address # i2c bus 总线 0 # 读取 i2c 总线 0 的 slave address 为 0x36 的设备的寄存器 0x4F0C, 读一个 char # 0x36 是 ovx3c 的 slave address （7bit i2c address） i2ctransfer -y -f 0 w2@0x36 0x4F 0x0C r1 dump 寄存器 00~FF i2cdump HELLO@WORLD:~# i2cdump Error: No i2c-bus specified! Usage: i2cdump [-f] [-y] [-r first-last] I2CBUS ADDRESS [MODE [BANK [BANKREG]]] I2CBUS is an integer or an I2C bus name ADDRESS is an integer (0x03 - 0x77) MODE is one of: b (byte, default) w (word) W (word on even register addresses) s (SMBus block) i (I2C block) c (consecutive byte) Append p for SMBus PEC i2cdump -f -y \u0026lt;I2CBUS\u0026gt; \u0026lt;SLAVE_ADDRESS\u0026gt; ","date":"7 February, 2023","id":76,"permalink":"/posts/i2c_cmd/","summary":"","tags":"I2C Linux","title":"I2C command"},{"content":"DDR 压测命令 测试之前可以使用 free -m 查看内存使用情况。\n» free total used free shared buff/cache available Mem: 16193884 1268028 13921020 6528 1004836 14587148 Swap: 4194304 0 4194304 » free -m total used free shared buff/cache available Mem: 15814 1231 13598 6 984 14252 根据 available 至设置 DDR 压测内存大小。\nstressapptest 安装 stressapptest stressapptest - stress test application for simulating high load situations\nsudo apt install stressapptest stressapptest help » stressapptest -h Stats: SAT revision 1.0.6_autoconf, 64 bit binary Log: buildd @ lgw01-amd64-029 on Sun Mar 22 18:14:26 UTC 2020 from open source release Usage: ./sat(32|64) [options] -M mbytes megabytes of ram to test -H mbytes minimum megabytes of hugepages to require -s seconds number of seconds to run -m threads number of memory copy threads to run -i threads number of memory invert threads to run -C threads number of memory CPU stress threads to run --findfiles find locations to do disk IO automatically -d device add a direct write disk thread with block device (or file) \u0026#39;device\u0026#39; -f filename add a disk thread with tempfile \u0026#39;filename\u0026#39; -l logfile log output to file \u0026#39;logfile\u0026#39; --max_errors n exit early after finding \u0026#39;n\u0026#39; errors -v level verbosity (0-20), default is 8 -W Use more CPU-stressful memory copy -A run in degraded mode on incompatible systems -p pagesize size in bytes of memory chunks --filesize size size of disk IO tempfiles -n ipaddr add a network thread connecting to system at \u0026#39;ipaddr\u0026#39; --listen run a thread to listen for and respond to network threads. --no_errors run without checking for ECC or other errors --force_errors inject false errors to test error handling --force_errors_like_crazy inject a lot of false errors to test error handling -F don\u0026#39;t result check each transaction --stop_on_errors Stop after finding the first error. --read-block-size size of block for reading (-d) --write-block-size size of block for writing (-d). If not defined, the size of block for writing will be defined as the size of block for reading --segment-size size of segments to split disk into (-d) --cache-size size of disk cache (-d) --blocks-per-segment number of blocks to read/write per segment per iteration (-d) --read-threshold maximum time (in us) a block read should take (-d) --write-threshold maximum time (in us) a block write should take (-d) --random-threads number of random threads for each disk write thread (-d) --destructive write/wipe disk partition (-d) --monitor_mode only do ECC error polling, no stress load. --cc_test do the cache coherency testing --cc_inc_count number of times to increment the cacheline\u0026#39;s member --cc_line_count number of cache line sized datastructures to allocate for the cache coherency threads to operate --paddr_base allocate memory starting from this address --pause_delay delay (in seconds) between power spikes --pause_duration duration (in seconds) of each pause --local_numa choose memory regions associated with each CPU to be tested by that CPU --remote_numa choose memory regions not associated with each CPU to be tested by that CPU --interleave_size bytes size in bytes of each channel\u0026#39;s data as interleaved between memory channels --channel_width bits width in bits of each memory channel --memory_channel u1,u2 defines a comma-separated list of names for dram packages in a memory channel. Use multiple times to define multiple channels. ./stressapptest -M 14200 -s 36000 -m 8 -i 8 -C 8 -l /data/stressapptest.log 参数说明 -M 14200: 测试内存大小 14200M -s 36000: 测试时常10h，压力测试建议不小于1h -m threads：这个参数用于指定运行内存拷贝线程的数量。内存拷贝线程是执行内存数据复制操作的线程，增加线程数量可以增加内存操作的并发度，从而增加对系统的内存压力。 -i threads：这个参数用于指定运行内存反转（invert）线程的数量。内存反转线程通常是指执行内存数据位反转操作的线程，这也是一种压力测试，可以用于测试内存的写入和读取性能。 -C threads：表示启动的 CPU 压力测试线程的数量。增加这个数字可以增加 CPU 的负载，从而测试 CPU 在高压力下的性能表现。 若测试通过，则终端会打印：Status: PASS – please verify no corrected errors。\nbw_mem ./bw_mem 128M rdwr ","date":"3 February, 2023","id":77,"permalink":"/posts/ddr-%E5%8E%8B%E6%B5%8B%E5%91%BD%E4%BB%A4/","summary":"测试之前可以使用 free -m 查看内存使用情况。","tags":"DDR stress","title":"DDR 压测命令"},{"content":"tar xvf e2fsprogs-1.42.8.tar.gz cd e2fsprogs-1.42.8 mkdir build cd build/ ../configure make sudo make install 问题：\nubuntu20.04 编译报错 undefined reference to 'makedev'\n解决方法: vim \u0026lt;path-to-e2fsprogs-1.42.8\u0026gt;/lib/blkid/devname.c 添加头文件 #include \u0026lt;sys/sysmacros.h\n","date":"3 February, 2023","id":78,"permalink":"/posts/e2fsprogs-1.42.8%E6%BA%90%E7%A0%81%E7%BC%96%E8%AF%91%E5%AE%89%E8%A3%85/","summary":"问题：","tags":"e2fs","title":"e2fsprogs-1.42.8 源码编译安装"},{"content":"flowchart LR root[\u0026#34;微积分基础到傅里叶变换学习路径🧠\u0026#34;] %% 一级节点 root --\u0026gt; prereq[\u0026#34;预备知识 📘\u0026#34;] root --\u0026gt; calc1[\u0026#34;一元微积分 📐\u0026#34;] root --\u0026gt; calcn[\u0026#34;多元微积分 ⛳\u0026#34;] root --\u0026gt; ode[\u0026#34;常微分方程 📏\u0026#34;] root --\u0026gt; series[\u0026#34;级数理论 📊\u0026#34;] root --\u0026gt; ft[\u0026#34;傅里叶变换（CFT） 🎛️\u0026#34;] root --\u0026gt; dftfft[\u0026#34;DFT 与 FFT 📈\u0026#34;] root --\u0026gt; app[\u0026#34;应用与实践 💡\u0026#34;] root --\u0026gt; res[\u0026#34;学习资源 🧰\u0026#34;] %% 预备知识二级节点 prereq --\u0026gt; algebra[\u0026#34;基础代数与函数\u0026#34;] prereq --\u0026gt; analytic_geo[\u0026#34;解析几何\u0026#34;] algebra --\u0026gt; real_complex[\u0026#34;实数与复数运算\u0026#34;] algebra --\u0026gt; func_graph[\u0026#34;函数图像与定义域\u0026#34;] algebra --\u0026gt; func_prop[\u0026#34;函数性质：奇偶、周期、连续\u0026#34;] algebra --\u0026gt; target1[\u0026#34;📌 目标：理解基本函数行为，为微积分打下基础\u0026#34;] analytic_geo --\u0026gt; plane_geo[\u0026#34;平面几何：直线、圆、二次曲线\u0026#34;] analytic_geo --\u0026gt; vector_geo[\u0026#34;向量与空间几何：模、点积、叉积\u0026#34;] analytic_geo --\u0026gt; target2[\u0026#34;📌 目标：掌握正交概念，为后续傅里叶展开准备\u0026#34;] %% 一元微积分二级节点 calc1 --\u0026gt; limit_cont[\u0026#34;极限与连续\u0026#34;] calc1 --\u0026gt; deriv_diff[\u0026#34;导数与微分\u0026#34;] calc1 --\u0026gt; integral[\u0026#34;积分学\u0026#34;] limit_cont --\u0026gt; limit_concept[\u0026#34;极限概念、左右极限\u0026#34;] limit_cont --\u0026gt; continuity[\u0026#34;连续性与间断点\u0026#34;] limit_cont --\u0026gt; target3[\u0026#34;📌 目标：能判断函数极限与连续性\u0026#34;] deriv_diff --\u0026gt; deriv_def[\u0026#34;导数定义（斜率）\u0026#34;] deriv_diff --\u0026gt; deriv_rules[\u0026#34;求导规则、链式法则\u0026#34;] deriv_diff --\u0026gt; high_deriv[\u0026#34;高阶导数与物理意义\u0026#34;] deriv_diff --\u0026gt; target4[\u0026#34;📌 目标：掌握导数定义及常用求导技巧\u0026#34;] integral --\u0026gt; indefinite[\u0026#34;不定积分与换元法\u0026#34;] integral --\u0026gt; definite[\u0026#34;定积分几何应用\u0026#34;] integral --\u0026gt; target5[\u0026#34;📌 目标：能计算面积/体积，理解积分与导数互逆\u0026#34;] %% 多元微积分二级节点 calcn --\u0026gt; partial_diff[\u0026#34;偏导数与全微分\u0026#34;] calcn --\u0026gt; multiple_integral[\u0026#34;重积分\u0026#34;] partial_diff --\u0026gt; multivar_graph[\u0026#34;多元函数图像\u0026#34;] partial_diff --\u0026gt; partial_gradient[\u0026#34;偏导、全微分、梯度\u0026#34;] partial_diff --\u0026gt; target6[\u0026#34;📌 目标：掌握多变量函数变化率\u0026#34;] multiple_integral --\u0026gt; double_integral[\u0026#34;二重积分、极坐标变换\u0026#34;] multiple_integral --\u0026gt; region_symmetry[\u0026#34;区域划分与对称性\u0026#34;] multiple_integral --\u0026gt; target7[\u0026#34;📌 目标：能计算二重积分、应用于体积求解\u0026#34;] %% 常微分方程二级节点 ode --\u0026gt; ode1st[\u0026#34;一阶微分方程\u0026#34;] ode --\u0026gt; ode2nd[\u0026#34;二阶线性方程\u0026#34;] ode --\u0026gt; ode_fourier[\u0026#34;与傅里叶的联系\u0026#34;] ode1st --\u0026gt; sep_var[\u0026#34;分离变量法、齐次、线性微分方程\u0026#34;] ode1st --\u0026gt; target8[\u0026#34;📌 目标：掌握常见一阶微分方程求解方法\u0026#34;] ode2nd --\u0026gt; char_eq[\u0026#34;特征方程法（实根/复根/重根）\u0026#34;] ode2nd --\u0026gt; non_homo[\u0026#34;非齐次解：待定系数法\u0026#34;] ode2nd --\u0026gt; target9[\u0026#34;📌 目标：能求解二阶微分方程，理解系统响应\u0026#34;] ode_fourier --\u0026gt; diff_to_alg[\u0026#34;微分方程变换为代数方程\u0026#34;] ode_fourier --\u0026gt; target10[\u0026#34;📌 目标：了解频域解微分方程的优势\u0026#34;] %% 级数理论二级节点 series --\u0026gt; num_series[\u0026#34;数项级数\u0026#34;] series --\u0026gt; power_series[\u0026#34;幂级数\u0026#34;] series --\u0026gt; fourier_series[\u0026#34;傅里叶级数 🔁\u0026#34;] num_series --\u0026gt; conv_tests[\u0026#34;收敛判别法：比值、比较、交错级数\u0026#34;] num_series --\u0026gt; target11[\u0026#34;📌 目标：判断级数是否收敛\u0026#34;] power_series --\u0026gt; taylor_exp[\u0026#34;泰勒展开、收敛半径、逐项微积分\u0026#34;] power_series --\u0026gt; target12[\u0026#34;📌 目标：将函数展开为幂级数近似\u0026#34;] fourier_series --\u0026gt; trig_exp[\u0026#34;三角级数展开\u0026#34;] fourier_series --\u0026gt; orthogonality[\u0026#34;正交性与傅里叶系数计算\u0026#34;] fourier_series --\u0026gt; periodic_ext[\u0026#34;周期延拓与一般周期函数\u0026#34;] fourier_series --\u0026gt; target13[\u0026#34;📌 目标：理解周期函数的频率分解\u0026#34;] %% 傅里叶变换（CFT）二级节点 ft --\u0026gt; series_to_transform[\u0026#34;从级数到变换\u0026#34;] ft --\u0026gt; definition_inverse[\u0026#34;定义与逆变换\u0026#34;] ft --\u0026gt; core_properties[\u0026#34;核心性质 ⭐\u0026#34;] ft --\u0026gt; common_pairs[\u0026#34;常用变换对 🧮\u0026#34;] series_to_transform --\u0026gt; period_limit[\u0026#34;周期极限 → 非周期函数\u0026#34;] series_to_transform --\u0026gt; discrete_freq[\u0026#34;离散频率 → 连续频率\u0026#34;] series_to_transform --\u0026gt; target14[\u0026#34;📌 目标：建立傅里叶变换直觉\u0026#34;] definition_inverse --\u0026gt; forward_inverse[\u0026#34;正变换/逆变换公式\u0026#34;] definition_inverse --\u0026gt; complex_exp[\u0026#34;复指数表示优势\u0026#34;] definition_inverse --\u0026gt; target15[\u0026#34;📌 目标：掌握 CFT 定义及运算\u0026#34;] core_properties --\u0026gt; linearity[\u0026#34;线性、时移频移\u0026#34;] core_properties --\u0026gt; diff_integral[\u0026#34;微分与积分性质\u0026#34;] core_properties --\u0026gt; energy_conservation[\u0026#34;能量守恒（帕塞瓦尔）\u0026#34;] core_properties --\u0026gt; target16[\u0026#34;📌 目标：通过性质简化变换运算\u0026#34;] common_pairs --\u0026gt; rect_sinc[\u0026#34;矩形窗 → sinc\u0026#34;] common_pairs --\u0026gt; delta_exp[\u0026#34;冲激函数 δ，指数函数\u0026#34;] common_pairs --\u0026gt; target17[\u0026#34;📌 目标：熟记常见函数的变换对\u0026#34;] %% DFT 与 FFT 二级节点 dftfft --\u0026gt; discrete_background[\u0026#34;离散化背景\u0026#34;] dftfft --\u0026gt; dft_def[\u0026#34;DFT 定义\u0026#34;] dftfft --\u0026gt; fft[\u0026#34;快速傅里叶变换\u0026#34;] discrete_background --\u0026gt; sampling_theorem[\u0026#34;采样定理（奈奎斯特频率）\u0026#34;] discrete_background --\u0026gt; target18[\u0026#34;📌 目标：理解信号数字化过程\u0026#34;] dft_def --\u0026gt; discrete_mapping[\u0026#34;时域 ↔ 频域的离散映射\u0026#34;] dft_def --\u0026gt; target19[\u0026#34;📌 目标：掌握离散变换计算流程\u0026#34;] fft --\u0026gt; divide_conquer[\u0026#34;分治法，复杂度 O(N log N)\u0026#34;] fft --\u0026gt; target20[\u0026#34;📌 目标：掌握 FFT 原理与实用意义\u0026#34;] %% 应用与实践二级节点 app --\u0026gt; signal_proc[\u0026#34;信号处理 🎧\u0026#34;] app --\u0026gt; image_proc[\u0026#34;图像处理 🖼️\u0026#34;] app --\u0026gt; pde[\u0026#34;偏微分方程求解\u0026#34;] signal_proc --\u0026gt; spectrum_analysis[\u0026#34;频谱分析、滤波器设计（低通/高通）\u0026#34;] signal_proc --\u0026gt; conv_mult[\u0026#34;卷积变频域乘法\u0026#34;] signal_proc --\u0026gt; target21[\u0026#34;📌 目标：能用 FFT 实际处理信号\u0026#34;] image_proc --\u0026gt; noise_removal[\u0026#34;去周期噪声、边缘检测\u0026#34;] image_proc --\u0026gt; target22[\u0026#34;📌 目标：理解图像频率信息\u0026#34;] pde --\u0026gt; heat_wave[\u0026#34;解热传导 / 波动方程\u0026#34;] pde --\u0026gt; target23[\u0026#34;📌 目标：掌握变换方法在 PDE 中的应用\u0026#34;] %% 学习资源二级节点 res --\u0026gt; textbooks[\u0026#34;教材推荐 📚\u0026#34;] res --\u0026gt; online_courses[\u0026#34;在线课程 🎓\u0026#34;] res --\u0026gt; tools_practice[\u0026#34;工具与练习 🛠️\u0026#34;] res --\u0026gt; target24[\u0026#34;📌 目标：搭配练习和可视化工具，提升理解效率\u0026#34;] textbooks --\u0026gt; tongji[\u0026#34;高等数学（同济第七版）第1-6章：函数、导数、积分\u0026#34;] textbooks --\u0026gt; oppenheim_ss[\u0026#34;《信号与系统》Oppenheim：第3、4章傅里叶分析\u0026#34;] textbooks --\u0026gt; oppenheim_fs[\u0026#34;《傅里叶级数与积分变换》（奥本海姆）\u0026#34;] online_courses --\u0026gt; coursera_calc[\u0026#34;Coursera《Calculus for Everyone》[链接](https://www.coursera.org/learn/calculus1)\u0026#34;] online_courses --\u0026gt; mit_signals[\u0026#34;edX MIT《Signals and Systems》[链接](https://ocw.mit.edu/courses/6-003-signals-and-systems-spring-2010/)\u0026#34;] online_courses --\u0026gt; khan_academy[\u0026#34;Khan Academy：微积分 + 傅里叶变换\u0026#34;] tools_practice --\u0026gt; python_fft[\u0026#34;Python：numpy.fft，scipy.signal\u0026#34;] tools_practice --\u0026gt; matlab_fft[\u0026#34;Matlab：fft, freqz\u0026#34;] tools_practice --\u0026gt; desmos[\u0026#34;Desmos：函数图像可视化\u0026#34;] tools_practice --\u0026gt; math_se[\u0026#34;Math Stack Exchange：高质量问题解答\u0026#34;] ","date":"3 February, 2023","id":79,"permalink":"/posts/math/","summary":"","tags":"math","title":"math"},{"content":"python2.7 环境及包管理 sudo apt install python2.7 curl https://bootstrap.pypa.io/pip/2.7/get-pip.py --output get-pip.py sudo python2.7 get-pip.py pip2 install simplejson ","date":"3 February, 2023","id":80,"permalink":"/posts/python2.7-%E7%8E%AF%E5%A2%83%E5%8F%8A%E5%8C%85%E7%AE%A1%E7%90%86/","summary":"","tags":"Python","title":"python2.7 环境及包管理"},{"content":"vscode remote-ssh 免密登录 环境声明 win10 vscode + remote-ssh + virtualbox (ubuntu 20.04)\nwindows 配置 安装 vscode，remote-ssh 插件 生成 ssh key：ssh-keygen.exe -t rsa 然后一路回车 用户目录下会生成 id_rsa id_rsa.pub 两个文件 服务器 ubuntu 配置 安装 ssh server: sudo apt install openssh-server\n启动 ssh: sudo service sshd start\n此时 windows 就可以通过终端工具 ssh 登录服务器\n生成 ssh key：ssh-keygen.exe -t rsa 然后一路回车\nsudo vim /etc/ssh/sshd_config 取消注释 PubkeyAuthentication yes\n将 windows 生成的 id_rsa.pub 文件的内容加入服务器 ~/.ssh/authorized_keys 文件中，如果该文件不存在就创建一个\nsudo service sshd restart\nwindows 配置 修改用户目录下的配置文件：C:\\Users\\Administrator\\.ssh\\config，内容如下：\nHost 127.0.0.1 HostName 127.0.0.1 User luyang Port 22 Host：别名随便起 HostName: ubuntu 服务器 IP User: ubuntu 登录用户 Port：ssh 登录端口 至此 vscode remote-ssh 便可以免密码登录服务器\n","date":"3 February, 2023","id":81,"permalink":"/posts/vscode_remote-ssh_%E5%85%8D%E5%AF%86%E7%99%BB%E5%BD%95%E9%85%8D%E7%BD%AE/","summary":"win10 vscode + remote-ssh + virtualbox (ubuntu 20.04)","tags":"vscode ssh","title":"vscode remote-ssh 免密登录配置"},{"content":"交叉编译 glibc-2.35 glibc-2.35 更新需要同步用新版本的交叉编译器，这里直接在 Linaro 官网下载了最新的 gcc-linaro-7.5.0-2019.12-x86_64_arm-linux-gnueabihf\nexport PATH=\u0026#34;/code/gcc-linaro-7.5.0-2019.12-x86_64_armlinux-gnueabihf/bin\u0026#34;:$PATH export CROSS_COMPILE=arm-linux-gnueabihf- mkdir build_out; cd build_out ../configure --prefix=/code/glibc-2.35/build_out \\ --host=arm-linux-gnueabihf make make install ","date":"3 February, 2023","id":82,"permalink":"/posts/%E4%BA%A4%E5%8F%89%E7%BC%96%E8%AF%91-glibc-2.35/","summary":"glibc-2.35 更新需要同步用新版本的交叉编译器，这里直接在 Linaro 官网下载了最新的 gcc-linaro-7.5.0-2019.12-x86_64_arm-linux-gnueabihf","tags":"glibc","title":"交叉编译 glibc-2.35"},{"content":"交叉编译 libxml2-2.9.10 依赖 zlib 源码编译出来的目标文件，请先参考如何交叉编译 zlib 完成之后再来编译。\nexport PATH=\u0026#34;\u0026lt;path-to-gcc-linaro-5.3-2016.02-x86_64_arm-linuxgnueabihf\u0026gt;/bin\u0026#34;:$PATH export CROSS_COMPILE=arm-linux-gnueabihf mkdir build_out ./configure --prefix=/code/libxml2-2.9.10/build_out \\ --disable-static \\ --with-python=no \\ --host=arm-linux-gnueabihf \\ --with-zlib=/code/zlib-1.2.12/build_out make make install ","date":"3 February, 2023","id":83,"permalink":"/posts/%E4%BA%A4%E5%8F%89%E7%BC%96%E8%AF%91-libxml2-2.9.10/","summary":"依赖 zlib 源码编译出来的目标文件，请先参考如何交叉编译 zlib 完成之后再来编译。","tags":"libxml","title":"交叉编译 libxml2-2.9.10"},{"content":"交叉编译 Python-2.7.16 需要在代码的根路径新建一个 config.sit，内容参考如下： --enable-shared﻿ 生成动态链接库\nexport PATH=\u0026#34;\u0026lt;path-to-gcc-linaro-5.3-2016.02-x86_64_arm-linuxgnueabihf\u0026gt;/bin\u0026#34;:$PATH export CROSS_COMPILE=arm-linux-gnueabihf export CONFIG_SITE=./config.site # config.site 文件内容如下： cat config.site ac_cv_file__dev_ptmx=no ac_cv_file__dev_ptc=no ./configure --prefix=/code/Python-2.7.16/build_out \\ --host=arm-linux-gnueabihf \\ --build=x86_64 \\ --disable-ipv6 \\ --enable-shared make make install ","date":"3 February, 2023","id":84,"permalink":"/posts/%E4%BA%A4%E5%8F%89%E7%BC%96%E8%AF%91-python-2.7.16/","summary":"","tags":"Python","title":"交叉编译 Python-2.7.16"},{"content":"交叉编译 tcpdump-4.99.1 tcp dump 主页 tcpdump-4.99.1.tar.gz libpcap-1.10.1.tar.gz 参考：https://blog.csdn.net/onlyshi/article/details/81081707 tcpdump 依赖 libpcap，需要先编译 libcap。 #!/bin/bash export LIBCAP=/code/libpcap-1.10.1 export TCPDUMP=/code/tcpdump-4.99.1 export CROSS_COMPILETOOL=aarch64-bst-linux cd $LIBCAP mkdir -p install ./configure --prefix=./install --host=arm-linux-gnueabihf --with-pcap=linux make make install cd $TCPDUMP mkdir -p install ./configure --prefix=./install --host=arm-linux-gnueabihf make make install ","date":"3 February, 2023","id":85,"permalink":"/posts/%E4%BA%A4%E5%8F%89%E7%BC%96%E8%AF%91-tcpdump-4.99.1/","summary":"","tags":"tcpdump","title":"交叉编译 tcpdump-4.99.1"},{"content":"交叉编译 zlib-1.2.12 export PATH=\u0026#34;\u0026lt;path-to-gcc-linaro-5.3-2016.02-x86_64_arm-linux-gnueabihf\u0026gt;/bin\u0026#34;:$PATH export CROSS_COMPILE=arm-linux-gnueabihf export HOST=arm-linux-gnueabihf mkdir build_out ./configure --prefix=/code/zlib-1.2.12/build_out make make install ","date":"3 February, 2023","id":86,"permalink":"/posts/%E4%BA%A4%E5%8F%89%E7%BC%96%E8%AF%91-zlib-1.2.12/","summary":"","tags":"zlib","title":"交叉编译 zlib-1.2.12"},{"content":"痛点说明 当前板子集成的是 busybox dmesg，打印内核日志不支持 CST 时间戳格式，无法与应用层日志时间对齐\nroot@qualcomm:~# busybox dmesg --help BusyBox v1.29.2 (2021-07-28 06:25:45 UTC) multi-call binary. Usage: dmesg [-c] [-n LEVEL] [-s SIZE] Print or control the kernel ring buffer -c Clear ring buffer after printing -n LEVEL Set console logging level -s SIZE Buffer size -r Print raw message buffer 时间戳格式\n[ 74.247018] overflow FE mux_index 4 [ 74.269371] overflow FE mux_index 4 [ 74.294086] overflow FE mux_index 4 交叉编译 dmesg@util-linux git clone https://github.com/util-linux/util-linux.git sudo apt install autopoint autoconf automake libtool mkdir build ./tools/config-gen all # --prefix 必须是绝对路径 export PATH=$PATH:\u0026lt;path-to-cross-compile\u0026gt; ./configure --host=aarch64-linux-gnu --prefix=/home/luyang/code/tt/util-linux/build make dmesg -j8 $ file dmesg dmesg: ELF 64-bit LSB executable, ARM aarch64, version 1 (SYSV), dynamically linked, interpreter /lib/ld-linux-aarch64.so.1, for GNU/Linux 3.14.0, BuildID[sha1]=64098e1379e47231f4f3b1578fa842bc3d1d1251, with debug_info, not strippedfile dmesg 编译报错及解决方案\nfatal error: sys/random.h: No such file or directory `vim lib/randutils.c +30` 修改前：`# include \u0026lt;sys/random.h\u0026gt;` 修改后：`# include \u0026lt;/usr/include/linux/random.h\u0026gt;` 结果验证 把 dmesg 推到板子的 /userdata 目录下，然后登录板子进入 /userdata 目录\nroot@qualcomm:/userdata# while true; do ./dmesg; ./dmesg --time-format iso -c; echo; date; sleep 1; done Sat Jan 1 00:01:03 CST 2000 [ 74.247018] overflow FE mux_index 4 [ 74.269371] overflow FE mux_index 4 [ 74.294086] overflow FE mux_index 4 [ 74.294564] overflow FE mux_index 4 [ 74.295046] FE overflow 16 mux_index 4 temp_flow 0x10 [ 74.295709] FE overflow 0 mux_index 4 temp_flow 0x0 [ 74.231740] overflow FE mux_index 4 [ 74.247018] overflow FE mux_index 4 [ 74.269371] overflow FE mux_index 4 [ 74.294086] overflow FE mux_index 4 [ 74.294564] overflow FE mux_index 4 [ 74.295046] FE overflow 16 mux_index 4 temp_flow 0x10 [ 74.295709] FE overflow 0 mux_index 4 temp_flow 0x0 2000-01-01T00:01:03,774136+08:00 overflow FE mux_index 4 2000-01-01T00:01:03,789414+08:00 overflow FE mux_index 4 2000-01-01T00:01:03,811767+08:00 overflow FE mux_index 4 2000-01-01T00:01:03,836482+08:00 overflow FE mux_index 4 2000-01-01T00:01:03,836960+08:00 overflow FE mux_index 4 2000-01-01T00:01:03,837442+08:00 FE overflow 16 mux_index 4 temp_flow 0x10 2000-01-01T00:01:03,838105+08:00 FE overflow 0 mux_index 4 temp_flow 0x0 ","date":"1 February, 2023","id":87,"permalink":"/posts/dmesg_support_iso_timestamp/","summary":"当前板子集成的是 busybox dmesg，打印内核日志不支持 CST 时间戳格式，无法与应用层日志时间对齐","tags":"linux dmesg","title":"dmesg use CST timestamp"},{"content":"关于 MIPI CSI-2 clock 模式 MIPI_CSI-2_Specification_v1\n7 Physical Layer 7 物理层\nThe CSI-2 uses the MIPI Alliance Standard for D-PHY [2] physical layer.\nCSI - 2 使用 MIPI 联盟的 D - PHY [2] 物理层标准。\nThe physical layer for a CSI-2 implementation is composed of between one and four unidirectional data Lanes and one clock Lane.\nCSI - 2 实现的物理层由一到四个单向数据通道和一个时钟通道组成。\nAll CSI-2 transmitters and receivers shall support continuous clock behavior on the Clock Lane, and optionally may support non-continuous clock behavior.\n所有 CSI - 2 发送器和接收器应在时钟通道上支持连续时钟行为，并且可选择支持非连续时钟行为。\nFor [[continuous]] clock behavior the Clock Lane remains in high-speed mode generating active clock signals between the transmission of data packets.\n对于[[连续]]时钟行为，时钟通道在数据包传输之间保持在高速模式，生成有效时钟信号。\nFor [[non-continuous]] clock behavior the Clock Lane enters the LP-11 state between the transmission of data packets.\n对于[[非连续]]时钟行为，时钟通道在数据包传输之间进入 LP - 11 状态。\nThe minimum physical layer requirement for a CSI-2 transmitter is\nCSI - 2 发送器的最低物理层要求是\nData Lane Module: Unidirectional master, HS-TX, LP-TX and a CIL-MUYN function\n数据通道#模块：单向主设备，高速发送（HS - TX），低速发送（LP - TX）以及 CIL - MUYN 功能\nClock Lane Module: Unidirectional master, HS-TX. LP-TX and a CIL-MCNN function\n时钟通道#模块：单向主设备，高速发送（HS - TX），低速发送（LP - TX）以及 CIL - MCNN 功能\nThe minimum physical layer requirement for a CSI-2 receiver is\nCSI - 2 接收器的最低物理层要求是\nData Lane Module: Unidirectional slave, HS-RX, LP-RX, and a CIL-SUYN function\n数据通道#模块：单向从设备，高速接收（HS - RX），低速接收（LP - RX）以及 CIL - SUYN 功能\nClock Lane Module: All unidirectional slave, HS-RX, LP-RX, and a CIL-SCNN function\n时钟通道#模块：所有单向从设备，高速接收（HS - RX），低速接收（LP - RX）以及 CIL - SCNN 功能\nAll CSI-2 implementations shall support forward escape ULPM on all Data Lanes.\n所有 CSI - 2 实现应在所有数据通道上支持前向逃逸超低功耗模式（ULPM）。\n连续模式 在连续模式下，MIPI 时钟会持续运行，不间断地提供时钟信号。这意味着时钟信号在任何时候都是可用的，使得数据可以在任何时间点进行传输。连续模式的优点在于其稳定性和可预测性，因为它确保了时钟信号的连续性和一致性。然而，连续模式也可能导致更高的功耗，因为时钟信号始终在运行，即使在没有数据传输的时候也是如此。\n非连续模式 相比之下，非连续模式的 MIPI 时钟会在没有数据传输需求时停止运行，从而节省功耗。在非连续模式下，时钟信号只在需要时进行提供，这意味着在没有数据传输时，时钟信号会处于休眠状态。这种模式对于需要延长电池寿命的移动设备来说非常有用，因为它可以减少不必要的功耗。然而，非连续模式可能会导致一些延迟，因为每次需要传输数据时都需要重新启动时钟信号。\n","date":"30 January, 2023","id":88,"permalink":"/posts/gmsl2_csi2_clk/","summary":"MIPI_CSI-2_Specification_v1","tags":"","title":"GMSL2 CSI-2 clock"},{"content":"ubuntu 20.04\nsudo apt install gcc perl curl wget git vim build-essential make cmake bison flex android-sdk-ext4-utils mtd-utils zlib1g-dev lzop python2 curl https://bootstrap.pypa.io/pip/2.7/get-pip.py --output get-pip.py sudo python2 get-pip.py $ pip --version pip 20.3.4 from /home/luyang/.local/lib/python2.7/site-packages/pip (python 2.7) pip install networkx==1.8.1 pip install xlrd==0.9.3 pip install simplejson==3.17.6 pip install numpy==1.16.5 ","date":"30 January, 2023","id":89,"permalink":"/posts/hobotbuildenv/","summary":"ubuntu 20.04","tags":"","title":"Hobot 编译环境"},{"content":"ROS app project 新建一个空目录作为项目顶层目录： mkdir catkin_ws; cd catkin_ws\ncatkin_ws 目录下新建 src 目录：mkdir src\ncatkin_make Notice:\nbash 下操作 必须创建 src 目录 执行完 catkin_make 之后目录下就创建了一堆文件：\nluyang@KFC:~/catkin_ws$ tree -L 2 . ├── build │ ├── CATKIN_IGNORE │ ├── CMakeCache.txt │ ├── CMakeFiles │ ├── CTestConfiguration.ini │ ├── CTestCustom.cmake │ ├── CTestTestfile.cmake │ ├── Makefile │ ├── atomic_configure │ ├── bin │ ├── catkin │ ├── catkin_generated │ ├── catkin_make.cache │ ├── cmake_install.cmake │ ├── gtest │ └── test_results ├── devel │ ├── _setup_util.py │ ├── env.sh │ ├── lib │ ├── local_setup.bash │ ├── local_setup.fish │ ├── local_setup.sh │ ├── local_setup.zsh │ ├── setup.bash │ ├── setup.fish │ ├── setup.sh │ └── setup.zsh └── src └── CMakeLists.txt -\u0026gt; /opt/ros/noetic/share/catkin/cmake/toplevel.cmake 11 directories, 19 files cd src git clone https://github.com/ros/ros_tutorials.git 编译 demo\ncd ../ catkin_ws$ source devel/setup.bash catkin_ws$ catkin_make luyang@KFC:~/catkin_ws$ ls src/ros_tutorials/ ros_tutorials roscpp_tutorials rospy_tutorials turtlesim luyang@KFC:~//catkin_ws$ ls src/ros_tutorials/turtlesim/ CHANGELOG.rst CMakeLists.txt images include launch msg package.xml src srv tutorials 运行小乌龟：\n# 终端 A roscore # 终端 B rosrun turtlesim turtlesim_node ","date":"30 January, 2023","id":90,"permalink":"/posts/ros/","summary":"新建一个空目录作为项目顶层目录： mkdir catkin_ws; cd catkin_ws","tags":"","title":"ROS"},{"content":"td ubuntu 18.04\nsudo apt-get install -y wget zip openssh-server sshfs expect gcc python2.7 python3 xz-utils git make vim android-tools-adb android-tools-fastboot libyaml-dev libssl-dev bc u-boot-tools nfs-common gawk rsync rdiff android-tools-fsutils sudo apt-get install libncurses5-dev libncursesw5-dev libelf-dev libgmp-dev libmpc-dev ","date":"30 January, 2023","id":91,"permalink":"/posts/%E8%80%81%E9%BB%91%E7%BC%96%E8%AF%91%E7%8E%AF%E5%A2%83/","summary":"","tags":"","title":"老黑编译环境"},{"content":"Anaconda 安装 https://github.com/akfamily/akshare/blob/main/docs/topic/anaconda/anaconda-00.md\nResources akshare wiki PyCharm Jupyter notebook support ","date":"26 June, 2021","id":92,"permalink":"/posts/stock/","summary":"https://github.com/akfamily/akshare/blob/main/docs/topic/anaconda/anaconda-00.md","tags":"Python stock akshare","title":"akshare\r 学习笔记"},{"content":"Git Submodule 全面技术文档 📘 简介 Git Submodule（子模块）是 Git 提供的一种机制，使得一个 Git 仓库可以包含另一个 Git 仓库作为其子目录。这在大型项目中非常有用，例如依赖多个第三方库、模块化项目结构、多个项目共享组件等场景。\n📦 基本概念 主仓库（Superproject）：包含子模块的顶层仓库。 子模块（Submodule）：嵌套在主仓库中的另一个 Git 仓库，记录的是其特定提交版本。 .gitmodules 文件：记录子模块路径和对应的远程地址。 子模块 HEAD 是“冻结”的：主仓库记录的是子模块的某个提交哈希值，而不是其分支。 📥 子模块的基本操作 添加子模块 git submodule add \u0026lt;repository-url\u0026gt; [\u0026lt;path\u0026gt;] 例如：\ngit submodule add https://github.com/example/libfoo external/libfoo 这将：\n克隆子模块到指定路径 在 .gitmodules 添加记录 在主仓库中记录子模块当前 commit 克隆带子模块的项目 git clone --recurse-submodules \u0026lt;repo-url\u0026gt; 或者：\ngit clone \u0026lt;repo-url\u0026gt; cd \u0026lt;repo-name\u0026gt; git submodule update --init --recursive 更新子模块内容 拉取最新的子模块版本：\ngit submodule update --remote --merge 如果你只是想把子模块切换到其远程分支的最新提交：\ngit submodule update --remote 🔁 子模块日常工作流 切换分支时初始化子模块 git checkout \u0026lt;branch-name\u0026gt; git submodule update --init --recursive 提交包含子模块更新的更改 cd external/libfoo git pull origin master # 更新子模块内容 cd ../.. git add external/libfoo git commit -m \u0026#34;Update submodule libfoo\u0026#34; 注意：提交的是子模块指针的变化（commit hash 改变）。\n🧰 子模块文件详解 .gitmodules 位于主仓库根目录，内容如下：\n[submodule \u0026#34;external/libfoo\u0026#34;] path = external/libfoo url = https://github.com/example/libfoo.git 这个文件会被纳入版本控制。\n.git/config 中的对应配置 每个本地 clone 后，Git 会在 .git/config 中创建类似配置（不纳入版本控制）：\n[submodule \u0026#34;external/libfoo\u0026#34;] url = https://github.com/example/libfoo.git 🔧 子模块常用命令速查表 功能 命令 添加子模块 git submodule add \u0026lt;url\u0026gt; [path] 初始化子模块（首次克隆后） git submodule init 同步子模块 git submodule update 递归更新子模块 git submodule update --init --recursive 拉取最新子模块 git submodule update --remote 删除子模块（手动操作） 见下方删除子模块流程 查看状态 git submodule status 检查子模块 URL 是否更新 git submodule sync ❌ 删除子模块 Git 目前不提供自动删除子模块的命令，需手动操作：\n# 1. 删除子模块目录 rm -rf path/to/submodule # 2. 从 .gitmodules 移除记录 git config -f .gitmodules --remove-section submodule.path/to/submodule git add .gitmodules # 3. 从主仓库配置中删除子模块引用 git config -f .git/config --remove-section submodule.path/to/submodule # 4. 从索引中移除 git rm --cached path/to/submodule ⚠️ 注意事项与最佳实践 子模块指针是一个 commit ID，不会自动跟踪子模块的分支变更。 子模块更新后，主仓库必须提交子模块的新 commit ID。 变更子模块内容时，需进入子模块目录进行操作。 子模块无法用于需要频繁同步的双向开发，适合版本相对稳定的依赖项。 🆚 子模块 vs Subtree 简要对比 特性 Submodule Subtree 子项目为独立仓库 ✅ ✅ 子仓库是否固定版本 ✅ ❌（可合并） 合并提交历史 ❌ ✅ 操作复杂度 较高 较低（git subtree 命令较少） 主项目控制子模块内容 不直接控制 可直接改动 🧪 实战建议 多人协作建议 每次 clone 时务必执行 --recurse-submodules 或 update --init 变更子模块内容请务必同时 commit 子模块和主仓库变更 定期执行 git submodule status 检查同步状态 在 CI/CD 中使用 # 建议在 CI 中使用以下命令拉取完整内容 git submodule update --init --recursive 🔚 总结 Git 子模块是强大但略微复杂的依赖管理机制。使用得当可以有效分离模块和组件，但需注意版本控制方式的不同与操作规范性。\n","date":"1 January, 1970","id":93,"permalink":"/posts/-git-submodule-%E5%85%A8%E9%9D%A2%E6%8A%80%E6%9C%AF%E6%96%87%E6%A1%A3/","summary":"Git Submodule（子模块）是 Git 提供的一种机制，使得一个 Git 仓库可以包含另一个 Git 仓库作为其子目录。这在大型项目中非常有用，例如依赖多个第三方库、模块化项目结构、多个项目共享组件等场景。","tags":"git submodule github","title":"📘 Git Submodule 全面技术文档"},{"content":"📘Linux Firmware Node (fwnode) 统一设备模型 1. 引言 Linux fwnode（Firmware Node）统一设备模型是 Linux 内核中用于抽象不同固件描述机制的通用框架。它为设备树（Device Tree）、ACPI（Advanced Configuration and Power Interface）以及其他固件描述方式提供了统一的接口，使得驱动程序可以以相同的方式访问设备属性信息，而无需关心底层的固件实现细节。\n2. 历史背景与发展历程 2.1 早期固件描述问题 在 fwnode 框架出现之前，Linux 内核面临以下挑战：\n平台依赖性强：ARM 平台主要使用 Device Tree，x86 平台使用 ACPI 代码重复：驱动程序需要为不同固件格式编写重复的解析代码 维护困难：跨平台驱动维护成本高，兼容性问题频发 struct device *dev =...; int ret, irq; /* 检查设备是否关联了设备树节点 */ if (dev-\u0026gt;of_node) { /* 如果存在，则使用 of_* 系列 API 从设备树中读取属性 */ ret = of_property_read_u32(dev-\u0026gt;of_node, \u0026#34;interrupts\u0026#34;, \u0026amp;irq); if (ret) { // 错误处理 } } else if (ACPI_HANDLE(dev)) { /* 否则，检查设备是否有关联的 ACPI 句柄 */ /* 使用 ACPI 特定的 API 来解析 _CRS (Current Resource Settings) */ /* 这通常涉及到一套复杂、冗长的 ACPI 资源解析逻辑 */ //... complex ACPI resource parsing logic... } else { /* 可能还有基于平台数据的传统硬编码方式 */ //... } 2.2 发展时间线 Linux 内核社区对统一设备描述接口的探索始于 2014 年，旨在解决多固件接口并存带来的架构性问题。fwnode 框架正是这一架构演进的核心成果。以下是该框架的演进时间线和关键节点：\n2.1 时间线与里程碑 时间 里程碑 描述 2014 概念提出 内核核心开发者 Rafael J. Wysocki 首次提出 “统一固件描述接口” 概念，目标是抽象 DT 与 ACPI 的异构性 2015 初始实现 fwnode_handle 和基本的抽象框架首次被合入内核主线（4.x 开始） 2016 支持 ACPI fwnode 开始全面支持基于 ACPI 的设备描述与节点绑定，实现与设备树等价的抽象访问 2017–2019 高级功能扩展 添加支持图形化拓扑（graph nodes）、软件节点（swnode）、引用计数、路径解析等高级能力 2020–现在 持续优化与应用拓展 在性能、可维护性和安全性方面不断改进，广泛应用于 I2C、SPI、GPIO、USB、MIPI、PCI 等通用设备驱动 2.2 推动者与维护者 fwnode 的设计和推进由内核电源管理子系统的核心维护者 Rafael J. Wysocki 主导，其他如 Andy Shevchenko、Greg Kroah-Hartman 等开发者也为其在设备模型中的集成和扩展提供了大量贡献。\n相关子系统涉及：\ndrivers/base（核心驱动模型） drivers/of（设备树适配层） drivers/acpi（ACPI 层封装） drivers/base/swnode.c（软件节点支持） include/linux/fwnode.h（核心 API 定义） 2.3 应用范围与影响力 fwnode 框架的引入，极大地提升了驱动的跨平台兼容性和开发效率。它已经成为 Linux 内核中中大型设备驱动的标准架构组件：\n✅ 已迁移子系统示例：\nSPI 控制器（如 DesignWare SPI、Mediatek SPI） I2C 控制器 GPIO 子系统 USB Host/Device 控制器 CSI/MIPI 摄像头接口 PCI host bridge 初始化代码 多媒体子系统中的 graph-based 描述（如 HDMI、DSI、V4L2） ✅ 典型优势：\n同一驱动无需判断 dev-\u0026gt;of_node 还是 ACPI_HANDLE()，直接使用 dev_fwnode() 即可统一访问设备信息 支持 DT/ACPI/SWNode 无缝集成，便于平台代码抽象 使驱动代码更具可测试性与模块化能力 2.4 关键版本节点（内核版本参考） Linux 版本 演进亮点 4.1–4.4 初始 fwnode_handle 框架建立 4.5–4.9 ACPI fwnode 封装完善 4.10–4.19 引入 swnode，支持虚拟设备 5.0–5.4 图形拓扑、引用计数增强；device_get_match_data() 推广 5.5–5.15+ 广泛推广至 I2C/SPI/USB 驱动中，默认采用 fwnode 访问 3. 架构设计 3.1 整体架构 ┌─────────────────────┐ │ Driver Layer │ ← 驱动程序层 └─────────┬───────────┘ │ ┌─────────▼───────────┐ │ fwnode APIs │ ← 统一 API 层 └─────────┬───────────┘ │ ┌─────────▼───────────┐ │ fwnode Operations │ ← 操作函数层 └─────┬───┬───┬───────┘ │ │ │ ┌─────▼─┐ │ ┌─▼─────┐ │ DT │ │ │ ACPI │ ← 固件实现层 │fwnode │ │ │fwnode │ └───────┘ │ └───────┘ │ ┌─────▼─────┐ │ Other │ │ fwnode │ └───────────┘ 3.2 核心数据结构 /** * struct fwnode_handle - firmware node handle * @secondary: 指向次要固件节点的指针 * @ops: 操作函数集合指针 * @dev: 关联的设备指针 */ struct fwnode_handle { struct fwnode_handle *secondary; const struct fwnode_operations *ops; struct device *dev; struct list_head suppliers; struct list_head consumers; u8 flags; }; 3.3 操作函数接口 /** * struct fwnode_operations - fwnode 操作函数集 */ struct fwnode_operations { struct fwnode_handle *(*get)(struct fwnode_handle *fwnode); void (*put)(struct fwnode_handle *fwnode); bool (*device_is_available)(const struct fwnode_handle *fwnode); const void *(*device_get_match_data)(const struct fwnode_handle *fwnode, const struct device *dev); bool (*property_present)(const struct fwnode_handle *fwnode, const char *propname); int (*property_read_int_array)(const struct fwnode_handle *fwnode, const char *propname, unsigned int elem_size, void *val, size_t nval); int (*property_read_string_array)(const struct fwnode_handle *fwnode, const char *propname, const char **val, size_t nval); const char *(*get_name)(const struct fwnode_handle *fwnode); const char *(*get_name_prefix)(const struct fwnode_handle *fwnode); struct fwnode_handle *(*get_parent)(const struct fwnode_handle *fwnode); struct fwnode_handle *(*get_next_child_node)(const struct fwnode_handle *fwnode, struct fwnode_handle *child); struct fwnode_handle *(*get_named_child_node)(const struct fwnode_handle *fwnode, const char *name); int (*get_reference_args)(const struct fwnode_handle *fwnode, const char *prop, const char *nargs_prop, unsigned int nargs, unsigned int index, struct fwnode_reference_args *args); struct fwnode_handle *(*graph_get_next_endpoint)(const struct fwnode_handle *fwnode, struct fwnode_handle *prev); struct fwnode_handle *(*graph_get_remote_endpoint)(const struct fwnode_handle *fwnode); struct fwnode_handle *(*graph_get_port_parent)(struct fwnode_handle *fwnode); int (*graph_parse_endpoint)(const struct fwnode_handle *fwnode, struct fwnode_endpoint *endpoint); void *(*iomap)(struct fwnode_handle *fwnode, int index); int (*irq_get)(const struct fwnode_handle *fwnode, unsigned int index); int (*add_links)(struct fwnode_handle *fwnode); }; 4. 核心组件详解 4.1 fwnode_handle 结构体 fwnode_handle 是整个框架的核心，它代表一个固件节点的抽象：\n// 示例：获取和释放 fwnode struct fwnode_handle *fwnode_get(struct fwnode_handle *fwnode) { if (!fwnode) return NULL; return fwnode-\u0026gt;ops-\u0026gt;get ? fwnode-\u0026gt;ops-\u0026gt;get(fwnode) : fwnode; } void fwnode_put(struct fwnode_handle *fwnode) { if (!fwnode) return; if (fwnode-\u0026gt;ops-\u0026gt;put) fwnode-\u0026gt;ops-\u0026gt;put(fwnode); } 4.2 设备属性操作 4.2.1 属性存在性检查 bool fwnode_property_present(const struct fwnode_handle *fwnode, const char *propname) { bool ret; if (IS_ERR_OR_NULL(fwnode)) return false; ret = fwnode_call_bool_op(fwnode, property_present, propname); if (!ret \u0026amp;\u0026amp; !IS_ERR_OR_NULL(fwnode-\u0026gt;secondary)) ret = fwnode_call_bool_op(fwnode-\u0026gt;secondary, property_present, propname); return ret; } 4.2.2 整数属性读取 int fwnode_property_read_u32_array(const struct fwnode_handle *fwnode, const char *propname, u32 *val, size_t nval) { int ret; ret = fwnode_call_int_op(fwnode, property_read_int_array, propname, sizeof(u32), val, nval); if (ret == -EINVAL \u0026amp;\u0026amp; !IS_ERR_OR_NULL(fwnode-\u0026gt;secondary)) ret = fwnode_call_int_op(fwnode-\u0026gt;secondary, property_read_int_array, propname, sizeof(u32), val, nval); return ret; } 4.2.3 字符串属性读取 int fwnode_property_read_string_array(const struct fwnode_handle *fwnode, const char *propname, const char **val, size_t nval) { int ret; ret = fwnode_call_int_op(fwnode, property_read_string_array, propname, val, nval); if (ret == -EINVAL \u0026amp;\u0026amp; !IS_ERR_OR_NULL(fwnode-\u0026gt;secondary)) ret = fwnode_call_int_op(fwnode-\u0026gt;secondary, property_read_string_array, propname, val, nval); return ret; } 4.3 节点遍历操作 4.3.1 子节点遍历 #define fwnode_for_each_child_node(fwnode, child) \\ for (child = fwnode_get_next_child_node(fwnode, NULL); child; \\ child = fwnode_get_next_child_node(fwnode, child)) struct fwnode_handle *fwnode_get_next_child_node(const struct fwnode_handle *fwnode, struct fwnode_handle *child) { if (IS_ERR_OR_NULL(fwnode)) return NULL; return fwnode_call_ptr_op(fwnode, get_next_child_node, child); } 4.3.2 父节点获取 struct fwnode_handle *fwnode_get_parent(const struct fwnode_handle *fwnode) { if (IS_ERR_OR_NULL(fwnode)) return NULL; return fwnode_call_ptr_op(fwnode, get_parent); } 4.4 图形节点支持 图形节点用于描述设备间的连接关系，特别是在多媒体子系统中：\n/** * struct fwnode_endpoint - 端点描述结构体 */ struct fwnode_endpoint { unsigned int port; unsigned int id; const struct fwnode_handle *local_fwnode; }; int fwnode_graph_parse_endpoint(const struct fwnode_handle *fwnode, struct fwnode_endpoint *endpoint) { memset(endpoint, 0, sizeof(*endpoint)); endpoint-\u0026gt;local_fwnode = fwnode; return fwnode_call_int_op(fwnode, graph_parse_endpoint, endpoint); } 5. 实现机制 5.1 Device Tree fwnode 实现 static const struct fwnode_operations of_fwnode_ops = { .get = of_fwnode_get, .put = of_fwnode_put, .device_is_available = of_fwnode_device_is_available, .device_get_match_data = of_fwnode_device_get_match_data, .property_present = of_fwnode_property_present, .property_read_int_array = of_fwnode_property_read_int_array, .property_read_string_array = of_fwnode_property_read_string_array, .get_name = of_fwnode_get_name, .get_name_prefix = of_fwnode_get_name_prefix, .get_parent = of_fwnode_get_parent, .get_next_child_node = of_fwnode_get_next_child_node, .get_named_child_node = of_fwnode_get_named_child_node, .get_reference_args = of_fwnode_get_reference_args, .graph_get_next_endpoint = of_fwnode_graph_get_next_endpoint, .graph_get_remote_endpoint = of_fwnode_graph_get_remote_endpoint, .graph_get_port_parent = of_fwnode_graph_get_port_parent, .graph_parse_endpoint = of_fwnode_graph_parse_endpoint, .iomap = of_fwnode_iomap, .irq_get = of_fwnode_irq_get, .add_links = of_fwnode_add_links, }; const struct fwnode_handle *of_fwnode_handle(const struct device_node *node) { return node ? \u0026amp;node-\u0026gt;fwnode : NULL; } 5.2 ACPI fwnode 实现 static const struct fwnode_operations acpi_fwnode_ops = { .get = acpi_fwnode_get, .put = acpi_fwnode_put, .device_is_available = acpi_fwnode_device_is_available, .device_get_match_data = acpi_fwnode_device_get_match_data, .property_present = acpi_fwnode_property_present, .property_read_int_array = acpi_fwnode_property_read_int_array, .property_read_string_array = acpi_fwnode_property_read_string_array, .get_name = acpi_fwnode_get_name, .get_name_prefix = acpi_fwnode_get_name_prefix, .get_parent = acpi_fwnode_get_parent, .get_next_child_node = acpi_fwnode_get_next_child_node, .get_named_child_node = acpi_fwnode_get_named_child_node, .get_reference_args = acpi_fwnode_get_reference_args, .graph_get_next_endpoint = acpi_fwnode_graph_get_next_endpoint, .graph_get_remote_endpoint = acpi_fwnode_graph_get_remote_endpoint, .graph_get_port_parent = acpi_fwnode_graph_get_port_parent, .graph_parse_endpoint = acpi_fwnode_graph_parse_endpoint, .iomap = acpi_fwnode_iomap, .irq_get = acpi_fwnode_irq_get, .add_links = acpi_fwnode_add_links, }; 6. 使用流程 6.1 典型使用流程 1. 获取设备的 fwnode_handle ↓ 2. 检查属性是否存在 ↓ 3. 读取属性值 ↓ 4. 处理子节点（如需要） ↓ 5. 释放 fwnode 引用 6.2 代码示例 /** * 示例驱动程序使用 fwnode API */ static int example_driver_probe(struct platform_device *pdev) { struct device *dev = \u0026amp;pdev-\u0026gt;dev; struct fwnode_handle *fwnode = dev_fwnode(dev); struct fwnode_handle *child; u32 reg_value; const char *clock_name; int ret; /* 检查必要属性是否存在 */ if (!fwnode_property_present(fwnode, \u0026#34;reg\u0026#34;)) { dev_err(dev, \u0026#34;Missing \u0026#39;reg\u0026#39; property\\n\u0026#34;); return -ENODEV; } /* 读取寄存器地址 */ ret = fwnode_property_read_u32(fwnode, \u0026#34;reg\u0026#34;, \u0026amp;reg_value); if (ret) { dev_err(dev, \u0026#34;Failed to read \u0026#39;reg\u0026#39; property: %d\\n\u0026#34;, ret); return ret; } /* 读取时钟名称 */ ret = fwnode_property_read_string(fwnode, \u0026#34;clock-names\u0026#34;, \u0026amp;clock_name); if (!ret) dev_info(dev, \u0026#34;Using clock: %s\\n\u0026#34;, clock_name); /* 遍历子节点 */ fwnode_for_each_child_node(fwnode, child) { const char *child_name; ret = fwnode_property_read_string(child, \u0026#34;label\u0026#34;, \u0026amp;child_name); if (!ret) dev_info(dev, \u0026#34;Found child: %s\\n\u0026#34;, child_name); } return 0; } 7. 高级功能 7.1 引用计数管理 fwnode 框架实现了自动引用计数管理，确保节点在使用期间不会被释放：\nstatic inline struct fwnode_handle *fwnode_handle_get(struct fwnode_handle *fwnode) { return fwnode_get(fwnode); } static inline void fwnode_handle_put(struct fwnode_handle *fwnode) { fwnode_put(fwnode); } 7.2 设备链接管理 fwnode 支持设备间依赖关系的自动管理：\nint fwnode_link_add(struct fwnode_handle *con, struct fwnode_handle *sup) { struct fwnode_link *link; int ret = 0; mutex_lock(\u0026amp;fwnode_link_lock); list_for_each_entry(link, \u0026amp;sup-\u0026gt;suppliers, s_hook) if (link-\u0026gt;consumer == con) goto out; link = kzalloc(sizeof(*link), GFP_KERNEL); if (!link) { ret = -ENOMEM; goto out; } link-\u0026gt;supplier = sup; link-\u0026gt;consumer = con; list_add(\u0026amp;link-\u0026gt;s_hook, \u0026amp;sup-\u0026gt;suppliers); list_add(\u0026amp;link-\u0026gt;c_hook, \u0026amp;con-\u0026gt;consumers); out: mutex_unlock(\u0026amp;fwnode_link_lock); return ret; } 7.3 图形节点扩展 支持复杂的设备连接图描述：\nstruct fwnode_handle *fwnode_graph_get_next_endpoint(const struct fwnode_handle *fwnode, struct fwnode_handle *prev) { if (IS_ERR_OR_NULL(fwnode)) return NULL; return fwnode_call_ptr_op(fwnode, graph_get_next_endpoint, prev); } struct fwnode_handle *fwnode_graph_get_remote_endpoint(const struct fwnode_handle *fwnode) { if (IS_ERR_OR_NULL(fwnode)) return NULL; return fwnode_call_ptr_op(fwnode, graph_get_remote_endpoint); } 8. 最佳实践 8.1 驱动程序设计原则 统一接口使用\n/* 推荐：使用 fwnode API */ ret = fwnode_property_read_u32(dev_fwnode(dev), \u0026#34;reg\u0026#34;, \u0026amp;reg); /* 不推荐：直接使用特定固件 API */ // ret = of_property_read_u32(dev-\u0026gt;of_node, \u0026#34;reg\u0026#34;, \u0026amp;reg); 错误处理\nstruct fwnode_handle *child; fwnode_for_each_child_node(fwnode, child) { ret = process_child_node(child); if (ret) { fwnode_handle_put(child); /* 重要：释放引用 */ return ret; } } 资源清理\nstatic void example_driver_cleanup(struct device *dev) { struct fwnode_handle *fwnode = dev_fwnode(dev); /* fwnode 本身由设备框架管理，无需手动释放 */ /* 但子节点引用需要显式释放 */ } 8.2 性能优化建议 缓存常用属性\nstruct example_data { u32 cached_reg; const char *cached_name; }; static int example_cache_properties(struct device *dev, struct example_data *data) { struct fwnode_handle *fwnode = dev_fwnode(dev); fwnode_property_read_u32(fwnode, \u0026#34;reg\u0026#34;, \u0026amp;data-\u0026gt;cached_reg); fwnode_property_read_string(fwnode, \u0026#34;name\u0026#34;, \u0026amp;data-\u0026gt;cached_name); return 0; } 避免重复查找\n/* 不推荐：重复查找 */ if (fwnode_property_present(fwnode, \u0026#34;enable-gpios\u0026#34;)) { fwnode_property_read_u32(fwnode, \u0026#34;enable-gpios\u0026#34;, \u0026amp;gpio); } /* 推荐：一次性读取并检查返回值 */ ret = fwnode_property_read_u32(fwnode, \u0026#34;enable-gpios\u0026#34;, \u0026amp;gpio); if (!ret) { /* 使用 gpio 值 */ } 8.3 调试技巧 属性检查\nstatic void debug_print_properties(struct device *dev) { struct fwnode_handle *fwnode = dev_fwnode(dev); if (fwnode_property_present(fwnode, \u0026#34;reg\u0026#34;)) dev_dbg(dev, \u0026#34;Has \u0026#39;reg\u0026#39; property\\n\u0026#34;); if (fwnode_property_present(fwnode, \u0026#34;interrupts\u0026#34;)) dev_dbg(dev, \u0026#34;Has \u0026#39;interrupts\u0026#39; property\\n\u0026#34;); } 节点层次结构调试\nstatic void debug_print_node_hierarchy(struct fwnode_handle *fwnode, int level) { struct fwnode_handle *child; const char *name; name = fwnode_get_name(fwnode); pr_debug(\u0026#34;%*s%s\\n\u0026#34;, level * 2, \u0026#34;\u0026#34;, name ?: \u0026#34;\u0026lt;unnamed\u0026gt;\u0026#34;); fwnode_for_each_child_node(fwnode, child) { debug_print_node_hierarchy(child, level + 1); } } 9. 故障排查 9.1 常见问题 属性不存在错误\n/* 问题：假设属性存在 */ fwnode_property_read_u32(fwnode, \u0026#34;missing-prop\u0026#34;, \u0026amp;value); /* 解决：检查返回值 */ ret = fwnode_property_read_u32(fwnode, \u0026#34;maybe-missing\u0026#34;, \u0026amp;value); if (ret == -EINVAL) dev_warn(dev, \u0026#34;Property \u0026#39;maybe-missing\u0026#39; not found, using default\\n\u0026#34;); 节点引用泄漏\n/* 问题：忘记释放子节点引用 */ fwnode_for_each_child_node(fwnode, child) { if (error_condition) return -EFAULT; /* 泄漏了 child 引用 */ } /* 解决：正确释放引用 */ fwnode_for_each_child_node(fwnode, child) { if (error_condition) { fwnode_handle_put(child); return -EFAULT; } } 9.2 调试工具 内核调试选项\n# 启用设备树调试 echo 1 \u0026gt; /sys/kernel/debug/dynamic_debug/control echo \u0026#39;file drivers/of/* +p\u0026#39; \u0026gt; /sys/kernel/debug/dynamic_debug/control sysfs 接口\n# 查看设备固件信息 cat /sys/devices/.../firmware_node/... 10. 未来发展 10.1 发展趋势 性能优化：继续优化属性查找和缓存机制 功能扩展：支持更多固件格式和特性 工具改进：更好的调试和分析工具 10.2 相关技术 设备资源管理：与 devres 框架的深度集成 电源管理：与 PM 框架的协作优化 热插拔支持：动态设备管理能力增强 11. 结论 Linux fwnode 统一设备模型为内核提供了一套优雅的固件抽象层，有效解决了跨平台驱动开发的复杂性问题。通过提供统一的 API 接口，它简化了驱动程序的开发和维护，提高了代码的可重用性和可移植性。\n随着 Linux 内核的持续发展，fwnode 框架将继续演进，为更多的硬件平台和使用场景提供支持。对于内核开发者而言，深入理解和正确使用 fwnode API 是编写高质量、跨平台驱动程序的关键技能。\n附录 相关源码路径： drivers/base/property.c drivers/of/property.c drivers/acpi/property.c include/linux/fwnode.h 官方文档： Documentation/devicetree/bindings/ Documentation/driver-api/fwnode.rst ","date":"1 January, 1970","id":94,"permalink":"/posts/linux-firmware-node-fwnode-%E7%BB%9F%E4%B8%80%E8%AE%BE%E5%A4%87%E6%A8%A1%E5%9E%8B/","summary":"Linux fwnode（Firmware Node）统一设备模型是 Linux 内核中用于抽象不同固件描述机制的通用框架。它为设备树（Device Tree）、ACPI（Advanced Configuration and Power Interface）以及其他固件描述方式提供了统一的接口，使得驱动程序可以以相同的方式访问设备属性信息，而无需关心底层的固件实现细节。","tags":"linux ACPI DTS DeviceTree kernel firmware fwnode","title":"📘 Linux Firmware Node (fwnode) 统一设备模型"},{"content":"在 Linux 上编译和安装 CMake CMake 是一个跨平台的开源构建系统生成器，广泛用于软件开发项目。本文将介绍如何在 Linux 系统上从源代码编译并安装 CMake，确保你能够使用最新版本的功能。\n准备工作 在开始之前，确保你的系统已经安装了必要的开发工具和库。对于基于 Debian 的系统（如 Ubuntu），可以运行以下命令来安装所需的依赖项：\nsudo apt-get update sudo apt-get install build-essential libssl-dev build-essential：包含编译 C/C++ 程序所需的工具，如 gcc、g++ 和 make。 libssl-dev：提供 OpenSSL 的开发库，用于加密功能。 克隆 CMake 源代码 从 CMake 的官方 GitHub 仓库克隆指定版本的源代码。这里以 v4.0.3 版本为例：\ngit clone --branch v4.0.3 --single-branch https://github.com/Kitware/CMake.git cd CMake --branch v4.0.3：指定克隆的分支为 v4.0.3，这是你想要安装的版本。 --single-branch：只克隆指定的分支，减少克隆的数据量，节省时间和磁盘空间。 配置和编译 CMake 在 CMake 的源代码目录中，运行以下命令进行配置和编译：\n./bootstrap \u0026amp;\u0026amp; make -j8 ./bootstrap：运行 CMake 的配置脚本，它会检查系统环境并生成适合当前系统的构建文件。 make -j8：使用 make 命令进行编译，-j8 参数表示同时使用 8 个线程进行编译，可以加快编译速度（根据你的 CPU 核心数调整）。 如果系统中没有安装 OpenSSL，或者你不想使用 OpenSSL，可以在配置时添加 -DCMAKE_USE_OPENSSL=OFF 参数：\n./bootstrap -- -DCMAKE_USE_OPENSSL=OFF make -j8 安装 CMake 编译完成后，运行以下命令将 CMake 安装到系统中：\nsudo make install 默认情况下，CMake 会被安装到 /usr/local/bin 目录下。\n验证安装 你可以通过以下命令验证安装是否成功：\ncmake --version 如果安装成功，你应该能够看到类似以下的输出：\ncmake version 4.0.3 ","date":"1 January, 1970","id":95,"permalink":"/posts/linux-%E7%B3%BB%E7%BB%9F%E6%BA%90%E7%A0%81%E7%BC%96%E8%AF%91%E5%92%8C%E5%AE%89%E8%A3%85-cmake/","summary":"CMake 是一个跨平台的开源构建系统生成器，广泛用于软件开发项目。本文将介绍如何在 Linux 系统上从源代码编译并安装 CMake，确保你能够使用最新版本的功能。","tags":"linux cmake","title":"📘 Linux 系统源码编译和安装 CMake"},{"content":"https://www.analog.com/media/en/technical-documentation/user-guides/gmsl2-general-user-guide.pdf\nhttps://www.analog.com/media/en/technical-documentation/data-sheets/max96752.pdf\nhttps://www.analog.com/media/en/technical-documentation/data-sheets/max9295d.pdf\nGMSL2 General User Guide Key Features • Four-wire main (connects to remote peripheral) or four-wire subordinate (connects to µC/SoC).\n• Remote-side SPI bus supports SPI modes 0 or 3; local-side SPI bus supports SPI mode 0.\n• Device filtering on (multiple SPI interfaces with different SPI IDs) or off (point-to-point SPI interface).\n• Subordinate Select active low or high.\n• 600kHz to 25MHz or 50MHz SPI clock (depending on device).\n• MSB first (for control commands).\n• Pin or I2C control of RO and BNE input/output.\n18.Serial Peripheral Interface 18.3.3.1 SPI Burst Write Set RO. Send 0xA0 (Set SPI Target = 0, optional if only one device). Send 0xA4/A5 (Assert SS1/SS2). Clear RO. Send Cmd Byte (Read/Write and Address MS bit). Send Addrs Byte. Send Write Byte. Set RO. Wait for BNE = 1. Send 0xA6/Read Byte (Discard). Clear RO. Repeat 7 - 11 until all data is written. Set RO. Wait for BNE = 1. Send 0xA6/Read Byte (Discard) (Clear SS). Send 0xA6/Read Byte (Discard) (Clear SS). 18.3.3.2 SPI Burst Read Set RO. Send 0xA0 (Set SPI Target = 0, optional if only one device). Send 0xA4/A5 (Assert SS1/SS2). Clear RO. Send Cmd Byte (Read/Write and Address MS bit). Send Addrs Byte. Set RO. Wait for BNE = 1. Send 0xA7/Read Byte (Read Data) (Discard first two reads, remaining are valid). Repeat Steps 8 - 9 until all but two bytes are read. Wait for BNE = 1. Send 0xA6/Read Byte (Valid Data) (Clear SS). Send 0xA6/Read Byte (Last Valid Data) (Clear SS). 硬件框图 SPI 初始化 详细寄存器描述可以参考官网提供的 DataSheet\nIndex Device Reg Value Desc 1 MAX9295D 0x173 0xFA 2 MAX9295D 0x174 0xFA SCK 600KHz 3 MAX9295D 0x175 0xFA SCK 600KHz 4 MAX9295D 0x176 0x0C 5 MAX96752 0x4E6 0x03 0x4E6 0x4F6 6 MAX96752 0x4E9 0x00 0x4E9 0x4F9 7 MAX9295D 0x172 0x00 #SPI mode 0 8 MAX96752 0x4E0 0x09 0x4E0 0x4F0 9 MAX9295D 0X170 0X0B SPI mode 0 的波形 SPI mode 3 配置 0x172 设置 0x0C OK 错误的配置：0x172 设置 0x04 ","date":"1 January, 1970","id":96,"permalink":"/posts/adi_gmsl2_serdes_spi/","summary":"https://www.analog.com/media/en/technical-documentation/user-guides/gmsl2-general-user-guide.pdf","tags":"ADI MAXIM SERDES GMSL MIPI SPI","title":"ADI GMSL2 SERDES SPI"},{"content":"下载jdk 1.7\nhttps://repo.huaweicloud.com/java/jdk/7u80-b15/jdk-7u80-linux-x64.tar.gz\n解压\ntar xzvf jdk-7u80-linux-x64.tar.gz\nandroid 18.04 jdk1.7 android 7.1 安装\nsudo mv jdk1.7.0_80 /usr/lib/\nswitchjdk7.sh 文件内容如下，该文件放在代码顶层目录：\n# add JDK7 cofig ---- export JAVA_HOME=/usr/lib/jdk1.7.0_80/ export JRE_HOME=${JAVA_HOME}/jre export CLASSPATH=.:${JAVA_HOME}/lib:${JRE_HOME}/lib export PATH=${JAVA_HOME}/bin:$PATH # add JDK7 cofig ---- 执行如下命令切换java 1.7，仅当前终端有效\nsource switchjdk7.sh\nhttps://repo.huaweicloud.com/java/jdk/6u45-b06/\nhttps://repo.huaweicloud.com/java/jdk/7u80-b15/\nhttps://www.oracle.com/java/technologies/javase/javase-jdk8-downloads.html\n","date":"1 January, 1970","id":97,"permalink":"/posts/androidjava-.7%E7%8E%AF%E5%A2%83%E9%85%8D%E7%BD%AE/","summary":"下载jdk 1.7","tags":"android java","title":"Android Java 1.7 环境配置"},{"content":"工具 AndroidStudio 信息 Android Studio 默认设置\nSDK Folder: \u0026ldquo;%APPDATA%\\Local\\Android\\Sdk\u0026rdquo; JDK Folder: \u0026ldquo;C:\\Program Files\\Android\\Android Studio\\jre\u0026rdquo; 问题解决 安装完Android Studio首次启动报错 Unable to access Android SDK add-on list 选择cancel\ngradle 下载环境配置 For Windows\nC:\\Users\\luyang\\.gradle\\init.gradle 如果没有该文件就自己新建一个，内容如下\nallprojects{ repositories { def ALIYUN_REPOSITORY_URL = \u0026#39;https://maven.aliyun.com/repository/public/\u0026#39; def ALIYUN_JCENTER_URL = \u0026#39;https://maven.aliyun.com/repository/jcenter/\u0026#39; def ALIYUN_GOOGLE_URL = \u0026#39;https://maven.aliyun.com/repository/google/\u0026#39; def ALIYUN_GRADLE_PLUGIN_URL = \u0026#39;https://maven.aliyun.com/repository/gradle-plugin/\u0026#39; all { ArtifactRepository repo -\u0026gt; if(repo instanceof MavenArtifactRepository){ def url = repo.url.toString() if (url.startsWith(\u0026#39;https://repo1.maven.org/maven2/\u0026#39;)) { project.logger.lifecycle \u0026#34;Repository ${repo.url} replaced by $ALIYUN_REPOSITORY_URL.\u0026#34; remove repo } if (url.startsWith(\u0026#39;https://jcenter.bintray.com/\u0026#39;)) { project.logger.lifecycle \u0026#34;Repository ${repo.url} replaced by $ALIYUN_JCENTER_URL.\u0026#34; remove repo } if (url.startsWith(\u0026#39;https://dl.google.com/dl/android/maven2/\u0026#39;)) { project.logger.lifecycle \u0026#34;Repository ${repo.url} replaced by $ALIYUN_GOOGLE_URL.\u0026#34; remove repo } if (url.startsWith(\u0026#39;https://plugins.gradle.org/m2/\u0026#39;)) { project.logger.lifecycle \u0026#34;Repository ${repo.url} replaced by $ALIYUN_GRADLE_PLUGIN_URL.\u0026#34; remove repo } } } maven { url ALIYUN_REPOSITORY_URL } maven { url ALIYUN_JCENTER_URL } maven { url ALIYUN_GOOGLE_URL } maven { url ALIYUN_GRADLE_PLUGIN_URL } } } ubuntu android studio system entry Android Studio -\u0026gt; Tools -\u0026gt; Create Desktop Entry\n","date":"1 January, 1970","id":98,"permalink":"/posts/androidstudioenv/","summary":"Android Studio 默认设置","tags":"android AndroidStudio","title":"Android Studio Env"},{"content":"am 命令说明 am start -n 命令是 Android 调试桥（ADB）工具的一部分，用于在 Android 设备上启动一个活动。以下是该命令及其组成部分的详细解释：\nam: 代表 Activity Manager（活动管理器）。它是一个命令行工具，可以用于在 Android 设备上执行各种与活动、服务和广播相关的操作。 start: 这个子命令用于启动一个活动。活动表示一个带有用户界面的单个屏幕，启动活动意味着打开一个特定的应用程序界面。 -n: 该选项指定你想要启动的活动的组件名称。组件名称由两部分组成： 应用程序的 包名（例如 com.android.gallery3d）。 你想要启动的活动的 完整类名（例如 .app.GalleryActivity）。 组件名称的格式为 package_name/.ActivityName。\n使用示例 启动图库应用的主活动：\nadb shell am start -n com.android.gallery3d/.app.GalleryActivity adb shell: 在设备上打开一个命令行界面。 am start -n: 启动指定的活动。 com.android.gallery3d/.app.GalleryActivity: 指定要启动的包名和活动。 其他选项 --display \u0026lt;display_id\u0026gt;: 如果设备有多个显示屏，可以指定使用哪个显示屏。 -d \u0026lt;data_uri\u0026gt;: 指定一个数据 URI（例如文件路径或网页链接），活动在启动时可以使用这个 URI。 -a \u0026lt;action\u0026gt;: 指定要执行的操作，例如 android.intent.action.VIEW。 实际示例 如果你想在显示屏 3 上打开图库应用中的特定图片：\nadb shell am start -n com.android.gallery3d/.app.GalleryActivity --display 3 这个命令将在显示屏 3 上打开图库应用的 GalleryActivity。\n如何获取 package_name 以及 activity_name pm list packages 命令获取当前系统中的所有 package。\n130|console:/ # pm list packages ...... package:com.android.internal.systemui.navbar.gestural package:com.android.gallery3d package:com.android.providers.userdictionary ...... 以 gallery3d com.android.gallery3d 为例：\nconsole:/ # dumpsys package com.android.gallery3d | grep -A 1 \u0026#39;MAIN\u0026#39; android.intent.action.MAIN:[ 1080.400705] servicemanager: Since \u0026#39;artd\u0026#39; could not be found, trying to start it as a lazy AIDL service. (if it\u0026#39;s not configured to be a lazy service, it may be stuck starting or still starting). c99ebe com.android.gallery3d/.app.GalleryActivity filter 92aab1f Action: \u0026#34;android.intent.action.MAIN\u0026#34; Category: \u0026#34;android.intent.category.DEFAULT\u0026#34; -- Action: \u0026#34;android.intent.action.MAIN\u0026#34; be96ced com.andro[ 1080.418995] init: starting service \u0026#39;artd\u0026#39;... id.gallery3d/.app.Gallery filter de1c722 Action: \u0026#34;android.intent.action.MAIN\u0026#34; Category: \u0026#34;android.intent.category.DEFAULT\u0026#34; -- Action: \u0026#34;android.intent.action.MAIN\u0026#34; Category: \u0026#34;android.intent.category.DEFAULT\u0026#34; -- [ 1080.446599] init: ... started service \u0026#39;artd\u0026#39; has pid 2312 [ 1080.458298] BpBinder: onLastStrongRef automatically unlinking death recipients: privateFlags=[ PRIVATE_FLAG_ACTIVITIES_RESIZE_MODE_RESIZEABLE_VIA_SDK_VERSION PRIVATE_FLAG_REQUEST_LEGACY_EXTERNAL_STORAGE HAS_DOMAIN_URLS PRODUCT PRIVATE_FLAG_ALLOW_NATIVE_HEAP_POINTER_TAGGING ] forceQueryable=false -- privatePkgFlags=[ PRI[ 1080.472553] init: Control message: Processed ctl.interface_start for \u0026#39;aidl/artd\u0026#39; from pid: 248 (/system/bin/servicemanager) VATE_FLAG_ACTIVITIES_RESIZE_MODE_RESIZEABLE_VIA_SDK_VERSION PRIVATE_FLAG_REQUEST_LEGACY_EXTERNAL_STORAGE HAS_DOMAIN_URLS PRODUCT PRIVATE_FLAG_ALLOW_NATIVE_HEAP_POINTER_TAGGING ] apexModuleName=null 关键信息：c99ebe com.android.gallery3d/.app.GalleryActivity filter 92aab1f\n对应的 package and activity name 组合：com.android.gallery3d/.app.GalleryActivity\n套用到 am 命令中就是：\nam start -n com.android.gallery3d/.app.GalleryActivity --display 3 ","date":"1 January, 1970","id":99,"permalink":"/posts/android%E4%BD%BF%E7%94%A8am%E5%91%BD%E4%BB%A4%E5%90%AF%E5%8A%A8%E4%B8%80%E4%B8%AA%E6%B4%BB%E5%8A%A8%E7%BB%84%E4%BB%B6/","summary":"am start -n 命令是 Android 调试桥（ADB）工具的一部分，用于在 Android 设备上启动一个活动。以下是该命令及其组成部分的详细解释：","tags":"android adb am pm activity","title":"Android 使用 am 命令启动一个活动组件"},{"content":"Android10的基线代码google已经将prebuilt的ccache移除,但是保留了相关功能选项\ncommit 326e7e2cbd95fc2b1a1f858fb29904c9d3974843 Author: Dan Willemsen \u0026lt;dwillemsen@google.com\u0026gt; Date: Thu Apr 5 15:48:16 2018 -0700 Remove our binary of ccache This version is rather old, and has many known bugs. The build system is no longer providing ccache, but preserving the option to use your own at your own risk. Bug: 32748498 Test: cs/ccache Change-Id: I894a11445127bf8cb3a7ac5a119c500f2c572fb9 安卓10之前配置\nexport USE_CCACHE=true export CCACHE_DIR=$HOME/.cache prebuilts/misc/linux-x86/ccache/ccache -M 10G 安卓10+通过使用的HOST操作系统安装对应的ccache软件包\nexport USE_CCACHE=true export CCACHE_EXEC=/usr/bin/ccache export CCACHE_DIR=$HOME/.cache ${CCACHE_EXEC} -M 50G 可以通过如下命令查询cache状态 ccache -s\n","date":"1 January, 1970","id":100,"permalink":"/posts/android10%E7%BC%96%E8%AF%91%E5%BC%80%E5%90%AFccache/","summary":"Android10的基线代码google已经将prebuilt的ccache移除,但是保留了相关功能选项","tags":"windows android ccache","title":"Android10编译开启ccache"},{"content":"Window10 Beyond Compare BCompare-4.2.4.22795 key key\nH1bJTd2SauPv5Garuaq0Ig43uqq5NJOEw94wxdZTpU-pFB9GmyPk677gJ vC1Ro6sbAvKR4pVwtxdCfuoZDb6hJ5bVQKqlfihJfSYZt-xVrVU27+0Ja hFbqTmYskatMTgPyjvv99CF2Te8ec+Ys2SPxyZAF0YwOCNOWmsyqN5y9t q2Kw2pjoiDs5gIH-uw5U49JzOB6otS7kThBJE-H9A76u4uUvR8DKb+VcB rWu5qSJGEnbsXNfJdq5L2D8QgRdV-sXHp2A-7j1X2n4WIISvU1V9koIyS NisHFBTcWJS0sC5BTFwrtfLEE9lEwz2bxHQpWJiu12ZeKpi+7oUSqebX+ 如果运行Beyond Compare报错\nThis license key has been revoked ..... C:\\Users\\\u0026lt;username\u0026gt;\\AppData\\Roaming\\Scooter Software\\ 目录下的内容全部删除重新启动BeyondCompare即可。\nfix windows 右键菜单中没有beyond compare选项 Explorer Shell Extension\n","date":"1 January, 1970","id":101,"permalink":"/posts/beyondcompare/","summary":"key","tags":"BeyondCompare","title":"BeyondCompare"},{"content":" c++ 为什么有些类属性使用普通的指针定义，而不是使用智能指针 DogClass *ptr; 而不是 std::unique_ptr\u0026lt;DogClass\u0026gt; ptr;\nC++ 前向声明与指针使用指南 前向声明与不完整类型 在 C++ 中，前向声明（Forward Declaration）允许我们在不包含完整类定义的情况下引用一个类。这对于减少编译依赖和解决循环依赖问题非常有用。\n// 前向声明示例 class MyClass; // 只声明存在性，不提供定义 此时，MyClass 被称为不完整类型（Incomplete Type），因为编译器只知道该类存在，但不知道它的大小、成员或方法。\nstd::unique_ptr 与不完整类型 当使用 std::unique_ptr 管理前向声明类的对象时，会出现问题：\n// 头文件中 class MyForwardDeclaredClass; // 前向声明 class Container { private: std::unique_ptr\u0026lt;MyForwardDeclaredClass\u0026gt; ptr_; // 编译错误! }; 上述代码在编译时会失败，错误类似于：\nerror: invalid application of \u0026#39;sizeof\u0026#39; to incomplete type \u0026#39;MyForwardDeclaredClass\u0026#39; 原因分析 这个问题出现的原因是：\nstd::unique_ptr 的析构函数需要知道如何删除它管理的对象 为此，编译器需要在编译 Container 类时知道 MyForwardDeclaredClass 的完整定义 当编译器尝试计算不完整类型的 sizeof 时，无法确定其大小，因此报错 具体来说，std::unique_ptr 的默认删除器 std::default_delete 在析构时会执行：\ntemplate \u0026lt;typename T\u0026gt; void std::default_delete\u0026lt;T\u0026gt;::operator()(T* ptr) const { static_assert(sizeof(T) \u0026gt; 0, \u0026#34;Type must be complete\u0026#34;); delete ptr; } 当类型不完整时，sizeof(T) 无法计算，触发 static_assert 失败。\n解决方案 1. 使用原始指针配合手动内存管理 // 头文件 class MyForwardDeclaredClass; // 前向声明 class Container { private: MyForwardDeclaredClass* ptr_ = nullptr; public: ~Container() { if (ptr_) { delete ptr_; ptr_ = nullptr; } } }; 这种方法避免了编译期 sizeof 检查，因为原始指针不需要知道所指向对象的大小。但必须注意手动管理内存，避免内存泄漏。\n2. 将 unique_ptr 的定义移至实现文件 // 头文件 Container.h class MyForwardDeclaredClass; class Container { private: std::unique_ptr\u0026lt;MyForwardDeclaredClass\u0026gt; ptr_; public: Container(); ~Container(); // 声明析构函数，但在实现文件中定义 }; // 实现文件 Container.cpp #include \u0026#34;Container.h\u0026#34; #include \u0026#34;MyForwardDeclaredClass.h\u0026#34; // 包含完整定义 Container::Container() : ptr_(new MyForwardDeclaredClass()) {} Container::~Container() = default; // 在这里，类型已完整，析构函数可以正常工作 这种方法是PIMPL（Pointer to Implementation）模式的一种应用。\n3. 使用自定义删除器 // 头文件 class MyForwardDeclaredClass; class Container { private: std::unique_ptr\u0026lt;MyForwardDeclaredClass, void(*)(MyForwardDeclaredClass*)\u0026gt; ptr_; public: Container(); ~Container(); }; // 实现文件 #include \u0026#34;Container.h\u0026#34; #include \u0026#34;MyForwardDeclaredClass.h\u0026#34; static void deleter(MyForwardDeclaredClass* ptr) { delete ptr; } Container::Container() : ptr_(new MyForwardDeclaredClass(), deleter) {} Container::~Container() = default; 最佳实践 优先使用完整类型：如果可能，尽量在使用 std::unique_ptr 的头文件中包含完整类定义 PIMPL 模式：当需要隐藏实现细节时，使用 PIMPL 模式并在实现文件中定义析构函数 混合方法： 头文件中使用原始指针声明 实现文件中使用 std::unique_ptr 管理生命周期 注意其他智能指针： std::shared_ptr 也需要完整类型，但可以使用自定义删除器解决 std::weak_ptr 继承了 std::shared_ptr 的限制 总结 不能对不完整类型使用 std::unique_ptr 的根本原因是智能指针需要在编译时确定对象的大小和删除方式。处理这一限制的方法包括使用原始指针、将智能指针的定义移至实现文件，或使用自定义删除器。理解这些技术可以帮助我们更有效地管理 C++ 代码中的对象生命周期和头文件依赖。\n","date":"1 January, 1970","id":102,"permalink":"/posts/c++-%E5%89%8D%E5%90%91%E5%A3%B0%E6%98%8E%E4%B8%8E%E6%8C%87%E9%92%88%E4%BD%BF%E7%94%A8%E6%8C%87%E5%8D%97/","summary":"在 C++ 中，前向声明（Forward Declaration）允许我们在不包含完整类定义的情况下引用一个类。这对于减少编译依赖和解决循环依赖问题非常有用。","tags":"cpp 前向声明 ForwardDeclaration","title":"C++ 前向声明与指针使用指南"},{"content":"Crystal Oscillator 晶体振荡器\n无源晶振 晶振本身并不能起振，需要借助外部振荡电路。因此在实际电路中需要IC上电正常后晶振才能起振。 此时才能测量出晶振波形。 常见晶振频率 晶振常用的频率为 4MHz ~ 50MHz\n网络PHY常见 25MHz GMSL SERDES常见 25MHz 电子钟表常见 32.768MHz 常见无源晶振pin脚定义 无源晶振的频率pin脚不分正负极\n两pin脚无源晶振：一个pin脚为频率输出pin脚，另外一个pin脚是频率输入pin脚。即使反过来，晶振依旧正常工作。 三pin脚晶振：两侧引脚为频率输出pin脚与频率输入pin脚，中间引脚接地。除了注意让这个接地pin脚去接地(GND)，两侧引脚的用法与两脚晶振无异。 四脚贴片无源晶振：pin 1和pin 3为频率输入引脚及频率输出引脚，其余两个pin脚均为接地引脚，即使把它旋转180度，也只是pin 1和pin 3互换位置，即输入pin脚变成了输出pin脚，而输出pin脚则变成输入pin脚，晶振依旧可以正常工作，不会导致任何性能及功能差异。 无源晶振两边加谐振电容 无源晶振的标称频率指在测试时有一个“负载电容”的条件—在晶振工作时满足这个条件， 振荡频率才可能与频率标称值一致（只有在合适的外接电容值满足无源晶振的起振要求时，晶振才能正常工作）。\n无源晶振的实际输出频率并不是完全固定的，而是可以在一定范围内微调，起微调作用的就是这两个外接电容。\n切记: 谐振电容一定要按照芯片参考设计来，搞错了不起振，爱因斯坦可不负责, 高尔基血的教训\nAWR2243 40MHz 晶振起振后波形 ","date":"1 January, 1970","id":103,"permalink":"/posts/crystal/","summary":"Crystal Oscillator 晶体振荡器","tags":"electronic crystal 反相器 皮尔斯振荡器 石英晶体谐振器 爱因斯坦","title":"crystal"},{"content":" Linux debian 4.9.0-6-amd64 #1 SMP Debian 4.9.82-1+deb9u3 (2018-03-02) x86_64\nkk@debian:~$ cat /etc/network/interfaces\n# This file describes the network interfaces available on your system # and how to activate them. For more information, see interfaces(5). source /etc/network/interfaces.d/* # The loopback network interface auto lo iface lo inet loopback 修改后\n# This file describes the network interfaces available on your system # and how to activate them. For more information, see interfaces(5). source /etc/network/interfaces.d/* # The loopback network interface auto lo enp0s3 iface lo inet loopback iface enp0s3 inet static address 192.168.20.103 netmask 255.255.255.0 gateway 192.168.20.1 dns-nameservers 114.114.114.114 kk@debian:~$ /sbin/ifconfig\nenp0s3: flags=4163\u0026lt;UP,BROADCAST,RUNNING,MULTICAST\u0026gt; mtu 1500 inet 192.168.20.103 netmask 255.255.255.0 broadcast 192.168.20.255 inet6 fe80::a00:27ff:fe30:e855 prefixlen 64 scopeid 0x20\u0026lt;link\u0026gt; ether 08:00:27:30:e8:55 txqueuelen 1000 (Ethernet) RX packets 87 bytes 8538 (8.3 KiB) RX errors 0 dropped 0 overruns 0 frame 0 TX packets 155 bytes 21027 (20.5 KiB) TX errors 0 dropped 0 overruns 0 carrier 0 collisions 0 lo: flags=73\u0026lt;UP,LOOPBACK,RUNNING\u0026gt; mtu 65536 inet 127.0.0.1 netmask 255.0.0.0 inet6 ::1 prefixlen 128 scopeid 0x10\u0026lt;host\u0026gt; loop txqueuelen 1 (Local Loopback) RX packets 0 bytes 0 (0.0 B) RX errors 0 dropped 0 overruns 0 frame 0 TX packets 0 bytes 0 (0.0 B) TX errors 0 dropped 0 overruns 0 carrier 0 collisions 0 重启网络服务\nsudo /etc/init.d/networking restart\n这样修改之后, 内网可以 ssh 登陆虚拟机, 但是虚拟机无法连接外网.\n修改方案:\nsudo vim /etc/resolv.conf\n默认该文件是空, 添加如下行:\nnameserver 114.114.114.114 重启网络服务\nsudo /etc/init.d/networking restart\n","date":"1 January, 1970","id":104,"permalink":"/posts/debian4.9configstaticip/","summary":"Linux debian 4.9.0-6-amd64 #1 SMP Debian 4.9.82-1+deb9u3 (2018-03-02) x86_64","tags":"debian network","title":"Debian 4.9 Config Static Ip.md"},{"content":"关于 Dokuwiki 详细信息, 请访问官网.\n安装配置 本教程基于 ubuntu 17.10 x64\n参考 DokuWiki Installation 安装 apache php apt-get install apache2 apt-get install php7.1 libapache2-mod-php7.1 php7.1-xml 配置 apache php 修改文件 apache2/sites-available/000-default.conf 配置 apache2 document root 为 dokuwiki 根目录 - DocumentRoot /var/www/html + DocumentRoot /var/www/wikihub 修改文件 /etc/apache2/apache2.conf 配置 apache security \u0026lt;Directory /\u0026gt; Options FollowSymLinks - AllowOverride none + AllowOverride All Require all denied \u0026lt;/Directory\u0026gt; \u0026lt;Directory /usr/share\u0026gt; AllowOverride None Require all granted \u0026lt;/Directory\u0026gt; \u0026lt;Directory /var/www/\u0026gt; Options Indexes FollowSymLinks - AllowOverride none + AllowOverride All Require all granted \u0026lt;/Directory\u0026gt; Activate the \u0026lsquo;mod_rewrite\u0026rsquo; in apache2 to enable .htaccess sudo a2enmod rewrite \u0026amp;\u0026amp; sudo service apache2 restart 安装 dokuwiki 从 dokuwiki 官方下载页面 下载最新版的安装包.\n解压缩下载的压缩包, 并上传/复制到你的网站空间中.\n注意这里一定要将 dokuwiki 的根目录修改为与前边 apache 的配置一致\n我的目录结构如下\nroot@jerry-VirtualBox:/var/www/wikihub# ll total 96 drwxr-xr-x 9 www-data www-data 4096 10月 30 13:30 ./ drwxr-xr-x 3 root root 4096 10月 30 13:29 ../ drwxr-xr-x 2 www-data www-data 4096 10月 30 13:30 bin/ drwxr-xr-x 2 www-data www-data 4096 10月 30 13:30 conf/ -rw-r--r-- 1 www-data www-data 18092 10月 30 13:30 COPYING drwxr-xr-x 12 www-data www-data 4096 10月 30 13:30 data/ -rw-r--r-- 1 www-data www-data 3692 10月 30 13:30 doku.php -rw-r--r-- 1 www-data www-data 19374 10月 30 13:30 feed.php drwxr-xr-x 8 www-data www-data 4096 10月 30 13:35 .git/ -rw-r--r-- 1 www-data www-data 1744 10月 30 13:30 .htaccess.dist drwxr-xr-x 6 www-data www-data 4096 10月 30 13:30 inc/ -rw-r--r-- 1 www-data www-data 2097 10月 30 13:30 index.php drwxr-xr-x 8 www-data www-data 4096 10月 30 13:30 lib/ -rw-r--r-- 1 www-data www-data 306 10月 30 13:30 README drwxr-xr-x 8 www-data www-data 4096 10月 30 13:30 vendor/ -rw-r--r-- 1 www-data www-data 33 10月 30 13:30 VERSION 修改文件权限(否则可能因为权限问题导致访问失败)\nsudo chown -R www-data:www-data /var/www/wikihub 通过浏览器访问 http://localhost/install.php, 并按照页面给出的提示进行安装. 相关填写项描述如下\n维基名称：你wiki的名字，比如我的是wikihub 启用ACL（推荐）：即启用权限控制，这个保持默认（选中状态） 超级用户：输入超级用户的用户名 全名：超级用户的全名，和上一个一样就行 E-Mail：超级用户的电子邮件地址 密码：超级用户的密码 请再输一次：再次输入密码 初始的ACL政策：全局权限控制策略，在下拉列表中选择一个合适的 开放的维基（任何人都有读、写、上传的权限） 公开的维基（任何人都有读的权限，只有注册用户才有写和上传的权限） 关闭的维基（只有注册用户才有读、写、上传的权限） 填写完成后按 保存 完成安装. 为了安全, 最好删除目录下的 install.php 文件. 虽然 Dokuwiki 自身也有保护, install.php 已经不能再次运行, 不过还是以防万一吧.\n通过浏览器访问 http://localhost/dokuwiki.php, 就可以用之前注册的账户登陆进行 wiki 的撰写了.\n常用插件 vshare Plugin to easily embed videos from various video sharing sites into DokuWiki\n","date":"1 January, 1970","id":105,"permalink":"/posts/dokuwiki/","summary":"关于 Dokuwiki 详细信息, 请访问官网.","tags":"dokuwiki wiki","title":"dokuwiki"},{"content":"Flutter 学习笔记 Windows Flutter SDK 安装 Download the Flutter archive from your mirror site. In your preferred browser, go to Flutter SDK archive. https://docs.flutter.cn/release/archive?tab=windows\n20240726 当前最新版本： Flutter 版本： 3.22.3 Dart 版本：3.4.4 https://storage.flutter-io.cn/flutter_infra_release/releases/stable/windows/flutter_windows_3.22.3-stable.zip\n将 flutter_windows_3.22.3-stable.zip sdk 解压到任意位置(根据个人喜好放置)\n\u0026lt;path-to-flutter_windows_3.22.3-stable\u0026gt;\\flutter\n添加环境变量：\n\u0026lt;path-to-flutter_windows_3.22.3-stable\u0026gt;\\flutter\\bin 添加到环境变量 PATH\n验证安装是否成功 重新打开一个新的 Powershell 终端执行：flutter doctor 出现如下界面，说明SDK 安装成功\nPS C:\\Users\\max_h\u0026gt; flutter doctor Doctor summary (to see all details, run flutter doctor -v): [√] Flutter (Channel stable, 3.22.3, on Microsoft Windows [版本 10.0.22631.3880], locale zh-CN) [√] Windows Version (Installed version of Windows is version 10 or higher) [√] Android toolchain - develop for Android devices (Android SDK version 34.0.0) [√] Chrome - develop for the web [√] Visual Studio - develop Windows apps (Visual Studio Community 2022 17.9.6) [√] Android Studio (version 2024.1) [√] VS Code (version 1.87.2) [√] Connected device (3 available) [√] Network resources • No issues found! 配置国内镜像源 Tsinghua University TUNA Association maintains the mirrors.tuna.tsinghua.edu.cn mirror. It includes the Flutter SDK and pub packages.\nTo set your machine to use this mirror, use these commands.\nOn macOS, Linux, or ChromeOS:\nexport PUB_HOSTED_URL=https://mirrors.tuna.tsinghua.edu.cn/dart-pub; export FLUTTER_STORAGE_BASE_URL=https://mirrors.tuna.tsinghua.edu.cn/fluttercontent_copy On Windows:\n$env:PUB_HOSTED_URL=\u0026#34;https://mirrors.tuna.tsinghua.edu.cn/dart-pub\u0026#34;; $env:FLUTTER_STORAGE_BASE_URL=\u0026#34;https://mirrors.tuna.tsinghua.edu.cn/flutter\u0026#34; Using Flutter in China\nhttps://docs.flutter.dev/community/china\n","date":"1 January, 1970","id":106,"permalink":"/posts/flutter/","summary":"将 flutter_windows_3.22.3-stable.zip sdk 解压到任意位置(根据个人喜好放置)","tags":"flutter dart","title":"Flutter"},{"content":"Git 提供了以下两种方式来指定使用哪个 SSH Key 进行认证：\n使用 Git Config 命令 使用 git config 命令来配置 Git 的全局或本地参数。在这个命令中，可以使用 core.sshCommand 参数来指定使用哪个 SSH Key 进行认证。\n例如：\n# 全局范围内使用 SSH Key $ git config --global core.sshCommand \u0026#34;ssh -i ~/.ssh/my_private_key\u0026#34; # 仅对当前仓库使用 SSH Key $ git config core.sshCommand \u0026#34;ssh -i ~/.ssh/my_private_key\u0026#34; 上面的命令会告诉 Git，使用 ~/.ssh/my_private_key 文件作为 SSH 私钥进行认证。\n使用 Git Clone 命令 在使用 git clone 命令克隆项目时，可以通过 -c 或 --config 参数来指定使用哪个 SSH Key 进行认证。示例如下：\n$ git clone -c core.sshCommand=\u0026#34;ssh -i ~/.ssh/my_private_key\u0026#34; git@github.com:user/repo.git 上面的命令将会使用 -i ~/.ssh/my_private_key 指定的 SSH Key 进行认证。\ngit push 使用指定的ssh private key 在使用 Git 上传代码时，可以通过指定 ssh private key 来进行身份验证而非输入用户名和密码。\n打开终端（命令行），并进入到 Git 本地仓库所在目录。 输入以下命令来配置 Git 使用指定的 ssh private key：\n# 如果不执行该指令，ssh-add 可能会报错：Could not open a connection to your authentication agent. eval $(ssh-agent -s) # 其中 /path/to/private/key 替换成你的私钥文件路径。 ssh-add /path/to/private/key 确认已将 private key 加入 ssh-agent 后，在命令行中输入以下命令来测试连接： ssh -T git@github.com # 如果连接成功，则会显示如下信息：\u0026#34;Hi {your username}! You\u0026#39;ve successfully authenticated, but GitHub does not provide shell access.\u0026#34; 执行 Git Push 操作 git push origin master 注意事项 使用 SSH Key 进行认证时，私钥文件必须设置正确的权限（一般是 0600），否则会导致认证失败。\n","date":"1 January, 1970","id":107,"permalink":"/posts/git%E4%BD%BF%E7%94%A8%E6%8C%87%E5%AE%9A%E7%9A%84ssh_key/","summary":"Git 提供了以下两种方式来指定使用哪个 SSH Key 进行认证：","tags":"git ssh github","title":"git 使用指定的 ssh key"},{"content":"nvm node npm curl -o- https://raw.githubusercontent.com/creationix/nvm/v0.33.6/install.sh | bash source ~/.zshrc nvm install node npm config set registry https://registry.npm.taobao.org gitbook npm install gitbook-cli -g gitbook 常见命令 List installed versions:\ngitbook ls List available versions on NPM:\ngitbook ls-remote Install a specific version:\ngitbook fetch 2.1.0 # or a pre-release gitbook fetch beta Update to the latest version\ngitbook update Uninstall a specific version\ngitbook uninstall 2.0.1 使用 gitbook init gitbook serve (该命令首先会执行 gitbook build 编译书籍, 完成以后会打开一个 web 服务器, 监听在本地的 4000 端口) plugin 安装方法 在 git book 项目的根目录下执行\nnpm install \u0026lt;plugin_name\u0026gt; 常用 plugins 列表 gitbook-plugin-page-toc install this plugin npm install gitbook-plugin-page-toc add below code to book.json under the root dir of your git book repo { \u0026#34;plugins\u0026#34;: [ \u0026#34;page-toc\u0026#34; ], \u0026#34;pluginsConfig\u0026#34;: { } } gitbook-plugin-todo install this plugin npm install --save gitbook-plugin-todo add below code to book.json under the root dir of your git book repo { \u0026#34;plugins\u0026#34;: [\u0026#34;todo\u0026#34;] } gitbook-plugin-toggle-chapters install this plugin npm install gitbook-plugin-toggle-chapters add below code to book.json under the root dir of your git book repo { \u0026#34;plugins\u0026#34;: [\u0026#34;toggle-chapters\u0026#34;] } gitbook-plugin-youtubex install this plugin git clone https://github.com/ymcatar/gitbook-plugin-youtubex node_modules/gitbook-plugin-youtubex add below code to book.json under the root dir of your git book repo \u0026#34;plugins\u0026#34;: [\u0026#34;youtubex\u0026#34;] \u0026#34;pluginsConfig\u0026#34;: { \u0026#34;youtubex\u0026#34;: { \u0026#34;embedDescription\u0026#34;: { \u0026#34;en\u0026#34;: \u0026#34;Watch this video!\u0026#34;, \u0026#34;de\u0026#34;: \u0026#34;Eingebettetes video:\u0026#34; } } } jadu/gitbook-theme clone theme project git clone https://github.com/jadu/gitbook-theme.git cp -r gitbook-theme/assets node_modules/ add below code to book.json under the root dir of your git book repo \u0026#34;styles\u0026#34;:{ \u0026#34;website\u0026#34;: \u0026#34;assets/continuum/cxm.css\u0026#34; } 执行命令 gitbook install 生成 pdf epub 在gitbook中实现多级导航栏的支持 ","date":"1 January, 1970","id":108,"permalink":"/posts/gitbook/","summary":"List installed versions:","tags":"gitbook","title":"gitbook"},{"content":"MAX96724 MAX96724 相关资源 product overview MAX96724/F/R 英文数据手册 Rev.4 MAX96724/F/R Users Guide GMSL2 Channel Specification User Guide Rev 1 MAX96717F: CSI-2 to GMSL2 Serializer Data Sheet (Rev. 5) MAX96724 MAX9295D pipes and csi2 GMSL2 forward link and reverse link In GMSL2, the [[forward link]] transmits data from the serializer (e.g., a camera) to the deserializer (e.g., a display or processor), while the [[[reverse link]]] transmits data in the opposite direction, from the deserializer to the serializer.\nGMSL2 uses a full-duplex, bidirectional architecture, meaning both channels operate simultaneously.\nForward Channel Transmits video and other data from the serializer to the deserializer. Operates at a fixed data rate of either 3 Gbps or 6 Gbps.\nReverse Channel Transmits control signals, status information, and sometimes audio data from the deserializer to the serializer. Operates at a fixed data rate of 187.5 Mbps.\n如何确认 DEV_ID 0xD 如何配置并确认 GMSL mode 和 GMSL RX rate 0x6 0x10 0x11 0x18 如何确认 GMSL Link Lock Status 配置流程：\nmax96724fr-user-guide.pdf\ngmsl2-general-user-guide.pdf\n实际调试中，系统开机内核初始化 serdes 之后，通过脚本去修改 GMSL2 link rate 为 6G\n参考 gmsl2-general-user-guide.pdf 描述的流程：\n修改 serializer and deserializer 为 6G 对 seserializer 执行一次 GMSL link one-shot reset 即可 (我的实验中通过对 deser GMSL link 做了一次 one-shot reset，因此对 ser 或者 deser 其中之一做一次 GMSL Link one-shot reset 即可) gmsl2-general-user-guide.pdf 如何确认serializer 是否收到了mipi 数据以及 mipi 数据量是否超过了 GMSL 的带宽 https://www.analog.com/media/en/technical-documentation/data-sheets/max96717f.pdf\nMAX96717 有 1 个 pipe line: pipe Z, 其他 serdes 自行查看相应数据手册。 VID_TX Z 包含的寄存器就是关于 PIPE Z 的寄存器。\nBIT 7: PCLKDET 用于标识是否收到 mipi 数据，如果该位为 1，表示收到了 mipi 数据。\nBIT 5: OVERFLOW 用于标识 mipi 数据量是否超过了 GMSL 带宽，如果该位为 1，表示收到了 mipi 数据量超过了 GMSL 带宽。\n如果当前 GMSL 带宽配置为 3G 则可以尝试调试 GMSL 为 6G。 如果 GMSL 已经为 6G 就只能优化 mipi 带宽或调整方案。 e.g. MAX9295D 为例：\ni2ctransfer -y -f 0 w2@\u0026lt;slave address\u0026gt; 0x01 0x02 r1 i2ctransfer -y -f 0 w2@\u0026lt;slave address\u0026gt; 0x01 0x0A r1 i2ctransfer -y -f 0 w2@\u0026lt;slave address\u0026gt; 0x01 0x12 r1 i2ctransfer -y -f 0 w2@\u0026lt;slave address\u0026gt; 0x01 0x1A r1 没数据返回结果：0x0A 有数据返回结果：0x8A\n关于解串器别名摄像头 MAX96717 提供了两组别名寄存器，请注意这些寄存器 bit0 reserved\nreg description 0x42 SRC_A[6:0] 0x43 DST_A[6:0] 0x44 SRC_B[6:0] 0x45 DST_B[6:0] 注意： SRC \u0026mdash; ALIAS ADDR, DST \u0026mdash; ORIGIN ADDR\nWhen an 12c transaction across the GiISLlink has a device address ma!ching 1zcSRc A the dewce address as seen on theremote side is replaced by the deviceaddress in 12C DSTA\n# i2ctransfer -y -f 0 w2@0x44 0x00 0x42 r1 0xa8 = 0x54 \u0026lt;\u0026lt; 1 # i2ctransfer -y -f 0 w2@0x44 0x00 0x43 r1 0x52 = 0x29 \u0026lt;\u0026lt; 1 # i2ctransfer -y -f 0 w2@0x44 0x00 0x44 r1 0xaa = 0x55 \u0026lt;\u0026lt; 1 # i2ctransfer -y -f 0 w2@0x44 0x00 0x45 r1 0x50 = 0x28 \u0026lt;\u0026lt; 1 手动控制 SER MFP 对外输出高低电平 MAX96717 MFP ctrl register\n// MFP0 ~ MFP16 static uint16_t max96717_mfp_ctrl_regs[] = { 0x02BE, 0x02C1, 0x02C4, 0x02C7, 0x02CA, 0x02CD, 0x02D0, 0x02D3, 0x02D6, 0x02D9, 0x02DC, 0x02DF, 0x02E2, 0x02E5, 0x02E8, 0x02EB, 0x2EE}; 输出低电平，value 设置为 0x80\n输出高电平，value 设置为 0x90\nserializer device i2c address （如果已经别名请使用alias i2c address）\n命令格式：\ni2ctransfer -y -f \u0026lt;i2c_bus\u0026gt; w3@\u0026lt;i2c_addr\u0026gt; \u0026lt;reg_high_8bit\u0026gt; \u0026lt;reg_low_8bit\u0026gt; \u0026lt;value\u0026gt; 假设 i2c bus 0, i2c alias address 0x44，MFP6, MFP7 输出低电平\ni2ctransfer -y -f 0 w3@0x44 0x02 0xD0 0x80 i2ctransfer -y -f 0 w3@0x44 0x02 0xD3 0x80 假设 i2c bus 0, i2c alias address 0x44，MFP6, MFP7 输出高电平\ni2ctransfer -y -f 0 w3@0x44 0x02 0xD0 0x90 i2ctransfer -y -f 0 w3@0x44 0x02 0xD3 0x90 MAX96724 MAX96717 I2C 速率配置 Fast-mode Plus\n#!/bin/bash # DES i2ctransfer -y -f 0 w3@0x05 0x06 0x40 0x06 i2ctransfer -y -f 0 w3@0x05 0x06 0x41 0x76 # SER i2ctransfer -y -f 0 w3@0x44 0x00 0x40 0x06 i2ctransfer -y -f 0 w3@0x44 0x00 0x41 0x76 MAX96724 ![[Pasted image 20240827225310.png]] ![[Pasted image 20240827225321.png]] ![[Pasted image 20240827225333.png]]\nMAX96717 ![[Pasted image 20240827225457.png]] ![[Pasted image 20240827225505.png]] ![[Pasted image 20240827225513.png]]\n关于 GMSL2 Soft DataType definition 像素格式代码 描述 0x10 GENERIC8 0x11 GENERIC8 0x12 EMBEDDED 0x1E YUV422 8-bit 0x1F YUV422 10-bit 0x22 RGB565 0x23 RGB666 0x24 RGB888 0x2A RAW8 0x2B RAW10 0x2C RAW12 0x2D RAW14 0x2E RAW16 0x2F RAW20 0x30 YUV422 12-bit 0x31 UDP8 0x32 UDP8 0x33 UDP8 0x34 UDP8 0x35 UDP8 0x36 UDP8 0x37 UDP8 ","date":"1 January, 1970","id":109,"permalink":"/posts/adi_serdes/","summary":"In GMSL2, the [[forward link]] transmits data from the serializer (e.g., a camera) to the deserializer (e.g., a display or processor), while the [[[reverse link]]] transmits data in the opposite direction, from the deserializer to the serializer.","tags":"ADI MAXIM SERDES GMSL MIPI","title":"GMSL SERDES 笔记"},{"content":"HPM OpenHarmony HPM 指的是 “Harmony Package Manager”\nHPM Part Module level HPM Part：用于实现模块或 Part 的复用。分发的内容可以是源码或二进制文件。通常，这样的 HPM Part 对应着一个代码仓库，是代码仓库的一个版本。\nDistribution-level HPM Part：用于描述操作系统发行版。它由一系列依赖部件和用于构建发行版的脚本组成。该发行版包含完整操作系统的各种组件（如驱动程序、内核、框架和应用程序）。构建后生成的镜像可用于烧录。\nHPM Part 由两种类型的文件组成：描述文件和内容文件。\n图 1 部件/模块级 HPM 部件与分布级 HPM 部件之间的关系\nOpenHarmony Package Manager （HPM） 是一个连接 consumers 和 providers 的开放式协作平台。HPM 部件是由 HPM 管理的对象。\n通过 HPM 平台，提供商可以发布 HPM Parts，消费者可以下载和使用 HPM Parts。\nProviders 声明 HPM 部件的属性并将其发布到平台。 Consumer 在指定版本的 HPM Part 中声明依赖，获取所需的资源。 HPM 包括以下内容 hpm-cli：@ohos/hpm-cli 发布的跨平台命令行工具 hpm-cli 工具提供了一系列用于创建、构建、安装、打包、运行和发布 HPM 部件的命令。您可以使用这些命令来管理 HPM 部件的生命周期。\nDevEco Marketplace：服务器上的资源仓库 在 DevEco Marketplace 上，您可以按类别注册、存储和搜索 HPM Part。每个 HPM Part 都有一个页面，可以访问其自述文件、依赖项、历史版本、更改历史记录、许可证、下载量和源代码存储库地址。您可以将 HPM Parts 发布到此资源存储库。\n","date":"1 January, 1970","id":110,"permalink":"/posts/harmony-hpm-%E5%8C%85%E7%AE%A1%E7%90%86%E5%99%A8/","summary":"OpenHarmony HPM 指的是 “Harmony Package Manager”","tags":"OpenHarmony","title":"Harmony HPM 包管理器"},{"content":"hugo\ntheme: next\ninstall hugo create a new site hugo new site \u0026lt;sitename\u0026gt; add theme Usage of next theme download theme file: git clone https://github.com/xtfly/hugo-theme-next.git next copy next directory to themes directory in your hugo site move config.toml to the root directory in your hugo site, and modify it to the actual information for your site. create some markdown files in directory(content/post), like https://github.com/xtfly/xtfly.github.io/tree/hugo/content start hugo server in root directory: hugo server open browser: http://localhost:1313/ start server hugo server --bind 0.0.0.0 --baseURL http://10.0.0.7:1313 框架 [blog]$ ls archetypes config.toml content data layouts public resources static themes 博客内容 将你写的博客内容markdown文档所在目录链接到 content 目录，链接文件命名为 post 将你的about目录链接到 content 目录，链接文件名为 about [blog]$ tree content/ content/ ├── about -\u0026gt; /home/lv/post/about └── post -\u0026gt; /home/lv/post 博客发布 将博客发布内容路径链接为 hugo 的根目录， 链接文件命名为 public\nhugo markdown 插入图片 e.g.\n图片名字：nescafe.png hugo 工程 content/post/hello.md content/post/ 目录下创建 markdown 文档同名文件夹 hello 将图片 nescafe.png 放入 content/post/hello/ 目录下 markdown 文件 hello.md 中引用方法：![](nescafe.png) Q\u0026amp;A https://discourse.gohugo.io/t/binding-server-to-local-ip-or-0-0-0-0-does-not-work/18999 https://wefox.me/docs/create_blog_on_github_by_hugo/ ","date":"1 January, 1970","id":111,"permalink":"/posts/hugo/","summary":"hugo","tags":"hugo blog","title":"hugo"},{"content":"100BASE-TX\niPerf- The ultimate speed test tool for TCP, UDP and SCTP\nTest the limits of your network + Internet neutrality test 编译安装 iperf windows 端直接下载二进制文件\niPerf 3.1.3 (8 jun 2016 - 1.3 MiB for Windows Vista 64bits to Windows 10 64bits) 嵌入式平台需要从源码[[交叉编译]]安装\niPerf C++ source |iPerf 3.1.3|8 jun 2016|537 KiB| 交叉编译安装 export PATH=\u0026#34;/code/gcc-linaro-7.5.0-2019.12-x86_64_armlinux-gnueabihf/bin\u0026#34;:$PATH export CROSS_COMPILE=arm-linux-gnueabihf- mkdir build_out; cd build_out ../configure --prefix=/code/glibc-2.35/build_out \\ --host=arm-linux-gnueabihf make make install 测试 嵌入式客户端 root@nxp:/# iperf3 -c 192.168.3.229 -i 10 -t 60 -u -b 1000M -A 2 Connecting to host 192.168.3.229, port 5201 [ 4] local 192.168.3.250 port 42474 connected to 192.168.3.229 port 5201 [ ID] Interval Transfer Bandwidth Total Datagrams [ 4] 0.00-10.00 sec 1.12 GBytes 958 Mbits/sec 146184 [ 4] 10.00-20.00 sec 1.12 GBytes 958 Mbits/sec 146232 [ 4] 20.00-30.00 sec 1.12 GBytes 958 Mbits/sec 146205 [ 4] 30.00-40.00 sec 1.12 GBytes 958 Mbits/sec 146232 [ 4] 40.00-50.00 sec 1.12 GBytes 958 Mbits/sec 146232 [ 4] 50.00-60.00 sec 1.12 GBytes 958 Mbits/sec 146235 - - - - - - - - - - - - - - - - - - - - - - - - - [ ID] Interval Transfer Bandwidth Jitter Lost/Total Datagrams [ 4] 0.00-60.00 sec 6.69 GBytes 958 Mbits/sec 637732049.574 ms 389951/389962 (1e+02%) [ 4] Sent 389962 datagrams iperf Done. 测试概要：\n测试工具： iperf3 测试时间： 60 秒 客户端 IP： 192.168.3.250 服务器 IP： 192.168.3.229 带宽测试结果：\n传输量（Transfer）： 在测试期间共传输了 6.69 GBytes 的数据。 带宽（Bandwidth）： 平均带宽约为 958 Mbits/秒。 抖动（Jitter）： 抖动非常高，平均达到了 637,732,049.574 毫秒。 丢包率（Lost/Total Datagrams）： 共丢失了 389,951 个数据包中的 389,951 个（丢包率达到了 100%）。 测试详细信息：\n带宽测试开始后，平均带宽稳定在约 958 Mbits/秒。 抖动（Jitter）非常高，每个测试间隔都显示非常大的抖动值，可能表明网络连接不稳定。 丢包率达到了 100%，所有的数据包都丢失了，这也是网络连接不稳定的表现。 结论：\n根据测试结果，可以得出以下结论：\n测试中的带宽表现良好，平均带宽约为 958 Mbits/秒，这表示在某些方面网络连接是高速的。 高抖动值表明网络连接不稳定，导致数据包传输的不一致性。 丢包率达到了 100%，所有的数据包都丢失了，这也是网络连接不稳定的表现。 建议进一步分析和排除网络问题，以改善网络性能和稳定性。网络连接的高带宽潜力可能受到抖动和丢包的影响，因此优化网络连接以减少这些问题可能会提高性能。在执行网络性能测试时，低抖动和低丢包率通常是期望的结果，可以提供更稳定和高速的网络连接。\nwindows server PS C:\\Users\\vc++6.0\\Downloads\\iperf-3.1.3-win64\\iperf-3.1.3-win64\u0026gt; .\\iperf3.exe -s ----------------------------------------------------------- Server listening on 5201 ----------------------------------------------------------- Accepted connection from 192.168.3.250, port 60790 [ 5] local 192.168.3.229 port 5201 connected to 192.168.3.250 port 55010 [ ID] Interval Transfer Bandwidth Jitter Lost/Total Datagrams [ 5] 0.00-1.01 sec 184 KBytes 1.49 Mbits/sec 301187251.198 ms 0/23 (0%) [ 5] 1.01-2.01 sec 0.00 Bytes 0.00 bits/sec 301187251.198 ms 0/0 (0%) [ 5] 2.01-3.01 sec 0.00 Bytes 0.00 bits/sec 301187251.198 ms 0/0 (0%) [ 5] 3.01-4.00 sec 0.00 Bytes 0.00 bits/sec 301187251.198 ms 0/0 (0%) [ 5] 4.00-5.01 sec 0.00 Bytes 0.00 bits/sec 301187251.198 ms 0/0 (0%) [ 5] 5.01-6.00 sec 0.00 Bytes 0.00 bits/sec 301187251.198 ms 0/0 (0%) [ 5] 6.00-7.00 sec 0.00 Bytes 0.00 bits/sec 301187251.198 ms 0/0 (0%) [ 5] 7.00-8.00 sec 0.00 Bytes 0.00 bits/sec 301187251.198 ms 0/0 (0%) [ 5] 8.00-9.00 sec 0.00 Bytes 0.00 bits/sec 301187251.198 ms 0/0 (0%) [ 5] 9.00-10.01 sec 0.00 Bytes 0.00 bits/sec 301187251.198 ms 0/0 (0%) [ 5] 10.01-11.01 sec 0.00 Bytes 0.00 bits/sec 301187251.198 ms 0/0 (0%) [ 5] 11.01-12.00 sec 0.00 Bytes 0.00 bits/sec 301187251.198 ms 0/0 (0%) [ 5] 12.00-13.00 sec 0.00 Bytes 0.00 bits/sec 301187251.198 ms 0/0 (0%) [ 5] 13.00-14.00 sec 0.00 Bytes 0.00 bits/sec 301187251.198 ms 0/0 (0%) [ 5] 14.00-15.00 sec 0.00 Bytes 0.00 bits/sec 301187251.198 ms 0/0 (0%) [ 5] 15.00-16.00 sec 0.00 Bytes 0.00 bits/sec 301187251.198 ms 0/0 (0%) [ 5] 16.00-17.01 sec 0.00 Bytes 0.00 bits/sec 301187251.198 ms 0/0 (0%) [ 5] 17.01-18.00 sec 0.00 Bytes 0.00 bits/sec 301187251.198 ms 0/0 (0%) [ 5] 18.00-19.00 sec 120 KBytes 986 Kbits/sec 114394655.053 ms 274384/274399 (1e+02%) [ 5] 19.00-20.00 sec 0.00 Bytes 0.00 bits/sec 114394655.053 ms 0/0 (0%) [ 5] 20.00-21.00 sec 0.00 Bytes 0.00 bits/sec 114394655.053 ms 0/0 (0%) [ 5] 21.00-22.00 sec 0.00 Bytes 0.00 bits/sec 114394655.053 ms 0/0 (0%) [ 5] 22.00-23.01 sec 0.00 Bytes 0.00 bits/sec 114394655.053 ms 0/0 (0%) [ 5] 23.01-24.01 sec 0.00 Bytes 0.00 bits/sec 114394655.053 ms 0/0 (0%) [ 5] 24.01-25.00 sec 0.00 Bytes 0.00 bits/sec 114394655.053 ms 0/0 (0%) [ 5] 25.00-26.01 sec 0.00 Bytes 0.00 bits/sec 114394655.053 ms 0/0 (0%) [ 5] 26.01-27.01 sec 0.00 Bytes 0.00 bits/sec 114394655.053 ms 0/0 (0%) [ 5] 27.01-28.01 sec 0.00 Bytes 0.00 bits/sec 114394655.053 ms 0/0 (0%) [ 5] 28.01-29.01 sec 128 KBytes 1.05 Mbits/sec 40732978.068 ms 146944/146960 (1e+02%) [ 5] 29.01-30.01 sec 0.00 Bytes 0.00 bits/sec 40732978.068 ms 0/0 (0%) [ 5] 30.01-31.01 sec 0.00 Bytes 0.00 bits/sec 40732978.068 ms 0/0 (0%) [ 5] 31.01-32.00 sec 0.00 Bytes 0.00 bits/sec 40732978.068 ms 0/0 (0%) [ 5] 32.00-33.00 sec 0.00 Bytes 0.00 bits/sec 40732978.068 ms 0/0 (0%) [ 5] 33.00-34.00 sec 0.00 Bytes 0.00 bits/sec 40732978.068 ms 0/0 (0%) [ 5] 33.00-34.00 sec 0.00 Bytes 0.00 bits/sec 40732978.068 ms 0/0 (0%) - - - - - - - - - - - - - - - - - - - - - - - - - [ ID] Interval Transfer Bandwidth Jitter Lost/Total Datagrams [ 5] 0.00-34.00 sec 0.00 Bytes 0.00 bits/sec 40732978.068 ms 421328/421382 (1e+02%) 测试概要：\n测试工具： iperf3 测试时间： 34 秒 服务器 IP： 192.168.3.229 客户端 IP： 192.168.3.250 带宽测试结果：\n传输量（Transfer）： 在测试期间共传输了 184 KBytes 的数据。 带宽（Bandwidth）： 平均带宽约为 1.49 Mbits/秒。 抖动（Jitter）： 抖动非常高，平均达到了 301,187,251.198 毫秒。 丢包率（Lost/Total Datagrams）： 共丢失了 421,328 个数据包中的 421,328 个（丢包率达到了 100%）。 测试详细信息：\n测试开始后，带宽在测试的前几秒内表现得非常低，平均带宽只有 1.49 Mbits/秒。 抖动（Jitter）非常高，每个测试间隔都显示非常大的抖动值，可能表明网络连接不稳定。 在测试的中间阶段，带宽测试结果显示了一些数据包的传输，但仍然非常低。 在测试的最后，带宽略有增加，但仍然很低，且丢包率高达 100%。 结论：\n根据测试结果，可以得出以下结论：\n测试中的带宽非常低，平均值约为 1.49 Mbits/秒，这可能表明存在网络性能问题。 高抖动值表明网络连接不稳定，导致数据包传输的不一致性。 丢包率达到了 100%，所有的数据包都丢失了，这也是网络连接不稳定的表现。 建议进一步分析和排除网络问题，以改善网络性能和稳定性。这可以包括检查网络硬件、减少网络拥塞、优化网络配置等措施。在执行网络性能测试时，低抖动和低丢包率通常是期望的结果，可以提供更稳定和高速的网络连接。\n","date":"1 January, 1970","id":112,"permalink":"/posts/iperf-%E6%B5%8B%E8%AF%95%E7%BD%91%E7%BB%9C%E5%B8%A6%E5%AE%BD/","summary":"100BASE-TX","tags":"iperf network BandWidth","title":"iperf 测试网络带宽"},{"content":"关键命令 # 清空文件系统缓存, 测试读写命令之前需要执行该命令 sudo sh -c \u0026#34;sync \u0026amp;\u0026amp; echo 3 \u0026gt; /proc/sys/vm/drop_caches\u0026#34; # dd 写入速度测试 dd if=/dev/zero of=./test_write count=200 bs=1024k # dd 读取速度测试 dd if=./test_write of=/dev/null bs=1024k 测试脚本 #!/bin/bash # 检查是否提供了足够的参数 if [ $# -lt 1 ]; then echo \u0026#34;Usage: $0 test_count\u0026#34; exit 1 fi # ANSI颜色码 green_color=\u0026#34;\\e[32m\u0026#34; # 绿色 red_color=\u0026#34;\\e[31m\u0026#34; # 红色 reset_color=\u0026#34;\\e[0m\u0026#34; # 重置颜色 total_iterations=$1 # 初始化计数器 write_success_count=0 write_failure_count=0 read_success_count=0 read_failure_count=0 echo \u0026#34;Total number of iterations: $total_iterations\u0026#34; for ((i=1; i\u0026lt;=$total_iterations; i++)); do # 清空文件系统缓存 sudo sh -c \u0026#34;sync \u0026amp;\u0026amp; echo 3 \u0026gt; /proc/sys/vm/drop_caches\u0026#34; # 执行dd写入测试 if dd if=/dev/zero of=./test_write count=200 bs=1024k 2\u0026gt;\u0026amp;1 | grep -q \u0026#34;records in\u0026#34;; then write_speed=$(dd if=./test_write of=/dev/null bs=1024k 2\u0026gt;\u0026amp;1 | awk \u0026#39;/copied/ {print $(NF-1), $NF}\u0026#39;) echo \u0026#34;write speed: $write_speed\u0026#34; ((write_success_count++)) else echo \u0026#34;write failed\u0026#34; ((write_failure_count++)) fi # 再次清空文件系统缓存 sudo sh -c \u0026#34;sync \u0026amp;\u0026amp; echo 3 \u0026gt; /proc/sys/vm/drop_caches\u0026#34; # 执行dd读取测试 if dd if=./test_write of=/dev/null bs=1024k 2\u0026gt;\u0026amp;1 | grep -q \u0026#34;records in\u0026#34;; then read_speed=$(dd if=./test_write of=/dev/null bs=1024k 2\u0026gt;\u0026amp;1 | awk \u0026#39;/copied/ {print $(NF-1), $NF}\u0026#39;) echo \u0026#34;read speed: $read_speed\u0026#34; ((read_success_count++)) else echo \u0026#34;read failed\u0026#34; ((read_failed_count++)) fi echo \u0026#34;----------------\u0026#34; done # 输出总的测试次数、成功次数和失败次数 echo \u0026#34;Total number of tests: $total_iterations\u0026#34; echo -e \u0026#34;${green_color}Number of write successful tests: $write_success_count${reset_color}\u0026#34; echo -e \u0026#34;${green_color}Number of read successful tests: $read_success_count${reset_color}\u0026#34; echo -e \u0026#34;${red_color}Number of write failed tests: $write_failure_count${reset_color}\u0026#34; echo -e \u0026#34;${red_color}Number of read failed tests: $read_failure_count${reset_color}\u0026#34; ","date":"1 January, 1970","id":113,"permalink":"/posts/linux_test_disk_i_o_with_dd/","summary":"","tags":"linux dd disk performance","title":"Linux Test Disk with dd command"},{"content":"系统基本信息 [baihao@vstation ~]$ screenfetch ██████████████████ ████████ baihao@vstation ██████████████████ ████████ OS: Manjaro 20.2.1 Nibia ██████████████████ ████████ Kernel: x86_64 Linux 5.9.16-1-MANJARO ██████████████████ ████████ Uptime: 17m ████████ ████████ Packages: 1220 ████████ ████████ ████████ Shell: bash 5.1.0 ████████ ████████ ████████ Resolution: 1920x951 ████████ ████████ ████████ DE: Xfce4 ████████ ████████ ████████ WM: Xfwm4 ████████ ████████ ████████ WM Theme: Matcha-sea ████████ ████████ ████████ GTK Theme: Matcha-sea [GTK2] ████████ ████████ ████████ Icon Theme: Papirus-Maia ████████ ████████ ████████ Font: Noto Sans 10 ████████ ████████ ████████ Disk: 241G / 674G (37%) CPU: Intel Core i7-10510U @ 2x 2.304GHz GPU: llvmpipe (LLVM 11.0.0, 256 bits) RAM: 2134MiB / 3935MiB wps + fcitx5 无法输入中文 参考\n在wps中使用fcitx5 WPS for Linux 无法使用fcitx中文输入法问题的解决方案 修改如下：\n[baihao@vstation ~]$ head /usr/bin/wps #!/bin/bash gOpt= +export GTK_IM_MODULE=fcitx +export QT_IM_MODULE=fcitx5 +export XMODIFIERS=@im=fcitx #gOptExt=-multiply [baihao@vstation ~]$ head /usr/bin/et #!/bin/bash gOpt= +export GTK_IM_MODULE=fcitx +export QT_IM_MODULE=fcitx5 +export XMODIFIERS=@im=fcitx #gOptExt=-multiply gTemplateExt=(\u0026#34;ett\u0026#34; \u0026#34;xlt\u0026#34; \u0026#34;xltx\u0026#34; \u0026#34;xltm\u0026#34;) [baihao@vstation ~]$ head /usr/bin/wpp #!/bin/bash gOpt= +export GTK_IM_MODULE=fcitx +export QT_IM_MODULE=fcitx5 +export XMODIFIERS=@im=fcitx #gOptExt=-multiply gTemplateExt=(\u0026#34;dpt\u0026#34; \u0026#34;pot\u0026#34; \u0026#34;potx\u0026#34; \u0026#34;potm\u0026#34;) ","date":"1 January, 1970","id":114,"permalink":"/posts/manjaro/","summary":"参考","tags":"manjaro","title":"manjaro"},{"content":"I2C 总线规范\nMPQ8873\n电源芯片：MPQ8873\n36V、3A 连续输出电流、全温、4 开关、同步升降压变换器、符合 AEC-Q100 认证\nroot@a1000:/# i2cdetect -y -r 1 0 1 2 3 4 5 6 7 8 9 a b c d e f 00: -- -- -- -- -- -- -- -- -- -- -- -- -- 10: -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- 20: -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- 30: -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- 40: -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- 50: -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- 60: -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- 70: -- -- -- -- -- -- -- -- 开机后扫描不到 i2c 地址\n查看芯片手册没有说明默认 I2C 地址。\n增加 -a 选项就可以看到了\nroot@a1000:/userdata# i2cdetect -y -a -r 1 0 1 2 3 4 5 6 7 8 9 a b c d e f 00: -- 01 -- -- -- -- -- -- -- -- -- -- -- -- -- -- 10: -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- 20: -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- 30: -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- 40: -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- 50: -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- 60: -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- 70: -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- Chip Address The MPQ8873 supports 16 different addresses from 00h to 0Fh, which can be preset in register 08h via the I 2C bus. When the master sends the address as an 8-bit value, the 7-bit address should be followed by a 0 or 1 to indicate a write or read operation, respectively. Figure 24 shows a write sequence, and Figure 25 shows a read sequence.\nroot@a1000:/userdata# i2cget -y -a -f 1 0x01 0x08 0x11 root@a1000:/userdata# i2cset -y -a -f 1 0x01 0x08 0xa1 root@a1000:/userdata# i2cdetect -y -a -r 1 0 1 2 3 4 5 6 7 8 9 a b c d e f 00: -- -- -- -- -- -- -- -- -- -- 0a -- -- -- -- -- 10: -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- 20: -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- 30: -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- 40: -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- 50: -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- 60: -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- 70: -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- root@a1000:/userdata# i2cget -y -a -f 1 0x0a 0x08 0xa1 root@a1000:/userdata# i2cget -y -a -f 1 0x0a 0x00 0x78 root@a1000:/userdata# i2cget -y -a -f 1 0x0a 0x01 0x9c root@a1000:/userdata# i2cset -y -a -f 1 0x0a 0x00 0x55 输出电压实测 8.5V\n","date":"1 January, 1970","id":115,"permalink":"/posts/mpq8873%E8%BE%93%E5%87%BA%E7%94%B5%E5%8E%8B%E8%B0%83%E8%8A%82/","summary":"I2C 总线规范","tags":"I2C MPQ8873 PMIC 电源","title":"MPQ8873 输出电压调节"},{"content":"nlohmann json Modern C++ JSON lib 摘要 本文档全面介绍了 nlohmann/json，一个广受欢迎的现代C++ JSON库。我们将从其起源与发展入手，探讨其在C++生态系统中的地位，并与其他主流C++ JSON库进行比较。随后，深入剖析 nlohmann/json 的架构与设计哲学，揭示其简洁易用的特点。最后，文档将详细阐述 nlohmann/json 在C++项目中的具体应用，包括安装、基本语法、核心API以及高级用法，旨在为C++开发者提供一份权威、实用的参考指南。\n关键词: C++, JSON, nlohmann/json, 数据序列化, 反序列化, 开源库\n1. nlohmann/json 简介 1.1 nlohmann的起源与发展 nlohmann/json 库由Niels Lohmann于2013年启动开发，其设计初衷是为C++提供一个现代、直观且功能完备的JSON处理解决方案。在JSON成为Web应用和数据交换事实标准的背景下，C++社区对一个易于使用且性能良好的JSON库的需求日益增长。早期的C++ JSON库往往存在API复杂、学习曲线陡峭或依赖外部库过多的问题。nlohmann/json 的出现，以其仅头文件、无需编译、API设计与标准库容器（如 std::vector 和 std::map）高度契合的特点，迅速获得了C++开发者的青睐。\n自发布以来，nlohmann/json 持续迭代，不断完善功能、提升性能并修复潜在问题。它在GitHub上拥有庞大的社区支持和活跃的开发，已成为C++生态系统中处理JSON数据的首选库之一，广泛应用于各种项目，包括嵌入式系统、高性能服务器、桌面应用等。\n1.2 与其他C++ JSON库的比较 C++社区拥有多种JSON处理库，各有优劣。下表对 nlohmann/json 与其他几个主流C++ JSON库进行了比较：\n特性/库 nlohmann/json RapidJSON Boost.PropertyTree jsoncpp API设计 直观，类似STL容器操作 DOM/SAX，性能导向 树形结构，通用数据 DOM，传统C++风格 易用性 极高，学习曲线平缓 中等，需要理解DOM/SAX模型 中等，需要理解属性树概念 中等，较为传统 性能 良好，满足大多数应用 极高，注重解析和序列化速度 中等，通用性带来的开销 中等 依赖 仅头文件，无外部依赖 仅头文件，无外部依赖 Boost库，依赖较重 需编译，无外部依赖 功能完备性 完备，支持各种JSON操作 完备，支持各种JSON操作 完备，但JSON仅是其一种格式 完备 内存效率 良好，但可能不如RapidJSON极致 极高，池分配器优化 中等 中等 编译时间 快速（仅头文件） 快速（仅头文件） 较慢（Boost库） 较慢（需编译） 总结:\nnlohmann/json: 适用于追求开发效率、代码简洁性和易用性的项目。其API设计哲学使得C++开发者能够以自然的方式操作JSON数据。 RapidJSON: 适用于对性能有极致要求的场景，如大数据处理、高并发服务器等。但其API相对底层，学习成本较高。 Boost.PropertyTree: 提供更通用的树状数据结构处理能力，JSON只是其支持的一种序列化格式。适用于需要处理多种配置或数据格式的复杂系统。 jsoncpp: 一个成熟但相对传统的C++ JSON库，其API风格可能不如 nlohmann/json 现代和直观。 1.3 nlohmann的架构与设计理念 nlohmann/json 的核心设计理念是**“像使用标准库容器一样使用JSON”**。它通过重载运算符和提供类似STL的接口，使得JSON对象的创建、访问和修改变得异常直观。\n其架构主要基于一个 basic_json 模板类，该类可以根据需要进行特化，以支持不同类型和自定义的分配器。默认的 json 类型是 basic_json\u0026lt;std::map, std::vector, std::string, bool, int64_t, uint64_t, double, std::allocator\u0026gt; 的别名，它代表了JSON数据模型中的六种基本类型：null、布尔值、数字（整数和浮点数）、字符串、数组和对象。\n设计原则:\n仅头文件 (Header-Only): nlohmann/json 仅由一个头文件 (json.hpp) 组成，无需编译即可直接包含到项目中，极大地简化了集成过程。 强类型安全 (Strong Type Safety): 尽管JSON本身是无模式的，但 nlohmann/json 在运行时提供了类型检查机制。尝试以错误类型访问JSON值会抛出异常，有助于在开发阶段发现问题。 直观的API: 借鉴C++标准库的设计思想，通过重载 operator[]、operator=、push_back 等，使得JSON操作与C++容器操作保持一致性。 异常安全 (Exception Safety): 库在发生错误时（如类型不匹配、键不存在等）会抛出 json::exception 或其派生类，允许开发者使用 try-catch 机制进行错误处理。 透明的序列化/反序列化 (Transparent Serialization/Deserialization): 通过集成 operator\u0026lt;\u0026lt; 和 operator\u0026gt;\u0026gt;，使得JSON数据的I/O操作与C++流操作无缝衔接。 支持自定义类型 (Support for Custom Types): 提供了 to_json 和 from_json 机制，允许开发者轻松地将自定义C++对象序列化为JSON，以及将JSON反序列化为自定义对象。 C++11及更高版本兼容: 充分利用C++11及后续标准的新特性，如右值引用、auto 关键字、列表初始化等，使得代码更加现代和高效。 2. nlohmann在C++中的应用 2.1 nlohmann的安装与引用 由于 nlohmann/json 是一个仅头文件的库，其安装和引用过程非常简单。\n2.1.1 安装 手动下载 直接从GitHub仓库下载最新的 json.hpp 文件：https://github.com/nlohmann/json/releases\n将其放置在您的C++项目可以找到的某个包含路径下。\nCMake 如果您的项目使用CMake，可以通过 FetchContent 或 add_subdirectory 来集成。\n使用 FetchContent (推荐):\ninclude(FetchContent) FetchContent_Declare( nlohmann_json GIT_REPOSITORY https://github.com/nlohmann/json.git GIT_TAG v3.11.2 # 或其他最新版本 ) FetchContent_MakeAvailable(nlohmann_json) # 在您的目标中链接 target_link_libraries(YourProject PRIVATE nlohmann_json::nlohmann_json) 包管理器 Conan: 在 conanfile.txt 或 conanfile.py 中添加 nlohmann_json/x.y.z。 vcpkg: vcpkg install nlohmann-json Homebrew (macOS/Linux): brew install nlohmann-json 2.1.2 引用 在C++源文件中，只需简单地包含 json.hpp 头文件即可：\n#include \u0026lt;iostream\u0026gt; #include \u0026#34;json.hpp\u0026#34; // 如果json.hpp在项目根目录或指定包含路径下 // 或者 #include \u0026lt;nlohmann/json.hpp\u0026gt; 如果通过CMake或包管理器安装 为了方便使用 nlohmann::json 类型，通常会使用 using 声明：\nusing json = nlohmann::json; 2.2 基本语法 nlohmann/json 提供了与C++标准库容器相似的直观API，使得JSON数据的操作变得非常自然。\n2.2.1 JSON对象的创建与初始化\n#include \u0026lt;iostream\u0026gt; #include \u0026#34;json.hpp\u0026#34; using json = nlohmann::json; int main() { // 1. 空JSON对象 json j_empty_object = json::object(); json j_empty_object_alt = {}; // 使用列表初始化创建空对象 // 2. 空JSON数组 json j_empty_array = json::array(); json j_empty_array_alt = json::parse(\u0026#34;[]\u0026#34;); // 从字符串解析空数组 // 3. 直接初始化JSON对象 json j_object = { {\u0026#34;name\u0026#34;, \u0026#34;Alice\u0026#34;}, {\u0026#34;age\u0026#34;, 30}, {\u0026#34;isStudent\u0026#34;, false}, {\u0026#34;courses\u0026#34;, {\u0026#34;Math\u0026#34;, \u0026#34;Physics\u0026#34;, \u0026#34;Chemistry\u0026#34;}}, {\u0026#34;address\u0026#34;, { {\u0026#34;street\u0026#34;, \u0026#34;123 Main St\u0026#34;}, {\u0026#34;city\u0026#34;, \u0026#34;Anytown\u0026#34;} }} }; std::cout \u0026lt;\u0026lt; \u0026#34;Initialized JSON Object:\\n\u0026#34; \u0026lt;\u0026lt; j_object.dump(4) \u0026lt;\u0026lt; std::endl; // 4. 直接初始化JSON数组 json j_array = {\u0026#34;apple\u0026#34;, 123, true, 3.14, nullptr}; std::cout \u0026lt;\u0026lt; \u0026#34;\\nInitialized JSON Array:\\n\u0026#34; \u0026lt;\u0026lt; j_array.dump(4) \u0026lt;\u0026lt; std::endl; return 0; } 2.2.2 访问JSON元素\n通过键名访问 (对象): 使用 operator[] 或 at()。at() 在键不存在时会抛出异常，而 operator[] 会创建新键。 通过索引访问 (数组): 使用 operator[] 或 at()。 类型检查: is_string(), is_number(), is_boolean(), is_array(), is_object(), is_null()。 类型转换: 使用 get\u0026lt;T\u0026gt;() 或隐式转换。 #include \u0026lt;iostream\u0026gt; #include \u0026#34;json.hpp\u0026#34; using json = nlohmann::json; int main() { json data = { {\u0026#34;name\u0026#34;, \u0026#34;Bob\u0026#34;}, {\u0026#34;age\u0026#34;, 25}, {\u0026#34;city\u0026#34;, \u0026#34;New York\u0026#34;}, {\u0026#34;interests\u0026#34;, {\u0026#34;coding\u0026#34;, \u0026#34;reading\u0026#34;, \u0026#34;hiking\u0026#34;}}, {\u0026#34;details\u0026#34;, { {\u0026#34;is_active\u0026#34;, true}, {\u0026#34;member_since\u0026#34;, 2020} }}, {\u0026#34;null_value\u0026#34;, nullptr} }; // 访问对象元素 std::cout \u0026lt;\u0026lt; \u0026#34;Name: \u0026#34; \u0026lt;\u0026lt; data[\u0026#34;name\u0026#34;] \u0026lt;\u0026lt; std::endl; // Bob std::cout \u0026lt;\u0026lt; \u0026#34;Age: \u0026#34; \u0026lt;\u0026lt; data.at(\u0026#34;age\u0026#34;) \u0026lt;\u0026lt; std::endl; // 25 // 访问数组元素 std::cout \u0026lt;\u0026lt; \u0026#34;First interest: \u0026#34; \u0026lt;\u0026lt; data[\u0026#34;interests\u0026#34;][0] \u0026lt;\u0026lt; std::endl; // coding std::cout \u0026lt;\u0026lt; \u0026#34;Second interest (using at()): \u0026#34; \u0026lt;\u0026lt; data.at(\u0026#34;interests\u0026#34;).at(1) \u0026lt;\u0026lt; std::endl; // reading // 访问嵌套元素 std::cout \u0026lt;\u0026lt; \u0026#34;Is active: \u0026#34; \u0026lt;\u0026lt; data[\u0026#34;details\u0026#34;][\u0026#34;is_active\u0026#34;] \u0026lt;\u0026lt; std::endl; // true // 类型检查 if (data[\u0026#34;age\u0026#34;].is_number()) { std::cout \u0026lt;\u0026lt; \u0026#34;Age is a number.\u0026#34; \u0026lt;\u0026lt; std::endl; } if (data[\u0026#34;interests\u0026#34;].is_array()) { std::cout \u0026lt;\u0026lt; \u0026#34;Interests is an array.\u0026#34; \u0026lt;\u0026lt; std::endl; } if (data[\u0026#34;null_value\u0026#34;].is_null()) { std::cout \u0026lt;\u0026lt; \u0026#34;Null value is null.\u0026#34; \u0026lt;\u0026lt; std::endl; } // 类型转换 std::string name = data[\u0026#34;name\u0026#34;].get\u0026lt;std::string\u0026gt;(); int age = data[\u0026#34;age\u0026#34;]; // 隐式转换 bool isActive = data[\u0026#34;details\u0026#34;][\u0026#34;is_active\u0026#34;]; std::cout \u0026lt;\u0026lt; \u0026#34;Name (converted): \u0026#34; \u0026lt;\u0026lt; name \u0026lt;\u0026lt; std::endl; std::cout \u0026lt;\u0026lt; \u0026#34;Age (converted): \u0026#34; \u0026lt;\u0026lt; age \u0026lt;\u0026lt; std::endl; std::cout \u0026lt;\u0026lt; \u0026#34;Is active (converted): \u0026#34; \u0026lt;\u0026lt; isActive \u0026lt;\u0026lt; std::endl; // 访问不存在的键 (operator[] 会创建，at() 会抛异常) std::cout \u0026lt;\u0026lt; \u0026#34;Trying to access non-existent key (operator[]): \u0026#34; \u0026lt;\u0026lt; data[\u0026#34;non_existent_key\u0026#34;] \u0026lt;\u0026lt; std::endl; // std::cout \u0026lt;\u0026lt; data.at(\u0026#34;another_non_existent_key\u0026#34;) \u0026lt;\u0026lt; std::endl; // 这会抛出 json::out_of_range 异常 return 0; } 2.2.3 修改JSON元素\n#include \u0026lt;iostream\u0026gt; #include \u0026#34;json.hpp\u0026#34; using json = nlohmann::json; int main() { json profile = { {\u0026#34;name\u0026#34;, \u0026#34;Charlie\u0026#34;}, {\u0026#34;age\u0026#34;, 28}, {\u0026#34;email\u0026#34;, \u0026#34;charlie@example.com\u0026#34;} }; std::cout \u0026lt;\u0026lt; \u0026#34;Original profile:\\n\u0026#34; \u0026lt;\u0026lt; profile.dump(4) \u0026lt;\u0026lt; std::endl; // 修改现有值 profile[\u0026#34;age\u0026#34;] = 29; profile[\u0026#34;email\u0026#34;] = \u0026#34;charlie.new@example.com\u0026#34;; // 添加新键值对 profile[\u0026#34;occupation\u0026#34;] = \u0026#34;Software Engineer\u0026#34;; // 添加新数组元素 profile[\u0026#34;skills\u0026#34;] = {\u0026#34;C++\u0026#34;, \u0026#34;Python\u0026#34;, \u0026#34;JavaScript\u0026#34;}; profile[\u0026#34;skills\u0026#34;].push_back(\u0026#34;Go\u0026#34;); // 修改嵌套对象 profile[\u0026#34;address\u0026#34;] = { {\u0026#34;street\u0026#34;, \u0026#34;456 Oak Ave\u0026#34;}, {\u0026#34;zip\u0026#34;, \u0026#34;10001\u0026#34;} }; profile[\u0026#34;address\u0026#34;][\u0026#34;city\u0026#34;] = \u0026#34;San Francisco\u0026#34;; std::cout \u0026lt;\u0026lt; \u0026#34;\\nModified profile:\\n\u0026#34; \u0026lt;\u0026lt; profile.dump(4) \u0026lt;\u0026lt; std::endl; return 0; } 2.2.4 遍历JSON\nnlohmann/json 支持基于范围的 for 循环遍历JSON对象和数组。\n#include \u0026lt;iostream\u0026gt; #include \u0026#34;json.hpp\u0026#34; using json = nlohmann::json; int main() { json data = { {\u0026#34;id\u0026#34;, 101}, {\u0026#34;title\u0026#34;, \u0026#34;Sample Document\u0026#34;}, {\u0026#34;tags\u0026#34;, {\u0026#34;programming\u0026#34;, \u0026#34;json\u0026#34;, \u0026#34;c++\u0026#34;}}, {\u0026#34;contributors\u0026#34;, { {\u0026#34;name\u0026#34;, \u0026#34;Alice\u0026#34;}, {\u0026#34;id\u0026#34;, 1} }}, {\u0026#34;contributors\u0026#34;, { {\u0026#34;name\u0026#34;, \u0026#34;Bob\u0026#34;}, {\u0026#34;id\u0026#34;, 2} }} }; std::cout \u0026lt;\u0026lt; \u0026#34;Iterating over JSON object (key-value pairs):\\n\u0026#34;; for (json::iterator it = data.begin(); it != data.end(); ++it) { std::cout \u0026lt;\u0026lt; \u0026#34; Key: \u0026#34; \u0026lt;\u0026lt; it.key() \u0026lt;\u0026lt; \u0026#34;, Value: \u0026#34; \u0026lt;\u0026lt; it.value() \u0026lt;\u0026lt; std::endl; } // 或者使用基于范围的 for 循环 (更简洁) // for (auto const\u0026amp; [key, val] : data.items()) { // C++17 结构化绑定 // std::cout \u0026lt;\u0026lt; \u0026#34; Key: \u0026#34; \u0026lt;\u0026lt; key \u0026lt;\u0026lt; \u0026#34;, Value: \u0026#34; \u0026lt;\u0026lt; val \u0026lt;\u0026lt; std::endl; // } std::cout \u0026lt;\u0026lt; \u0026#34;\\nIterating over JSON array (tags):\\n\u0026#34;; for (const auto\u0026amp; tag : data[\u0026#34;tags\u0026#34;]) { std::cout \u0026lt;\u0026lt; \u0026#34; Tag: \u0026#34; \u0026lt;\u0026lt; tag \u0026lt;\u0026lt; std::endl; } std::cout \u0026lt;\u0026lt; \u0026#34;\\nIterating over array of objects (contributors):\\n\u0026#34;; // 注意：如果\u0026#34;contributors\u0026#34;是对象，则第二次赋值会覆盖第一次。 // 这里假设它是一个数组，演示迭代数组中的对象 // 重新构建data，确保contributors是数组 json actual_data = { {\u0026#34;id\u0026#34;, 101}, {\u0026#34;title\u0026#34;, \u0026#34;Sample Document\u0026#34;}, {\u0026#34;tags\u0026#34;, {\u0026#34;programming\u0026#34;, \u0026#34;json\u0026#34;, \u0026#34;c++\u0026#34;}}, {\u0026#34;contributors\u0026#34;, json::array({ {{\u0026#34;name\u0026#34;, \u0026#34;Alice\u0026#34;}, {\u0026#34;id\u0026#34;, 1}}, {{\u0026#34;name\u0026#34;, \u0026#34;Bob\u0026#34;}, {\u0026#34;id\u0026#34;, 2}} })} }; for (const auto\u0026amp; contributor : actual_data[\u0026#34;contributors\u0026#34;]) { std::cout \u0026lt;\u0026lt; \u0026#34; Contributor Name: \u0026#34; \u0026lt;\u0026lt; contributor[\u0026#34;name\u0026#34;] \u0026lt;\u0026lt; \u0026#34;, ID: \u0026#34; \u0026lt;\u0026lt; contributor[\u0026#34;id\u0026#34;] \u0026lt;\u0026lt; std::endl; } return 0; } 2.3 核心 API nlohmann/json 提供了丰富的核心API，用于JSON数据的解析、序列化、查询、操作和类型转换。\n2.3.1 解析与序列化\n解析 (Parsing): 从字符串、文件流等解析JSON数据。 json::parse(source): 从字符串或输入流解析。 json::accept(source): 检查字符串是否是有效的JSON而无需完整解析。 序列化 (Serialization): 将JSON数据转换为字符串。 dump(indent = -1, indent_char = ' ', ensure_ascii = false): 将JSON序列化为字符串。indent 参数用于美化输出，-1 表示不美化。 #include \u0026lt;iostream\u0026gt; #include \u0026lt;fstream\u0026gt; #include \u0026#34;json.hpp\u0026#34; using json = nlohmann::json; int main() { // 从字符串解析 std::string json_str = R\u0026#34;({\u0026#34;product\u0026#34;: \u0026#34;Laptop\u0026#34;, \u0026#34;price\u0026#34;: 1200.50, \u0026#34;inStock\u0026#34;: true})\u0026#34;; json product_data = json::parse(json_str); std::cout \u0026lt;\u0026lt; \u0026#34;Parsed from string:\\n\u0026#34; \u0026lt;\u0026lt; product_data.dump(4) \u0026lt;\u0026lt; std::endl; // 从文件解析 // 假设存在一个名为 \u0026#34;config.json\u0026#34; 的文件 // {\u0026#34;setting1\u0026#34;: \u0026#34;value1\u0026#34;, \u0026#34;setting2\u0026#34;: 123} std::ofstream ofs(\u0026#34;config.json\u0026#34;); ofs \u0026lt;\u0026lt; R\u0026#34;({\u0026#34;setting1\u0026#34;: \u0026#34;value1\u0026#34;, \u0026#34;setting2\u0026#34;: 123})\u0026#34;; ofs.close(); std::ifstream ifs(\u0026#34;config.json\u0026#34;); if (ifs.is_open()) { json config; ifs \u0026gt;\u0026gt; config; // 使用运算符重载进行解析 std::cout \u0026lt;\u0026lt; \u0026#34;\\nParsed from file:\\n\u0026#34; \u0026lt;\u0026lt; config.dump(4) \u0026lt;\u0026lt; std::endl; ifs.close(); } else { std::cerr \u0026lt;\u0026lt; \u0026#34;Error: Could not open config.json\u0026#34; \u0026lt;\u0026lt; std::endl; } // 序列化为字符串 (美化输出) std::string pretty_json = product_data.dump(2); // 2个空格缩进 std::cout \u0026lt;\u0026lt; \u0026#34;\\nPretty JSON:\\n\u0026#34; \u0026lt;\u0026lt; pretty_json \u0026lt;\u0026lt; std::endl; // 序列化为紧凑字符串 (无缩进) std::string compact_json = product_data.dump(); // 默认无缩进 (indent = -1) std::cout \u0026lt;\u0026lt; \u0026#34;\\nCompact JSON:\\n\u0026#34; \u0026lt;\u0026lt; compact_json \u0026lt;\u0026lt; std::endl; return 0; } 2.3.2 查找与查询\ncount(key): 检查JSON对象中是否存在某个键。 contains(key): 检查JSON对象中是否存在某个键 (C++20)。 find(key): 返回指向键值对的迭代器，如果不存在则返回 end()。 value(key, default_value): 安全地获取某个键的值，如果键不存在则返回默认值。 #include \u0026lt;iostream\u0026gt; #include \u0026#34;json.hpp\u0026#34; using json = nlohmann::json; int main() { json user = { {\u0026#34;id\u0026#34;, 1001}, {\u0026#34;username\u0026#34;, \u0026#34;johndoe\u0026#34;}, {\u0026#34;email\u0026#34;, \u0026#34;john@example.com\u0026#34;}, {\u0026#34;roles\u0026#34;, {\u0026#34;admin\u0026#34;, \u0026#34;editor\u0026#34;}} }; // 检查键是否存在 if (user.count(\u0026#34;username\u0026#34;)) { std::cout \u0026lt;\u0026lt; \u0026#34;Username exists: \u0026#34; \u0026lt;\u0026lt; user[\u0026#34;username\u0026#34;] \u0026lt;\u0026lt; std::endl; } if (user.contains(\u0026#34;email\u0026#34;)) { // C++20 及以上版本可用 std::cout \u0026lt;\u0026lt; \u0026#34;Email exists: \u0026#34; \u0026lt;\u0026lt; user[\u0026#34;email\u0026#34;] \u0026lt;\u0026lt; std::endl; } // 使用 find() auto it = user.find(\u0026#34;roles\u0026#34;); if (it != user.end()) { std::cout \u0026lt;\u0026lt; \u0026#34;Roles found: \u0026#34; \u0026lt;\u0026lt; *it \u0026lt;\u0026lt; std::endl; } else { std::cout \u0026lt;\u0026lt; \u0026#34;Roles not found.\u0026#34; \u0026lt;\u0026lt; std::endl; } auto non_existent_it = user.find(\u0026#34;password\u0026#34;); if (non_existent_it == user.end()) { std::cout \u0026lt;\u0026lt; \u0026#34;Password not found (as expected).\u0026#34; \u0026lt;\u0026lt; std::endl; } // 使用 value() 安全获取 std::string city = user.value(\u0026#34;city\u0026#34;, \u0026#34;Unknown\u0026#34;); // city不存在，返回\u0026#34;Unknown\u0026#34; std::cout \u0026lt;\u0026lt; \u0026#34;User\u0026#39;s city: \u0026#34; \u0026lt;\u0026lt; city \u0026lt;\u0026lt; std::endl; std::string username = user.value(\u0026#34;username\u0026#34;, \u0026#34;Guest\u0026#34;); // username存在，返回实际值 std::cout \u0026lt;\u0026lt; \u0026#34;User\u0026#39;s username: \u0026#34; \u0026lt;\u0026lt; username \u0026lt;\u0026lt; std::endl; return 0; } 2.3.3 修改与删除\nclear(): 清空JSON对象或数组。 erase(): 删除元素。 push_back(): 向数组添加元素。 emplace(): 在对象中插入元素。 update(): 合并或更新JSON对象。 #include \u0026lt;iostream\u0026gt; #include \u0026#34;json.hpp\u0026#34; using json = nlohmann::json; int main() { json settings = { {\u0026#34;theme\u0026#34;, \u0026#34;dark\u0026#34;}, {\u0026#34;fontSize\u0026#34;, 14}, {\u0026#34;notifications\u0026#34;, true}, {\u0026#34;features\u0026#34;, {\u0026#34;darkMode\u0026#34;, \u0026#34;autoSave\u0026#34;}} }; std::cout \u0026lt;\u0026lt; \u0026#34;Original settings:\\n\u0026#34; \u0026lt;\u0026lt; settings.dump(4) \u0026lt;\u0026lt; std::endl; // 修改值 settings[\u0026#34;fontSize\u0026#34;] = 16; // 添加新键值对 settings[\u0026#34;language\u0026#34;] = \u0026#34;en-US\u0026#34;; // 删除键值对 settings.erase(\u0026#34;notifications\u0026#34;); // 按键删除 // 或者 settings.erase(settings.find(\u0026#34;notifications\u0026#34;)); // 按迭代器删除 // 向数组添加元素 settings[\u0026#34;features\u0026#34;].push_back(\u0026#34;spellCheck\u0026#34;); settings[\u0026#34;features\u0026#34;].insert(settings[\u0026#34;features\u0026#34;].begin(), \u0026#34;hotReload\u0026#34;); // 插入到开头 // 清空数组 // settings[\u0026#34;features\u0026#34;].clear(); std::cout \u0026lt;\u0026lt; \u0026#34;\\nModified settings:\\n\u0026#34; \u0026lt;\u0026lt; settings.dump(4) \u0026lt;\u0026lt; std::endl; // update() 合并对象 json new_defaults = { {\u0026#34;language\u0026#34;, \u0026#34;zh-CN\u0026#34;}, // 会覆盖 {\u0026#34;defaultFolder\u0026#34;, \u0026#34;/home/user/docs\u0026#34;}, // 会添加 {\u0026#34;fontSize\u0026#34;, 12} // 会覆盖 }; settings.update(new_defaults); std::cout \u0026lt;\u0026lt; \u0026#34;\\nSettings after update:\\n\u0026#34; \u0026lt;\u0026lt; settings.dump(4) \u0026lt;\u0026lt; std::endl; return 0; } 2.4 高级语法 2.4.1 自定义类型序列化与反序列化\nnlohmann/json 提供了强大的机制，允许开发者轻松地将自定义C++结构体或类与JSON数据进行双向转换，无需手动编写复杂的解析和构建逻辑。这通过为自定义类型重载 to_json 和 from_json 函数来实现。\n#include \u0026lt;iostream\u0026gt; #include \u0026#34;json.hpp\u0026#34; using json = nlohmann::json; // 定义一个自定义结构体 struct Person { std::string name; int age; std::vector\u0026lt;std::string\u0026gt; hobbies; bool is_student; }; // 为 Person 类型提供 to_json 函数（将 Person 转换为 json） void to_json(json\u0026amp; j, const Person\u0026amp; p) { j = json{{\u0026#34;name\u0026#34;, p.name}, {\u0026#34;age\u0026#34;, p.age}, {\u0026#34;hobbies\u0026#34;, p.hobbies}, {\u0026#34;is_student\u0026#34;, p.is_student}}; } // 为 Person 类型提供 from_json 函数（将 json 转换为 Person） void from_json(const json\u0026amp; j, Person\u0026amp; p) { j.at(\u0026#34;name\u0026#34;).get_to(p.name); j.at(\u0026#34;age\u0026#34;).get_to(p.age); j.at(\u0026#34;hobbies\u0026#34;).get_to(p.hobbies); j.at(\u0026#34;is_student\u0026#34;).get_to(p.is_student); } int main() { // 1. 将 C++ 对象序列化为 JSON Person alice = {\u0026#34;Alice\u0026#34;, 25, {\u0026#34;reading\u0026#34;, \u0026#34;cycling\u0026#34;}, true}; json j_alice = alice; // 自动调用 to_json(j_alice, alice) std::cout \u0026lt;\u0026lt; \u0026#34;Alice as JSON:\\n\u0026#34; \u0026lt;\u0026lt; j_alice.dump(4) \u0026lt;\u0026lt; std::endl; // 2. 将 JSON 反序列化为 C++ 对象 json j_bob = R\u0026#34;( { \u0026#34;name\u0026#34;: \u0026#34;Bob\u0026#34;, \u0026#34;age\u0026#34;: 30, \u0026#34;hobbies\u0026#34;: [\u0026#34;gaming\u0026#34;, \u0026#34;hiking\u0026#34;], \u0026#34;is_student\u0026#34;: false } )\u0026#34;_json; // 使用 _json 字面量操作符解析字符串 Person bob = j_bob.get\u0026lt;Person\u0026gt;(); // 自动调用 from_json(j_bob, bob) std::cout \u0026lt;\u0026lt; \u0026#34;\\nBob (from JSON):\\n\u0026#34;; std::cout \u0026lt;\u0026lt; \u0026#34;Name: \u0026#34; \u0026lt;\u0026lt; bob.name \u0026lt;\u0026lt; std::endl; std::cout \u0026lt;\u0026lt; \u0026#34;Age: \u0026#34; \u0026lt;\u0026lt; bob.age \u0026lt;\u0026lt; std::endl; std::cout \u0026lt;\u0026lt; \u0026#34;Hobbies: \u0026#34;; for (const auto\u0026amp; hobby : bob.hobbies) { std::cout \u0026lt;\u0026lt; hobby \u0026lt;\u0026lt; \u0026#34; \u0026#34;; } std::cout \u0026lt;\u0026lt; \u0026#34;\\nIs Student: \u0026#34; \u0026lt;\u0026lt; (bob.is_student ? \u0026#34;Yes\u0026#34; : \u0026#34;No\u0026#34;) \u0026lt;\u0026lt; std::endl; // 错误处理：如果 JSON 缺少某个字段，from_json 会抛出异常 json invalid_json = R\u0026#34;({\u0026#34;name\u0026#34;: \u0026#34;Eve\u0026#34;, \u0026#34;age\u0026#34;: 22})\u0026#34;_json; try { Person eve = invalid_json.get\u0026lt;Person\u0026gt;(); } catch (const json::exception\u0026amp; e) { std::cerr \u0026lt;\u0026lt; \u0026#34;\\nError deserializing invalid_json: \u0026#34; \u0026lt;\u0026lt; e.what() \u0026lt;\u0026lt; std::endl; } return 0; } 2.4.2 JSON Pointer\nJSON Pointer (RFC 6901) 提供了一种标准化的方式来在JSON文档中定位特定的值。nlohmann/json 完全支持JSON Pointer。\n#include \u0026lt;iostream\u0026gt; #include \u0026#34;json.hpp\u0026#34; using json = nlohmann::json; int main() { json doc = R\u0026#34;( { \u0026#34;foo\u0026#34;: [\u0026#34;bar\u0026#34;, \u0026#34;baz\u0026#34;], \u0026#34;\u0026#34;: 0, \u0026#34;a/b\u0026#34;: 1, \u0026#34;c%d\u0026#34;: 2, \u0026#34;e^f\u0026#34;: 3, \u0026#34;g|h\u0026#34;: 4, \u0026#34;i\\\\j\u0026#34;: 5, \u0026#34;k\\\u0026#34;l\u0026#34;: 6, \u0026#34; \u0026#34;: 7, \u0026#34;m~n\u0026#34;: 8, \u0026#34;object\u0026#34;: { \u0026#34;nested_key\u0026#34;: \u0026#34;nested_value\u0026#34; }, \u0026#34;array\u0026#34;: [ {\u0026#34;item1\u0026#34;: \u0026#34;value1\u0026#34;}, {\u0026#34;item2\u0026#34;: \u0026#34;value2\u0026#34;} ] } )\u0026#34;_json; // 使用 JSON Pointer 访问元素 std::cout \u0026lt;\u0026lt; \u0026#34;doc[\\\u0026#34;/foo/0\\\u0026#34;]: \u0026#34; \u0026lt;\u0026lt; doc.at(\u0026#34;/foo/0\u0026#34;) \u0026lt;\u0026lt; std::endl; // \u0026#34;bar\u0026#34; std::cout \u0026lt;\u0026lt; \u0026#34;doc[\\\u0026#34;/a~1b\\\u0026#34;]: \u0026#34; \u0026lt;\u0026lt; doc.at(\u0026#34;/a~1b\u0026#34;) \u0026lt;\u0026lt; std::endl; // 1 (斜杠编码为 ~1) std::cout \u0026lt;\u0026lt; \u0026#34;doc[\\\u0026#34;/m~0n\\\u0026#34;]: \u0026#34; \u0026lt;\u0026lt; doc.at(\u0026#34;/m~0n\u0026#34;) \u0026lt;\u0026lt; std::endl; // 8 (波浪号编码为 ~0) std::cout \u0026lt;\u0026lt; \u0026#34;doc[\\\u0026#34;/object/nested_key\\\u0026#34;]: \u0026#34; \u0026lt;\u0026lt; doc.at(\u0026#34;/object/nested_key\u0026#34;) \u0026lt;\u0026lt; std::endl; // \u0026#34;nested_value\u0026#34; std::cout \u0026lt;\u0026lt; \u0026#34;doc[\\\u0026#34;/array/0/item1\\\u0026#34;]: \u0026#34; \u0026lt;\u0026lt; doc.at(\u0026#34;/array/0/item1\u0026#34;) \u0026lt;\u0026lt; std::endl; // \u0026#34;value1\u0026#34; // JSON Pointer 赋值 doc[\u0026#34;/foo/1\u0026#34;] = \u0026#34;qux\u0026#34;; std::cout \u0026lt;\u0026lt; \u0026#34;\\nModified doc (foo/1):\\n\u0026#34; \u0026lt;\u0026lt; doc.dump(4) \u0026lt;\u0026lt; std::endl; // JSON Pointer 添加新值 doc[\u0026#34;/new_key\u0026#34;] = \u0026#34;new_value\u0026#34;; std::cout \u0026lt;\u0026lt; \u0026#34;\\nModified doc (new_key):\\n\u0026#34; \u0026lt;\u0026lt; doc.dump(4) \u0026lt;\u0026lt; std::endl; // 检查是否存在 if (doc.contains(\u0026#34;/object/nested_key\u0026#34;)) { std::cout \u0026lt;\u0026lt; \u0026#34;\\n\u0026#39;/object/nested_key\u0026#39; exists.\u0026#34; \u0026lt;\u0026lt; std::endl; } // 错误处理：访问不存在的 JSON Pointer try { std::cout \u0026lt;\u0026lt; doc.at(\u0026#34;/non_existent_path\u0026#34;) \u0026lt;\u0026lt; std::endl; } catch (const json::exception\u0026amp; e) { std::cerr \u0026lt;\u0026lt; \u0026#34;Error accessing non-existent path: \u0026#34; \u0026lt;\u0026lt; e.what() \u0026lt;\u0026lt; std::endl; } return 0; } 2.4.3 JSON Patch\nJSON Patch ([[RFC 6902]]) 定义了一种标准的数据格式，用于描述对JSON文档的更改。nlohmann/json 提供了对JSON Patch 的支持，包括生成和应用补丁。\n#include \u0026lt;iostream\u0026gt; #include \u0026#34;json.hpp\u0026#34; using json = nlohmann::json; int main() { json document = R\u0026#34;( { \u0026#34;baz\u0026#34;: \u0026#34;qux\u0026#34;, \u0026#34;foo\u0026#34;: [\u0026#34;bar\u0026#34;, \u0026#34;baz\u0026#34;], \u0026#34;glossary\u0026#34;: { \u0026#34;title\u0026#34;: \u0026#34;example glossary\u0026#34; } } )\u0026#34;_json; json other_document = R\u0026#34;( { \u0026#34;baz\u0026#34;: \u0026#34;boo\u0026#34;, \u0026#34;foo\u0026#34;: [\u0026#34;bar\u0026#34;, \u0026#34;boo\u0026#34;], \u0026#34;test\u0026#34;: \u0026#34;hello\u0026#34;, \u0026#34;glossary\u0026#34;: { \u0026#34;title\u0026#34;: \u0026#34;updated glossary\u0026#34; } } )\u0026#34;_json; std::cout \u0026lt;\u0026lt; \u0026#34;Original Document:\\n\u0026#34; \u0026lt;\u0026lt; document.dump(4) \u0026lt;\u0026lt; std::endl; std::cout \u0026lt;\u0026lt; \u0026#34;\\nOther Document:\\n\u0026#34; \u0026lt;\u0026lt; other_document.dump(4) \u0026lt;\u0026lt; std::endl; // 1. 生成 JSON Patch // 计算从 document 到 other_document 的差异 json patch = json::diff(document, other_document); std::cout \u0026lt;\u0026lt; \u0026#34;\\nGenerated JSON Patch:\\n\u0026#34; \u0026lt;\u0026lt; patch.dump(4) \u0026lt;\u0026lt; std::endl; // 2. 应用 JSON Patch json patched_document = document.patch(patch); std::cout \u0026lt;\u0026lt; \u0026#34;\\nDocument after applying patch:\\n\u0026#34; \u0026lt;\u0026lt; patched_document.dump(4) \u0026lt;\u0026lt; std::endl; // 验证补丁是否正确应用 if (patched_document == other_document) { std::cout \u0026lt;\u0026lt; \u0026#34;\\nPatched document matches other_document.\u0026#34; \u0026lt;\u0026lt; std::endl; } else { std::cout \u0026lt;\u0026lt; \u0026#34;\\nPatched document does NOT match other_document.\u0026#34; \u0026lt;\u0026lt; std::endl; } // 手动创建 JSON Patch json manual_patch = json::array({ {{\u0026#34;op\u0026#34;, \u0026#34;replace\u0026#34;}, {\u0026#34;path\u0026#34;, \u0026#34;/baz\u0026#34;}, {\u0026#34;value\u0026#34;, \u0026#34;new_qux\u0026#34;}}, {{\u0026#34;op\u0026#34;, \u0026#34;add\u0026#34;}, {\u0026#34;path\u0026#34;, \u0026#34;/new_key\u0026#34;}, {\u0026#34;value\u0026#34;, 123}}, {{\u0026#34;op\u0026#34;, \u0026#34;remove\u0026#34;}, {\u0026#34;path\u0026#34;, \u0026#34;/foo/0\u0026#34;}} }); json doc_to_patch = document; // 复制一份进行操作 try { doc_to_patch = doc_to_patch.patch(manual_patch); std::cout \u0026lt;\u0026lt; \u0026#34;\\nDocument after applying manual patch:\\n\u0026#34; \u0026lt;\u0026lt; doc_to_patch.dump(4) \u0026lt;\u0026lt; std::endl; } catch (const json::exception\u0026amp; e) { std::cerr \u0026lt;\u0026lt; \u0026#34;Error applying manual patch: \u0026#34; \u0026lt;\u0026lt; e.what() \u0026lt;\u0026lt; std::endl; } return 0; } 结论 nlohmann/json 库凭借其仅头文件、直观的API设计、强大的功能集以及对C++现代特性的充分利用，已成为C++处理JSON数据的首选解决方案。它不仅简化了JSON的解析和序列化过程，还通过支持JSON Pointer 和 JSON Patch 等高级特性，极大地提升了C++在复杂数据操作方面的能力。无论是小型配置解析还是大型系统间的数据交换，nlohmann/json 都能提供一个高效、可靠且易于维护的工具。随着C++标准的不断演进，nlohmann/json 也将继续保持其领先地位，为C++开发者提供更加便捷和强大的JSON处理体验。\n参考文献 [1] nlohmann/json GitHub Repository: https://github.com/nlohmann/json [2] JSON (JavaScript Object Notation) - ECMA-404 The JSON Data Interchange Format: https://www.ecma-international.org/publications-and-standards/standards/ecma-404/ [3] RFC 6901 - JSON Pointer: https://tools.ietf.org/html/rfc6901 [4] RFC 6902 - JSON Patch: https://tools.ietf.org/html/rfc6902 ","date":"1 January, 1970","id":116,"permalink":"/posts/nlohmann_json/","summary":"本文档全面介绍了 nlohmann/json，一个广受欢迎的现代C++ JSON库。我们将从其起源与发展入手，探讨其在C++生态系统中的地位，并与其他主流C++ JSON库进行比较。随后，深入剖析 nlohmann/json 的架构与设计哲学，揭示其简洁易用的特点。最后，文档将详细阐述 nlohmann/json 在C++项目中的具体应用，包括安装、基本语法、核心API以及高级用法，旨在为C++开发者提供一份权威、实用的参考指南。","tags":"opensource json nlohmann","title":"nlohmann json lib"},{"content":"环境 ubuntu 18.04 x64\n依赖工具 jdk 1.8 universal-ctags tomcat8 opengrok 配置流程 jdk 安装 sudo apt install openjdk-8-jdk openjdk-8-jdk-headless openjdk-8-jre openjdk-8-jre-dcevm openjdk-8-jre-headless\n通常android编译环境能够正常工作jdk环境已经ok.\n$ java -version openjdk version \u0026#34;1.8.0_252\u0026#34; OpenJDK Runtime Environment (build 1.8.0_252-8u252-b09-1~18.04-b09) OpenJDK 64-Bit Server VM (build 25.252-b09, mixed mode) universal-ctags ubuntu 自带包管理器安装的 ctags 是 exuberant-ctags, 如果已经安装请先通过如下命令卸载\nsudo apt purge exuberant-ctags 通过源码安装 universal-ctags\ngit clone https://gitee.com/neo532/universal-ctags.git cd universal-ctags ./autogen.sh ./configure make sudo make install $ /usr/local/bin/ctags --version Universal Ctags 0.0.0(054bee0), Copyright (C) 2015 Universal Ctags Team Universal Ctags is derived from Exuberant Ctags. Exuberant Ctags 5.8, Copyright (C) 1996-2009 Darren Hiebert Compiled: May 10 2020, 10:34:29 URL: https://ctags.io/ Optional compiled features: +wildcards, +regex, +iconv, +option-directory tomcat8 sudo apt install tomcat8 sudo service tomcat8 start opengrok How to setup OpenGrok\n安装工具包 下载opengrok-非source code版， 漫长的等待\u0026hellip;\u0026hellip;\n搭建 opengrok 目录结构 sudo mkdir /opengrok/{src,data,dist,etc,log}\n解压opengrok到指定路径 tar -C /opengrok/dist --strip-components=1 -xzf opengrok-X.Y.Z.tar.gz\nInstall management tools (optional) cd /opengrok/dist/tools python3 -m pip install opengrok-tools.tar.gz Deploy the web application cp /opengrok/dist/lib/source.war /var/lib/tomcat8/webapps/ Indexing 通过修改如下 -s 选项来配置修改源码路径.\n假设我的android源码路径为 /opengrok/src/A64_android ，则使用如下参数：\njava \\ -Djava.util.logging.config.file=/opengrok/etc/logging.properties \\ -jar /opengrok/dist/lib/opengrok.jar \\ -c /usr/local/bin/ctags \\ -s /opengrok/src -d /opengrok/data -H -P -S -G \\ -W /opengrok/etc/configuration.xml -U http://localhost:8080/source RTFSC 访问网址： http://localhost:8080/source/\n","date":"1 January, 1970","id":117,"permalink":"/posts/opengrok/","summary":"ubuntu 18.04 x64","tags":"opengrok","title":"opengrok"},{"content":"代码下载 OpenHarmony源代码以 [[HPM]] 部分的形式提供，可以通过以下任意方式获取：\n从Gitee代码库获取源码。您可以使用repo或git工具从代码仓库下载最新的代码。\n从DevEco Marketplace获取源代码。访问DevEco Marketplace ，搜索您想要的开源发行版，并下载组件列表（或自定义组件并下载组件列表）。然后使用hpm-cli工具在本地PC上下载并安装组件和编译工具链。\n从镜像站点下载发行版的压缩文件。该方法下载速度较快，因此您也可以使用该方法获取早期版本的源代码。\n从GitHub镜像仓库获取源码。您可以使用repo或git工具从代码仓库下载最新的代码。\ngitee 获取源码 sudo apt -y install git git-lfs vim python3 python3-pip git config --global user.name \u0026lt;\u0026gt; git config --global user.email \u0026lt;\u0026gt; cd /usr/bin sudo ln -s pyhon3 python 安装 repo 工具\nmkdir ~/bin curl https://gitee.com/oschina/repo/raw/fork_flow/repo-py3 -o ~/bin/repo chmod a+x ~/bin/repo pip3 install -i https://repo.huaweicloud.com/repository/pypi/simple requests 将repo工具的路径添加到环境变量中\nvim ~/.bashrc # Edit environment variables. export PATH=~/bin:$PATH # Add the path of the **repo** tool to the end of environment variables. source ~/.bashrc # Apply environment variables. 如果您想开发商业功能，请下载发布代码，该代码更稳定。如果您想快速访问适合您的开发的最新功能，请下载主代码。\n如何获取OpenHarmony版本源码，请参见版本说明。\n方法一（推荐）：使用repo工具通过SSH下载源码。 （您必须注册SSH公钥才能访问Gitee。）\nrepo init -u git@gitee.com:openharmony/manifest.git -b master --no-repo-verify repo sync -c repo forall -c \u0026#39;git lfs pull\u0026#39; 方法二：使用repo工具通过HTTPS下载源码。\nrepo init -u https://gitee.com/openharmony/manifest.git -b master --no-repo-verify repo sync -c repo forall -c \u0026#39;git lfs pull\u0026#39; 编译 自行安装 Docker 环境 docker 环境搭建\nmkdir ~/OpenHarmony cd ~/OpenHarmony docker run --rm -ti -e HARDWARE=ipcamera_hi3516dv300 -v ${PWD}/out:/OpenHarmony/out ystyle/open-harmony bash repo sync -c python build.py ${HARDWARE} -b debug ","date":"1 January, 1970","id":118,"permalink":"/posts/openharmony-%E4%BB%A3%E7%A0%81%E4%B8%8B%E8%BD%BD%E7%BC%96%E8%AF%91/","summary":"OpenHarmony源代码以 [[HPM]] 部分的形式提供，可以通过以下任意方式获取：","tags":"OpenHarmony","title":"OpenHarmony 代码下载编译"},{"content":"PCIe M.2 技术文档 1. 硬件物理层与接口规范 1.1 M.2 物理规格 M.2（原称 Next Generation Form Factor, NGFF）是一种紧凑型扩展接口标准，用于替代 mSATA 和 mini-PCIe。其命名方式为 WWLL，其中：\nWW = 宽度（固定为 22 mm） LL = 长度（单位：mm） 常见尺寸：\n尺寸代号 长度（mm） 典型用途 2230 30 Wi-Fi、蓝牙模块 2242 42 轻量级 SSD、嵌入式存储 2260 60 中端 NVMe SSD 2280 80 主流消费级/企业级 NVMe SSD 22110 110 高容量企业级 SSD（双面 NAND） 注：2280 是目前桌面与笔记本最广泛采用的规格。\n1.2 防呆键位（Keying） M.2 插槽通过缺口位置（Key ID）定义支持的协议和电气接口：\nKey ID 位置（引脚） 支持协议 PCIe 通道数 典型设备 B Key Pin 12–19 SATA、PCIe ×2、USB 2.0/3.0、Audio ≤ 2 lanes SATA SSD、低端 NVMe、网卡 M Key Pin 59–66 PCIe ×4、SATA（部分） ≤ 4 lanes 高性能 NVMe SSD B+M Key 同时具备 B 与 M 缺口 兼容 B 或 M 插槽 ×2（B）或 ×4（M） 通用型 NVMe SSD（如 Samsung 970 EVO） ⚠️ 关键区分：\nM.2 是物理接口标准（定义尺寸、引脚、供电） NVMe 是逻辑协议（运行在 PCIe 之上的存储协议） 一块 M.2 SSD 可能使用 SATA 协议（走 AHCI）或 NVMe 协议（走 PCIe），二者不可混用。 1.3 电气特性 供电电压：+3.3V（主电源），部分支持 +1.8V 辅助电源 最大功耗：通常 ≤ 8W（高性能 SSD 可达 10W+，需主板供电支持） 信号完整性： PCIe 通道需严格阻抗控制（差分 85–100 Ω） 高速信号（\u0026gt;8 GT/s）对 PCB 走线长度、过孔、参考平面敏感 热设计： 高性能 NVMe（如 PCIe 4.0 ×4）在持续写入时温度可达 70–85°C 主板常配备 M.2 散热马甲（Heatsink），部分支持热节流（Thermal Throttling） 1.4 与传统接口对比 接口 带宽（理论） 协议 尺寸 热插拔 典型用途 M.2 (PCIe ×4) 4 GB/s (3.0) / 8 GB/s (4.0) NVMe / SATA 超紧凑 否（通常） SSD、Wi-Fi mSATA 0.6 GB/s AHCI (SATA) 类似 M.2 2242 否 老旧 SSD PCIe x4 插槽 同 M.2 任意 PCIe 大型 是 显卡、网卡 SATA III 0.6 GB/s AHCI 线缆连接 是 2.5\u0026quot; SSD/HDD M.2尺寸命名 下表列出了PCI Express M.2规范5.1版中有关M.2命名方式的详细信息\nNOTES:\n仅在双插槽规格时使用。 高度尺寸中包含标签。 该尺寸为11.5毫米，但在类型命名中写作11（例如，BGA类型1113）。 对于BGA SSD，最大高度以锡球压缩后的高度为准，无论BGA直接安装在平台上还是安装在模块板上都适用。 采用连接器设计时，允许有绝缘标签。 Key G仅供客户使用，带有该钥位的产品不属于M.2标准，使用风险由客户自行承担。 仅在需指定顶部表面为平面的情况下使用。 仅当扩展卡的单针脚电流需求超过0.5安（正常功率额定值）和/或卡片外形更改为M.2-1A类型时使用。 M.2-1A仅支持22毫米和30毫米宽度。 2. 协议栈与传输标准 2.1 M.2 支持的协议 M.2 本身不规定协议，仅提供物理连接。通过 Key 位选择协议：\nSATA 模式：使用 AHCI 驱动，性能受限于 SATA III（~600 MB/s） PCIe 模式：支持 NVMe（主流）或其他 PCIe Endpoint（如网卡、GPU） ✅ 当前 \u0026gt;95% 高性能 M.2 SSD 采用 PCIe + NVMe 组合。\n2.2 PCIe 版本与带宽 PCIe 版本 单通道带宽（单向） ×4 总带宽（双向） 实际吞吐（NVMe） PCIe 3.0 985 MB/s ~3.94 GB/s ~3.5 GB/s PCIe 4.0 1.97 GB/s ~7.88 GB/s ~7.0 GB/s PCIe 5.0 3.94 GB/s ~15.75 GB/s ~14 GB/s 📌 实际吞吐受 NAND 速度、主控、队列深度限制，通常低于理论值。\n2.3 NVMe 协议架构 NVMe 专为 PCIe SSD 设计，核心优势在于 高并行性 与 低延迟。\n核心机制： Submission Queue (SQ)：主机向设备提交 I/O 命令 Completion Queue (CQ)：设备返回完成状态 多队列（Multi-Queue）： 每个 CPU 核可绑定独立 I/O 队列（减少锁竞争） 队列深度可达 64K 条目（AHCI 仅 32） 命令类型： Admin Commands：创建/删除队列、固件更新、SMART I/O Commands：Read/Write/Flush/Dataset Management 与 AHCI 对比优势： 特性 AHCI (SATA) NVMe (PCIe) 队列深度 1（32 条目） 多队列（64K 条目） 中断延迟 高（MSI-X 有限） 极低（MSI-X + 多向量） CPU 利用率 高 低（高效批处理） 并行性 串行命令处理 真正并行 I/O 2.4 其他 M.2 应用 Wi-Fi 6/6E/7 模块：使用 PCIe + USB 协议（Key E，非本节重点） WWAN（4G/5G）：Key B 蓝牙、SSD 缓存模块：均通过 M.2 实现小型化 3. 典型应用场景与产品生态 3.1 主流产品 消费级：Samsung 980 Pro（PCIe 4.0）、WD Black SN850X、Crucial T700（PCIe 5.0） 企业级：Intel P5510、Micron 9400、Kioxia CM7 嵌入式：Solidigm D5-P5336（30.72TB，22110） 3.2 部署差异 平台 特点 笔记本 通常 1× M.2（2280），供电/散热受限，多用 PCIe 3.0/4.0 台式机 1–3× M.2 插槽，支持 PCIe 4.0/5.0，常带散热片 服务器 多 M.2 或 U.2 + M.2 混合，支持热插拔、PLP（断电保护） 嵌入式 2242/2230 尺寸，宽温设计，低功耗模式 3.3 高级用例 RAID 0/1：通过主板 BIOS 或 Linux mdadm 软件 RAID 缓存加速：Intel RST、Linux bcache / dm-cache 持久内存（PMEM）：部分 Optane M.2 设备支持，通过 ndctl 管理 M.2 扩展卡：PCIe x4 转 1/2/4× M.2，用于无原生 M.2 插槽的台式机 4. Linux 内核支持与驱动架构 4.1 驱动模型 Linux NVMe 驱动位于：\ndrivers/nvme/ ├── host/ # 主机端驱动 │ ├── pci.c # PCIe 探测与初始化（核心） │ ├── core.c # 通用 NVMe 逻辑 │ └── ... ├── target/ # NVMe-oF（网络存储） └── ... 关键内核配置选项（/boot/config-*）：\nCONFIG_NVME_CORE=y # NVMe 核心框架 CONFIG_NVME_PCI=y # PCIe NVMe 设备支持 CONFIG_NVME_FABRICS=y # NVMe over Fabrics（如 TCP/RDMA） ✅ 版本要求：\n基础支持：Linux Kernel ≥ 3.3（实验性） 完整生产支持：≥ 4.4（多队列、blk-mq 集成） PCIe 5.0：≥ 6.0+（需硬件配合） 4.2 设备探测流程 PCIe Enumeration：BIOS/UEFI 或内核扫描 PCIe 总线 驱动匹配：nvme_pci_driver 通过 Vendor/Device ID 绑定 初始化： 读取 CAP（Controller Capabilities）寄存器 分配 SQ/CQ 创建块设备 nvme0n1 块设备注册：通过 nvme_ns_setup_streams() 等注册到 /dev/ 4.3 块设备接口 命名规则： Controller: /dev/nvme0（管理接口） Namespace: /dev/nvme0n1（主存储空间） Partitions: /dev/nvme0n1p1, /dev/nvme0n1p2\u0026hellip; 4.4 blk-mq 与多队列 Linux 使用 blk-mq（Block Multi-Queue） 框架将 NVMe 队列映射到 CPU 每个硬件队列 ↔ 一个软件提交队列（struct blk_mq_hw_ctx） 启用方式：默认开启（nvme_core.mq_mode=1） 4.5 电源管理与热插拔 ASPM（Active State Power Management）： 通过 pcie_aspm=force 内核参数启用 可降低链路功耗（L0s/L1 状态） D3cold：设备完全断电（需主板支持） 热插拔： 需主板 BIOS 启用 PCIe Hotplug Linux 通过 echo 1 \u0026gt; /sys/bus/pci/rescan 触发扫描 4.6 故障排查（dmesg 示例） # 设备未识别 nvme 0000:01:00.0: Unable to read CAP register # 超时 nvme nvme0: I/O 12345 timeout # 电源问题 nvme nvme0: Device not ready; aborting reset # 固件错误 nvme nvme0: fatal error: DNR bit set 5. Linux 工具链与运维实践 5.1 设备识别 lspci -v | grep -A 10 -i nvme lsblk # 查看块设备 ls -l /dev/disk/by-id/ # 持久化命名（推荐用于 fstab） 持久化 ID 示例：\n/dev/disk/by-id/nvme-SAMSUNG_MZVL21T0HCLR-00B00_S699NF0R234567\n5.2 性能测试 # 使用 fio 测试随机读写 fio --name=randread --ioengine=libaio --rw=randread --bs=4k \\ --size=1G --numjobs=4 --direct=1 --runtime=60 --group_reporting # 使用 nvme-cli 查看健康状态 nvme smart-log /dev/nvme0 nvme id-ctrl /dev/nvme0 # 控制器信息 nvme id-ns /dev/nvme0n1 # 命名空间信息 5.3 固件管理 nvme fw-download /dev/nvme0 --fw=file.bin nvme fw-activate /dev/nvme0 --action=2 --slot=1 # 激活并下次启动生效 5.4 分区与文件系统 fdisk /dev/nvme0n1 mkfs.ext4 /dev/nvme0n1p1 mount /dev/disk/by-id/nvme-... /mnt/ssd 5.5 监控工具 iostat -x 1 # 实时 I/O 统计 iotop -o # 按进程 I/O 排序 smartctl -d nvme -a /dev/nvme0 # SMART 信息（需 smartmontools ≥ 7.0） 5.6 内核调优 队列深度（默认通常足够）： echo 1024 \u0026gt; /sys/block/nvme0n1/queue/nr_requests I/O 调度器（NVMe 推荐 mq-deadline 或 none）： echo mq-deadline \u0026gt; /sys/block/nvme0n1/queue/scheduler 中断亲和性（多核优化）： # 查看 IRQ cat /proc/interrupts | grep nvme # 绑定到 CPU 0-3 echo 0f \u0026gt; /proc/irq/123/smp_affinity 附录：PCIe 带宽对比表 PCIe 版本 编码方式 单 Lane 速率 ×4 双向带宽 实际 NVMe 吞吐（典型） PCIe 3.0 128b/130b 8 GT/s ~31.5 Gb/s (3.94 GB/s) ≤ 3.5 GB/s PCIe 4.0 128b/130b 16 GT/s ~63 Gb/s (7.88 GB/s) ≤ 7.0 GB/s PCIe 5.0 128b/130b 32 GT/s ~126 Gb/s (15.75 GB/s) ≤ 14 GB/s 注：NVMe 协议开销、NAND 速度、主控效率导致实际吞吐低于理论值。\n","date":"1 January, 1970","id":119,"permalink":"/posts/pcie_m.2_%E6%8A%80%E6%9C%AF%E6%96%87%E6%A1%A3/","summary":"M.2（原称 Next Generation Form Factor, NGFF）是一种紧凑型扩展接口标准，用于替代 mSATA 和 mini-PCIe。其命名方式为 WWLL，其中：","tags":"PCIe SSD NVMe","title":"PCIe M.2 技术"},{"content":"环境准备 下载repo工具\nuser110@server005:~/bin$ curl https://mirrors.tuna.tsinghua.edu.cn/git/git-repo -o repo user110@server005:~/bin$ chmod +x repo 添加环境变量中\nuser110@server005:~/bin$ vim ~/.bashrc # add code PATH=$PATH:$HOME/bin export REPO_URL=‘git://10.20.6.145/git-repo’ # repo 源地址 user110@server005:~/bin$ source ~/.bashrc 上传 ssh public key\n拉代码 初始化\nuser110@server005:~/delete$ repo init -u \u0026lt;ssh://user112@10.20.6.136:29418/platform/manifest.git\u0026gt; -b \u0026lt;branch\u0026gt; -m \u0026lt;manifest_xml\u0026gt; -u:表示git仓库地址 -m:表示具体的xml文件 -b:表示指定特殊的分支 同步\nuser110@server005:~/delete$ repo sync –j8 工作流 创建开发分支 repo start \u0026lt;branch_name\u0026gt; -all 修改 修改代码\n提交 git add \u0026lt;files to be added\u0026gt; git commit -m \u0026#34;xxxxxx\u0026#34; 上传 repo upload or git push origin HEAD:refs/for/\u0026lt;branch_name\u0026gt; repo 目录内容简介 条目 描述 manifests 各种 manifest 配置(每一个对应一种项目配置) 的源代码 manifests.git 管理 manifests 源代码的 .git 文件 manifest.xml repo init 初始化项目时(-m), 从 manifests 里(软)链接过来的对应配置 project.list 所有 project 的清单 project-objects 保存所有 private project 的 git 库 projects 保存所有 public project 的 git 库 repo repo 工具的源代码 ","date":"1 January, 1970","id":120,"permalink":"/posts/repo/","summary":"下载repo工具","tags":"android repo","title":"repo"},{"content":"安装 For ubuntu\n# smbclient 用来测试 samba 服务 sudo apt install samba smbclient For arch\nsudo pacman -Sy samba smbclient 配置文件 /etc/samba/smb.conf 末尾追加如下内容:\n注意这里的 [share] windows 映射网络驱动器的时候路径为: \\\\\u0026lt;ubuntu ip\u0026gt;\\share\n[share] path = /home/username/Public public = yes writable = yes valid users = username //映射时的登陆名 create mask = 0644 force create mode = 0644 directory mask = 0755 force directory mode = 0755 available = yes 设置密码 sudo touch /etc/samba/smbpasswd sudo smbpasswd -a username # then insert password 重启 samba 服务 For ubuntu\nsudo service smbd restart For arch\nsudo systemctl restart smb 测试 samba 服务 smbclient -L //localhost/Public # 如果提示输入密码说明共享服务成功 windows 挂载 samba 共享 两种挂载方式\nwin+r, 输入 ubuntu ip windows 文件管理器, 映射网络驱动器, 输入路径 \\\\\u0026lt;ubuntu ip\u0026gt;\\share Linux CLI 挂载 samba 共享 sudo mount -t cifs -o username=${USER},password=${PASSWORD},uid=\u0026lt;user\u0026gt;,gid=\u0026lt;group\u0026gt; //server-address/folder /mount/path/on/ubuntu uid,gid 指定为对应smb client用户的id，如果不指定挂载后所有文件显示为root:root mode. 多用户多目录 samba 配置 创建共享目录并配置权限 # samba 用户，仅用于配置文件目录用户及用户组，不用于 samba 客户端访问登录账号 sudo useradd samba sudo mkdir /samba sudo mkdir -p /samba/public sudo mkdir -p /samba/software sudo mkdir -p /samba/hardware sudo chown samba:samba /samba -R # sudo chmod 755 /samba -R 创建账号密码 用户添加命令 sudo useradd xxx 默认不会创建 home sudo adduser xxx 默认会创建 home sbin/nologin 不需要这些账号登录服务器权限 # 管理者用户 sudo useradd -s /sbin/nologin henan # 部门级公共用户 sudo useradd -d /samba/software -s /sbin/nologin software sudo useradd -d /samba/hardware -s /sbin/nologin hardware sudo chown samba:samba /samba -R sudo chown software:samba /samba/software sudo chown hardware:samba /samba/hardware chmod 777 /samba/public smbpasswd 命令设置密码，用于 samba 服务中对用户权限进行管理 sudo smbpasswd -a henan sudo smbpasswd -a software sudo smbpasswd -a hardware 参数说明：\n-a 添加用户 -x 删除用户 -d 冻结用户 -n 密码置空 配置samba /etc/samba/smb.conf\n[public] path=/samba/public public=yes writeable=yes browseable=yes create mask=0775 directory mask=0775 [software] path=/samba/software writeable=yes browseable=yes create mask=0775 directory mask=0775 valid users=software,henan [hardware] path=/samba/hardware writeable=yes browseable=yes create mask=0775 directory mask=0775 valid users=hardware,henan 参数项说明：\n参数 说明 comment 注释说明 path 分享资源的完整路径名称，除了路径要正确外，目录的权限也要设正确 browseable 是yes/否no在浏览资源中显示共享目录，若为否则必须指定共享路径才能存取 printable 是yes/否no允许打印 hide dot ftles 是yes/否no隐藏隐藏文件 public 是yes/否no公开共享，若为否则进行身份验证(只有当security = share 时此项才起作用) guest ok 是yes/否no公开共享，若为否则进行身份验证(只有当security = share 时此项才起作用) read only 是yes/否no以只读方式共享当与writable发生冲突时也writable为准 writable 是yes/否no不以只读方式共享当与read only发生冲突时，无视read only vaild users 设定只有此名单内的用户才能访问共享资源(拒绝优先)(用户名/@组名) invalid users 设定只有此名单内的用户不能访问共享资源(拒绝优先)(用户名/@组名) read list 设定此名单内的成员为只读(用户名/@组名) write list 若设定为只读时，则只有此设定的名单内的成员才可作写入动作(用户名/@组名) create mask 建立文件时所给的权限 directory mask 建立目录时所给的权限 force group 指定存取资源时须以此设定的群组使用者进入才能存取(用户名/@组名) force user 指定存取资源时须以此设定的使用者进入才能存取(用户名/@组名) allow hosts 设定只有此网段/IP的用户才能访问共享资源 allwo hosts = 网段 except IP deny hosts 设定只有此网段/IP的用户不能访问共享资源 allow hosts= 本网段指定IP指定IP deny hosts= 指定IP本网段指定IP 解决访问共享时提示多重连接的问题 windows 命令行执行：\nnet use * /del /y ","date":"1 January, 1970","id":121,"permalink":"/posts/samba/","summary":"For ubuntu","tags":"samba linux","title":"samba"},{"content":"注释字体设置 Options-\u0026gt;Style Properties 左边Style Name下找到Comment、Comment Multi Line、Comment Right、Comment Single Line 在右边对应的Font属性框下的Font Name中选“Pick...” 设置自己喜欢的字体然后确定，退回Style Properties界面，Size设为12。 Options-\u0026gt;Save Configuration 背景护眼颜色 在顶部菜单栏依次选择 Option→Preferences，中文版的选择 选项\u0026ndash;\u0026gt;参数选择，选择上面的colors（颜色）选项，箭头移至第二项Window Background( 窗口背景)左键单击选中，再点击右边的Color选项在右边的RGB框输入如下参数：\nR(红) 204 G(绿)232 B(蓝)207 添加到自定义颜色-\u0026gt;确定 ","date":"1 January, 1970","id":122,"permalink":"/posts/sourceinsight/","summary":"在顶部菜单栏依次选择 Option→Preferences，中文版的选择 选项\u0026ndash;\u0026gt;参数选择，选择上面的colors（颜色）选项，箭头移至第二项Window Background( 窗口背景)左键单击选中，再点击右边的Color选项在右边的RGB框输入如下参数：","tags":"SourceInsight","title":"Source Insight"},{"content":"Ubuntu 20.04.6 安装 TP-Link AC1300 USB 无线网卡驱动 确认 Ubuntu 系统信息 lsb_release -a $ lsb_release -a No LSB modules are available. Distributor ID:\tUbuntu Description:\tUbuntu 20.04.6 LTS Release:\t20.04 Codename:\tfocal uname -a $ uname -a Linux kkg12333-HP-ProBook-440-14-inch-G10-Notebook-PC 5.15.0-119-generic #129~20.04.1-Ubuntu SMP Wed Aug 7 13:07:13 UTC 2024 x86_64 x86_64 x86_64 GNU/Linux 安装依赖工具 ## see uname -a sudo apt-get install git linux-headers-5.15.0-119-generic build-essential dkms 下载驱动源码 git clone https://github.com/cilynx/rtl88x2bu.git 驱动安装步骤 cd rtl88x2bu export VER=$(sed -n \u0026#39;s/\\PACKAGE_VERSION=\u0026#34;\\(.*\\)\u0026#34;/\\1/p\u0026#39; dkms.conf) echo ${VER} sudo rsync -rvhP ./ /usr/src/rtl88x2bu-${VER} sudo dkms add -m rtl88x2bu -v ${VER} sudo dkms build -m rtl88x2bu -v ${VER} sudo dkms install -m rtl88x2bu -v ${VER} sudo modprobe 88x2bu 各个安装阶段的日志供参考 VER $ echo ${VER} 5.8.7.1 rsync $ sudo rsync -rvhP ./ /usr/src/rtl88x2bu-${VER} sending incremental file list created directory /usr/src/rtl88x2bu-5.8.7.1 ./ .gitignore 430 100% 0.00kB/s 0:00:00 (xfr#1, to-chk=680/682) Kconfig 130 100% 126.95kB/s 0:00:00 (xfr#2, to-chk=679/682) LICENSE 18.09K 100% 17.25MB/s 0:00:00 (xfr#3, to-chk=678/682) Makefile 72.99K 100% 69.60MB/s 0:00:00 (xfr#4, to-chk=677/682) README.md 8.94K 100% 8.53MB/s 0:00:00 (xfr#5, to-chk=676/682) clean 90 100% 87.89kB/s 0:00:00 (xfr#6, to-chk=675/682) deploy.sh 731 100% 713.87kB/s 0:00:00 (xfr#7, to-chk=674/682) dkms.conf 276 100% 269.53kB/s 0:00:00 (xfr#8, to-chk=673/682) halmac.mk 2.00K 100% 1.91MB/s 0:00:00 (xfr#9, to-chk=672/682) ifcfg-wlan0 51 100% 49.80kB/s 0:00:00 (xfr#10, to-chk=671/682) rtl8822b.mk 1.92K 100% 1.83MB/s 0:00:00 (xfr#11, to-chk=670/682) runwpa 415 100% 405.27kB/s 0:00:00 (xfr#12, to-chk=669/682) wlan0dhcp 294 100% 287.11kB/s 0:00:00 (xfr#13, to-chk=668/682) .github/ .github/workflows/ .github/workflows/build.yml 1.99K 100% 969.24kB/s 0:00:00 (xfr#14, to-chk=660/682) core/ core/rtw_ap.c 156.98K 100% 49.90MB/s 0:00:00 (xfr#15, to-chk=659/682) core/rtw_beamforming.c 58.71K 100% 14.00MB/s 0:00:00 (xfr#16, to-chk=658/682) core/rtw_br_ext.c 46.47K 100% 11.08MB/s 0:00:00 (xfr#17, to-chk=657/682) core/rtw_bt_mp.c 50.55K 100% 12.05MB/s 0:00:00 (xfr#18, to-chk=656/682) core/rtw_btcoex.c 50.67K 100% 9.66MB/s 0:00:00 (xfr#19, to-chk=655/682) core/rtw_btcoex_wifionly.c 1.39K 100% 271.29kB/s 0:00:00 (xfr#20, to-chk=654/682) core/rtw_chplan.c 62.60K 100% 11.94MB/s 0:00:00 (xfr#21, to-chk=653/682) core/rtw_chplan.h 2.97K 100% 580.86kB/s 0:00:00 (xfr#22, to-chk=652/682) core/rtw_cmd.c 157.90K 100% 25.10MB/s 0:00:00 (xfr#23, to-chk=651/682) core/rtw_debug.c 213.16K 100% 29.04MB/s 0:00:00 (xfr#24, to-chk=650/682) core/rtw_eeprom.c 7.07K 100% 985.77kB/s 0:00:00 (xfr#25, to-chk=649/682) core/rtw_ieee80211.c 75.70K 100% 9.02MB/s 0:00:00 (xfr#26, to-chk=648/682) core/rtw_io.c 27.36K 100% 3.26MB/s 0:00:00 (xfr#27, to-chk=647/682) core/rtw_ioctl_query.c 710 100% 86.67kB/s 0:00:00 (xfr#28, to-chk=646/682) core/rtw_ioctl_set.c 23.36K 100% 2.79MB/s 0:00:00 (xfr#29, to-chk=645/682) core/rtw_iol.c 10.98K 100% 1.31MB/s 0:00:00 (xfr#30, to-chk=644/682) core/rtw_mem.c 3.42K 100% 417.72kB/s 0:00:00 (xfr#31, to-chk=643/682) core/rtw_mi.c 42.32K 100% 5.04MB/s 0:00:00 (xfr#32, to-chk=642/682) core/rtw_mlme.c 167.41K 100% 17.74MB/s 0:00:00 (xfr#33, to-chk=641/682) core/rtw_mlme_ext.c 496.20K 100% 39.43MB/s 0:00:00 (xfr#34, to-chk=640/682) core/rtw_mp.c 106.99K 100% 8.50MB/s 0:00:00 (xfr#35, to-chk=639/682) core/rtw_odm.c 16.91K 100% 1.34MB/s 0:00:00 (xfr#36, to-chk=638/682) core/rtw_p2p.c 164.96K 100% 12.10MB/s 0:00:00 (xfr#37, to-chk=637/682) core/rtw_pwrctrl.c 79.81K 100% 5.44MB/s 0:00:00 (xfr#38, to-chk=636/682) core/rtw_recv.c 142.57K 100% 9.71MB/s 0:00:00 (xfr#39, to-chk=635/682) core/rtw_rf.c 39.87K 100% 2.53MB/s 0:00:00 (xfr#40, to-chk=634/682) core/rtw_rm.c 58.98K 100% 3.75MB/s 0:00:00 (xfr#41, to-chk=633/682) core/rtw_rm_fsm.c 23.96K 100% 1.52MB/s 0:00:00 (xfr#42, to-chk=632/682) core/rtw_rm_util.c 9.39K 100% 611.59kB/s 0:00:00 (xfr#43, to-chk=631/682) core/rtw_rson.c 18.26K 100% 1.16MB/s 0:00:00 (xfr#44, to-chk=630/682) core/rtw_sdio.c 4.28K 100% 278.52kB/s 0:00:00 (xfr#45, to-chk=629/682) core/rtw_security.c 95.66K 100% 5.70MB/s 0:00:00 (xfr#46, to-chk=628/682) core/rtw_sreset.c 9.40K 100% 573.91kB/s 0:00:00 (xfr#47, to-chk=627/682) core/rtw_sta_mgt.c 36.96K 100% 2.20MB/s 0:00:00 (xfr#48, to-chk=626/682) core/rtw_tdls.c 109.44K 100% 6.14MB/s 0:00:00 (xfr#49, to-chk=625/682) core/rtw_vht.c 38.23K 100% 2.14MB/s 0:00:00 (xfr#50, to-chk=624/682) core/rtw_wapi.c 42.74K 100% 2.40MB/s 0:00:00 (xfr#51, to-chk=623/682) core/rtw_wapi_sms4.c 27.65K 100% 1.55MB/s 0:00:00 (xfr#52, to-chk=622/682) core/rtw_wlan_util.c 131.89K 100% 6.99MB/s 0:00:00 (xfr#53, to-chk=621/682) core/rtw_xmit.c 161.66K 100% 8.57MB/s 0:00:00 (xfr#54, to-chk=620/682) core/efuse/ core/efuse/rtw_efuse.c 92.04K 100% 4.62MB/s 0:00:00 (xfr#55, to-chk=617/682) core/mesh/ core/mesh/rtw_mesh.c 114.13K 100% 5.44MB/s 0:00:00 (xfr#56, to-chk=616/682) core/mesh/rtw_mesh.h 20.47K 100% 999.37kB/s 0:00:00 (xfr#57, to-chk=615/682) core/mesh/rtw_mesh_hwmp.c 49.27K 100% 2.35MB/s 0:00:00 (xfr#58, to-chk=614/682) core/mesh/rtw_mesh_hwmp.h 2.15K 100% 105.22kB/s 0:00:00 (xfr#59, to-chk=613/682) core/mesh/rtw_mesh_pathtbl.c 33.22K 100% 1.51MB/s 0:00:00 (xfr#60, to-chk=612/682) core/mesh/rtw_mesh_pathtbl.h 7.61K 100% 353.98kB/s 0:00:00 (xfr#61, to-chk=611/682) hal/ hal/HalPwrSeqCmd.c 5.52K 100% 256.65kB/s 0:00:00 (xfr#62, to-chk=610/682) hal/hal_btcoex.c 177.62K 100% 7.70MB/s 0:00:00 (xfr#63, to-chk=609/682) hal/hal_btcoex_wifionly.c 7.65K 100% 339.40kB/s 0:00:00 (xfr#64, to-chk=608/682) hal/hal_com.c 446.84K 100% 17.76MB/s 0:00:00 (xfr#65, to-chk=607/682) hal/hal_com_c2h.h 4.47K 100% 181.80kB/s 0:00:00 (xfr#66, to-chk=606/682) hal/hal_com_phycfg.c 178.02K 100% 6.79MB/s 0:00:00 (xfr#67, to-chk=605/682) hal/hal_dm.c 55.97K 100% 2.14MB/s 0:00:00 (xfr#68, to-chk=604/682) hal/hal_dm.h 3.66K 100% 143.05kB/s 0:00:00 (xfr#69, to-chk=603/682) hal/hal_dm_acs.c 17.45K 100% 681.72kB/s 0:00:00 (xfr#70, to-chk=602/682) hal/hal_dm_acs.h 5.50K 100% 215.04kB/s 0:00:00 (xfr#71, to-chk=601/682) hal/hal_halmac.c 131.59K 100% 5.02MB/s 0:00:00 (xfr#72, to-chk=600/682) hal/hal_halmac.h 10.77K 100% 420.62kB/s 0:00:00 (xfr#73, to-chk=599/682) hal/hal_intf.c 53.64K 100% 2.05MB/s 0:00:00 (xfr#74, to-chk=598/682) hal/hal_mcc.c 123.79K 100% 4.54MB/s 0:00:00 (xfr#75, to-chk=597/682) hal/hal_mp.c 93.97K 100% 3.45MB/s 0:00:00 (xfr#76, to-chk=596/682) hal/hal_phy.c 6.37K 100% 239.15kB/s 0:00:00 (xfr#77, to-chk=595/682) hal/btc/ hal/btc/btc_basic_types.h 1.25K 100% 46.84kB/s 0:00:00 (xfr#78, to-chk=587/682) hal/btc/halbtc8822b1ant.c 171.65K 100% 6.30MB/s 0:00:00 (xfr#79, to-chk=586/682) hal/btc/halbtc8822b1ant.h 14.61K 100% 548.90kB/s 0:00:00 (xfr#80, to-chk=585/682) hal/btc/halbtc8822b2ant.c 171.09K 100% 6.04MB/s 0:00:00 (xfr#81, to-chk=584/682) hal/btc/halbtc8822b2ant.h 14.62K 100% 528.90kB/s 0:00:00 (xfr#82, to-chk=583/682) hal/btc/halbtc8822bwifionly.c 2.19K 100% 79.28kB/s 0:00:00 (xfr#83, to-chk=582/682) hal/btc/halbtc8822bwifionly.h 1.23K 100% 44.60kB/s 0:00:00 (xfr#84, to-chk=581/682) hal/btc/halbtcoutsrc.h 48.32K 100% 1.71MB/s 0:00:00 (xfr#85, to-chk=580/682) hal/btc/mp_precomp.h 3.21K 100% 116.25kB/s 0:00:00 (xfr#86, to-chk=579/682) hal/efuse/ hal/efuse/efuse_mask.h 4.32K 100% 156.29kB/s 0:00:00 (xfr#87, to-chk=578/682) hal/efuse/rtl8822b/ hal/efuse/rtl8822b/HalEfuseMask8822B_PCIE.c 1.87K 100% 67.67kB/s 0:00:00 (xfr#88, to-chk=576/682) hal/efuse/rtl8822b/HalEfuseMask8822B_PCIE.h 1.01K 100% 36.64kB/s 0:00:00 (xfr#89, to-chk=575/682) hal/efuse/rtl8822b/HalEfuseMask8822B_SDIO.c 1.82K 100% 65.94kB/s 0:00:00 (xfr#90, to-chk=574/682) hal/efuse/rtl8822b/HalEfuseMask8822B_SDIO.h 1.01K 100% 36.68kB/s 0:00:00 (xfr#91, to-chk=573/682) hal/efuse/rtl8822b/HalEfuseMask8822B_USB.c 1.86K 100% 67.24kB/s 0:00:00 (xfr#92, to-chk=572/682) hal/efuse/rtl8822b/HalEfuseMask8822B_USB.h 1.01K 100% 36.53kB/s 0:00:00 (xfr#93, to-chk=571/682) hal/hal_hci/ hal/hal_hci/hal_usb.c 13.36K 100% 483.15kB/s 0:00:00 (xfr#94, to-chk=570/682) hal/halmac/ hal/halmac/halmac_2_platform.h 2.86K 100% 103.55kB/s 0:00:00 (xfr#95, to-chk=569/682) hal/halmac/halmac_api.c 18.54K 100% 670.57kB/s 0:00:00 (xfr#96, to-chk=568/682) hal/halmac/halmac_api.h 3.44K 100% 124.42kB/s 0:00:00 (xfr#97, to-chk=567/682) hal/halmac/halmac_bit2.h 2.86M 100% 82.75MB/s 0:00:00 (xfr#98, to-chk=566/682) hal/halmac/halmac_bit_8197f.h 920.02K 100% 24.37MB/s 0:00:00 (xfr#99, to-chk=565/682) hal/halmac/halmac_bit_8812f.h 1.14M 100% 27.87MB/s 0:00:00 (xfr#100, to-chk=564/682) hal/halmac/halmac_bit_8814b.h 1.36M 100% 30.80MB/s 0:00:00 (xfr#101, to-chk=563/682) hal/halmac/halmac_bit_8821c.h 1.00M 100% 21.76MB/s 0:00:00 (xfr#102, to-chk=562/682) hal/halmac/halmac_bit_8822b.h 951.76K 100% 20.17MB/s 0:00:00 (xfr#103, to-chk=561/682) hal/halmac/halmac_bit_8822c.h 1.13M 100% 22.92MB/s 0:00:00 (xfr#104, to-chk=560/682) hal/halmac/halmac_dbg.c 4.50K 100% 93.42kB/s 0:00:00 (xfr#105, to-chk=559/682) hal/halmac/halmac_dbg.h 862 100% 17.91kB/s 0:00:00 (xfr#106, to-chk=558/682) hal/halmac/halmac_fw_info.h 5.07K 100% 105.26kB/s 0:00:00 (xfr#107, to-chk=557/682) hal/halmac/halmac_fw_offload_c2h_ap.h 43.62K 100% 887.47kB/s 0:00:00 (xfr#108, to-chk=556/682) hal/halmac/halmac_fw_offload_c2h_nic.h 31.04K 100% 631.43kB/s 0:00:00 (xfr#109, to-chk=555/682) hal/halmac/halmac_fw_offload_h2c_ap.h 76.42K 100% 1.52MB/s 0:00:00 (xfr#110, to-chk=554/682) hal/halmac/halmac_fw_offload_h2c_nic.h 52.44K 100% 1.04MB/s 0:00:00 (xfr#111, to-chk=553/682) hal/halmac/halmac_gpio_cmd.h 3.00K 100% 61.10kB/s 0:00:00 (xfr#112, to-chk=552/682) hal/halmac/halmac_h2c_extra_info_ap.h 14.64K 100% 297.93kB/s 0:00:00 (xfr#113, to-chk=551/682) hal/halmac/halmac_h2c_extra_info_nic.h 10.31K 100% 209.68kB/s 0:00:00 (xfr#114, to-chk=550/682) hal/halmac/halmac_hw_cfg.h 3.86K 100% 78.61kB/s 0:00:00 (xfr#115, to-chk=549/682) hal/halmac/halmac_intf_phy_cmd.h 1.43K 100% 29.05kB/s 0:00:00 (xfr#116, to-chk=548/682) hal/halmac/halmac_original_c2h_ap.h 44.00K 100% 895.20kB/s 0:00:00 (xfr#117, to-chk=547/682) hal/halmac/halmac_original_c2h_nic.h 29.35K 100% 597.19kB/s 0:00:00 (xfr#118, to-chk=546/682) hal/halmac/halmac_original_h2c_ap.h 105.41K 100% 2.09MB/s 0:00:00 (xfr#119, to-chk=545/682) hal/halmac/halmac_original_h2c_nic.h 71.53K 100% 1.39MB/s 0:00:00 (xfr#120, to-chk=544/682) hal/halmac/halmac_pcie_reg.h 1.76K 100% 35.04kB/s 0:00:00 (xfr#121, to-chk=543/682) hal/halmac/halmac_pwr_seq_cmd.h 2.80K 100% 55.84kB/s 0:00:00 (xfr#122, to-chk=542/682) hal/halmac/halmac_reg2.h 225.09K 100% 4.38MB/s 0:00:00 (xfr#123, to-chk=541/682) hal/halmac/halmac_reg_8197f.h 26.70K 100% 532.19kB/s 0:00:00 (xfr#124, to-chk=540/682) hal/halmac/halmac_reg_8812f.h 34.24K 100% 682.34kB/s 0:00:00 (xfr#125, to-chk=539/682) hal/halmac/halmac_reg_8814b.h 42.06K 100% 838.21kB/s 0:00:00 (xfr#126, to-chk=538/682) hal/halmac/halmac_reg_8821c.h 30.90K 100% 615.75kB/s 0:00:00 (xfr#127, to-chk=537/682) hal/halmac/halmac_reg_8822b.h 27.98K 100% 557.64kB/s 0:00:00 (xfr#128, to-chk=536/682) hal/halmac/halmac_reg_8822c.h 33.95K 100% 663.07kB/s 0:00:00 (xfr#129, to-chk=535/682) hal/halmac/halmac_rx_bd_nic.h 1.60K 100% 31.17kB/s 0:00:00 (xfr#130, to-chk=534/682) hal/halmac/halmac_rx_desc_ap.h 25.52K 100% 498.48kB/s 0:00:00 (xfr#131, to-chk=533/682) hal/halmac/halmac_rx_desc_chip.h 43.01K 100% 840.10kB/s 0:00:00 (xfr#132, to-chk=532/682) hal/halmac/halmac_rx_desc_nic.h 17.85K 100% 348.65kB/s 0:00:00 (xfr#133, to-chk=531/682) hal/halmac/halmac_sdio_reg.h 1.95K 100% 38.01kB/s 0:00:00 (xfr#134, to-chk=530/682) hal/halmac/halmac_state_machine.h 4.34K 100% 84.84kB/s 0:00:00 (xfr#135, to-chk=529/682) hal/halmac/halmac_tx_bd_nic.h 4.64K 100% 90.61kB/s 0:00:00 (xfr#136, to-chk=528/682) hal/halmac/halmac_tx_desc_ap.h 112.81K 100% 2.15MB/s 0:00:00 (xfr#137, to-chk=527/682) hal/halmac/halmac_tx_desc_buffer_ap.h 65.44K 100% 1.25MB/s 0:00:00 (xfr#138, to-chk=526/682) hal/halmac/halmac_tx_desc_buffer_chip.h 28.72K 100% 560.86kB/s 0:00:00 (xfr#139, to-chk=525/682) hal/halmac/halmac_tx_desc_buffer_nic.h 28.74K 100% 561.35kB/s 0:00:00 (xfr#140, to-chk=524/682) hal/halmac/halmac_tx_desc_chip.h 201.65K 100% 3.77MB/s 0:00:00 (xfr#141, to-chk=523/682) hal/halmac/halmac_tx_desc_ie_ap.h 66.78K 100% 1.25MB/s 0:00:00 (xfr#142, to-chk=522/682) hal/halmac/halmac_tx_desc_ie_chip.h 26.56K 100% 508.50kB/s 0:00:00 (xfr#143, to-chk=521/682) hal/halmac/halmac_tx_desc_ie_nic.h 28.46K 100% 545.00kB/s 0:00:00 (xfr#144, to-chk=520/682) hal/halmac/halmac_tx_desc_nic.h 52.71K 100% 1009.31kB/s 0:00:00 (xfr#145, to-chk=519/682) hal/halmac/halmac_type.h 79.74K 100% 1.49MB/s 0:00:00 (xfr#146, to-chk=518/682) hal/halmac/halmac_usb_reg.h 771 100% 14.76kB/s 0:00:00 (xfr#147, to-chk=517/682) hal/halmac/halmac_88xx/ hal/halmac/halmac_88xx/halmac_88xx_cfg.h 1.38K 100% 26.37kB/s 0:00:00 (xfr#148, to-chk=515/682) hal/halmac/halmac_88xx/halmac_bb_rf_88xx.c 11.61K 100% 222.35kB/s 0:00:00 (xfr#149, to-chk=514/682) hal/halmac/halmac_88xx/halmac_bb_rf_88xx.h 1.89K 100% 36.21kB/s 0:00:00 (xfr#150, to-chk=513/682) hal/halmac/halmac_88xx/halmac_cfg_wmac_88xx.c 30.50K 100% 583.97kB/s 0:00:00 (xfr#151, to-chk=512/682) hal/halmac/halmac_88xx/halmac_cfg_wmac_88xx.h 4.05K 100% 77.63kB/s 0:00:00 (xfr#152, to-chk=511/682) hal/halmac/halmac_88xx/halmac_common_88xx.c 95.66K 100% 1.75MB/s 0:00:00 (xfr#153, to-chk=510/682) hal/halmac/halmac_88xx/halmac_common_88xx.h 5.22K 100% 97.96kB/s 0:00:00 (xfr#154, to-chk=509/682) hal/halmac/halmac_88xx/halmac_efuse_88xx.c 59.19K 100% 1.09MB/s 0:00:00 (xfr#155, to-chk=508/682) hal/halmac/halmac_88xx/halmac_efuse_88xx.h 4.14K 100% 77.71kB/s 0:00:00 (xfr#156, to-chk=507/682) hal/halmac/halmac_88xx/halmac_flash_88xx.c 9.26K 100% 173.87kB/s 0:00:00 (xfr#157, to-chk=506/682) hal/halmac/halmac_88xx/halmac_flash_88xx.h 1.29K 100% 24.26kB/s 0:00:00 (xfr#158, to-chk=505/682) hal/halmac/halmac_88xx/halmac_fw_88xx.c 32.93K 100% 618.35kB/s 0:00:00 (xfr#159, to-chk=504/682) hal/halmac/halmac_88xx/halmac_fw_88xx.h 2.02K 100% 38.01kB/s 0:00:00 (xfr#160, to-chk=503/682) hal/halmac/halmac_88xx/halmac_gpio_88xx.c 6.63K 100% 124.53kB/s 0:00:00 (xfr#161, to-chk=502/682) hal/halmac/halmac_88xx/halmac_gpio_88xx.h 1.63K 100% 30.65kB/s 0:00:00 (xfr#162, to-chk=501/682) hal/halmac/halmac_88xx/halmac_init_88xx.c 29.51K 100% 554.22kB/s 0:00:00 (xfr#163, to-chk=500/682) hal/halmac/halmac_88xx/halmac_init_88xx.h 1.97K 100% 37.00kB/s 0:00:00 (xfr#164, to-chk=499/682) hal/halmac/halmac_88xx/halmac_mimo_88xx.c 26.05K 100% 489.13kB/s 0:00:00 (xfr#165, to-chk=498/682) hal/halmac/halmac_88xx/halmac_mimo_88xx.h 2.71K 100% 50.95kB/s 0:00:00 (xfr#166, to-chk=497/682) hal/halmac/halmac_88xx/halmac_usb_88xx.c 13.89K 100% 260.87kB/s 0:00:00 (xfr#167, to-chk=496/682) hal/halmac/halmac_88xx/halmac_usb_88xx.h 2.72K 100% 51.03kB/s 0:00:00 (xfr#168, to-chk=495/682) hal/halmac/halmac_88xx/halmac_8822b/ hal/halmac/halmac_88xx/halmac_8822b/halmac_8822b_cfg.h 2.65K 100% 49.67kB/s 0:00:00 (xfr#169, to-chk=493/682) hal/halmac/halmac_88xx/halmac_8822b/halmac_cfg_wmac_8822b.c 3.98K 100% 74.74kB/s 0:00:00 (xfr#170, to-chk=492/682) hal/halmac/halmac_88xx/halmac_8822b/halmac_cfg_wmac_8822b.h 1.28K 100% 23.96kB/s 0:00:00 (xfr#171, to-chk=491/682) hal/halmac/halmac_88xx/halmac_8822b/halmac_common_8822b.c 4.61K 100% 86.56kB/s 0:00:00 (xfr#172, to-chk=490/682) hal/halmac/halmac_88xx/halmac_8822b/halmac_common_8822b.h 1.21K 100% 22.65kB/s 0:00:00 (xfr#173, to-chk=489/682) hal/halmac/halmac_88xx/halmac_8822b/halmac_gpio_8822b.c 30.92K 100% 580.60kB/s 0:00:00 (xfr#174, to-chk=488/682) hal/halmac/halmac_88xx/halmac_8822b/halmac_gpio_8822b.h 1.27K 100% 23.94kB/s 0:00:00 (xfr#175, to-chk=487/682) hal/halmac/halmac_88xx/halmac_8822b/halmac_init_8822b.c 34.06K 100% 639.67kB/s 0:00:00 (xfr#176, to-chk=486/682) hal/halmac/halmac_88xx/halmac_8822b/halmac_init_8822b.h 1.51K 100% 28.38kB/s 0:00:00 (xfr#177, to-chk=485/682) hal/halmac/halmac_88xx/halmac_8822b/halmac_phy_8822b.c 4.39K 100% 82.44kB/s 0:00:00 (xfr#178, to-chk=484/682) hal/halmac/halmac_88xx/halmac_8822b/halmac_pwr_seq_8822b.c 24.52K 100% 460.51kB/s 0:00:00 (xfr#179, to-chk=483/682) hal/halmac/halmac_88xx/halmac_8822b/halmac_pwr_seq_8822b.h 1.43K 100% 26.93kB/s 0:00:00 (xfr#180, to-chk=482/682) hal/halmac/halmac_88xx/halmac_8822b/halmac_usb_8822b.c 4.66K 100% 87.48kB/s 0:00:00 (xfr#181, to-chk=481/682) hal/halmac/halmac_88xx/halmac_8822b/halmac_usb_8822b.h 1.43K 100% 26.80kB/s 0:00:00 (xfr#182, to-chk=480/682) hal/led/ hal/led/hal_led.c 6.53K 100% 120.34kB/s 0:00:00 (xfr#183, to-chk=479/682) hal/led/hal_usb_led.c 112.28K 100% 2.02MB/s 0:00:00 (xfr#184, to-chk=478/682) hal/phydm/ hal/phydm/ap_makefile.mk 7.04K 100% 129.66kB/s 0:00:00 (xfr#185, to-chk=477/682) hal/phydm/halhwimg.h 4.12K 100% 75.95kB/s 0:00:00 (xfr#186, to-chk=476/682) hal/phydm/mp_precomp.h 968 100% 17.84kB/s 0:00:00 (xfr#187, to-chk=475/682) hal/phydm/phydm.c 86.98K 100% 1.57MB/s 0:00:00 (xfr#188, to-chk=474/682) hal/phydm/phydm.h 39.73K 100% 731.96kB/s 0:00:00 (xfr#189, to-chk=473/682) hal/phydm/phydm.mk 8.46K 100% 155.94kB/s 0:00:00 (xfr#190, to-chk=472/682) hal/phydm/phydm_adaptivity.c 23.76K 100% 437.85kB/s 0:00:00 (xfr#191, to-chk=471/682) hal/phydm/phydm_adaptivity.h 3.55K 100% 65.39kB/s 0:00:00 (xfr#192, to-chk=470/682) hal/phydm/phydm_adc_sampling.c 50.78K 100% 935.58kB/s 0:00:00 (xfr#193, to-chk=469/682) hal/phydm/phydm_adc_sampling.h 4.69K 100% 86.42kB/s 0:00:00 (xfr#194, to-chk=468/682) hal/phydm/phydm_antdect.c 34.01K 100% 626.60kB/s 0:00:00 (xfr#195, to-chk=467/682) hal/phydm/phydm_antdect.h 2.18K 100% 40.17kB/s 0:00:00 (xfr#196, to-chk=466/682) hal/phydm/phydm_antdiv.c 196.22K 100% 3.47MB/s 0:00:00 (xfr#197, to-chk=465/682) hal/phydm/phydm_antdiv.h 14.87K 100% 268.92kB/s 0:00:00 (xfr#198, to-chk=464/682) hal/phydm/phydm_api.c 88.68K 100% 1.57MB/s 0:00:00 (xfr#199, to-chk=463/682) hal/phydm/phydm_api.h 6.21K 100% 112.23kB/s 0:00:00 (xfr#200, to-chk=462/682) hal/phydm/phydm_auto_dbg.c 22.11K 100% 399.88kB/s 0:00:00 (xfr#201, to-chk=461/682) hal/phydm/phydm_auto_dbg.h 2.94K 100% 53.13kB/s 0:00:00 (xfr#202, to-chk=460/682) hal/phydm/phydm_beamforming.c 65.30K 100% 1.15MB/s 0:00:00 (xfr#203, to-chk=459/682) hal/phydm/phydm_beamforming.h 9.68K 100% 175.11kB/s 0:00:00 (xfr#204, to-chk=458/682) hal/phydm/phydm_cck_pd.c 31.92K 100% 577.22kB/s 0:00:00 (xfr#205, to-chk=457/682) hal/phydm/phydm_cck_pd.h 4.75K 100% 85.85kB/s 0:00:00 (xfr#206, to-chk=456/682) hal/phydm/phydm_cck_rx_pathdiv.c 4.99K 100% 88.53kB/s 0:00:00 (xfr#207, to-chk=455/682) hal/phydm/phydm_cck_rx_pathdiv.h 2.19K 100% 38.94kB/s 0:00:00 (xfr#208, to-chk=454/682) hal/phydm/phydm_ccx.c 58.23K 100% 1.01MB/s 0:00:00 (xfr#209, to-chk=453/682) hal/phydm/phydm_ccx.h 7.35K 100% 130.43kB/s 0:00:00 (xfr#210, to-chk=452/682) hal/phydm/phydm_cfotracking.c 18.44K 100% 327.41kB/s 0:00:00 (xfr#211, to-chk=451/682) hal/phydm/phydm_cfotracking.h 2.37K 100% 42.12kB/s 0:00:00 (xfr#212, to-chk=450/682) hal/phydm/phydm_debug.c 181.82K 100% 3.15MB/s 0:00:00 (xfr#213, to-chk=449/682) hal/phydm/phydm_debug.h 13.12K 100% 232.99kB/s 0:00:00 (xfr#214, to-chk=448/682) hal/phydm/phydm_dfs.c 82.36K 100% 1.43MB/s 0:00:00 (xfr#215, to-chk=447/682) hal/phydm/phydm_dfs.h 5.37K 100% 95.40kB/s 0:00:00 (xfr#216, to-chk=446/682) hal/phydm/phydm_dig.c 89.78K 100% 1.53MB/s 0:00:00 (xfr#217, to-chk=445/682) hal/phydm/phydm_dig.h 8.81K 100% 153.58kB/s 0:00:00 (xfr#218, to-chk=444/682) hal/phydm/phydm_direct_bf.c 11.79K 100% 205.51kB/s 0:00:00 (xfr#219, to-chk=443/682) hal/phydm/phydm_direct_bf.h 1.56K 100% 27.20kB/s 0:00:00 (xfr#220, to-chk=442/682) hal/phydm/phydm_dynamictxpower.c 21.56K 100% 376.03kB/s 0:00:00 (xfr#221, to-chk=441/682) hal/phydm/phydm_dynamictxpower.h 3.93K 100% 68.50kB/s 0:00:00 (xfr#222, to-chk=440/682) hal/phydm/phydm_features.h 2.46K 100% 42.81kB/s 0:00:00 (xfr#223, to-chk=439/682) hal/phydm/phydm_features_ap.h 6.30K 100% 109.85kB/s 0:00:00 (xfr#224, to-chk=438/682) hal/phydm/phydm_features_ce.h 5.57K 100% 97.15kB/s 0:00:00 (xfr#225, to-chk=437/682) hal/phydm/phydm_features_ce2_kernel.h 2.27K 100% 39.59kB/s 0:00:00 (xfr#226, to-chk=436/682) hal/phydm/phydm_features_iot.h 4.39K 100% 76.63kB/s 0:00:00 (xfr#227, to-chk=435/682) hal/phydm/phydm_features_win.h 5.12K 100% 89.30kB/s 0:00:00 (xfr#228, to-chk=434/682) hal/phydm/phydm_hwconfig.c 52.16K 100% 909.56kB/s 0:00:00 (xfr#229, to-chk=433/682) hal/phydm/phydm_hwconfig.h 2.75K 100% 47.97kB/s 0:00:00 (xfr#230, to-chk=432/682) hal/phydm/phydm_interface.c 44.75K 100% 780.38kB/s 0:00:00 (xfr#231, to-chk=431/682) hal/phydm/phydm_interface.h 9.73K 100% 169.70kB/s 0:00:00 (xfr#232, to-chk=430/682) hal/phydm/phydm_lna_sat.c 39.02K 100% 680.51kB/s 0:00:00 (xfr#233, to-chk=429/682) hal/phydm/phydm_lna_sat.h 4.64K 100% 80.88kB/s 0:00:00 (xfr#234, to-chk=428/682) hal/phydm/phydm_math_lib.c 6.14K 100% 107.06kB/s 0:00:00 (xfr#235, to-chk=427/682) hal/phydm/phydm_math_lib.h 3.70K 100% 64.52kB/s 0:00:00 (xfr#236, to-chk=426/682) hal/phydm/phydm_mp.c 10.74K 100% 187.29kB/s 0:00:00 (xfr#237, to-chk=425/682) hal/phydm/phydm_mp.h 2.75K 100% 47.87kB/s 0:00:00 (xfr#238, to-chk=424/682) hal/phydm/phydm_noisemonitor.c 13.66K 100% 238.30kB/s 0:00:00 (xfr#239, to-chk=423/682) hal/phydm/phydm_noisemonitor.h 1.45K 100% 25.36kB/s 0:00:00 (xfr#240, to-chk=422/682) hal/phydm/phydm_pathdiv.c 32.38K 100% 554.69kB/s 0:00:00 (xfr#241, to-chk=421/682) hal/phydm/phydm_pathdiv.h 3.92K 100% 67.14kB/s 0:00:00 (xfr#242, to-chk=420/682) hal/phydm/phydm_phystatus.c 97.06K 100% 1.62MB/s 0:00:00 (xfr#243, to-chk=419/682) hal/phydm/phydm_phystatus.h 23.29K 100% 399.00kB/s 0:00:00 (xfr#244, to-chk=418/682) hal/phydm/phydm_pmac_tx_setting.c 15.45K 100% 264.75kB/s 0:00:00 (xfr#245, to-chk=417/682) hal/phydm/phydm_pmac_tx_setting.h 3.19K 100% 54.64kB/s 0:00:00 (xfr#246, to-chk=416/682) hal/phydm/phydm_pow_train.c 5.14K 100% 87.99kB/s 0:00:00 (xfr#247, to-chk=415/682) hal/phydm/phydm_pow_train.h 2.73K 100% 46.79kB/s 0:00:00 (xfr#248, to-chk=414/682) hal/phydm/phydm_pre_define.h 25.55K 100% 437.83kB/s 0:00:00 (xfr#249, to-chk=413/682) hal/phydm/phydm_precomp.h 18.14K 100% 310.72kB/s 0:00:00 (xfr#250, to-chk=412/682) hal/phydm/phydm_primary_cca.c 4.86K 100% 83.20kB/s 0:00:00 (xfr#251, to-chk=411/682) hal/phydm/phydm_primary_cca.h 2.96K 100% 50.63kB/s 0:00:00 (xfr#252, to-chk=410/682) hal/phydm/phydm_psd.c 14.97K 100% 256.42kB/s 0:00:00 (xfr#253, to-chk=409/682) hal/phydm/phydm_psd.h 1.98K 100% 33.84kB/s 0:00:00 (xfr#254, to-chk=408/682) hal/phydm/phydm_rainfo.c 62.64K 100% 1.05MB/s 0:00:00 (xfr#255, to-chk=407/682) hal/phydm/phydm_rainfo.h 7.94K 100% 136.00kB/s 0:00:00 (xfr#256, to-chk=406/682) hal/phydm/phydm_reg.h 9.33K 100% 159.80kB/s 0:00:00 (xfr#257, to-chk=405/682) hal/phydm/phydm_regdefine11ac.h 3.49K 100% 59.86kB/s 0:00:00 (xfr#258, to-chk=404/682) hal/phydm/phydm_regdefine11n.h 7.76K 100% 130.64kB/s 0:00:00 (xfr#259, to-chk=403/682) hal/phydm/phydm_regtable.h 21.60K 100% 363.67kB/s 0:00:00 (xfr#260, to-chk=402/682) hal/phydm/phydm_rssi_monitor.c 4.52K 100% 76.05kB/s 0:00:00 (xfr#261, to-chk=401/682) hal/phydm/phydm_rssi_monitor.h 1.80K 100% 30.31kB/s 0:00:00 (xfr#262, to-chk=400/682) hal/phydm/phydm_smt_ant.c 74.55K 100% 1.23MB/s 0:00:00 (xfr#263, to-chk=399/682) hal/phydm/phydm_smt_ant.h 6.91K 100% 116.33kB/s 0:00:00 (xfr#264, to-chk=398/682) hal/phydm/phydm_soml.c 48.07K 100% 809.35kB/s 0:00:00 (xfr#265, to-chk=397/682) hal/phydm/phydm_soml.h 5.34K 100% 89.93kB/s 0:00:00 (xfr#266, to-chk=396/682) hal/phydm/phydm_types.h 8.43K 100% 141.94kB/s 0:00:00 (xfr#267, to-chk=395/682) hal/phydm/sd4_phydm_2_kernel.mk 6.73K 100% 113.31kB/s 0:00:00 (xfr#268, to-chk=394/682) hal/phydm/halrf/ hal/phydm/halrf/halphyrf_ap.c 71.47K 100% 1.18MB/s 0:00:00 (xfr#269, to-chk=390/682) hal/phydm/halrf/halphyrf_ap.h 4.32K 100% 72.79kB/s 0:00:00 (xfr#270, to-chk=389/682) hal/phydm/halrf/halphyrf_ce.c 41.70K 100% 702.08kB/s 0:00:00 (xfr#271, to-chk=388/682) hal/phydm/halrf/halphyrf_ce.h 3.50K 100% 58.93kB/s 0:00:00 (xfr#272, to-chk=387/682) hal/phydm/halrf/halphyrf_iot.c 26.20K 100% 441.14kB/s 0:00:00 (xfr#273, to-chk=386/682) hal/phydm/halrf/halphyrf_iot.h 3.34K 100% 56.25kB/s 0:00:00 (xfr#274, to-chk=385/682) hal/phydm/halrf/halphyrf_win.c 46.28K 100% 779.20kB/s 0:00:00 (xfr#275, to-chk=384/682) hal/phydm/halrf/halphyrf_win.h 3.33K 100% 56.03kB/s 0:00:00 (xfr#276, to-chk=383/682) hal/phydm/halrf/halrf.c 77.28K 100% 1.25MB/s 0:00:00 (xfr#277, to-chk=382/682) hal/phydm/halrf/halrf.h 24.93K 100% 412.59kB/s 0:00:00 (xfr#278, to-chk=381/682) hal/phydm/halrf/halrf_debug.c 9.35K 100% 154.76kB/s 0:00:00 (xfr#279, to-chk=380/682) hal/phydm/halrf/halrf_debug.h 3.88K 100% 64.20kB/s 0:00:00 (xfr#280, to-chk=379/682) hal/phydm/halrf/halrf_dpk.h 3.85K 100% 63.64kB/s 0:00:00 (xfr#281, to-chk=378/682) hal/phydm/halrf/halrf_features.h 1.31K 100% 21.62kB/s 0:00:00 (xfr#282, to-chk=377/682) hal/phydm/halrf/halrf_iqk.h 3.54K 100% 58.51kB/s 0:00:00 (xfr#283, to-chk=376/682) hal/phydm/halrf/halrf_kfree.c 90.49K 100% 1.46MB/s 0:00:00 (xfr#284, to-chk=375/682) hal/phydm/halrf/halrf_kfree.h 5.77K 100% 95.50kB/s 0:00:00 (xfr#285, to-chk=374/682) hal/phydm/halrf/halrf_powertracking.c 5.62K 100% 93.10kB/s 0:00:00 (xfr#286, to-chk=373/682) hal/phydm/halrf/halrf_powertracking.h 1.40K 100% 23.24kB/s 0:00:00 (xfr#287, to-chk=372/682) hal/phydm/halrf/halrf_powertracking_ap.c 54.71K 100% 905.52kB/s 0:00:00 (xfr#288, to-chk=371/682) hal/phydm/halrf/halrf_powertracking_ap.h 12.43K 100% 205.77kB/s 0:00:00 (xfr#289, to-chk=370/682) hal/phydm/halrf/halrf_powertracking_ce.c 33.22K 100% 549.84kB/s 0:00:00 (xfr#290, to-chk=369/682) hal/phydm/halrf/halrf_powertracking_ce.h 10.66K 100% 176.49kB/s 0:00:00 (xfr#291, to-chk=368/682) hal/phydm/halrf/halrf_powertracking_iot.c 30.48K 100% 504.47kB/s 0:00:00 (xfr#292, to-chk=367/682) hal/phydm/halrf/halrf_powertracking_iot.h 11.58K 100% 191.62kB/s 0:00:00 (xfr#293, to-chk=366/682) hal/phydm/halrf/halrf_powertracking_win.c 34.30K 100% 567.75kB/s 0:00:00 (xfr#294, to-chk=365/682) hal/phydm/halrf/halrf_powertracking_win.h 10.07K 100% 166.76kB/s 0:00:00 (xfr#295, to-chk=364/682) hal/phydm/halrf/halrf_psd.c 12.66K 100% 206.04kB/s 0:00:00 (xfr#296, to-chk=363/682) hal/phydm/halrf/halrf_psd.h 1.12K 100% 18.21kB/s 0:00:00 (xfr#297, to-chk=362/682) hal/phydm/halrf/halrf_txgapcal.c 9.86K 100% 160.47kB/s 0:00:00 (xfr#298, to-chk=361/682) hal/phydm/halrf/halrf_txgapcal.h 1.11K 100% 18.07kB/s 0:00:00 (xfr#299, to-chk=360/682) hal/phydm/halrf/rtl8822b/ hal/phydm/halrf/rtl8822b/halhwimg8822b_rf.c 707.87K 100% 11.07MB/s 0:00:00 (xfr#300, to-chk=358/682) hal/phydm/halrf/rtl8822b/halhwimg8822b_rf.h 16.67K 100% 266.94kB/s 0:00:00 (xfr#301, to-chk=357/682) hal/phydm/halrf/rtl8822b/halrf_8822b.c 19.43K 100% 311.03kB/s 0:00:00 (xfr#302, to-chk=356/682) hal/phydm/halrf/rtl8822b/halrf_8822b.h 2.15K 100% 34.34kB/s 0:00:00 (xfr#303, to-chk=355/682) hal/phydm/halrf/rtl8822b/halrf_iqk_8822b.c 61.52K 100% 984.94kB/s 0:00:00 (xfr#304, to-chk=354/682) hal/phydm/halrf/rtl8822b/halrf_iqk_8822b.h 2.35K 100% 37.57kB/s 0:00:00 (xfr#305, to-chk=353/682) hal/phydm/halrf/rtl8822b/halrf_rfk_init_8822b.c 23.48K 100% 375.83kB/s 0:00:00 (xfr#306, to-chk=352/682) hal/phydm/halrf/rtl8822b/halrf_rfk_init_8822b.h 1.10K 100% 17.67kB/s 0:00:00 (xfr#307, to-chk=351/682) hal/phydm/halrf/rtl8822b/version_rtl8822b_rf.h 1.03K 100% 16.49kB/s 0:00:00 (xfr#308, to-chk=350/682) hal/phydm/rtl8822b/ hal/phydm/rtl8822b/halhwimg8822b_bb.c 304.65K 100% 4.69MB/s 0:00:00 (xfr#309, to-chk=349/682) hal/phydm/rtl8822b/halhwimg8822b_bb.h 5.92K 100% 93.31kB/s 0:00:00 (xfr#310, to-chk=348/682) hal/phydm/rtl8822b/halhwimg8822b_mac.c 7.74K 100% 121.91kB/s 0:00:00 (xfr#311, to-chk=347/682) hal/phydm/rtl8822b/halhwimg8822b_mac.h 1.49K 100% 23.45kB/s 0:00:00 (xfr#312, to-chk=346/682) hal/phydm/rtl8822b/mp_precomp.h 656 100% 10.33kB/s 0:00:00 (xfr#313, to-chk=345/682) hal/phydm/rtl8822b/phydm_hal_api8822b.c 78.55K 100% 1.21MB/s 0:00:00 (xfr#314, to-chk=344/682) hal/phydm/rtl8822b/phydm_hal_api8822b.h 4.14K 100% 65.22kB/s 0:00:00 (xfr#315, to-chk=343/682) hal/phydm/rtl8822b/phydm_regconfig8822b.c 7.37K 100% 116.04kB/s 0:00:00 (xfr#316, to-chk=342/682) hal/phydm/rtl8822b/phydm_regconfig8822b.h 2.04K 100% 32.16kB/s 0:00:00 (xfr#317, to-chk=341/682) hal/phydm/rtl8822b/phydm_rtl8822b.c 17.36K 100% 273.42kB/s 0:00:00 (xfr#318, to-chk=340/682) hal/phydm/rtl8822b/phydm_rtl8822b.h 1.61K 100% 25.31kB/s 0:00:00 (xfr#319, to-chk=339/682) hal/phydm/rtl8822b/version_rtl8822b.h 1.31K 100% 20.62kB/s 0:00:00 (xfr#320, to-chk=338/682) hal/phydm/txbf/ hal/phydm/txbf/halcomtxbf.c 14.47K 100% 227.95kB/s 0:00:00 (xfr#321, to-chk=337/682) hal/phydm/txbf/halcomtxbf.h 4.10K 100% 64.53kB/s 0:00:00 (xfr#322, to-chk=336/682) hal/phydm/txbf/haltxbf8192e.c 13.39K 100% 210.89kB/s 0:00:00 (xfr#323, to-chk=335/682) hal/phydm/txbf/haltxbf8192e.h 1.88K 100% 29.64kB/s 0:00:00 (xfr#324, to-chk=334/682) hal/phydm/txbf/haltxbf8814a.c 22.12K 100% 348.46kB/s 0:00:00 (xfr#325, to-chk=333/682) hal/phydm/txbf/haltxbf8814a.h 2.45K 100% 38.64kB/s 0:00:00 (xfr#326, to-chk=332/682) hal/phydm/txbf/haltxbf8822b.c 38.52K 100% 606.65kB/s 0:00:00 (xfr#327, to-chk=331/682) hal/phydm/txbf/haltxbf8822b.h 2.27K 100% 35.72kB/s 0:00:00 (xfr#328, to-chk=330/682) hal/phydm/txbf/haltxbfinterface.c 42.14K 100% 663.81kB/s 0:00:00 (xfr#329, to-chk=329/682) hal/phydm/txbf/haltxbfinterface.h 3.93K 100% 61.93kB/s 0:00:00 (xfr#330, to-chk=328/682) hal/phydm/txbf/haltxbfjaguar.c 17.20K 100% 270.98kB/s 0:00:00 (xfr#331, to-chk=327/682) hal/phydm/txbf/haltxbfjaguar.h 2.25K 100% 34.92kB/s 0:00:00 (xfr#332, to-chk=326/682) hal/phydm/txbf/phydm_hal_txbf_api.c 21.00K 100% 325.58kB/s 0:00:00 (xfr#333, to-chk=325/682) hal/phydm/txbf/phydm_hal_txbf_api.h 2.73K 100% 42.27kB/s 0:00:00 (xfr#334, to-chk=324/682) hal/rtl8822b/ hal/rtl8822b/hal8822b_fw.c 2.22M 100% 31.64MB/s 0:00:00 (xfr#335, to-chk=323/682) hal/rtl8822b/hal8822b_fw.h 1.27K 100% 18.58kB/s 0:00:00 (xfr#336, to-chk=322/682) hal/rtl8822b/rtl8822b.h 6.44K 100% 93.85kB/s 0:00:00 (xfr#337, to-chk=321/682) hal/rtl8822b/rtl8822b_cmd.c 18.64K 100% 271.67kB/s 0:00:00 (xfr#338, to-chk=320/682) hal/rtl8822b/rtl8822b_halinit.c 9.58K 100% 139.65kB/s 0:00:00 (xfr#339, to-chk=319/682) hal/rtl8822b/rtl8822b_mac.c 6.68K 100% 97.31kB/s 0:00:00 (xfr#340, to-chk=318/682) hal/rtl8822b/rtl8822b_ops.c 109.78K 100% 1.56MB/s 0:00:00 (xfr#341, to-chk=317/682) hal/rtl8822b/rtl8822b_phy.c 67.37K 100% 982.00kB/s 0:00:00 (xfr#342, to-chk=316/682) hal/rtl8822b/usb/ hal/rtl8822b/usb/rtl8822bu.h 2.07K 100% 30.14kB/s 0:00:00 (xfr#343, to-chk=314/682) hal/rtl8822b/usb/rtl8822bu_halinit.c 11.78K 100% 171.70kB/s 0:00:00 (xfr#344, to-chk=313/682) hal/rtl8822b/usb/rtl8822bu_halmac.c 8.30K 100% 120.98kB/s 0:00:00 (xfr#345, to-chk=312/682) hal/rtl8822b/usb/rtl8822bu_io.c 1.57K 100% 22.88kB/s 0:00:00 (xfr#346, to-chk=311/682) hal/rtl8822b/usb/rtl8822bu_led.c 3.49K 100% 50.93kB/s 0:00:00 (xfr#347, to-chk=310/682) hal/rtl8822b/usb/rtl8822bu_ops.c 8.79K 100% 128.18kB/s 0:00:00 (xfr#348, to-chk=309/682) hal/rtl8822b/usb/rtl8822bu_recv.c 5.36K 100% 78.11kB/s 0:00:00 (xfr#349, to-chk=308/682) hal/rtl8822b/usb/rtl8822bu_xmit.c 30.81K 100% 449.03kB/s 0:00:00 (xfr#350, to-chk=307/682) include/ include/Hal8188EPhyCfg.h 6.47K 100% 94.25kB/s 0:00:00 (xfr#351, to-chk=306/682) include/Hal8188EPhyReg.h 35.29K 100% 514.40kB/s 0:00:00 (xfr#352, to-chk=305/682) include/Hal8188EPwrSeq.h 13.29K 100% 193.75kB/s 0:00:00 (xfr#353, to-chk=304/682) include/Hal8188FPhyCfg.h 2.69K 100% 39.19kB/s 0:00:00 (xfr#354, to-chk=303/682) include/Hal8188FPhyReg.h 36.76K 100% 527.88kB/s 0:00:00 (xfr#355, to-chk=302/682) include/Hal8188FPwrSeq.h 18.29K 100% 262.72kB/s 0:00:00 (xfr#356, to-chk=301/682) include/Hal8192EPhyCfg.h 3.38K 100% 48.56kB/s 0:00:00 (xfr#357, to-chk=300/682) include/Hal8192EPhyReg.h 36.63K 100% 526.09kB/s 0:00:00 (xfr#358, to-chk=299/682) include/Hal8192EPwrSeq.h 13.24K 100% 190.13kB/s 0:00:00 (xfr#359, to-chk=298/682) include/Hal8192FPhyCfg.h 2.63K 100% 37.78kB/s 0:00:00 (xfr#360, to-chk=297/682) include/Hal8192FPhyReg.h 35.87K 100% 515.11kB/s 0:00:00 (xfr#361, to-chk=296/682) include/Hal8192FPwrSeq.h 20.06K 100% 288.14kB/s 0:00:00 (xfr#362, to-chk=295/682) include/Hal8703BPhyCfg.h 2.64K 100% 37.90kB/s 0:00:00 (xfr#363, to-chk=294/682) include/Hal8703BPhyReg.h 35.98K 100% 516.64kB/s 0:00:00 (xfr#364, to-chk=293/682) include/Hal8703BPwrSeq.h 17.66K 100% 253.59kB/s 0:00:00 (xfr#365, to-chk=292/682) include/Hal8710BPhyCfg.h 2.56K 100% 36.72kB/s 0:00:00 (xfr#366, to-chk=291/682) include/Hal8710BPhyReg.h 35.87K 100% 515.11kB/s 0:00:00 (xfr#367, to-chk=290/682) include/Hal8710BPwrSeq.h 12.16K 100% 174.69kB/s 0:00:00 (xfr#368, to-chk=289/682) include/Hal8723BPhyCfg.h 2.64K 100% 37.96kB/s 0:00:00 (xfr#369, to-chk=288/682) include/Hal8723BPhyReg.h 35.87K 100% 515.08kB/s 0:00:00 (xfr#370, to-chk=287/682) include/Hal8723BPwrSeq.h 23.15K 100% 332.52kB/s 0:00:00 (xfr#371, to-chk=286/682) include/Hal8723DPhyCfg.h 2.64K 100% 37.87kB/s 0:00:00 (xfr#372, to-chk=285/682) include/Hal8723DPhyReg.h 35.87K 100% 515.11kB/s 0:00:00 (xfr#373, to-chk=284/682) include/Hal8723DPwrSeq.h 18.49K 100% 265.54kB/s 0:00:00 (xfr#374, to-chk=283/682) include/Hal8723PwrSeq.h 15.80K 100% 226.91kB/s 0:00:00 (xfr#375, to-chk=282/682) include/Hal8812PhyCfg.h 3.38K 100% 48.53kB/s 0:00:00 (xfr#376, to-chk=281/682) include/Hal8812PhyReg.h 24.84K 100% 351.56kB/s 0:00:00 (xfr#377, to-chk=280/682) include/Hal8812PwrSeq.h 18.59K 100% 263.15kB/s 0:00:00 (xfr#378, to-chk=279/682) include/Hal8814PhyCfg.h 4.58K 100% 64.86kB/s 0:00:00 (xfr#379, to-chk=278/682) include/Hal8814PhyReg.h 30.53K 100% 432.09kB/s 0:00:00 (xfr#380, to-chk=277/682) include/Hal8814PwrSeq.h 22.30K 100% 315.61kB/s 0:00:00 (xfr#381, to-chk=276/682) include/Hal8821APwrSeq.h 18.07K 100% 255.73kB/s 0:00:00 (xfr#382, to-chk=275/682) include/HalPwrSeqCmd.h 4.12K 100% 58.35kB/s 0:00:00 (xfr#383, to-chk=274/682) include/HalVerDef.h 11.02K 100% 155.97kB/s 0:00:00 (xfr#384, to-chk=273/682) include/autoconf.h 8.97K 100% 126.97kB/s 0:00:00 (xfr#385, to-chk=272/682) include/basic_types.h 10.76K 100% 152.22kB/s 0:00:00 (xfr#386, to-chk=271/682) include/circ_buf.h 864 100% 12.23kB/s 0:00:00 (xfr#387, to-chk=270/682) include/cmd_osdep.h 1.08K 100% 15.34kB/s 0:00:00 (xfr#388, to-chk=269/682) include/custom_gpio.h 1.04K 100% 14.79kB/s 0:00:00 (xfr#389, to-chk=268/682) include/drv_conf.h 17.34K 100% 245.46kB/s 0:00:00 (xfr#390, to-chk=267/682) include/drv_types.h 47.33K 100% 669.81kB/s 0:00:00 (xfr#391, to-chk=266/682) include/drv_types_ce.h 2.49K 100% 35.23kB/s 0:00:00 (xfr#392, to-chk=265/682) include/drv_types_gspi.h 1.37K 100% 19.35kB/s 0:00:00 (xfr#393, to-chk=264/682) include/drv_types_linux.h 725 100% 10.26kB/s 0:00:00 (xfr#394, to-chk=263/682) include/drv_types_pci.h 1.40K 100% 19.76kB/s 0:00:00 (xfr#395, to-chk=262/682) include/drv_types_sdio.h 2.94K 100% 41.57kB/s 0:00:00 (xfr#396, to-chk=261/682) include/drv_types_xp.h 2.54K 100% 35.98kB/s 0:00:00 (xfr#397, to-chk=260/682) include/ethernet.h 1.57K 100% 22.18kB/s 0:00:00 (xfr#398, to-chk=259/682) include/gspi_hal.h 983 100% 13.91kB/s 0:00:00 (xfr#399, to-chk=258/682) include/gspi_ops.h 7.79K 100% 110.18kB/s 0:00:00 (xfr#400, to-chk=257/682) include/gspi_ops_linux.h 722 100% 10.22kB/s 0:00:00 (xfr#401, to-chk=256/682) include/gspi_osintf.h 717 100% 10.15kB/s 0:00:00 (xfr#402, to-chk=255/682) include/h2clbk.h 847 100% 11.99kB/s 0:00:00 (xfr#403, to-chk=254/682) include/hal_btcoex.h 4.62K 100% 65.40kB/s 0:00:00 (xfr#404, to-chk=253/682) include/hal_btcoex_wifionly.h 3.38K 100% 47.89kB/s 0:00:00 (xfr#405, to-chk=252/682) include/hal_com.h 29.14K 100% 412.48kB/s 0:00:00 (xfr#406, to-chk=251/682) include/hal_com_h2c.h 35.36K 100% 500.51kB/s 0:00:00 (xfr#407, to-chk=250/682) include/hal_com_led.h 15.38K 100% 217.75kB/s 0:00:00 (xfr#408, to-chk=249/682) include/hal_com_phycfg.h 10.40K 100% 147.18kB/s 0:00:00 (xfr#409, to-chk=248/682) include/hal_com_reg.h 67.94K 100% 947.82kB/s 0:00:00 (xfr#410, to-chk=247/682) include/hal_data.h 23.10K 100% 322.28kB/s 0:00:00 (xfr#411, to-chk=246/682) include/hal_gspi.h 1.18K 100% 16.42kB/s 0:00:00 (xfr#412, to-chk=245/682) include/hal_ic_cfg.h 15.09K 100% 210.49kB/s 0:00:00 (xfr#413, to-chk=244/682) include/hal_intf.h 32.81K 100% 457.78kB/s 0:00:00 (xfr#414, to-chk=243/682) include/hal_pg.h 33.07K 100% 461.31kB/s 0:00:00 (xfr#415, to-chk=242/682) include/hal_phy.h 5.49K 100% 76.59kB/s 0:00:00 (xfr#416, to-chk=241/682) include/hal_phy_reg.h 14.70K 100% 205.09kB/s 0:00:00 (xfr#417, to-chk=240/682) include/hal_sdio.h 3.85K 100% 53.74kB/s 0:00:00 (xfr#418, to-chk=239/682) include/hal_sdio_coex.h 1.31K 100% 18.28kB/s 0:00:00 (xfr#419, to-chk=238/682) include/ieee80211.h 61.37K 100% 856.14kB/s 0:00:00 (xfr#420, to-chk=237/682) include/ieee80211_ext.h 7.43K 100% 103.72kB/s 0:00:00 (xfr#421, to-chk=236/682) include/if_ether.h 4.58K 100% 63.87kB/s 0:00:00 (xfr#422, to-chk=235/682) include/ip.h 4.04K 100% 56.36kB/s 0:00:00 (xfr#423, to-chk=234/682) include/mlme_osdep.h 1.07K 100% 14.96kB/s 0:00:00 (xfr#424, to-chk=233/682) include/nic_spec.h 1.24K 100% 17.27kB/s 0:00:00 (xfr#425, to-chk=232/682) include/osdep_intf.h 4.13K 100% 57.65kB/s 0:00:00 (xfr#426, to-chk=231/682) include/osdep_service.h 28.37K 100% 395.81kB/s 0:00:00 (xfr#427, to-chk=230/682) include/osdep_service_bsd.h 21.49K 100% 299.75kB/s 0:00:00 (xfr#428, to-chk=229/682) include/osdep_service_ce.h 4.52K 100% 63.11kB/s 0:00:00 (xfr#429, to-chk=228/682) include/osdep_service_linux.h 14.88K 100% 207.66kB/s 0:00:00 (xfr#430, to-chk=227/682) include/osdep_service_xp.h 4.83K 100% 67.41kB/s 0:00:00 (xfr#431, to-chk=226/682) include/pci_hal.h 1.61K 100% 22.50kB/s 0:00:00 (xfr#432, to-chk=225/682) include/pci_ops.h 4.30K 100% 59.93kB/s 0:00:00 (xfr#433, to-chk=224/682) include/pci_osintf.h 2.20K 100% 30.75kB/s 0:00:00 (xfr#434, to-chk=223/682) include/recv_osdep.h 2.69K 100% 37.51kB/s 0:00:00 (xfr#435, to-chk=222/682) include/rtl8188e_cmd.h 5.14K 100% 71.71kB/s 0:00:00 (xfr#436, to-chk=221/682) include/rtl8188e_dm.h 1.04K 100% 14.48kB/s 0:00:00 (xfr#437, to-chk=220/682) include/rtl8188e_hal.h 12.25K 100% 170.94kB/s 0:00:00 (xfr#438, to-chk=219/682) include/rtl8188e_led.h 1.40K 100% 19.46kB/s 0:00:00 (xfr#439, to-chk=218/682) include/rtl8188e_recv.h 3.45K 100% 48.09kB/s 0:00:00 (xfr#440, to-chk=217/682) include/rtl8188e_rf.h 953 100% 13.11kB/s 0:00:00 (xfr#441, to-chk=216/682) include/rtl8188e_spec.h 5.78K 100% 79.56kB/s 0:00:00 (xfr#442, to-chk=215/682) include/rtl8188e_sreset.h 921 100% 12.67kB/s 0:00:00 (xfr#443, to-chk=214/682) include/rtl8188e_xmit.h 7.61K 100% 104.73kB/s 0:00:00 (xfr#444, to-chk=213/682) include/rtl8188f_cmd.h 11.85K 100% 162.92kB/s 0:00:00 (xfr#445, to-chk=212/682) include/rtl8188f_dm.h 1.42K 100% 19.55kB/s 0:00:00 (xfr#446, to-chk=211/682) include/rtl8188f_hal.h 9.37K 100% 128.88kB/s 0:00:00 (xfr#447, to-chk=210/682) include/rtl8188f_led.h 1.55K 100% 21.33kB/s 0:00:00 (xfr#448, to-chk=209/682) include/rtl8188f_recv.h 2.25K 100% 30.96kB/s 0:00:00 (xfr#449, to-chk=208/682) include/rtl8188f_rf.h 856 100% 11.77kB/s 0:00:00 (xfr#450, to-chk=207/682) include/rtl8188f_spec.h 11.58K 100% 159.33kB/s 0:00:00 (xfr#451, to-chk=206/682) include/rtl8188f_sreset.h 919 100% 12.64kB/s 0:00:00 (xfr#452, to-chk=205/682) include/rtl8188f_xmit.h 19.77K 100% 271.98kB/s 0:00:00 (xfr#453, to-chk=204/682) include/rtl8192e_cmd.h 6.05K 100% 83.27kB/s 0:00:00 (xfr#454, to-chk=203/682) include/rtl8192e_dm.h 1.04K 100% 14.29kB/s 0:00:00 (xfr#455, to-chk=202/682) include/rtl8192e_hal.h 13.22K 100% 181.85kB/s 0:00:00 (xfr#456, to-chk=201/682) include/rtl8192e_led.h 1.36K 100% 18.69kB/s 0:00:00 (xfr#457, to-chk=200/682) include/rtl8192e_recv.h 9.32K 100% 128.14kB/s 0:00:00 (xfr#458, to-chk=199/682) include/rtl8192e_rf.h 883 100% 12.15kB/s 0:00:00 (xfr#459, to-chk=198/682) include/rtl8192e_spec.h 13.20K 100% 181.49kB/s 0:00:00 (xfr#460, to-chk=197/682) include/rtl8192e_sreset.h 922 100% 12.68kB/s 0:00:00 (xfr#461, to-chk=196/682) include/rtl8192e_xmit.h 19.93K 100% 274.18kB/s 0:00:00 (xfr#462, to-chk=195/682) include/rtl8192f_cmd.h 11.09K 100% 152.47kB/s 0:00:00 (xfr#463, to-chk=194/682) include/rtl8192f_dm.h 1.04K 100% 14.28kB/s 0:00:00 (xfr#464, to-chk=193/682) include/rtl8192f_hal.h 10.60K 100% 145.82kB/s 0:00:00 (xfr#465, to-chk=192/682) include/rtl8192f_led.h 1.44K 100% 19.75kB/s 0:00:00 (xfr#466, to-chk=191/682) include/rtl8192f_recv.h 4.08K 100% 56.08kB/s 0:00:00 (xfr#467, to-chk=190/682) include/rtl8192f_rf.h 2.67K 100% 36.68kB/s 0:00:00 (xfr#468, to-chk=189/682) include/rtl8192f_spec.h 21.92K 100% 301.55kB/s 0:00:00 (xfr#469, to-chk=188/682) include/rtl8192f_sreset.h 976 100% 13.42kB/s 0:00:00 (xfr#470, to-chk=187/682) include/rtl8192f_xmit.h 24.69K 100% 339.57kB/s 0:00:00 (xfr#471, to-chk=186/682) include/rtl8703b_cmd.h 11.85K 100% 162.99kB/s 0:00:00 (xfr#472, to-chk=185/682) include/rtl8703b_dm.h 1.42K 100% 19.55kB/s 0:00:00 (xfr#473, to-chk=184/682) include/rtl8703b_hal.h 9.50K 100% 130.64kB/s 0:00:00 (xfr#474, to-chk=183/682) include/rtl8703b_led.h 1.58K 100% 21.75kB/s 0:00:00 (xfr#475, to-chk=182/682) include/rtl8703b_recv.h 2.54K 100% 34.98kB/s 0:00:00 (xfr#476, to-chk=181/682) include/rtl8703b_rf.h 856 100% 11.77kB/s 0:00:00 (xfr#477, to-chk=180/682) include/rtl8703b_spec.h 18.91K 100% 260.08kB/s 0:00:00 (xfr#478, to-chk=179/682) include/rtl8703b_sreset.h 921 100% 12.67kB/s 0:00:00 (xfr#479, to-chk=178/682) include/rtl8703b_xmit.h 20.02K 100% 275.39kB/s 0:00:00 (xfr#480, to-chk=177/682) include/rtl8710b_cmd.h 10.18K 100% 140.03kB/s 0:00:00 (xfr#481, to-chk=176/682) include/rtl8710b_dm.h 1.42K 100% 19.27kB/s 0:00:00 (xfr#482, to-chk=175/682) include/rtl8710b_hal.h 9.06K 100% 122.88kB/s 0:00:00 (xfr#483, to-chk=174/682) include/rtl8710b_led.h 1.57K 100% 21.24kB/s 0:00:00 (xfr#484, to-chk=173/682) include/rtl8710b_lps_poff.h 2.79K 100% 37.86kB/s 0:00:00 (xfr#485, to-chk=172/682) include/rtl8710b_recv.h 3.44K 100% 46.62kB/s 0:00:00 (xfr#486, to-chk=171/682) include/rtl8710b_rf.h 763 100% 10.35kB/s 0:00:00 (xfr#487, to-chk=170/682) include/rtl8710b_spec.h 17.25K 100% 233.98kB/s 0:00:00 (xfr#488, to-chk=169/682) include/rtl8710b_sreset.h 921 100% 12.49kB/s 0:00:00 (xfr#489, to-chk=168/682) include/rtl8710b_xmit.h 24.27K 100% 329.14kB/s 0:00:00 (xfr#490, to-chk=167/682) include/rtl8723b_cmd.h 11.85K 100% 160.73kB/s 0:00:00 (xfr#491, to-chk=166/682) include/rtl8723b_dm.h 1.42K 100% 19.26kB/s 0:00:00 (xfr#492, to-chk=165/682) include/rtl8723b_hal.h 9.83K 100% 133.33kB/s 0:00:00 (xfr#493, to-chk=164/682) include/rtl8723b_led.h 1.56K 100% 21.13kB/s 0:00:00 (xfr#494, to-chk=163/682) include/rtl8723b_recv.h 2.54K 100% 34.51kB/s 0:00:00 (xfr#495, to-chk=162/682) include/rtl8723b_rf.h 856 100% 11.61kB/s 0:00:00 (xfr#496, to-chk=161/682) include/rtl8723b_spec.h 11.65K 100% 158.00kB/s 0:00:00 (xfr#497, to-chk=160/682) include/rtl8723b_sreset.h 921 100% 12.49kB/s 0:00:00 (xfr#498, to-chk=159/682) include/rtl8723b_xmit.h 20.00K 100% 271.31kB/s 0:00:00 (xfr#499, to-chk=158/682) include/rtl8723d_cmd.h 10.59K 100% 143.62kB/s 0:00:00 (xfr#500, to-chk=157/682) include/rtl8723d_dm.h 1.42K 100% 19.27kB/s 0:00:00 (xfr#501, to-chk=156/682) include/rtl8723d_hal.h 10.14K 100% 137.49kB/s 0:00:00 (xfr#502, to-chk=155/682) include/rtl8723d_led.h 1.57K 100% 21.24kB/s 0:00:00 (xfr#503, to-chk=154/682) include/rtl8723d_lps_poff.h 2.79K 100% 37.86kB/s 0:00:00 (xfr#504, to-chk=153/682) include/rtl8723d_recv.h 4.18K 100% 56.76kB/s 0:00:00 (xfr#505, to-chk=152/682) include/rtl8723d_rf.h 845 100% 11.46kB/s 0:00:00 (xfr#506, to-chk=151/682) include/rtl8723d_spec.h 16.41K 100% 222.53kB/s 0:00:00 (xfr#507, to-chk=150/682) include/rtl8723d_sreset.h 921 100% 12.49kB/s 0:00:00 (xfr#508, to-chk=149/682) include/rtl8723d_xmit.h 24.27K 100% 329.20kB/s 0:00:00 (xfr#509, to-chk=148/682) include/rtl8812a_cmd.h 7.08K 100% 96.04kB/s 0:00:00 (xfr#510, to-chk=147/682) include/rtl8812a_dm.h 1.03K 100% 14.02kB/s 0:00:00 (xfr#511, to-chk=146/682) include/rtl8812a_hal.h 15.04K 100% 204.03kB/s 0:00:00 (xfr#512, to-chk=145/682) include/rtl8812a_led.h 1.51K 100% 20.49kB/s 0:00:00 (xfr#513, to-chk=144/682) include/rtl8812a_recv.h 7.78K 100% 105.48kB/s 0:00:00 (xfr#514, to-chk=143/682) include/rtl8812a_rf.h 881 100% 11.95kB/s 0:00:00 (xfr#515, to-chk=142/682) include/rtl8812a_spec.h 10.66K 100% 144.59kB/s 0:00:00 (xfr#516, to-chk=141/682) include/rtl8812a_sreset.h 918 100% 12.28kB/s 0:00:00 (xfr#517, to-chk=140/682) include/rtl8812a_xmit.h 15.52K 100% 207.67kB/s 0:00:00 (xfr#518, to-chk=139/682) include/rtl8814a_cmd.h 10.87K 100% 145.36kB/s 0:00:00 (xfr#519, to-chk=138/682) include/rtl8814a_dm.h 897 100% 12.00kB/s 0:00:00 (xfr#520, to-chk=137/682) include/rtl8814a_hal.h 13.66K 100% 182.76kB/s 0:00:00 (xfr#521, to-chk=136/682) include/rtl8814a_led.h 1.45K 100% 19.36kB/s 0:00:00 (xfr#522, to-chk=135/682) include/rtl8814a_recv.h 10.07K 100% 134.74kB/s 0:00:00 (xfr#523, to-chk=134/682) include/rtl8814a_rf.h 883 100% 11.81kB/s 0:00:00 (xfr#524, to-chk=133/682) include/rtl8814a_spec.h 26.03K 100% 348.18kB/s 0:00:00 (xfr#525, to-chk=132/682) include/rtl8814a_sreset.h 920 100% 12.31kB/s 0:00:00 (xfr#526, to-chk=131/682) include/rtl8814a_xmit.h 19.95K 100% 266.87kB/s 0:00:00 (xfr#527, to-chk=130/682) include/rtl8814b_hal.h 8.94K 100% 119.62kB/s 0:00:00 (xfr#528, to-chk=129/682) include/rtl8814be_hal.h 1.08K 100% 14.50kB/s 0:00:00 (xfr#529, to-chk=128/682) include/rtl8814bu_hal.h 1.83K 100% 24.52kB/s 0:00:00 (xfr#530, to-chk=127/682) include/rtl8821a_spec.h 3.45K 100% 46.13kB/s 0:00:00 (xfr#531, to-chk=126/682) include/rtl8821a_xmit.h 4.25K 100% 56.88kB/s 0:00:00 (xfr#532, to-chk=125/682) include/rtl8821c_dm.h 887 100% 11.87kB/s 0:00:00 (xfr#533, to-chk=124/682) include/rtl8821c_hal.h 2.69K 100% 35.93kB/s 0:00:00 (xfr#534, to-chk=123/682) include/rtl8821c_spec.h 7.55K 100% 101.07kB/s 0:00:00 (xfr#535, to-chk=122/682) include/rtl8821ce_hal.h 841 100% 11.25kB/s 0:00:00 (xfr#536, to-chk=121/682) include/rtl8821cs_hal.h 839 100% 11.22kB/s 0:00:00 (xfr#537, to-chk=120/682) include/rtl8821cu_hal.h 894 100% 11.96kB/s 0:00:00 (xfr#538, to-chk=119/682) include/rtl8822b_hal.h 8.80K 100% 117.70kB/s 0:00:00 (xfr#539, to-chk=118/682) include/rtl8822be_hal.h 992 100% 13.27kB/s 0:00:00 (xfr#540, to-chk=117/682) include/rtl8822bs_hal.h 1.09K 100% 14.65kB/s 0:00:00 (xfr#541, to-chk=116/682) include/rtl8822bu_hal.h 1.83K 100% 24.52kB/s 0:00:00 (xfr#542, to-chk=115/682) include/rtl8822c_hal.h 9.22K 100% 123.30kB/s 0:00:00 (xfr#543, to-chk=114/682) include/rtl8822ce_hal.h 992 100% 13.27kB/s 0:00:00 (xfr#544, to-chk=113/682) include/rtl8822cs_hal.h 1.09K 100% 14.65kB/s 0:00:00 (xfr#545, to-chk=112/682) include/rtl8822cu_hal.h 1.83K 100% 24.52kB/s 0:00:00 (xfr#546, to-chk=111/682) include/rtw_android.h 3.73K 100% 49.95kB/s 0:00:00 (xfr#547, to-chk=110/682) include/rtw_ap.h 5.54K 100% 74.13kB/s 0:00:00 (xfr#548, to-chk=109/682) include/rtw_beamforming.h 8.95K 100% 119.70kB/s 0:00:00 (xfr#549, to-chk=108/682) include/rtw_br_ext.h 2.00K 100% 26.72kB/s 0:00:00 (xfr#550, to-chk=107/682) include/rtw_bt_mp.h 7.86K 100% 105.19kB/s 0:00:00 (xfr#551, to-chk=106/682) include/rtw_btcoex.h 19.54K 100% 261.41kB/s 0:00:00 (xfr#552, to-chk=105/682) include/rtw_btcoex_wifionly.h 1.08K 100% 14.49kB/s 0:00:00 (xfr#553, to-chk=104/682) include/rtw_byteorder.h 1.15K 100% 15.32kB/s 0:00:00 (xfr#554, to-chk=103/682) include/rtw_cmd.h 31.32K 100% 419.03kB/s 0:00:00 (xfr#555, to-chk=102/682) include/rtw_debug.h 26.82K 100% 358.79kB/s 0:00:00 (xfr#556, to-chk=101/682) include/rtw_eeprom.h 4.04K 100% 53.99kB/s 0:00:00 (xfr#557, to-chk=100/682) include/rtw_efuse.h 10.24K 100% 136.99kB/s 0:00:00 (xfr#558, to-chk=99/682) include/rtw_event.h 2.47K 100% 32.58kB/s 0:00:00 (xfr#559, to-chk=98/682) include/rtw_ht.h 12.33K 100% 162.76kB/s 0:00:00 (xfr#560, to-chk=97/682) include/rtw_io.h 18.95K 100% 250.01kB/s 0:00:00 (xfr#561, to-chk=96/682) include/rtw_ioctl.h 1.55K 100% 20.42kB/s 0:00:00 (xfr#562, to-chk=95/682) include/rtw_ioctl_query.h 721 100% 9.51kB/s 0:00:00 (xfr#563, to-chk=94/682) include/rtw_ioctl_set.h 1.80K 100% 23.81kB/s 0:00:00 (xfr#564, to-chk=93/682) include/rtw_iol.h 5.48K 100% 72.28kB/s 0:00:00 (xfr#565, to-chk=92/682) include/rtw_mcc.h 9.28K 100% 122.43kB/s 0:00:00 (xfr#566, to-chk=91/682) include/rtw_mem.h 1.41K 100% 18.57kB/s 0:00:00 (xfr#567, to-chk=90/682) include/rtw_mi.h 11.50K 100% 151.82kB/s 0:00:00 (xfr#568, to-chk=89/682) include/rtw_mlme.h 48.20K 100% 636.05kB/s 0:00:00 (xfr#569, to-chk=88/682) include/rtw_mlme_ext.h 49.80K 100% 657.17kB/s 0:00:00 (xfr#570, to-chk=87/682) include/rtw_mp.h 25.93K 100% 342.17kB/s 0:00:00 (xfr#571, to-chk=86/682) include/rtw_mp_phy_regdef.h 38.09K 100% 502.73kB/s 0:00:00 (xfr#572, to-chk=85/682) include/rtw_odm.h 3.46K 100% 45.71kB/s 0:00:00 (xfr#573, to-chk=84/682) include/rtw_p2p.h 7.99K 100% 105.43kB/s 0:00:00 (xfr#574, to-chk=83/682) include/rtw_pwrctrl.h 17.86K 100% 235.75kB/s 0:00:00 (xfr#575, to-chk=82/682) include/rtw_qos.h 2.12K 100% 27.91kB/s 0:00:00 (xfr#576, to-chk=81/682) include/rtw_recv.h 19.11K 100% 248.78kB/s 0:00:00 (xfr#577, to-chk=80/682) include/rtw_rf.h 9.14K 100% 119.04kB/s 0:00:00 (xfr#578, to-chk=79/682) include/rtw_rm.h 2.36K 100% 30.68kB/s 0:00:00 (xfr#579, to-chk=78/682) include/rtw_rm_fsm.h 9.54K 100% 124.18kB/s 0:00:00 (xfr#580, to-chk=77/682) include/rtw_rm_util.h 1.77K 100% 23.05kB/s 0:00:00 (xfr#581, to-chk=76/682) include/rtw_rson.h 2.51K 100% 32.66kB/s 0:00:00 (xfr#582, to-chk=75/682) include/rtw_sdio.h 1.17K 100% 15.27kB/s 0:00:00 (xfr#583, to-chk=74/682) include/rtw_security.h 15.24K 100% 198.40kB/s 0:00:00 (xfr#584, to-chk=73/682) include/rtw_sreset.h 1.86K 100% 24.21kB/s 0:00:00 (xfr#585, to-chk=72/682) include/rtw_tdls.h 9.52K 100% 123.93kB/s 0:00:00 (xfr#586, to-chk=71/682) include/rtw_version.h 108 100% 1.41kB/s 0:00:00 (xfr#587, to-chk=70/682) include/rtw_vht.h 10.27K 100% 133.75kB/s 0:00:00 (xfr#588, to-chk=69/682) include/rtw_wapi.h 6.61K 100% 86.02kB/s 0:00:00 (xfr#589, to-chk=68/682) include/rtw_xmit.h 29.85K 100% 388.70kB/s 0:00:00 (xfr#590, to-chk=67/682) include/sdio_hal.h 1.51K 100% 19.71kB/s 0:00:00 (xfr#591, to-chk=66/682) include/sdio_ops.h 8.45K 100% 110.01kB/s 0:00:00 (xfr#592, to-chk=65/682) include/sdio_ops_ce.h 1.82K 100% 23.75kB/s 0:00:00 (xfr#593, to-chk=64/682) include/sdio_ops_linux.h 2.60K 100% 33.87kB/s 0:00:00 (xfr#594, to-chk=63/682) include/sdio_ops_xp.h 1.82K 100% 23.67kB/s 0:00:00 (xfr#595, to-chk=62/682) include/sdio_osintf.h 717 100% 9.34kB/s 0:00:00 (xfr#596, to-chk=61/682) include/sta_info.h 19.50K 100% 253.91kB/s 0:00:00 (xfr#597, to-chk=60/682) include/usb_hal.h 1.93K 100% 25.16kB/s 0:00:00 (xfr#598, to-chk=59/682) include/usb_ops.h 4.99K 100% 64.93kB/s 0:00:00 (xfr#599, to-chk=58/682) include/usb_ops_linux.h 4.68K 100% 60.89kB/s 0:00:00 (xfr#600, to-chk=57/682) include/usb_osintf.h 951 100% 12.38kB/s 0:00:00 (xfr#601, to-chk=56/682) include/usb_vendor_req.h 1.94K 100% 25.27kB/s 0:00:00 (xfr#602, to-chk=55/682) include/wifi.h 42.94K 100% 559.10kB/s 0:00:00 (xfr#603, to-chk=54/682) include/wlan_bssdef.h 10.17K 100% 132.41kB/s 0:00:00 (xfr#604, to-chk=53/682) include/xmit_osdep.h 2.62K 100% 34.10kB/s 0:00:00 (xfr#605, to-chk=52/682) include/byteorder/ include/byteorder/big_endian.h 3.21K 100% 41.85kB/s 0:00:00 (xfr#606, to-chk=48/682) include/byteorder/generic.h 7.18K 100% 93.45kB/s 0:00:00 (xfr#607, to-chk=47/682) include/byteorder/little_endian.h 3.39K 100% 44.09kB/s 0:00:00 (xfr#608, to-chk=46/682) include/byteorder/swab.h 3.27K 100% 42.60kB/s 0:00:00 (xfr#609, to-chk=45/682) include/byteorder/swabb.h 4.02K 100% 52.34kB/s 0:00:00 (xfr#610, to-chk=44/682) include/cmn_info/ include/cmn_info/rtw_sta_info.h 8.45K 100% 110.03kB/s 0:00:00 (xfr#611, to-chk=43/682) include/linux/ include/linux/wireless.h 2.74K 100% 35.65kB/s 0:00:00 (xfr#612, to-chk=42/682) os_dep/ os_dep/osdep_service.c 65.68K 100% 843.98kB/s 0:00:00 (xfr#613, to-chk=41/682) os_dep/linux/ os_dep/linux/custom_gpio_linux.c 8.42K 100% 108.17kB/s 0:00:00 (xfr#614, to-chk=39/682) os_dep/linux/ioctl_cfg80211.c 317.52K 100% 3.98MB/s 0:00:00 (xfr#615, to-chk=38/682) os_dep/linux/ioctl_cfg80211.h 16.54K 100% 212.56kB/s 0:00:00 (xfr#616, to-chk=37/682) os_dep/linux/ioctl_linux.c 370.37K 100% 4.59MB/s 0:00:00 (xfr#617, to-chk=36/682) os_dep/linux/ioctl_mp.c 94.44K 100% 1.17MB/s 0:00:00 (xfr#618, to-chk=35/682) os_dep/linux/mlme_linux.c 11.41K 100% 144.71kB/s 0:00:00 (xfr#619, to-chk=34/682) os_dep/linux/os_intfs.c 158.40K 100% 1.94MB/s 0:00:00 (xfr#620, to-chk=33/682) os_dep/linux/recv_linux.c 20.08K 100% 251.35kB/s 0:00:00 (xfr#621, to-chk=32/682) os_dep/linux/rhashtable.c 20.62K 100% 258.14kB/s 0:00:00 (xfr#622, to-chk=31/682) os_dep/linux/rhashtable.h 25.50K 100% 319.27kB/s 0:00:00 (xfr#623, to-chk=30/682) os_dep/linux/rtw_android.c 35.95K 100% 450.08kB/s 0:00:00 (xfr#624, to-chk=29/682) os_dep/linux/rtw_cfgvendor.c 59.00K 100% 738.73kB/s 0:00:00 (xfr#625, to-chk=28/682) os_dep/linux/rtw_cfgvendor.h 26.36K 100% 329.99kB/s 0:00:00 (xfr#626, to-chk=27/682) os_dep/linux/rtw_proc.c 139.40K 100% 1.70MB/s 0:00:00 (xfr#627, to-chk=26/682) os_dep/linux/rtw_proc.h 2.29K 100% 28.68kB/s 0:00:00 (xfr#628, to-chk=25/682) os_dep/linux/rtw_rhashtable.c 2.23K 100% 27.88kB/s 0:00:00 (xfr#629, to-chk=24/682) os_dep/linux/rtw_rhashtable.h 2.51K 100% 31.48kB/s 0:00:00 (xfr#630, to-chk=23/682) os_dep/linux/usb_intf.c 53.33K 100% 667.68kB/s 0:00:00 (xfr#631, to-chk=22/682) os_dep/linux/usb_ops_linux.c 29.53K 100% 369.68kB/s 0:00:00 (xfr#632, to-chk=21/682) os_dep/linux/wifi_regd.c 3.70K 100% 46.32kB/s 0:00:00 (xfr#633, to-chk=20/682) os_dep/linux/wifi_regd.h 829 100% 10.38kB/s 0:00:00 (xfr#634, to-chk=19/682) os_dep/linux/xmit_linux.c 16.65K 100% 205.86kB/s 0:00:00 (xfr#635, to-chk=18/682) platform/ platform/custom_country_chplan.h 1.04K 100% 12.92kB/s 0:00:00 (xfr#636, to-chk=17/682) platform/platform_ARM_SUN50IW1P1_sdio.c 2.21K 100% 27.36kB/s 0:00:00 (xfr#637, to-chk=16/682) platform/platform_ARM_SUNnI_sdio.c 3.51K 100% 43.44kB/s 0:00:00 (xfr#638, to-chk=15/682) platform/platform_ARM_SUNxI_sdio.c 2.67K 100% 32.97kB/s 0:00:00 (xfr#639, to-chk=14/682) platform/platform_ARM_SUNxI_usb.c 3.90K 100% 48.15kB/s 0:00:00 (xfr#640, to-chk=13/682) platform/platform_ARM_WMT_sdio.c 1.53K 100% 18.94kB/s 0:00:00 (xfr#641, to-chk=12/682) platform/platform_RTK_DMP_usb.c 966 100% 11.94kB/s 0:00:00 (xfr#642, to-chk=11/682) platform/platform_aml_s905_sdio.c 1.48K 100% 18.34kB/s 0:00:00 (xfr#643, to-chk=10/682) platform/platform_aml_s905_sdio.h 1.05K 100% 12.98kB/s 0:00:00 (xfr#644, to-chk=9/682) platform/platform_arm_act_sdio.c 1.35K 100% 16.73kB/s 0:00:00 (xfr#645, to-chk=8/682) platform/platform_hisilicon_hi3798_sdio.c 2.67K 100% 32.94kB/s 0:00:00 (xfr#646, to-chk=7/682) platform/platform_hisilicon_hi3798_sdio.h 1.04K 100% 12.89kB/s 0:00:00 (xfr#647, to-chk=6/682) platform/platform_ops.c 897 100% 11.09kB/s 0:00:00 (xfr#648, to-chk=5/682) platform/platform_ops.h 887 100% 10.96kB/s 0:00:00 (xfr#649, to-chk=4/682) platform/platform_rockchips_sdio.c 1.72K 100% 21.27kB/s 0:00:00 (xfr#650, to-chk=3/682) platform/platform_sprd_sdio.c 2.05K 100% 25.32kB/s 0:00:00 (xfr#651, to-chk=2/682) platform/platform_zte_zx296716_sdio.c 1.46K 100% 18.07kB/s 0:00:00 (xfr#652, to-chk=1/682) platform/platform_zte_zx296716_sdio.h 989 100% 12.23kB/s 0:00:00 (xfr#653, to-chk=0/682) sent 27.55M bytes received 12.68K bytes 55.12M bytes/sec total size is 27.50M speedup is 1.00 dkms add $ sudo dkms add -m rtl88x2bu -v ${VER} Creating symlink /var/lib/dkms/rtl88x2bu/5.8.7.1/source -\u0026gt; /usr/src/rtl88x2bu-5.8.7.1 DKMS: add completed. dkms build $ sudo dkms build -m rtl88x2bu -v ${VER} Kernel preparation unnecessary for this kernel. Skipping... Building module: cleaning build area... \u0026#39;make\u0026#39; -j 16 KVER=5.15.0-119-generic src=/usr/src/rtl88x2bu-5.8.7.1....... Signing module: Generating a new Secure Boot signing key: Can\u0026#39;t load /var/lib/shim-signed/mok/.rnd into RNG 139669372728640:error:2406F079:random number generator:RAND_load_file:Cannot open file:../crypto/rand/randfile.c:98:Filename=/var/lib/shim-signed/mok/.rnd Generating a RSA private key ............+++++ ........................+++++ writing new private key to \u0026#39;/var/lib/shim-signed/mok/MOK.priv\u0026#39; ----- - /var/lib/dkms/rtl88x2bu/5.8.7.1/5.15.0-119-generic/x86_64/module/88x2bu.ko Secure Boot not enabled on this system. cleaning build area... DKMS: build completed. dkms install $ sudo dkms install -m rtl88x2bu -v ${VER} 88x2bu.ko: Running module version sanity check. - Original module - No original module exists within this kernel - Installation - Installing to /lib/modules/5.15.0-119-generic/updates/dkms/ depmod... DKMS: install completed. Reference cilynx/rtl88x2bu Install TP Link in Ubuntu 20.04 ","date":"1 January, 1970","id":123,"permalink":"/posts/ubuntu_200406_install_tp_link_ac1300_usb_wifi_adaptor_driver/","summary":"","tags":"tp-link realtek ubuntu wifi driver","title":"ubuntu 20.04.6 install tp link a1300 usb wifi adaptor driver"},{"content":"参考链接\nhttps://forum.suse.org.cn/t/eth0/2049/4 https://zh.opensuse.org/openSUSE:13.1%E5%B8%B8%E8%A7%81%E9%97%AE%E9%A2%98 Virtualbox 虚拟机装完没有网络？\nsudo systemctl start NetworkManager\n启动 NetworkManager 服务，会自动运行 DHCP 分配 IP 地址给你。之后可用：ping 127.0.0.1 或 ping 192.168.1.1测试（按 Ctrl + C 可停止 ping，不然会一直进行）。\n或用：\nsudo systemctl status NetworkManager\n查看其状态。一般情况下这时你的网络已经激活了。但你如果运行比如\nping www.baidu.com\n或者\nnslookup www.baidu.com\n是没有结果的。因为我们没指定系统查询域名所用的 DNS 服务器。\n/etc/resolv.conf文件的最后加入：\nnameserver 8.8.8.8 nameserver 8.8.4.4 之后就能 ping 或者 nslookup 百度了。\n","date":"1 January, 1970","id":124,"permalink":"/posts/virtualboxopensuse%E6%97%A0%E7%BD%91%E7%BB%9C%E5%9B%BE%E6%A0%87%E6%97%A0%E6%B3%95%E4%B8%8A%E7%BD%91/","summary":"参考链接","tags":"OpenSuse linux network virtualbox","title":"Virtualbox Opensuse 无网络图标 无法上网"},{"content":"内核源码根目录下创建 .vscode 目录\n.vscode 目录下创建 c_cpp_properties.json 文件，内容如下：\n{ \u0026#34;configurations\u0026#34;: [ { \u0026#34;name\u0026#34;: \u0026#34;Linux\u0026#34;, \u0026#34;includePath\u0026#34;: [ \u0026#34;${workspaceFolder}/**\u0026#34; ], \u0026#34;defines\u0026#34;: [ \u0026#34;__KERNEL__\u0026#34; ], [\u0026#34;compilerPath\u0026#34;: \u0026#34;/opt/bstos/2.3.0.4/sysroots/x86_64-bstsdk-linux/usr/bin/aarch64-bst-linux/aarch64-bst-linux-gcc\u0026#34;,](\u0026lt;https://www.notion.so/Docker-22f588b5e85d492895231b70d4b5c4a0?pvs=21\u0026gt;) \u0026#34;cStandard\u0026#34;: \u0026#34;c11\u0026#34;, \u0026#34;cppStandard\u0026#34;: \u0026#34;c++17\u0026#34;, \u0026#34;intelliSenseMode\u0026#34;: \u0026#34;gcc-x64\u0026#34; } ], \u0026#34;version\u0026#34;: 4 } 说明：\ncompilerPath 需要指定编译器bin文件的路径，而不是编译器所在目录 defines 添加 “KERNEL” 为了解决 uapi 相关头文件中会根据该宏控区分应用层和内核层，如果不定义可能出现头文件不存在问题 例如 include/uapi/linux/videodev2.h 中\n#ifndef __KERNEL__ #include \u0026lt;sys/time.h\u0026gt; #endif ","date":"1 January, 1970","id":125,"permalink":"/posts/vscode-%E9%98%85%E8%AF%BB-linux-%E5%86%85%E6%A0%B8%E4%BB%A3%E7%A0%81%E9%85%8D%E7%BD%AE/","summary":"内核源码根目录下创建 .vscode 目录","tags":"kernel linux vscode","title":"vscode 阅读 Linux 内核代码配置"},{"content":"操作手顺 手机USB连接电脑\nadb shell \u0026#34;setprop persist.adb.tcp.port 5555\u0026#34; adb tcpip 5555 手机连上wifi，确认ip地址 此时可以断开手USB，然后通过wifiadb连接\nadb connect 10.100.2.5 Q\u0026amp;A Issue 执行命令 adb connect 10.100.2.5 报错\nmissing port in specification: tcp:10.100.2.5 Answer 使用命令 adb connect 10.100.2.5:5555 解决\n","date":"1 January, 1970","id":126,"permalink":"/posts/wifiadb/","summary":"手机USB连接电脑","tags":"android adb","title":"Wifi Adb"},{"content":"win8 MSDN key RTM核心版 334NH-RXG76-64THK-C7CKG-D3VPT` MSDN专业版 XHQ8N-C3MCJ-RQXB6-WCHYG-C9WKB win10 激活码 VK7JG-NPHTM-C97JM-9MPGT-3V66T win10 开启远程桌面连接 \u0026ldquo;此电脑\u0026rdquo; 右键 属性\n远程设置\n远程协助\n允许远程协助连接这台计算机(R) 远程桌面\n允许远程连接到此计算机 仅允许运行使用网络级别身份验证的远程桌面的计算机连接(建议)(N) 请注意关闭防火墙. 否则可能出现连接失败.\n","date":"1 January, 1970","id":127,"permalink":"/posts/windows/","summary":"\u0026ldquo;此电脑\u0026rdquo; 右键 属性","tags":"windows","title":"windows"},{"content":"远程电脑启用远程桌面 如何使用远程桌面 - Microsoft 支持\n设置你想要连接以使其允许远程连接的电脑： 确保你拥有 Windows 11 专业版。 若要检查这一点，请选择“开始”，然后打开“设置”。 然后，在“系统”下，选择“关于”，并在“Windows 规范”下，查找“版本”。 有关如何获取 Windows 11 专业版的详细信息，请转到“将 Windows 家庭版升级为 Windows 专业版”。 准备就绪后，选择“开始”，然后打开“设置”。 然后，在“系统”下，选择“远程桌面”，将“远程桌面”设置为“打开”，然后选择“确认”。 记下“电脑名称”下的这台电脑的名称。 稍后将需要使用此名称。 注意事项：\n如果远程电脑账户为无密码登陆，则本地电脑使用 远程桌面 工具连接远程电脑时空密码会连接失败，解决方案参考: 远程主机允许无密码远程桌面连接 远程电脑命令行 ipconfig /all 查看网络 IP， 本地电脑既可以通过远程电脑的网络 IP 也可以通过远程电脑的名称进行远程连接 远程主机允许无密码远程桌面连接 win+r, 输入secpol.msc命令\n安全设置 → 本地策略 → 安全选项 找到： 账户:使用空密码的本地账户只允许进行控制台登陆 已启用 改为 已禁用 将该项使用空密码的本地账户只允许进行本地计算机密码键盘登录 禁用 掉，这样远程桌面就能在无密码登录了。\n","date":"1 January, 1970","id":128,"permalink":"/posts/windows_remote_desktop/","summary":"如何使用远程桌面 - Microsoft 支持","tags":"windows 远程控制","title":"Windows Remote Desktop"},{"content":"前置条件 install vcpkg vcpkg install boost-system:x64-windows boost-filesystem:x64-windows cmake boost 配置 if (WIN32) # 查找 Boost 库 find_package(Boost COMPONENTS filesystem system REQUIRED) if (Boost_FOUND) include_directories(${Boost_INCLUDE_DIRS}) link_directories(${Boost_LIBRARY_DIRS}) endif () endif (WIN32) 编译报错\n====================[ Build | radar_data_local_storage | Release-Visual Studio ]==== ...... CMake Error at C:/Program Files/JetBrains/CLion 2023.1.4/bin/cmake/win/x64/share/cmake-3.25/Modules/FindPackageHandleStandardArgs.cmake:230 (message): Could NOT find Boost (missing: Boost_INCLUDE_DIR filesystem system) Call Stack (most recent call first): C:/Program Files/JetBrains/CLion 2023.1.4/bin/cmake/win/x64/share/cmake-3.25/Modules/FindPackageHandleStandardArgs.cmake:600 (_FPHSA_FAILURE_MESSAGE) C:/Program Files/JetBrains/CLion 2023.1.4/bin/cmake/win/x64/share/cmake-3.25/Modules/FindBoost.cmake:2377 (find_package_handle_standard_args) C:/Users/luyang/.clion-vcpkg/vcpkg/scripts/buildsystems/vcpkg.cmake:855 (_find_package) TestDemo/CMakeLists.txt:8 (find_package) CMake Configure step failed. Build files cannot be regenerated correctly. -- Configuring incomplete, errors occurred! See also \u0026#34;C:/Users/luyang/Documents/TestDemo/cmake-build-release-visual-studio/CMakeFiles/CMakeOutput.log\u0026#34;. 增加 ：set(Boost_INCLUDE_DIR ${_VCPKG_INSTALLED_DIR}/x64-windows/include)\nif (WIN32) # 查找 Boost 库 set(Boost_INCLUDE_DIR ${_VCPKG_INSTALLED_DIR}/x64-windows/include) find_package(Boost COMPONENTS filesystem system REQUIRED) if (Boost_FOUND) include_directories(${Boost_INCLUDE_DIRS}) link_directories(${Boost_LIBRARY_DIRS}) endif () endif (WIN32) 链接 boost-system boost-filesystem if (WIN32) target_link_libraries(radar_data_local_storage Boost::filesystem Boost::system) endif(WIN32) ","date":"1 January, 1970","id":129,"permalink":"/posts/windows_vcpkg_boost/","summary":"编译报错","tags":"vcpkg boost cmake","title":"windows vcpkg boost 开发环境"},{"content":" 下载安装vscode\n下载安装java，不然无法预览plantuml\n下载安装该java安装包后没有设置相关java环境变量就可以预览plantuml了。 下载安装graphivz，不然预览类图报错如下：\nDot Executable:null No dot executable found Cannot find Graphivz. You should try @startuml testdot @enduml or java -jar plantuml.jar -testdot vscode插件列表（plantuml相关） Graphviz Preview by EFanZh PlantUML by jebbs ","date":"1 January, 1970","id":130,"permalink":"/posts/windowsvscodeplantuml%E7%8E%AF%E5%A2%83%E6%90%AD%E5%BB%BA/","summary":"下载安装vscode","tags":"plantuml windows vscode","title":"Windows Vscode Plantuml 环境搭建"},{"content":"基于 office 2016如何隐藏 word 行尾的换行标记 文件-选项,弹出 Word 选项对话框 选择 显示 取消勾选 段落标记(M) 删除隐藏的数据和个人信息 打开要删除个人信息的文件 文件-信息 检查问题-检查文档 点击检查 点击需要删除信息部分的 全部删除 ","date":"1 January, 1970","id":131,"permalink":"/posts/word/","summary":"","tags":"office word windows","title":"word"},{"content":" 注意：如下 usbipd 命令需要在 以管理员身份运行 的 powershell 中执行\nusbipd: USB/IP open-source project\n本文主要内容 本文主要介绍了如何在 Windows 10/11 系统中，通过 WSL 2（Windows Subsystem for Linux 2）的 Ubuntu 环境，使用 usbipd-win 项目访问 USB 转串口设备。同时，还探讨了普通用户进程访问设备时可能遇到的权限问题及其解决方案。\n前提条件 运行 Windows 11（内部版本 22000 或更高版本）。Windows 10 也支持，但需要一些额外步骤。 已安装并设置为最新版本的 WSL。 已安装并设置为 WSL 2 的 Linux 发行版。 大致流程 windows admin usbipd bind device -\u0026gt; windows admin usbipd attach device -\u0026gt; wsl2 ubuntu 操作 USB 设备 -\u0026gt; windows admin usbipd detach device -\u0026gt; windows admin usbipd unbind device\n下载安装必要工具 windows 端工具 下载 usbipd-win\nhttps://github.com/dorssel/usbipd-win/releases usbipd-win_5.1.0_x64.msi 重新以管理员身份打开一个 [[windows terminal]]\nwsl2 ubuntu 安装 usbutils sudo apt install usbutils 确认设备的 USBID 确定 usb 设备BUS-ID (通过对比是否插入设备两种情况下 usbipd.exe list 命令的结果)\n例如：\n不插设备执行结果\n$ usbipd.exe list Connected: BUSID VID:PID DEVICE STATE 1-1 30c9:0096 HP 5MP Camera, HP IR Camera, Camera DFU Device Not shared 1-10 8087:0033 英特尔(R) 无线 Bluetooth(R) Not shared Persisted: GUID DEVICE usbipd: warning: USB filter \u0026#39;USBPcap\u0026#39; is known to be incompatible with this software; \u0026#39;bind --force\u0026#39; will be required. 插入设备后执行结果\n$ usbipd.exe list Connected: BUSID VID:PID DEVICE STATE 1-1 30c9:0096 HP 5MP Camera, HP IR Camera, Camera DFU Device Not shared 1-3 1a86:7523 USB-SERIAL CH340 (COM4) Not shared Persisted: GUID DEVICE usbipd: warning: USB filter \u0026#39;USBPcap\u0026#39; is known to be incompatible with this software; \u0026#39;bind --force\u0026#39; will be required. 找到对应设备：1-3 就是我们需要的 BUSID\n1-3 1a86:7523 USB-SERIAL CH340 (COM4) Not shared bind 设备 $ usbipd bind --force -b 1-3 $ usbipd.exe list Connected: BUSID VID:PID DEVICE STATE 1-1 30c9:0096 HP 5MP Camera, HP IR Camera, Camera DFU Device Not shared 1-3 1a86:7523 USB-SERIAL CH340 (COM4) Shared (forced) 1-10 8087:0033 英特尔(R) 无线 Bluetooth(R) Not shared Persisted: GUID DEVICE usbipd: warning: USB filter \u0026#39;USBPcap\u0026#39; is known to be incompatible with this software; \u0026#39;bind --force\u0026#39; will be required. attach 设备 $ usbipd attach -w --busid 1-3 usbipd: info: Using WSL distribution \u0026#39;Ubuntu-24.04\u0026#39; to attach; the device will be available in all WSL 2 distributions. usbipd: info: Detected networking mode \u0026#39;nat\u0026#39;. usbipd: info: Using IP address 172.20.16.1 to reach the host. WSL wsl: �hKm0R localhost �NtM�n �FO*g\\��P0R WSL0NAT !j_ N�v WSL WSL N/ec localhost �Nt0 WSL WSL $ usbipd.exe list Connected: BUSID VID:PID DEVICE STATE 1-1 30c9:0096 HP 5MP Camera, HP IR Camera, Camera DFU Device Not shared 1-3 1a86:7523 USB-SERIAL CH340 (COM8) Attached 1-10 8087:0033 英特尔(R) 无线 Bluetooth(R) Not shared Persisted: GUID DEVICE usbipd: warning: USB filter \u0026#39;USBPcap\u0026#39; is known to be incompatible with this software; \u0026#39;bind --force\u0026#39; will be required. wsl2 ubuntu ## windows attach 设备之前 $ sudo lsusb Bus 001 Device 001: ID 1d6b:0002 Linux Foundation 2.0 root hub Bus 002 Device 001: ID 1d6b:0003 Linux Foundation 3.0 root hub ## windows attach 设备之后 $ sudo lsusb Bus 001 Device 001: ID 1d6b:0002 Linux Foundation 2.0 root hub Bus 001 Device 002: ID 1a86:7523 QinHeng Electronics CH340 serial converter Bus 002 Device 001: ID 1d6b:0003 Linux Foundation 3.0 root hub $ ls -lah /dev/ttyUSB0 crw-rw---- 1 root dialout 188, 0 Jun 19 14:37 /dev/ttyUSB0 测试打开 /dev/ttyUSB0 #include \u0026lt;iostream\u0026gt; #include \u0026lt;fcntl.h\u0026gt; // open() #include \u0026lt;unistd.h\u0026gt; // close() #include \u0026lt;errno.h\u0026gt; // errno #include \u0026lt;string.h\u0026gt; // strerror() int main() { const char* device = \u0026#34;/dev/ttyUSB0\u0026#34;; // O_RDWR: 读写模式 // O_NOCTTY: 不让这个设备成为控制终端 // O_NONBLOCK: 非阻塞模式打开 int fd = open(device, O_RDWR | O_NOCTTY | O_NONBLOCK); if (fd == -1) { std::cerr \u0026lt;\u0026lt; \u0026#34;Failed to open \u0026#34; \u0026lt;\u0026lt; device \u0026lt;\u0026lt; \u0026#34;: \u0026#34; \u0026lt;\u0026lt; strerror(errno) \u0026lt;\u0026lt; \u0026#34; (errno: \u0026#34; \u0026lt;\u0026lt; errno \u0026lt;\u0026lt; \u0026#34;)\u0026#34; \u0026lt;\u0026lt; std::endl; return 1; } std::cout \u0026lt;\u0026lt; \u0026#34;Successfully opened \u0026#34; \u0026lt;\u0026lt; device \u0026lt;\u0026lt; \u0026#34; with fd = \u0026#34; \u0026lt;\u0026lt; fd \u0026lt;\u0026lt; std::endl; // 后续可以添加串口配置代码（termios 等） close(fd); return 0; } g++ -o open_ttyUSB open_ttyUSB.cpp $ ./open_ttyUSB Successfully opened /dev/ttyUSB0 with fd = 3 为什么能够成功：因为当前用户默认已经属于 dialout 组\n$ groups luyang luyang : luyang adm dialout cdrom floppy sudo audio dip video plugdev users netdev docker 权限问题导致打开 /dev/ttyUSB 设备失败 在依次裸机直接安装 ubuntu 系统，默认用户不属于 dialout 组，会出现设备打开失败的情况。解决方案分三种\n方法 1：临时修改权限 可以使用 chmod 命令临时修改 /dev/ttyUSB0 的权限，使其对所有用户可读写：\nsudo chmod 666 /dev/ttyUSB0 这种方法简单快捷，但重启系统后权限会恢复默认，需要重新设置。\n方法 2：将用户添加到 dialout 组 /dev/ttyUSB0 设备通常属于 dialout 组。将普通用户添加到该组后，用户即可访问该设备：\nsudo usermod -aG dialout $USER 添加用户到组后，需要注销并重新登录，或者重启系统，使更改生效。\n方法 3：使用 udev 规则永久设置权限 通过创建 udev 规则，可以永久设置 /dev/ttyUSB0 的权限。步骤如下： 创建规则文件：\nsudo nano /etc/udev/rules.d/70-ttyusb.rules 在文件中添加以下内容：\nKERNEL==\u0026#34;ttyUSB[0-9]*\u0026#34;, MODE=\u0026#34;0666\u0026#34; 或者，根据设备的供应商 ID 和产品 ID 指定规则：\nSUBSYSTEM==\u0026#34;tty\u0026#34;, ATTRS{idVendor}==\u0026#34;1a86\u0026#34;, ATTRS{idProduct}==\u0026#34;7523\u0026#34;, MODE=\u0026#34;0666\u0026#34; 使用 lsusb 命令查看设备的供应商 ID 和产品 ID。如下：1a86:7523\n$ lsusb Bus 001 Device 001: ID 1d6b:0002 Linux Foundation 2.0 root hub Bus 001 Device 002: ID 1a86:7523 QinHeng Electronics CH340 serial converter Bus 002 Device 001: ID 1d6b:0003 Linux Foundation 3.0 root hub 保存文件后，重新加载 udev 规则：\nsudo udevadm control --reload-rules sudo udevadm trigger 然后重新插入 USB 设备。\ndetach 设备 $ usbipd.exe list Connected: BUSID VID:PID DEVICE STATE 1-1 30c9:0096 HP 5MP Camera, HP IR Camera, Camera DFU Device Not shared 1-3 1a86:7523 USB-SERIAL CH340 (COM8) Attached 1-10 8087:0033 英特尔(R) 无线 Bluetooth(R) Not shared Persisted: GUID DEVICE usbipd: warning: USB filter \u0026#39;USBPcap\u0026#39; is known to be incompatible with this software; \u0026#39;bind --force\u0026#39; will be required. $ usbipd detach --busid 1-3 $ usbipd.exe list Connected: BUSID VID:PID DEVICE STATE 1-1 30c9:0096 HP 5MP Camera, HP IR Camera, Camera DFU Device Not shared 1-3 1a86:7523 USB-SERIAL CH340 (COM8) Shared (forced) 1-10 8087:0033 英特尔(R) 无线 Bluetooth(R) Not shared Persisted: GUID DEVICE usbipd: warning: USB filter \u0026#39;USBPcap\u0026#39; is known to be incompatible with this software; \u0026#39;bind --force\u0026#39; will be required. unbind 设备 $ usbipd unbind -b 1-3 $ usbipd.exe list Connected: BUSID VID:PID DEVICE STATE 1-1 30c9:0096 HP 5MP Camera, HP IR Camera, Camera DFU Device Not shared 1-3 1a86:7523 USB-SERIAL CH340 (COM8) Not shared 1-10 8087:0033 英特尔(R) 无线 Bluetooth(R) Not shared Persisted: GUID DEVICE usbipd: warning: USB filter \u0026#39;USBPcap\u0026#39; is known to be incompatible with this software; \u0026#39;bind --force\u0026#39; will be required. ","date":"1 January, 1970","id":132,"permalink":"/posts/wsl2-ubuntu-%E8%AE%BF%E9%97%AE-usb-%E8%AE%BE%E5%A4%87/","summary":"注意：如下 usbipd 命令需要在 以管理员身份运行 的 powershell 中执行","tags":"PUBLIC USB WSL usbipd 权限","title":"wsl2 ubuntu 访问 USB 设备"},{"content":"秒级精度 time_t 保存自 UTC 1970 年 1 月 1 日 00:00 以来的秒数（不包括闰秒），对应于POSIX time Unix 和 POSIX 兼容系统将 time_t 类型作为带符号整数（通常为 32 或 64 位宽）来实现，它表示自 Unix 时间开始以来的秒数\ntime_t 和 struct tm 之间的转换接口\nstruct tm *localtime(const time_t *timep); struct tm *localtime_r(const time_t *timep, struct tm *result); time_t mktime(struct tm *tm); struct tm { int tm_sec; /* Seconds (0-60) */ int tm_min; /* Minutes (0-59) */ int tm_hour; /* Hours (0-23) */ int tm_mday; /* Day of the month (1-31) */ int tm_mon; /* Month (0-11) */ int tm_year; /* Year - 1900 */ int tm_wday; /* Day of the week (0-6, Sunday = 0) */ int tm_yday; /* Day in the year (0-365, 1 Jan = 0) */ int tm_isdst; /* Daylight saving time */ }; 获取当前时间的 time_t\n#include \u0026lt;time.h\u0026gt; NAME time - get time in seconds SYNOPSIS #include \u0026lt;time.h\u0026gt; time_t time(time_t *tloc); DESCRIPTION time() returns the time as the number of seconds since the Epoch, 1970-01-01 00:00:00 +0000 (UTC). If tloc is non-NULL, the return value is also stored in the memory pointed to by tloc. 当前时间转 struct tm 打印\nstd::tm* local_time = localtime(\u0026amp;current_time); // Print the local time std::cout \u0026lt;\u0026lt; \u0026#34;Current local time is: \u0026#34; \u0026lt;\u0026lt; (local_time-\u0026gt;tm_year + 1900) \u0026lt;\u0026lt; \u0026#34;-\u0026#34; \u0026lt;\u0026lt; (local_time-\u0026gt;tm_mon + 1) \u0026lt;\u0026lt; \u0026#34;-\u0026#34; \u0026lt;\u0026lt; local_time-\u0026gt;tm_mday \u0026lt;\u0026lt; \u0026#34; \u0026#34; \u0026lt;\u0026lt; local_time-\u0026gt;tm_hour \u0026lt;\u0026lt; \u0026#34;:\u0026#34; \u0026lt;\u0026lt; local_time-\u0026gt;tm_min \u0026lt;\u0026lt; \u0026#34;:\u0026#34; \u0026lt;\u0026lt; local_time-\u0026gt;tm_sec \u0026lt;\u0026lt; std::endl; 纳秒精度 struct timespec struct timespec { time_t tv_sec; /* seconds */ long tv_nsec; /* nanoseconds */ }; int clock_gettime(clockid_t clk_id, struct timespec *tp); int clock_settime(clockid_t clk_id, const struct timespec *tp); 关于 clk_id clk_id 参数是要对其采取行动的特定时钟的标识符。时钟可以是系统范围的，因此对所有进程都可见，或者如果它仅在单个进程内测量时间，则可以对每个进程都可见。\n所有实现都支持系统范围的实时时钟，该时钟由 CLOCK_REALTIME 标识。其时间表示自纪元以来的秒数和纳秒数。当其时间改变时，相对间隔的计时器不受影响，但绝对时间点的计时器会受到影响。\n可以实现更多时钟。相应时间值的解释和对计时器的影响尚未指定。\n足够新的 glibc 版本和 Linux 内核支持以下时钟：\nCLOCK_REALTIME 测量实际（即挂钟）时间的系统范围时钟。设置此时钟需要适当的权限。此时钟受系统时间不连续跳跃的影响（例如，如果系统管理员手动更改时钟），以及 adjtime(3) 和 NTP 执行的增量调整。\nCLOCK_REALTIME_COARSE（自 Linux 2.6.32 起；特定于 Linux） CLOCK_REALTIME 的更快但精度较低的版本。当您需要非常快但不是细粒度的时间戳时使用。需要每个架构支持，并且可能还需要 vdso(7) 中对此标志的架构支持。\nCLOCK_MONOTONIC 无法设置的时钟，表示自 POSIX 描述的“过去某个未指定的点”以来的单调时间。在 Linux 上，该点对应于系统自启动以来运行的秒数。\nCLOCK_MONOTONIC 时钟不受系统时间不连续跳跃的影响（例如，如果系统管理员手动更改时钟），但会受到 adjtime(3) 和 NTP 执行的增量调整的影响。此时钟不计算系统暂停的时间。\nCLOCK_MONOTONIC_COARSE（自 Linux 2.6.32 起；Linux 专用） CLOCK_MONOTONIC 的更快但精度更低的版本。当您需要非常快速但不是细粒度的时间戳时使用。需要每个架构支持，并且可能还需要 vdso(7) 中对此标志的架构支持。\nCLOCK_MONOTONIC_RAW（自 Linux 2.6.28 起；Linux 专用） 与 CLOCK_MONOTONIC 类似，但提供对不受 NTP 调整或 adjtime(3) 执行的增量调整影响的原始硬件时间的访问。此时钟不计算系统暂停的时间。\nCLOCK_BOOTTIME（自 Linux 2.6.39 起；Linux 专用） 与 CLOCK_MONOTONIC 相同，但它还包括系统暂停的任何时间。这允许应用程序获得可感知暂停的单调时钟，而无需处理 CLOCK_REALTIME 的复杂性，如果使用 settimeofday(2) 或类似方法更改时间，则可能会出现不连续性。\nCLOCK_PROCESS_CPUTIME_ID（自 Linux 2.6.12 起） 每个进程的 CPU 时间时钟（测量进程中所有线程所消耗的 CPU 时间）。\nCLOCK_THREAD_CPUTIME_ID（自 Linux 2.6.12 起） 线程专用的 CPU 时间时钟。\n根据时间戳设置系统时间 // Your existing code to get the timestamp_us uint64_t timestamp_us = 1629374305000000; // Example timestamp in microseconds // Convert the timestamp to seconds and microseconds struct timespec new_time; new_time.tv_sec = static_cast\u0026lt;time_t\u0026gt;(timestamp_us / 1000000); new_time.tv_nsec = (timestamp_us % 1000000) * 1000; // CLOCK_REALTIME is the identifier for the system-wide realtime clock int result = clock_settime(CLOCK_REALTIME, \u0026amp;new_time); if (result == -1) { std::cerr \u0026lt;\u0026lt; \u0026#34;Failed to set system time: \u0026#34; \u0026lt;\u0026lt; strerror(errno) \u0026lt;\u0026lt; std::endl; return 1; } std::cout \u0026lt;\u0026lt; \u0026#34;System time updated to: \u0026#34; \u0026lt;\u0026lt; new_time.tv_sec \u0026lt;\u0026lt; \u0026#34;s and \u0026#34; \u0026lt;\u0026lt; new_time.tv_nsec \u0026lt;\u0026lt; \u0026#34;ns\u0026#34; \u0026lt;\u0026lt; std::endl; 微秒精度 struct timeval struct timeval { time_t tv_sec; /* seconds */ suseconds_t tv_usec; /* microseconds */ }; struct timezone { int tz_minuteswest; /* minutes west of Greenwich */ int tz_dsttime; /* type of DST correction */ }; #include \u0026lt;sys/time.h\u0026gt; int gettimeofday(struct timeval *tv, struct timezone *tz); int settimeofday(const struct timeval *tv, const struct timezone *tz); struct timeval 和 struct timespec 都是POSIX标准中定义的时间结构体，用于表示时间点或时间间隔。它们在很多系统调用中用于获取或设置时间。以下是这两个结构体的详细说明：\nstruct timeval struct timeval 用于表示一个时间间隔，它包含两个字段：\ntv_sec: 表示秒（time_t 类型），time_t 通常是一个长整型（long），表示自Unix纪元（1970年1月1日 00:00:00 UTC）以来的秒数。 tv_usec: 表示微秒（suseconds_t 类型，通常是一个长整型），表示tv_sec后的微秒数。 这个结构体通常用于需要时间间隔的场景，比如在某些系统调用中指定超时时间。\nstruct timespec struct timespec 用于表示一个具体的时间点，它同样包含两个字段：\ntv_sec: 表示秒（time_t 类型），同struct timeval中的tv_sec。 tv_nsec: 表示纳秒（long 类型），表示tv_sec后的纳秒数。 struct timespec 提供了比 struct timeval 更高的时间精度（纳秒级对比微秒级），因此它更适合用于需要高分辨率时间点的场景。\n使用场景 struct timeval 常用于设置或获取某个操作的超时时间，例如在使用 select(), poll() 或者 gettimeofday() 函数时。 struct timespec 常用于需要设定或查询具体时间点的场合，例如使用 clock_gettime() 或 clock_settime() 函数。 #include \u0026lt;iostream\u0026gt; #include \u0026lt;ctime\u0026gt; #include \u0026lt;sys/time.h\u0026gt; int main() { // 使用struct timeval获取当前时间 struct timeval now_val; if (gettimeofday(\u0026amp;now_val, NULL) == -1) { perror(\u0026#34;gettimeofday\u0026#34;); return 1; } std::cout \u0026lt;\u0026lt; \u0026#34;Current time (usec): \u0026#34; \u0026lt;\u0026lt; now_val.tv_sec \u0026lt;\u0026lt; \u0026#34;s and \u0026#34; \u0026lt;\u0026lt; now_val.tv_usec \u0026lt;\u0026lt; \u0026#34;us since the epoch\u0026#34; \u0026lt;\u0026lt; std::endl; // 使用struct timespec获取当前时间 struct timespec now_spec; if (clock_gettime(CLOCK_REALTIME, \u0026amp;now_spec) == -1) { perror(\u0026#34;clock_gettime\u0026#34;); return 1; } std::cout \u0026lt;\u0026lt; \u0026#34;Current time (nsec): \u0026#34; \u0026lt;\u0026lt; now_spec.tv_sec \u0026lt;\u0026lt; \u0026#34;s and \u0026#34; \u0026lt;\u0026lt; now_spec.tv_nsec \u0026lt;\u0026lt; \u0026#34;ns since the epoch\u0026#34; \u0026lt;\u0026lt; std::endl; return 0; } ","date":"1 January, 1970","id":133,"permalink":"/posts/%E4%B8%80%E6%96%87%E6%90%9E%E6%87%82%E5%BA%94%E7%94%A8%E5%BC%80%E5%8F%91%E6%89%80%E9%9C%80linux%E7%B3%BB%E7%BB%9F%E6%97%B6%E9%97%B4%E7%9A%84%E7%9B%B8%E5%85%B3%E7%9F%A5%E8%AF%86%E7%82%B9/","summary":"time_t 和 struct tm 之间的转换接口","tags":"linux date timesync 时间同步 time","title":"一文搞懂应用开发所需 Linux 系统时间的相关知识点"},{"content":"交叉编译工具链是一个由编译器、连接器和解释器组成的综合开发环境，交叉编译工具链主要由binutils、gcc和glibc三个部分组成。\n有时出于减小 libc 库大小的考虑，也可以用别的 c 库来代替 glibc，例如 uClibc、dietlibc 和 newlib。\n从授权上，分为免费授权版和付费授权版。\n免费版目前有三大主流工具商提供\n第一是GNU（提供源码，自行编译制作） 第二是 Codesourcery 第三是Linora 收费版\nARM原厂提供的armcc IAR提供的编译器 等等 arm-none-linux-gnueabi-gcc：是 Codesourcery 公司（目前已经被Mentor收购）基于GCC推出的的ARM交叉编译工具。可用于交叉编译ARM（32位）系统中所有环节的代码，包括裸机程序、u-boot、Linux kernel、filesystem和App应用程序。\narm-linux-gnueabihf-gcc：是由 Linaro 公司基于GCC推出的的ARM交叉编译工具。可用于交叉编译ARM（32位）系统中所有环节的代码，包括裸机程序、u-boot、Linux kernel、filesystem和App应用程序。\naarch64-linux-gnu-gcc：是由 Linaro 公司基于GCC推出的的ARM交叉编译工具。可用于交叉编译ARMv8 64位目标中的裸机程序、u-boot、Linux kernel、filesystem和App应用程序。\narm-none-elf-gcc：是 Codesourcery 公司（目前已经被Mentor收购）基于GCC推出的的ARM交叉编译工具。可用于交叉编译ARM MCU（32位）芯片，如ARM7、ARM9、Cortex-M/R芯片程序。\narm-none-eabi-gcc：是 GNU 推出的的ARM交叉编译工具。可用于交叉编译ARM MCU（32位）芯片，如ARM7、ARM9、Cortex-M/R芯片程序。\n交叉编译工具链的命名规则为：arch [-vendor] [-os] [-(gnu)eabi]\narch – 体系架构，如ARM，MIPS（通过交叉编译工具生成的可执行文件或系统镜像的运行平台或环境） vendor – 工具链提供商 os – 目标操作系统（host主要操作平台，也就是编译时的系统） eabi – 嵌入式应用二进制接口（Embedded Application Binary Interface）根据对操作系统的支持与否， 根据对操作系统的支持与否，ARM GCC可分为支持和不支持操作系统\narm-none-eabi：这个是没有操作系统的，自然不可能支持那些跟操作系统关系密切的函数，比如fork(2)。他使用的是newlib这个专用于嵌入式系统的C库。 arm-none-linux-eabi：用于Linux的，使用Glibc 实例\n1、arm-none-eabi-gcc（ARM architecture，no vendor，not target an operating system，complies with the ARM EABI） 用于编译 ARM 架构的裸机系统（包括 ARM Linux 的 boot、kernel，不适用编译 Linux 应用 Application），一般适合 ARM7、Cortex-M 和 Cortex-R 内核的芯片使用，所以不支持那些跟操作系统关系密切的函数，比如fork(2)，他使用的是 newlib 这个专用于嵌入式系统的C库。\n2、arm-none-linux-gnueabi-gcc (ARM architecture, no vendor, creates binaries that run on the Linux operating system, and uses the GNU EABI) 主要用于基于ARM架构的Linux系统，可用于编译 ARM 架构的 u-boot、Linux内核、linux应用等。arm-none-linux-gnueabi基于GCC，使用Glibc库，经过 Codesourcery 公司优化过推出的编译器。arm-none-linux-gnueabi-xxx 交叉编译工具的浮点运算非常优秀。一般ARM9、ARM11、Cortex-A 内核，带有 Linux 操作系统的会用到。\n3、arm-eabi-gcc Android ARM 编译器。\n4、armcc ARM 公司推出的编译工具，功能和 arm-none-eabi 类似，可以编译裸机程序（u-boot、kernel），但是不能编译 Linux 应用程序。armcc一般和ARM开发工具一起，Keil MDK、ADS、RVDS和DS-5中的编译器都是armcc，所以 armcc 编译器都是收费的（爱国版除外，呵呵~~）。\n5、arm-none-uclinuxeabi-gcc 和 arm-none-symbianelf-gcc arm-none-uclinuxeabi 用于uCLinux，使用Glibc。 arm-none-symbianelf 用于symbian，没用过，不知道C库是什么 。\nABI 和 EABIABI\n二进制应用程序接口(Application Binary Interface (ABI) for the ARM Architecture)。在计算机中，应用二进制接口描述了应用程序（或者其他类型）和操作系统之间或其他应用程序的低级接口。 EABI：嵌入式ABI。嵌入式应用二进制接口指定了文件格式、数据类型、寄存器使用、堆积组织优化和在一个嵌入式软件中的参数的标准约定。开发者使用自己的汇编语言也可以使用 EABI 作为与兼容的编译器生成的汇编语言的接口。 两者主要区别是，ABI是计算机上的，EABI是嵌入式平台上（如ARM，MIPS等）。arm-linux-gnueabi-gcc 和 arm-linux-gnueabihf-gcc 两个交叉编译器分别适用于 armel 和 armhf 两个不同的架构，armel 和 armhf 这两种架构在对待浮点运算采取了不同的策略（有 fpu 的 arm 才能支持这两种浮点运算策略）。 其实这两个交叉编译器只不过是 gcc 的选项 -mfloat-abi 的默认值不同。gcc 的选项 -mfloat-abi 有三种值 soft、softfp、hard（其中后两者都要求 arm 里有 fpu 浮点运算单元，soft 与后两者是兼容的，但 softfp 和 hard 两种模式互不兼容）： soft： 不用fpu进行浮点计算，即使有fpu浮点运算单元也不用，而是使用软件模式。 softfp： armel架构（对应的编译器为 arm-linux-gnueabi-gcc ）采用的默认值，用fpu计算，但是传参数用普通寄存器传，这样中断的时候，只需要保存普通寄存器，中断负荷小，但是参数需要转换成浮点的再计算。 hard： armhf架构（对应的编译器 arm-linux-gnueabihf-gcc ）采用的默认值，用fpu计算，传参数也用fpu中的浮点寄存器传，省去了转换，性能最好，但是中断负荷高。 把以下测试使用的C文件内容保存成 mfloat.c： #include \u0026lt;stdio.h\u0026gt; int main(void) { double a,b,c; a = 23.543; b = 323.234; c = b/a; printf(“the 13/2 = %f\\n”, c); printf(“hello world !\\n”); return 0; } 1、使用 arm-linux-gnueabihf-gcc 编译，使用“-v”选项以获取更详细的信息：\narm-linux-gnueabihf-gcc -v mfloat.c COLLECT_GCC_OPTIONS=’-v’ ‘-march=armv7-a’ ‘-mfloat-abi=hard’ ‘-mfpu=vfpv3-d16′ ‘-mthumb’ -mfloat-abi=hard 可看出使用hard硬件浮点模式。 2、使用 arm-linux-gnueabi-gcc 编译：\narm-linux-gnueabi-gcc -v mfloat.c COLLECT_GCC_OPTIONS=’-v’ ‘-march=armv7-a’ ‘-mfloat-abi=softfp’ ‘-mfpu=vfpv3-d16′ ‘-mthumb’ -mfloat-abi=softfp 可看出使用softfp模式。\n参考资料\n交叉编译器 arm-linux-gnueabi 和 arm-linux-gnueabihf 的区别：http://www.cnblogs.com/xiaotlili/p/3306100.html arm-none-linux-gnueabi，arm-none-eabi 与arm-eabi 区别：http://blog.csdn.net/mantis_1984/article/details/21049273 What’s the difference between arm-linux- / arm-none-linux-gnueabi- / arm-fsl-linux-gnueabi- in LTIB?https://community.freescale.com/thread/313490 http://elinux.org/RPi_Kernel_Compilation https://github.com/raspberrypi/linux http://packages.ubuntu.com/precise/gcc-arm-linux-gnueabi http://mitchtech.net/raspberry-pi-kernel-compile/ ","date":"1 January, 1970","id":134,"permalink":"/posts/%E4%BA%A4%E5%8F%89%E7%BC%96%E8%AF%91%E5%B7%A5%E5%85%B7%E9%93%BE/","summary":"交叉编译工具链是一个由编译器、连接器和解释器组成的综合开发环境，交叉编译工具链主要由binutils、gcc和glibc三个部分组成。","tags":"编译器","title":"交叉编译工具链"},{"content":"关于雷达 AWR2243 ADC OVER CSI HSI AWR2243 的 CSI2 支持最高数据位速率（Data bit rate）为 600Mbps，DDR 时钟最高为 300Mhz。外部处理器 CSI2 支持的最高时钟至少要等于 AWR2243 配置的 CSI2 输出时钟。\nAWR2243 Data Sources Input Sources DFE(digital front-end) \u0026mdash; 设备实时数据 HIL(hardware in the loop) \u0026mdash; 数据回放 Interleaved and Non-Interleaved Modes 在 AWR12xx, AWR22xx, 和 XWR14xx 器件变体上，建议使用交织存储模式，因为它还有助于通过相应通道轻松映射和传输每个 RX 通道数据。\nAWR2243 的 ADC 存储器对于数据存储可以配置为交织模式或者是非交织模式。\n在交织模式下，ADC 数据是以采样点为间隔在不同接收通道下交织输出。对于非交织模式，ADC 数据按照接收通道把一个接收通道的完整的一个 chirp 数据输出后再输出另一个接收通道的数据。对于不同的模式，外部处理器在获取数据后，需要使用 EDMA 或者其他处理代码，正确重组数据，进行处理。在 mmwave_mcuplus_sdk_04_02_00_02 的例程里，DDMA 的例程使用了交织模式，TDMA 的例程使用了非交织模式。\n下面是不同模式数据数据输出的一个例子，Rx0、Rx1、Rx2、 Rx3 表示不同的接收通道。接收通道后面的数字表示采样点个数。N+1为每个 chirp 的采样点数。\n交织模式 Rx00 Rx10 Rx20 Rx30 Rx01 Rx11 Rx21 Rx31\u0026hellip;\u0026hellip;.Rx3N\n非交织模式 Rx00 Rx01 Rx02 Rx03\u0026hellip;..Rx0N Rx10 Rx11 Rx12 Rx13\u0026hellip;\u0026hellip;.Rx3N\nAWR2243 CSI2 接口输出的原始 ADC 数据格式 外部处理器的 CSI2 数据格式配置需要和AWR2243的ADC数据位数匹配。如果ADC数据位12位，外部处理器的CSI2的数据格式要配置为RAW12。如果ADC数据位14位，外部处理器的CSI2的数据格式要配置为RAW14。如果ADC数据为16位，外部处理器的CSI2数据格式要配置为RAW8。\nIt depends on the configuration set on the AWR2243 side. If you set 16bit ADC mode, RAW8 mode is used. If you set 12bit ADC mode RAW12 is used , in 14 bit ADC mode RAW14 is used.\n如果ADC数据为16位复数，对于一个采样点，AWR2243的CSI2接口上会先输出16位实部数据的低8位，然后输出实部数据的高8位，接下来输出虚部数据的低8位，最后是虚部的高8位。\nCSI是Camera Serial Interface的缩写，也就是摄像头串行接口，这个接口设计之初是用于摄像头传感器。在AWR2243上把一帧毫米波的数据模拟成宽度x高度的图像帧通过CSI2输出。一帧毫米波数据通过CSI2输出的帧的宽度和高度可以根据下面的公式进行计算。外部处理器可以根据下面的公式判断采集到的CSI2数据的数量是否和毫米波射频配置一致。\n分辨率配置 CSI2帧的宽度（单位：位） = 每个chirp的采样点数 x 接收通道数 x 2（复数采样）或者1（实时采样）x 每个采样点的位数\nCSI2帧的高度 = 每帧包含的chirp个数\n图像格式：RAW14，分辨率 3072 * 512\nWidth = 384 * 4(CH) * 2(复数采样) * 14 (每个采样点的位数 RAW14) = 3072 * 14 (bits）\nHeight = 512\nRAW Data Over D-PHY RAW10 格式具有 10 位像素值，但 CSI-2 标准指定最小数据宽度为 1 字节。由于无法传输部分像素数据，因此 CSI-2 根据所使用的像素格式具有各种像素打包标准。 10 位 RAW 像素数据的传输是通过将 4 个 10 位像素值打包到 5 个字节（5 * 8 位（1 字节）= 40 位）来完成的。这种情况下的最小数据包长度始终为 5 个字节。该标准以每像素位数值为基础，并查找必须是 1 字节（8 位）倍数的值。如果要平移的行的像素宽度不能被五整除，则多余的像素将用零填充。下表显示了 CSI-2 支持的格式数据包数据大小限制。\nData format 数据格式 Bits per Pixel (bpp) 每像素位数 (bpp) Pixels per packet (min) 每个数据包的像素（分钟） Packet length (byte) 数据包长度（字节） YUV420 8-bit (legacy) YUV420 8 位（传统） 12 2 3 YUV420 8-bit YUV420 8 位 12 2 2/4 YUV420 10-bit YUV420 10 位 15 4 5/10 YUV422 8-bit YUV422 8 位 16 2 4 YUV422 10-bit YUV422 10 位 20 2 5 RGB888 RGB888 24 1 3 RGB666 RGB666 18 4 9 RGB565 RGB565 16 1 2 RGB555 RGB555 15 1 2 RGB444 RGB444 12 1 2 RAW6 RAW6 6 4 3 RAW7 RAW7 7 8 7 RAW8 RAW8 8 1 1 RAW10 原始10 10 4 5 RAW12 RAW12 12 2 3 RAW14 RAW14 14 4 7 AWR2243 package 如上图，AWR2243 MIPI package，一个 Long Package DATA 包含了 1 整个 chirp 的数据。\nData Payload The data payload is constructed with the following three types of information:\nChirp profile information The actual chirp number ADC data corresponding to chirps of all four channels Interleaved fashion Chirp quality data (configurable) The payload is then split across the four physical data lanes and transmitted to the receiving D-PHY. The data packet packing format is shown in\nPacket Formats (AWR22xx/AWR12xx) The packet formats supported on AWR22xx/AWR12xx devices is shown below and is selected by issuing the data path configuration API.\nPacket 0 • On CSI2, the data can be RAW8/RAW12/RAW14 format and sent on any of the four configured virtual channels. • On LVDS, the data format can be 12/14/16 bit and are mapped onto the different lanes based on a format mapping selection done (using LVDS configuration API). 参考资料 AWR1xx and AWR22xx Data Path Programmer’s Guide (Rev. A) AWR2243 单芯片、76GHz 至 81GHz FMCW 收发器 数据表 (Rev. C) [AWR2243 CSI2接口详解](https://e2echina.ti.com/blogs_/b/the_process/posts/awr2243-csi2?keyMatch=MMWAVE%20PACKET%20FORMAT\u0026amp;_ticdt=MTY5MTQ3NTA1M3wwMTg5OTUxYTNkMzMwMDE3OTY5ZGVlMDYxMmIzMDUwNmYwMDE2MDY3MDBjOTl8W29iamVjdCBPYmplY3Rd) AWR2243 datasheet MMWAVE-DFP-2G 02.02.03.01 AWR2243: AWR2243 CSI2 pixel format problem - Sensors forum - Sensors - TI E2E support forums AWR1243: data packet packing format for RAW8 mode (8-bit) - Sensors forum - Sensors - TI E2E support forums AWR1243: Clarifications on modes and frames - Sensors forum - Sensors - TI E2E support forums AWR2243: Relation between CSI lane position and CSI pin - Sensors forum - Sensors - TI E2E support forums IWR1443: output width and height of CSI frame - Sensors forum - Sensors - TI E2E support forums https://developer.ridgerun.com/wiki/index.php/Camera_Sensor_Basics https://www.graniteriverlabs.com.cn/technical-blog/mipi-csi-2-d-phy/ ","date":"1 January, 1970","id":135,"permalink":"/posts/awr2243_adc/","summary":"AWR2243 的 CSI2 支持最高数据位速率（Data bit rate）为 600Mbps，DDR 时钟最高为 300Mhz。外部处理器 CSI2 支持的最高时钟至少要等于 AWR2243 配置的 CSI2 输出时钟。","tags":"awr2243 MIPI ADC MMWAVE radar","title":"关于雷达 AWR2243 ADC OVER CSI HSI"},{"content":"How to handle GPIO interrupt-like handling in Linux userspace 文件节点 /sys/class/gpio/gpio666# ls active_low device direction edge subsystem uevent value 只用对应 GPIO 有 irq 功能时才会有 edge 文件。\n/sys/class/gpio/export：是一个只写文件，用于导出需要使用的 GPIO 引脚 /sys/class/gpio/gpiox/: 是一个文件夹，在引脚导出后自动在 / sys/class/gpio / 目录下生成的 /sys/class/gpio/gpiox/active_low：是一个文件，用来控制电平的极性（写 1 是高电平还是写 0 是高电平），默认写 1 是高电平，这个文件不用去管它 /sys/class/gpio/gpiox/direction：是一个文件，用来控制 GPIO 是输入还是输出，往direction写 out 就是输出引脚，往direction写 in 就是输入引脚 /sys/class/gpio/gpiox/edge：是一个文件，在输入模式下，写 edge 文件，配置 gpio 为外部中断引脚 非中断引脚： none 上升沿触发： rising 下降沿触发： falling 边沿触发： both /sys/class/gpio/gpiox/value: 是一个文件，在输出模式下，写该文件表示 gpio 输出；在输入模式下读该文件表示输入 sysfs.txt\n\u0026#34;value\u0026#34; ... reads as either 0 (low) or 1 (high). If the GPIO is configured as an output, this value may be written; any nonzero value is treated as high. If the pin can be configured as interrupt-generating interrupt and if it has been configured to generate interrupts (see the description of \u0026#34;edge\u0026#34;), you can poll(2) on that file and poll(2) will return whenever the interrupt was triggered. If you use poll(2), set the events POLLPRI and POLLERR. If you use select(2), set the file descriptor in exceptfds. After poll(2) returns, either lseek(2) to the beginning of the sysfs file and read the new value or close the file and re-open it to read the value. \u0026#34;edge\u0026#34; ... reads as either \u0026#34;none\u0026#34;, \u0026#34;rising\u0026#34;, \u0026#34;falling\u0026#34;, or \u0026#34;both\u0026#34;. Write these strings to select the signal edge(s) that will make poll(2) on the \u0026#34;value\u0026#34; file return. This file exists only if the pin can be configured as an interrupt generating input pin. demo 一坨屎样代码\n#define GPIO_PIN_NUMBER 666 void* gpio_irq(void *arg) { int fd; fd_set readFds; char value; // 如果没有GPIO 导出文件，则打开 GPIO 导出文件 int exportFd = -1; struct stat dir_stat; char gpioDir[64]; sprintf(gpioDir, \u0026#34;/sys/class/gpio/gpio%d\u0026#34;, GPIO_PIN_NUMBER); if (stat(gpioDir, \u0026amp;dir_stat) != 0) { exportFd = open(\u0026#34;/sys/class/gpio/export\u0026#34;, O_WRONLY); if (exportFd == -1) { perror(\u0026#34;Error opening export file\u0026#34;); return EXIT_FAILURE; } // 将 GPIO 口编号写入到导出文件中 if (write(exportFd, \u0026#34;666\u0026#34;, 3) != 3) { perror(\u0026#34;Error writing to export file\u0026#34;); close(exportFd); return EXIT_FAILURE; } close(exportFd); } // 等待一小段时间，以确保 GPIO 口创建完成 usleep(10000); // 打开 GPIO 方向文件 char gpioDirectionPath[64]; sprintf(gpioDirectionPath, \u0026#34;/sys/class/gpio/gpio%d/direction\u0026#34;, GPIO_PIN_NUMBER); fd = open(gpioDirectionPath, O_WRONLY); if (fd \u0026lt; 0) { perror(\u0026#34;Error opening direction file\u0026#34;); return NULL; } // 将 GPIO 口方向设置为输入 if (write(fd, \u0026#34;in\u0026#34;, 2) != 2) { perror(\u0026#34;Error setting GPIO direction\u0026#34;); close(fd); return NULL; } close(fd); // 打开 GPIO edge 文件 char gpioEdgePath[64]; sprintf(gpioEdgePath, \u0026#34;/sys/class/gpio/gpio%d/edge\u0026#34;, GPIO_PIN_NUMBER); fd = open(gpioEdgePath, O_WRONLY); if (fd \u0026lt; 0) { perror(\u0026#34;Error opening edge file\u0026#34;); return NULL; } // 将 GPIO edge both if (write(fd, \u0026#34;rising\u0026#34;, 6) != 6) { perror(\u0026#34;Error setting GPIO edge\u0026#34;); close(fd); return NULL; } close(fd); // 打开 GPIO 值文件 char gpioValuePath[64]; sprintf(gpioValuePath, \u0026#34;/sys/class/gpio/gpio%d/value\u0026#34;, GPIO_PIN_NUMBER); int value_fd = open(gpioValuePath, O_RDONLY); if (value_fd \u0026lt; 0) { perror(\u0026#34;Error opening value file\u0026#34;); return NULL; } // 创建文件描述符集合 FD_ZERO(\u0026amp;readFds); FD_SET(value_fd, \u0026amp;readFds); // 监听 GPIO 的下降沿触发事件 while (true) { // 重新设置文件描述符集合 fd_set tempFds = readFds; // 监听文件描述符变化 int selectResult = select(value_fd + 1, NULL, NULL, \u0026amp;tempFds, NULL); if (selectResult \u0026lt; 0) { perror(\u0026#34;Error in select\u0026#34;); break; } else if (selectResult \u0026gt; 0) { // 检查 GPIO 的文件描述符是否可读 if (FD_ISSET(value_fd, \u0026amp;tempFds)) { DBG_PRINT(\u0026#34;====================\\n\u0026#34;); // 读取 GPIO 的值 lseek(value_fd, 0, SEEK_SET); read(value_fd, \u0026amp;value, 1); DBG_PRINT(\u0026#34;read value: %c\\n\u0026#34;, value); if (value == \u0026#39;0\u0026#39;) { DBG_PRINT(\u0026#34;+++++++++++++++ Falling edge detected! ++++++++++++++\\n\u0026#34;); // 在这里执行 GPIO 下降沿触发事件的处理 } else { DBG_PRINT(\u0026#34;--------------------Rising edge detected!--------------\\n\u0026#34;); // 在这里执行 GPIO 上升沿触发事件的处理 } } // usleep(1000*20); } } close(value_fd); // 关闭 GPIO 导出文件 int unexportFd = open(\u0026#34;/sys/class/gpio/unexport\u0026#34;, O_WRONLY); if (unexportFd \u0026lt; 0) { perror(\u0026#34;Error opening unexport file\u0026#34;); return NULL; } // 将 GPIO 口编号写入到取消导出文件中 if (write(unexportFd, \u0026#34;124\u0026#34;, 3) != 3) { perror(\u0026#34;Error writing to unexport file\u0026#34;); } close(unexportFd); return NULL; } edge: \u0026ldquo;none\u0026rdquo;, \u0026ldquo;rising\u0026rdquo;, \u0026ldquo;falling\u0026rdquo;，\u0026ldquo;both\u0026rdquo; 虽然申请的是 rising edge 中断，但是 select 返回中还是会响应上升沿，下降沿，请根据 read 结果做进一步判断 注意代码中 tempFds 的参数位置： int selectResult = select(value_fd + 1, NULL, NULL, \u0026amp;tempFds, NULL); ","date":"1 January, 1970","id":136,"permalink":"/posts/how_to_handle_gpio_interrupt_like_handling_in_linux_userspace/","summary":"只用对应 GPIO 有 irq 功能时才会有 edge 文件。","tags":"linux interrupt gpio userspace select poll","title":"如何在 Linux 用户空间中进行类似 GPIO 中断的处理"},{"content":"\n","date":"1 January, 1970","id":137,"permalink":"/posts/camera_%E5%9B%BE%E5%83%8F%E6%95%B0%E6%8D%AE%E6%A0%BC%E5%BC%8F_%E4%BB%8Ecmos%E5%88%B0mipi/","summary":"","tags":"cmos mipi raw bayer","title":"摄像头图像数据格式从cmos到mipi"},{"content":"","date":"1 January, 0001","id":138,"permalink":"/posts/c++-chrono/","summary":"","tags":"","title":""}]